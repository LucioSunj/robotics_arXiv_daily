{"Manipulation": {"2504.02792": "|**2025-04-03**|**Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets**|Abhishek Gupta Team|[2504.02792](http://arxiv.org/abs/2504.02792)|null|\n", "2504.02477": "|**2025-04-03**|**Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision**|Shibiao Xu Team|[2504.02477](http://arxiv.org/abs/2504.02477)|null|\n", "2504.02069": "|**2025-04-02**|**RoboAct-CLIP: Video-Driven Pre-training of Atomic Action Understanding for Robotics**|Qiang Nie Team|[2504.02069](http://arxiv.org/abs/2504.02069)|null|\n", "2504.01959": "|**2025-04-02**|**Slot-Level Robotic Placement via Visual Imitation from Single Human Video**|Arsalan Mousavian Team|[2504.01959](http://arxiv.org/abs/2504.01959)|null|\n", "2504.01766": "|**2025-04-02**|**Learning with Imperfect Models: When Multi-step Prediction Mitigates Compounding Error**|Nikolai Matni Team|[2504.01766](http://arxiv.org/abs/2504.01766)|null|\n", "2504.01708": "|**2025-04-02**|**TransforMerger: Transformer-based Voice-Gesture Fusion for Robust Human-Robot Communication**|Karla Stepanova Team|[2504.01708](http://arxiv.org/abs/2504.01708)|null|\n", "2504.01554": "|**2025-04-02**|**8-DoFs Cable Driven Parallel Robots for Bimanual Teleportation**|Josie Hughes Team|[2504.01554](http://arxiv.org/abs/2504.01554)|null|\n", "2504.01301": "|**2025-04-02**|**Bi-LAT: Bilateral Control-Based Imitation Learning via Natural Language and Action Chunking with Transformers**|Yuki Uranishi Team|[2504.01301](http://arxiv.org/abs/2504.01301)|null|\n", "2504.01260": "|**2025-04-02**|**The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction**|Matthew K. X. J Pan Team|[2504.01260](http://arxiv.org/abs/2504.01260)|null|\n", "2504.00707": "|**2025-04-01**|**Energy Weighted Learning Progress Guided Interleaved Multi-Task Learning**|Erhan Oztop Team|[2504.00707](http://arxiv.org/abs/2504.00707)|null|\n", "2504.00614": "|**2025-04-01**|**Learning Bipedal Locomotion on Gear-Driven Humanoid Robot Using Foot-Mounted IMUs**|Masaya Kinoshita Team|[2504.00614](http://arxiv.org/abs/2504.00614)|null|\n", "2504.00420": "|**2025-04-01**|**Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation**|Dong Wang Team|[2504.00420](http://arxiv.org/abs/2504.00420)|null|\n", "2504.00234": "|**2025-03-31**|**CBIL: Collective Behavior Imitation Learning for Fish from Real Videos**|Taku Komura Team|[2504.00234](http://arxiv.org/abs/2504.00234)|null|\n", "2503.24361": "|**2025-04-02**|**Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation**|Yuke Zhu Team|[2503.24361](http://arxiv.org/abs/2503.24361)|null|\n", "2503.24278": "|**2025-04-02**|**AutoEval: Autonomous Evaluation of Generalist Robot Manipulation Policies in the Real World**|Sergey Levine Team|[2503.24278](http://arxiv.org/abs/2503.24278)|**[link](https://github.com/zhouzypaul/auto_eval)**|\n", "2503.24070": "|**2025-03-31**|**HACTS: a Human-As-Copilot Teleoperation System for Robot Learning**|Jian Tang Team|[2503.24070](http://arxiv.org/abs/2503.24070)|null|\n", "2503.24009": "|**2025-03-31**|**Learning 3D-Gaussian Simulators from RGB Videos**|Georg Martius Team|[2503.24009](http://arxiv.org/abs/2503.24009)|null|\n", "2503.23877": "|**2025-03-31**|**ZeroMimic: Distilling Robotic Manipulation Skills from Web Videos**|Dinesh Jayaraman Team|[2503.23877](http://arxiv.org/abs/2503.23877)|**[link](https://github.com/everloom-129/rekep)**|\n", "2503.23835": "|**2025-03-31**|**Disambiguate Gripper State in Grasp-Based Tasks: Pseudo-Tactile as Feedback Enables Pure Simulation Learning**|Yue Wang Team|[2503.23835](http://arxiv.org/abs/2503.23835)|null|\n", "2503.23571": "|**2025-03-30**|**Can Visuo-motor Policies Benefit from Random Exploration Data? A Case Study on Stacking**|Florian T. Pokorny Team|[2503.23571](http://arxiv.org/abs/2503.23571)|null|\n", "2504.03515": "|**2025-04-04**|**Dexterous Manipulation through Imitation Learning: A Survey**|Hong Zhang Team|[2504.03515](http://arxiv.org/abs/2504.03515)|null|\n", "2504.03129": "|**2025-04-04**|**GraphSeg: Segmented 3D Representations via Graph Edge Addition and Contraction**|Weiming Zhi Team|[2504.03129](http://arxiv.org/abs/2504.03129)|null|\n", "2504.05287": "|**2025-04-07**|**RobustDexGrasp: Robust Dexterous Grasping of General Objects from Single-view Perception**|Jie Song Team|[2504.05287](http://arxiv.org/abs/2504.05287)|null|\n", "2504.05225": "|**2025-04-07**|**Vision-Language Model Predictive Control for Manipulation Planning and Trajectory Generation**|Wei Zhang Team|[2504.05225](http://arxiv.org/abs/2504.05225)|**[link](https://github.com/ppjmchen/vlmpc)**|\n", "2504.04991": "|**2025-04-07**|**Wavelet Policy: Imitation Policy Learning in Frequency Domain with Wavelet Transforms**|Hongrui Zhu Team|[2504.04991](http://arxiv.org/abs/2504.04991)|null|\n", "2504.04795": "|**2025-04-07**|**Embodied Perception for Test-time Grasping Detection Adaptation with Knowledge Infusion**|Fengyu Zhou Team|[2504.04795](http://arxiv.org/abs/2504.04795)|null|\n", "2504.04612": "|**2025-04-06**|**Tool-as-Interface: Learning Robot Policies from Human Tool Usage through Imitation Learning**|Katherine Driggs-Campbell Team|[2504.04612](http://arxiv.org/abs/2504.04612)|null|\n", "2504.04603": "|**2025-04-06**|**Diffusion-Based Approximate MPC: Fast and Consistent Imitation of Multi-Modal Action Distributions**|Katherine J. Kuchenbecker Team|[2504.04603](http://arxiv.org/abs/2504.04603)|null|\n", "2504.04573": "|**2025-04-06**|**DexTOG: Learning Task-Oriented Dexterous Grasp with Language**|Cewu Lu Team|[2504.04573](http://arxiv.org/abs/2504.04573)|null|\n", "2504.04516": "|**2025-04-06**|**DexSinGrasp: Learning a Unified Policy for Dexterous Object Singulation and Grasping in Cluttered Environments**|Lin Shao Team|[2504.04516](http://arxiv.org/abs/2504.04516)|null|\n", "2504.04395": "|**2025-04-06**|**Human-Level Competitive Pok\u00e9mon via Scalable Offline Reinforcement Learning with Transformers**|Yuke Zhu Team|[2504.04395](http://arxiv.org/abs/2504.04395)|null|\n", "2504.04259": "|**2025-04-05**|**ORCA: An Open-Source, Reliable, Cost-Effective, Anthropomorphic Robotic Hand for Uninterrupted Dexterous Task Learning**|Robert K. Katzschmann Team|[2504.04259](http://arxiv.org/abs/2504.04259)|null|\n", "2504.04170": "|**2025-04-09**|**Digital Gene: Learning about the Physical World through Analytic Concepts**|Cewu Lu Team|[2504.04170](http://arxiv.org/abs/2504.04170)|null|\n", "2504.06156": "|**2025-04-08**|**ViTaMIn: Learning Contact-Rich Tasks Through Robot-Free Visuo-Tactile Manipulation Interface**|Rui Chen Team|[2504.06156](http://arxiv.org/abs/2504.06156)|null|\n", "2504.06084": "|**2025-04-08**|**MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From Egocentric Videos**|Marc Pollefeys Team|[2504.06084](http://arxiv.org/abs/2504.06084)|null|\n", "2504.05987": "|**2025-04-08**|**Learning-enhanced electronic skin for tactile sensing on deformable surface based on electrical impedance tomography**|Yunjie Yang Team|[2504.05987](http://arxiv.org/abs/2504.05987)|null|\n", "2504.05628": "|**2025-04-08**|**Stratified Expert Cloning with Adaptive Selection for User Retention in Large-Scale Recommender Systems**|Yongqi Liu Team|[2504.05628](http://arxiv.org/abs/2504.05628)|null|\n", "2504.05585": "|**2025-04-08**|**TW-CRL: Time-Weighted Contrastive Reward Learning for Efficient Inverse Reinforcement Learning**|Stephen Xia Team|[2504.05585](http://arxiv.org/abs/2504.05585)|null|\n", "2504.05488": "|**2025-04-07**|**SPARK-Remote: A Cost-Effective System for Remote Bimanual Robot Teleoperation**|Karthik Desingh Team|[2504.05488](http://arxiv.org/abs/2504.05488)|null|\n", "2504.07091": "|**2025-04-09**|**AssistanceZero: Scalably Solving Assistance Games**|Anca Dragan Team|[2504.07091](http://arxiv.org/abs/2504.07091)|**[link](https://github.com/cassidylaidlaw/minecraft-building-assistance-game)**|\n", "2504.06961": "|**2025-04-09**|**Two by Two: Learning Multi-Task Pairwise Objects Assembly for Generalizable Robot Manipulation**|Huazhe Xu Team|[2504.06961](http://arxiv.org/abs/2504.06961)|null|\n", "2504.06819": "|**2025-04-09**|**Developing Modular Grasping and Manipulation Pipeline Infrastructure to Streamline Performance Benchmarking**|Holly Yanco Team|[2504.06819](http://arxiv.org/abs/2504.06819)|null|\n", "2504.06735": "|**2025-04-09**|**Interactive Expressive Motion Generation Using Dynamic Movement Primitives**|Kai O. Arras Team|[2504.06735](http://arxiv.org/abs/2504.06735)|null|\n", "2504.06596": "|**2025-04-09**|**Overcoming Dynamic Environments: A Hybrid Approach to Motion Planning for Manipulators**|Gavin Paul Team|[2504.06596](http://arxiv.org/abs/2504.06596)|null|\n", "2504.06584": "|**2025-04-09**|**CAFE-AD: Cross-Scenario Adaptive Feature Enhancement for Trajectory Planning in Autonomous Driving**|Yanyong Zhang Team|[2504.06584](http://arxiv.org/abs/2504.06584)|**[link](https://github.com/alniyatrui/cafe-ad)**|\n", "2504.06538": "|**2025-04-09**|**OPAL: Encoding Causal Understanding of Physical Systems for Robot Learning**|Tyler Fenstermaker Team|[2504.06538](http://arxiv.org/abs/2504.06538)|null|\n", "2504.07939": "|**2025-04-10**|**Echo: An Open-Source, Low-Cost Teleoperation System with Force Feedback for Dataset Collection in Robot Learning**|Dzmitry Tsetserukou Team|[2504.07939](http://arxiv.org/abs/2504.07939)|null|\n", "2504.07708": "|**2025-04-10**|**TOCALib: Optimal control library with interpolation for bimanual manipulation and obstacles avoidance**|Aleksandr Panov Team|[2504.07708](http://arxiv.org/abs/2504.07708)|null|\n", "2504.07375": "|**2025-04-10**|**Novel Diffusion Models for Multimodal 3D Hand Trajectory Prediction**|Hesheng Wang Team|[2504.07375](http://arxiv.org/abs/2504.07375)|**[link](https://github.com/irmvlab/mmtwin)**|\n", "2504.07309": "|**2025-04-09**|**Adaptive Vision-Guided Robotic Arm Control for Precision Pruning in Dynamic Orchard Environments**|Manoj Karkee Team|[2504.07309](http://arxiv.org/abs/2504.07309)|null|\n", "2504.08706": "|**2025-04-11**|**BiFlex: A Passive Bimodal Stiffness Flexible Wrist for Manipulation in Unstructured Environments**|Roberto Mart\u00edn-Mart\u00edn Team|[2504.08706](http://arxiv.org/abs/2504.08706)|null|\n", "2504.08438": "|**2025-04-11**|**Diffusion Models for Robotic Manipulation: A Survey**|Rania Rayyes Team|[2504.08438](http://arxiv.org/abs/2504.08438)|null|\n", "2504.10334": "|**2025-04-14**|**Flying Hand: End-Effector-Centric Framework for Versatile Aerial Manipulation Teleoperation and Policy Learning**|Guanya Shi Team|[2504.10334](http://arxiv.org/abs/2504.10334)|null|\n", "2504.10280": "|**2025-04-14**|**Look-to-Touch: A Vision-Enhanced Proximity and Tactile Sensor for Distance and Geometry Perception in Robotic Manipulation**|Guoying Gu Team|[2504.10280](http://arxiv.org/abs/2504.10280)|null|\n", "2504.10041": "|**2025-04-14**|**Prior Does Matter: Visual Navigation via Denoising Diffusion Bridge Models**|Hui Cheng Team|[2504.10041](http://arxiv.org/abs/2504.10041)|**[link](https://github.com/hren20/naivibridger)**|\n", "2504.09927": "|**2025-04-14**|**Efficient Task-specific Conditional Diffusion Policies: Shortcut Model Acceleration and SO(3) Optimization**|Wei Sui Team|[2504.09927](http://arxiv.org/abs/2504.09927)|null|\n", "2504.09188": "|**2025-04-12**|**Compliant Explicit Reference Governor for Contact Friendly Robotic Manipulators**|Marco M. Nicotra Team|[2504.09188](http://arxiv.org/abs/2504.09188)|null|\n", "2504.11247": "|**2025-04-15**|**Next-Future: Sample-Efficient Policy Learning for Robotic-Arm Tasks**|Suryansh Kumar Team|[2504.11247](http://arxiv.org/abs/2504.11247)|null|\n", "2504.11230": "|**2025-04-17**|**CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image**|Yi Zhu Team|[2504.11230](http://arxiv.org/abs/2504.11230)|null|\n", "2504.10783": "|**2025-04-15**|**Superfast Configuration-Space Convex Set Computation on GPUs for Online Motion Planning**|Daniela Rus Team|[2504.10783](http://arxiv.org/abs/2504.10783)|**[link](https://github.com/wernerpe/csdecomp)**|\n", "2504.10647": "|**2025-04-14**|**Improving In-Context Learning with Reasoning Distillation**|Xiang Gao Team|[2504.10647](http://arxiv.org/abs/2504.10647)|null|\n", "2504.12299": "|**2025-04-16**|**Adapting a World Model for Trajectory Following in a 3D Game**|Raluca Georgescu Team|[2504.12299](http://arxiv.org/abs/2504.12299)|null|\n", "2504.11827": "|**2025-04-16**|**Towards Forceful Robotic Foundation Models: a Literature Survey**|Nikolaus Correll Team|[2504.11827](http://arxiv.org/abs/2504.11827)|null|\n", "2504.11493": "|**2025-04-14**|**Toward Aligning Human and Robot Actions via Multi-Modal Demonstration Learning**|Fei Liu Team|[2504.11493](http://arxiv.org/abs/2504.11493)|**[link](https://github.com/utkauraslab/aligning_hr_actions)**|\n", "2504.13059": "|**2025-04-17**|**RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins**|Ping Luo Team|[2504.13059](http://arxiv.org/abs/2504.13059)|null|\n", "2504.13056": "|**2025-04-17**|**Adaptive Task Space Non-Singular Terminal Super-Twisting Sliding Mode Control of a 7-DOF Robotic Manipulator**|E. Witrant Team|[2504.13056](http://arxiv.org/abs/2504.13056)|null|\n", "2504.12967": "|**2025-04-17**|**Krysalis Hand: A Lightweight, High-Payload, 18-DoF Anthropomorphic End-Effector for Robotic Learning and Dexterous Manipulation**|Iman Soltani Team|[2504.12967](http://arxiv.org/abs/2504.12967)|null|\n", "2504.12799": "|**2025-04-17**|**TSGS: Improving Gaussian Splatting for Transparent Surface Reconstruction via Normal and De-lighting Priors**|Yi Yang Team|[2504.12799](http://arxiv.org/abs/2504.12799)|null|\n", "2504.12755": "|**2025-04-17**|**Trajectory Adaptation using Large Language Models**|Ravi Prakash Team|[2504.12755](http://arxiv.org/abs/2504.12755)|null|\n", "2504.12702": "|**2025-04-17**|**Embodied Neuromorphic Control Applied on a 7-DOF Robotic Manipulator**|Lei Wang Team|[2504.12702](http://arxiv.org/abs/2504.12702)|**[link](https://bitbucket.org/icubdataset/inverse-dynamic)**|\n", "2504.12636": "|**2025-04-21**|**A0: An Affordance-Aware Hierarchical Model for General Robotic Manipulation**|Xiaodan Liang Team|[2504.12636](http://arxiv.org/abs/2504.12636)|null|\n", "2504.12609": "|**2025-04-17**|**Crossing the Human-Robot Embodiment Gap with Sim-to-Real RL using One Human Demonstration**|Jeannette Bohg Team|[2504.12609](http://arxiv.org/abs/2504.12609)|null|\n", "2504.13807": "|**2025-04-18**|**DiffOG: Differentiable Policy Trajectory Optimization with Generalizability**|Yu She Team|[2504.13807](http://arxiv.org/abs/2504.13807)|null|\n", "2504.13803": "|**2025-04-18**|**Imitation Learning with Precisely Labeled Human Demonstrations**|Yilong Song Team|[2504.13803](http://arxiv.org/abs/2504.13803)|null|\n", "2504.13713": "|**2025-04-21**|**SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM**|Javier Civera Team|[2504.13713](http://arxiv.org/abs/2504.13713)|**[link](https://github.com/samuel-cerezo/SLAM-Render)**|\n", "2504.13711": "|**2025-04-18**|**Self-Mixing Laser Interferometry: In Search of an Ambient Noise-Resilient Alternative to Acoustic Sensing**|Francis wyffels Team|[2504.13711](http://arxiv.org/abs/2504.13711)|null|\n", "2504.13618": "|**2025-04-18**|**On the Importance of Tactile Sensing for Imitation Learning: A Case Study on Robotic Match Lighting**|Jan Peters Team|[2504.13618](http://arxiv.org/abs/2504.13618)|null|\n", "2504.13413": "|**2025-04-18**|**A Model-Based Approach to Imitation Learning through Multi-Step Predictions**|Na Li Team|[2504.13413](http://arxiv.org/abs/2504.13413)|null|\n", "2504.15229": "|**2025-04-21**|**Immersive Teleoperation Framework for Locomanipulation Tasks**|Dimitrios Kanoulas Team|[2504.15229](http://arxiv.org/abs/2504.15229)|null|\n", "2504.15226": "|**2025-04-21**|**A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing**|Kelly Cohen Team|[2504.15226](http://arxiv.org/abs/2504.15226)|null|\n", "2504.15129": "|**2025-04-21**|**A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment**|Huaping Liu Team|[2504.15129](http://arxiv.org/abs/2504.15129)|null|\n", "2504.14857": "|**2025-04-21**|**SuFIA-BC: Generating High Quality Demonstration Data for Visuomotor Policy Learning in Surgical Subtasks**|Animesh Garg Team|[2504.14857](http://arxiv.org/abs/2504.14857)|null|\n", "2504.14709": "|**2025-04-20**|**Exposing the Copycat Problem of Imitation-based Planner: A Novel Closed-Loop Simulator, Causal Benchmark and Joint IL-RL Baseline**|Hongsheng Li Team|[2504.14709](http://arxiv.org/abs/2504.14709)|null|\n", "2504.14634": "|**2025-04-24**|**Latent Representations for Visual Proprioception in Inexpensive Robots**|Ladislau B\u00f6l\u00f6ni Team|[2504.14634](http://arxiv.org/abs/2504.14634)|null|\n", "2504.16054": "|**2025-04-22**|**$\u03c0_{0.5}$: a Vision-Language-Action Model with Open-World Generalization**|Ury Zhilinsky Team|[2504.16054](http://arxiv.org/abs/2504.16054)|null|\n", "2504.15561": "|**2025-04-22**|**SPECI: Skill Prompts based Hierarchical Continual Imitation Learning for Robot Manipulation**|Xiangli Nie Team|[2504.15561](http://arxiv.org/abs/2504.15561)|null|\n", "2504.15535": "|**2025-04-22**|**VibeCheck: Using Active Acoustic Tactile Sensing for Contact-Rich Manipulation**|Matei Ciocarlie Team|[2504.15535](http://arxiv.org/abs/2504.15535)|null|\n", "2504.15517": "|**2025-04-22**|**Few-Shot Vision-Language Action-Incremental Policy Learning**|Weili Guan Team|[2504.15517](http://arxiv.org/abs/2504.15517)|null|\n", "2504.15472": "|**2025-04-21**|**LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning**|Boyuan Chen Team|[2504.15472](http://arxiv.org/abs/2504.15472)|null|\n", "2504.15327": "|**2025-04-23**|**Advancing Embodied Intelligence in Robotic-Assisted Endovascular Procedures: A Systematic Review of AI Solutions**|Peng Qi Team|[2504.15327](http://arxiv.org/abs/2504.15327)|null|\n", "2504.16925": "|**2025-04-23**|**Latent Diffusion Planning for Imitation Learning**|Chelsea Finn Team|[2504.16925](http://arxiv.org/abs/2504.16925)|null|\n", "2504.16738": "|**2025-04-23**|**MOSAIC: A Skill-Centric Algorithmic Framework for Long-Horizon Manipulation Planning**|Maxim Likhachev Team|[2504.16738](http://arxiv.org/abs/2504.16738)|null|\n", "2504.16464": "|**2025-04-23**|**ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance**|Shanghang Zhang Team|[2504.16464](http://arxiv.org/abs/2504.16464)|null|\n", "2504.16224": "|**2025-04-22**|**Mass-Adaptive Admittance Control for Robotic Manipulators**|Logan E. Beaver Team|[2504.16224](http://arxiv.org/abs/2504.16224)|null|\n", "2504.17784": "|**2025-04-24**|**Gripper Keypose and Object Pointflow as Interfaces for Bimanual Robotic Manipulation**|Jiangmiao Pang Team|[2504.17784](http://arxiv.org/abs/2504.17784)|null|\n", "2504.17771": "|**2025-04-24**|**Integrating Learning-Based Manipulation and Physics-Based Locomotion for Whole-Body Badminton Robot Control**|Dong Xuan Team|[2504.17771](http://arxiv.org/abs/2504.17771)|null|\n", "2504.17216": "|**2025-04-24**|**Robotic Grinding Skills Learning Based on Geodesic Length Dynamic Motion Primitives**|Han Ding Team|[2504.17216](http://arxiv.org/abs/2504.17216)|null|\n", "2504.17080": "|**2025-04-23**|**Geometric Formulation of Unified Force-Impedance Control on SE(3) for Robotic Manipulators**|Roberto Horowitz Team|[2504.17080](http://arxiv.org/abs/2504.17080)|null|\n", "2504.17006": "|**2025-04-23**|**A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs**|Younes Zerouali Team|[2504.17006](http://arxiv.org/abs/2504.17006)|null|\n", "2504.18538": "|**2025-04-25**|**Generalization Capability for Imitation Learning**|Yixiao Wang Team|[2504.18538](http://arxiv.org/abs/2504.18538)|null|\n", "2504.18481": "|**2025-04-25**|**Instrumentation for Better Demonstrations: A Case Study**|Francis wyffels Team|[2504.18481](http://arxiv.org/abs/2504.18481)|null|\n", "2504.18471": "|**2025-04-25**|**Action Flow Matching for Continual Robot Learning**|Lantao Liu Team|[2504.18471](http://arxiv.org/abs/2504.18471)|null|\n", "2504.18284": "|**2025-04-25**|**Design and Evaluation of a UGV-Based Robotic Platform for Precision Soil Moisture Remote Sensing**|George Nikolakopoulos Team|[2504.18284](http://arxiv.org/abs/2504.18284)|null|\n", "2504.18200": "|**2025-04-28**|**Implementation Analysis of Collaborative Robot Digital Twins in Physics Engines**|Hans D. Schotten Team|[2504.18200](http://arxiv.org/abs/2504.18200)|null|\n", "2504.18160": "|**2025-04-25**|**Offline Learning of Controllable Diverse Behaviors**|Ludovic Denoyer Team|[2504.18160](http://arxiv.org/abs/2504.18160)|null|\n", "2504.17959": "|**2025-04-24**|**CIVIL: Causal and Intuitive Visual Imitation Learning**|Dylan P. Losey Team|[2504.17959](http://arxiv.org/abs/2504.17959)|null|\n", "2504.17950": "|**2025-04-24**|**Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning**|Prithviraj Ammanabrolu Team|[2504.17950](http://arxiv.org/abs/2504.17950)|null|\n", "2504.17924": "|**2025-04-24**|**Learning Attentive Neural Processes for Planning with Pushing Actions**|Nicholas Roy Team|[2504.17924](http://arxiv.org/abs/2504.17924)|null|\n", "2504.17838": "|**2025-04-24**|**CaRL: Learning Scalable Planning Policies with Simple Rewards**|Andreas Geiger Team|[2504.17838](http://arxiv.org/abs/2504.17838)|null|\n", "2504.17817": "|**2025-04-23**|**Learning Underwater Active Perception in Simulation**|Donald G. Dansereau Team|[2504.17817](http://arxiv.org/abs/2504.17817)|null|\n", "2504.19736": "|**2025-04-28**|**UTTG_ A Universal Teleoperation Approach via Online Trajectory Generation**|Hesheng Wang Team|[2504.19736](http://arxiv.org/abs/2504.19736)|null|\n", "2504.19683": "|**2025-04-28**|**GPA-RAM: Grasp-Pretraining Augmented Robotic Attention Mamba for Spatial Task Learning**|Mengyuan Liu Team|[2504.19683](http://arxiv.org/abs/2504.19683)|null|\n", "2504.19341": "|**2025-04-27**|**PolyTouch: A Robust Multi-Modal Tactile Sensor for Contact-rich Manipulation Using Tactile-Diffusion Policies**|Edward Adelson Team|[2504.19341](http://arxiv.org/abs/2504.19341)|null|\n", "2504.19322": "|**2025-04-29**|**Learned Perceptive Forward Dynamics Model for Safe and Platform-aware Robotic Navigation**|Marco Hutter Team|[2504.19322](http://arxiv.org/abs/2504.19322)|**[link](https://github.com/leggedrobotics/fdm)**|\n", "2504.19077": "|**2025-04-27**|**Learning to Drive from a World Model**|Yassine Yousfi Team|[2504.19077](http://arxiv.org/abs/2504.19077)|null|\n", "2504.18904": "|**2025-04-26**|**RoboVerse: Towards a Unified Platform, Dataset and Benchmark for Scalable and Generalizable Robot Learning**|Pieter Abbeel Team|[2504.18904](http://arxiv.org/abs/2504.18904)|null|\n", "2504.18847": "|**2025-04-26**|**Imitation Learning for Autonomous Driving: Insights from Real-World Testing**|Tufan Kumbasar Team|[2504.18847](http://arxiv.org/abs/2504.18847)|null|\n", "2504.18794": "|**2025-04-26**|**Hierarchical Reinforcement Learning in Multi-Goal Spatial Navigation with Autonomous Mobile Robots**|Alfredo Weitzenfeld Team|[2504.18794](http://arxiv.org/abs/2504.18794)|null|\n", "2504.18792": "|**2025-04-26**|**STDArm: Transferring Visuomotor Policies From Static Data Training to Dynamic Robot Manipulation**|Yanyong Zhang Team|[2504.18792](http://arxiv.org/abs/2504.18792)|null|\n", "2504.20995": "|**2025-04-29**|**TesserAct: Learning 4D Embodied World Models**|Chuang Gan Team|[2504.20995](http://arxiv.org/abs/2504.20995)|null|\n", "2504.20969": "|**2025-04-29**|**XPG-RL: Reinforcement Learning with Explainable Priority Guidance for Efficiency-Boosted Mechanical Search**|Elena Shrestha Team|[2504.20969](http://arxiv.org/abs/2504.20969)|null|\n", "2504.20520": "|**2025-04-29**|**PRISM: Projection-based Reward Integration for Scene-Aware Real-to-Sim-to-Real Transfer with Few Demonstrations**|Xuguang Lan Team|[2504.20520](http://arxiv.org/abs/2504.20520)|null|\n", "2504.20506": "|**2025-04-29**|**SPARK Hand: Scooping-Pinching Adaptive Robotic Hand with Kempe Mechanism for Vertical Passive Grasp in Environmental Constraints**|Wenzeng Zhang Team|[2504.20506](http://arxiv.org/abs/2504.20506)|null|\n", "2504.21769": "|**2025-04-30**|**LLM-based Interactive Imitation Learning for Robotic Manipulation**|Stefan Wermter Team|[2504.21769](http://arxiv.org/abs/2504.21769)|null|\n", "2504.21530": "|**2025-04-30**|**RoboGround: Robotic Manipulation with Grounded Vision-Language Priors**|Zhou Zhao Team|[2504.21530](http://arxiv.org/abs/2504.21530)|null|\n", "2504.21486": "|**2025-04-30**|**Provably-Safe, Online System Identification**|Ram Vasudevan Team|[2504.21486](http://arxiv.org/abs/2504.21486)|null|\n", "2505.00693": "|**2025-05-06**|**Robotic Visual Instruction**|Xianzheng Ma Team|[2505.00693](http://arxiv.org/abs/2505.00693)|null|\n", "2505.00690": "|**2025-05-01**|**Towards Autonomous Micromobility through Scalable Urban Simulation**|Bolei Zhou Team|[2505.00690](http://arxiv.org/abs/2505.00690)|null|\n", "2505.00527": "|**2025-05-01**|**DeCo: Task Decomposition and Skill Composition for Zero-Shot Generalization in Long-Horizon 3D Manipulation**|Yang Gao Team|[2505.00527](http://arxiv.org/abs/2505.00527)|null|\n", "2505.00490": "|**2025-05-01**|**Optimal Interactive Learning on the Job via Facility Location Planning**|George Konidaris Team|[2505.00490](http://arxiv.org/abs/2505.00490)|null|\n", "2505.01383": "|**2025-05-02**|**FalconWing: An Open-Source Platform for Ultra-Light Fixed-Wing Aircraft Research**|Sayan Mitra Team|[2505.01383](http://arxiv.org/abs/2505.01383)|null|\n", "2505.02744": "|**2025-05-05**|**Re-purposing a modular origami manipulator into an adaptive physical computer for machine learning and robotic perception**|Suyi Li Team|[2505.02744](http://arxiv.org/abs/2505.02744)|null|\n", "2505.02597": "|**2025-05-05**|**Spatiotemporal Non-Uniformity-Aware Online Task Scheduling in Collaborative Edge Computing for Industrial Internet of Things**|Bo Lei Team|[2505.02597](http://arxiv.org/abs/2505.02597)|null|\n", "2505.02483": "|**2025-05-05**|**Automated Hybrid Reward Scheduling via Large Language Models for Robotic Skill Learning**|Jianqiang Li Team|[2505.02483](http://arxiv.org/abs/2505.02483)|null|\n", "2505.02388": "|**2025-05-05**|**MetaScenes: Towards Automated Replica Creation for Real-world 3D Scans**|Siyuan Huang Team|[2505.02388](http://arxiv.org/abs/2505.02388)|null|\n", "2505.02228": "|**2025-05-04**|**Coupled Distributional Random Expert Distillation for World Model Online Imitation Learning**|Hao Su Team|[2505.02228](http://arxiv.org/abs/2505.02228)|null|\n", "2505.02166": "|**2025-05-04**|**CrayonRobo: Object-Centric Prompt-Driven Vision-Language-Action Model for Robotic Manipulation**|Hao Dong Team|[2505.02166](http://arxiv.org/abs/2505.02166)|null|\n", "2505.02152": "|**2025-05-04**|**Interleave-VLA: Enhancing Robot Manipulation with Interleaved Image-Text Instructions**|Mingyu Ding Team|[2505.02152](http://arxiv.org/abs/2505.02152)|null|\n", "2505.01945": "|**2025-05-03**|**Act Natural! Extending Naturalistic Projection to Multimodal Behavior Scenarios**|David Fridovich-Keil Team|[2505.01945](http://arxiv.org/abs/2505.01945)|null|\n", "2505.01709": "|**2025-05-07**|**RoBridge: A Hierarchical Architecture Bridging Cognition and Execution for General Robotic Manipulation**|Xiaodan Liang Team|[2505.01709](http://arxiv.org/abs/2505.01709)|null|\n", "2505.03738": "|**2025-05-06**|**AMO: Adaptive Motion Optimization for Hyper-Dexterous Humanoid Whole-Body Control**|Xiaolong Wang Team|[2505.03738](http://arxiv.org/abs/2505.03738)|null|\n", "2505.03725": "|**2025-05-06**|**Meta-Optimization and Program Search using Language Models for Task and Motion Planning**|Marc Toussaint Team|[2505.03725](http://arxiv.org/abs/2505.03725)|null|\n", "2505.03561": "|**2025-05-06**|**Ergodic Generative Flows**|Yinchuan Li Team|[2505.03561](http://arxiv.org/abs/2505.03561)|null|\n", "2505.03344": "|**2025-05-06**|**RIFT: Closed-Loop RL Fine-Tuning for Realistic and Controllable Traffic Simulation**|Sifa Zheng Team|[2505.03344](http://arxiv.org/abs/2505.03344)|null|\n", "2505.03296": "|**2025-05-06**|**The Unreasonable Effectiveness of Discrete-Time Gaussian Process Mixtures for Robot Policy Learning**|Abhinav Valada Team|[2505.03296](http://arxiv.org/abs/2505.03296)|null|\n", "2505.03046": "|**2025-05-05**|**Sim2Real Transfer for Vision-Based Grasp Verification**|Markus Vincze Team|[2505.03046](http://arxiv.org/abs/2505.03046)|**[link](https://github.com/pauamargant/hsr-graspsynth)**|\n", "2505.02915": "|**2025-05-05**|**Zero-shot Sim2Real Transfer for Magnet-Based Tactile Sensor on Insertion Tasks**|Jia Deng Team|[2505.02915](http://arxiv.org/abs/2505.02915)|null|\n", "2505.04619": "|**2025-05-07**|**Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation**|Henrik I. Christensen Team|[2505.04619](http://arxiv.org/abs/2505.04619)|null|\n", "2505.03912": "|**2025-05-06**|**OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation**|Donglin Wang Team|[2505.03912](http://arxiv.org/abs/2505.03912)|null|\n", "2505.04999": "|**2025-05-08**|**CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations**|Stephen Tu Team|[2505.04999](http://arxiv.org/abs/2505.04999)|null|\n", "2505.04897": "|**2025-05-08**|**CubeDAgger: Improved Robustness of Interactive Imitation Learning without Violation of Dynamic Stability**|Taisuke Kobayashi Team|[2505.04897](http://arxiv.org/abs/2505.04897)|null|\n", "2505.04860": "|**2025-05-08**|**D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation**|Daniel Seita Team|[2505.04860](http://arxiv.org/abs/2505.04860)|null|\n", "2505.04831": "|**2025-05-07**|**Steerable Scene Generation with Post Training and Inference-Time Search**|Russ Tedrake Team|[2505.04831](http://arxiv.org/abs/2505.04831)|null|\n", "2505.04757": "|**2025-05-07**|**Primal-dual algorithm for contextual stochastic combinatorial optimization**|Axel Parmentier Team|[2505.04757](http://arxiv.org/abs/2505.04757)|null|\n", "2505.06219": "|**2025-05-09**|**VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction**|Roni Sengupta Team|[2505.06219](http://arxiv.org/abs/2505.06219)|null|\n", "2505.06191": "|**2025-05-09**|**Neuro-Symbolic Concepts**|Jiajun Wu Team|[2505.06191](http://arxiv.org/abs/2505.06191)|null|\n", "2505.06092": "|**2025-05-09**|**Robot Learning Using Multi-Coordinate Elastic Maps**|Reza Azadeh Team|[2505.06092](http://arxiv.org/abs/2505.06092)|null|\n", "2505.06079": "|**2025-05-09**|**TREND: Tri-teaching for Robust Preference-based Reinforcement Learning with Demonstrations**|Abhinav Shrivastava Team|[2505.06079](http://arxiv.org/abs/2505.06079)|null|\n", "2505.05800": "|**2025-05-09**|**3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks**|Farshad Khorrami Team|[2505.05800](http://arxiv.org/abs/2505.05800)|null|\n", "2505.05787": "|**2025-05-09**|**Demystifying Diffusion Policies: Action Memorization and Simple Lookup Table Alternatives**|Mac Schwager Team|[2505.05787](http://arxiv.org/abs/2505.05787)|null|\n", "2505.05784": "|**2025-05-09**|**FlowHFT: Flow Policy Induced Optimal High-Frequency Trading under Diverse Market Conditions**|Steve Yang Team|[2505.05784](http://arxiv.org/abs/2505.05784)|null|\n", "2505.06136": "|**2025-05-07**|**Efficient Sensorimotor Learning for Open-world Robot Manipulation**|Yifeng Zhu Team|[2505.06136](http://arxiv.org/abs/2505.06136)|null|\n", "2505.07819": "|**2025-05-12**|**H$^{\\mathbf{3}}$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning**|Huazhe Xu Team|[2505.07819](http://arxiv.org/abs/2505.07819)|null|\n", "2505.07815": "|**2025-05-12**|**Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models**|Jia-Bin Huang Team|[2505.07815](http://arxiv.org/abs/2505.07815)|null|\n", "2505.07802": "|**2025-05-12**|**Improving Trajectory Stitching with Flow Models**|Ioannis Havoutis Team|[2505.07802](http://arxiv.org/abs/2505.07802)|null|\n", "2505.07728": "|**2025-05-12**|**Guiding Data Collection via Factored Scaling Curves**|Anirudha Majumdar Team|[2505.07728](http://arxiv.org/abs/2505.07728)|null|\n", "2505.07455": "|**2025-05-12**|**GelFusion: Enhancing Robotic Manipulation under Visual Constraints via Visuotactile Fusion**|Peng Yin Team|[2505.07455](http://arxiv.org/abs/2505.07455)|null|\n", "2505.07395": "|**2025-05-12**|**ReinboT: Amplifying Robot Visual-Language Manipulation with Reinforcement Learning**|Donglin Wang Team|[2505.07395](http://arxiv.org/abs/2505.07395)|null|\n", "2505.07096": "|**2025-05-11**|**X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real**|Sanjiban Choudhury Team|[2505.07096](http://arxiv.org/abs/2505.07096)|null|\n", "2505.06923": "|**2025-05-11**|**YOPOv2-Tracker: An End-to-End Agile Tracking and Navigation Framework from Perception to Action**|Bailing Tian Team|[2505.06923](http://arxiv.org/abs/2505.06923)|null|\n", "2505.06771": "|**2025-05-10**|**JaxRobotarium: Training and Deploying Multi-Robot Policies in 10 Minutes**|Harish Ravichandar Team|[2505.06771](http://arxiv.org/abs/2505.06771)|null|\n", "2505.06748": "|**2025-05-10**|**Learned IMU Bias Prediction for Invariant Visual Inertial Odometry**|Nikolay Atanasov Team|[2505.06748](http://arxiv.org/abs/2505.06748)|null|\n", "2505.06628": "|**2025-05-10**|**ACORN: Adaptive Contrastive Optimization for Safe and Robust Fine-Grained Robotic Manipulation**|Zixian Yue Team|[2505.06628](http://arxiv.org/abs/2505.06628)|null|\n", "2505.06482": "|**2025-05-10**|**Video-Enhanced Offline Reinforcement Learning: A Model-Based Approach**|Xiaokang Yang Team|[2505.06482](http://arxiv.org/abs/2505.06482)|null|\n", "2505.06451": "|**2025-05-09**|**Adaptive Wiping: Adaptive contact-rich manipulation through few-shot imitation learning with Force-Torque feedback and pre-trained object representations**|Gentiane Venture Team|[2505.06451](http://arxiv.org/abs/2505.06451)|null|\n", "2505.08627": "|**2025-05-13**|**Augmented Reality for RObots (ARRO): Pointing Visuomotor Policies Towards Visual Robustness**|Wolfram Burgard Team|[2505.08627](http://arxiv.org/abs/2505.08627)|null|\n", "2505.08625": "|**2025-05-13**|**Beyond Predefined Actions: Integrating Behavior Trees and Dynamic Movement Primitives for Robot Learning from Demonstration**|Todor Stoyanov Team|[2505.08625](http://arxiv.org/abs/2505.08625)|null|\n", "2505.08548": "|**2025-05-13**|**From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation**|Jianye Hao Team|[2505.08548](http://arxiv.org/abs/2505.08548)|null|\n", "2505.08453": "|**2025-05-13**|**Parameter Estimation using Reinforcement Learning Causal Curiosity: Limits and Challenges**|Weisi Guo Team|[2505.08453](http://arxiv.org/abs/2505.08453)|null|\n", "2505.08376": "|**2025-05-13**|**Adaptive Diffusion Policy Optimization for Robotic Manipulation**|Zhuang Yang Team|[2505.08376](http://arxiv.org/abs/2505.08376)|null|\n", "2505.08364": "|**2025-05-13**|**Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation**|Qianchun Lu Team|[2505.08364](http://arxiv.org/abs/2505.08364)|null|\n", "2505.08361": "|**2025-05-13**|**Modeling Unseen Environments with Language-guided Composable Causal Components in Reinforcement Learning**|Biwei Huang Team|[2505.08361](http://arxiv.org/abs/2505.08361)|null|\n", "2505.08213": "|**2025-05-13**|**HandCept: A Visual-Inertial Fusion Framework for Accurate Proprioception in Dexterous Hands**|Yunhui Liu Team|[2505.08213](http://arxiv.org/abs/2505.08213)|null|\n", "2505.08194": "|**2025-05-13**|**CLTP: Contrastive Language-Tactile Pre-training for 3D Contact Geometry Understanding**|Shuo Wang Team|[2505.08194](http://arxiv.org/abs/2505.08194)|null|\n", "2505.08078": "|**2025-05-12**|**What Matters for Batch Online Reinforcement Learning in Robotics?**|Chelsea Finn Team|[2505.08078](http://arxiv.org/abs/2505.08078)|null|\n", "2505.09603": "|**2025-05-14**|**DataMIL: Selecting Data for Robot Imitation Learning with Datamodels**|Roberto Mart\u00edn-Mart\u00edn Team|[2505.09603](http://arxiv.org/abs/2505.09603)|null|\n", "2505.09601": "|**2025-05-14**|**Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware**|Ken Goldberg Team|[2505.09601](http://arxiv.org/abs/2505.09601)|null|\n", "2505.09577": "|**2025-05-14**|**VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation**|Shuo Wang Team|[2505.09577](http://arxiv.org/abs/2505.09577)|null|\n", "2505.09561": "|**2025-05-14**|**Learning Long-Context Diffusion Policies via Past-Token Prediction**|Chelsea Finn Team|[2505.09561](http://arxiv.org/abs/2505.09561)|null|\n", "2505.09546": "|**2025-05-14**|**Distilling Realizable Students from Unrealizable Teachers**|Sanjiban Choudhury Team|[2505.09546](http://arxiv.org/abs/2505.09546)|null|\n", "2505.09424": "|**2025-05-14**|**Exploring Pose-Guided Imitation Learning for Robotic Precise Insertion**|Qixin Cao Team|[2505.09424](http://arxiv.org/abs/2505.09424)|null|\n", "2505.09308": "|**2025-05-14**|**Neural Multivariate Regression: Qualitative Insights from the Unconstrained Feature Model**|Keith Ross Team|[2505.09308](http://arxiv.org/abs/2505.09308)|null|\n", "2505.09144": "|**2025-05-14**|**Latent Theory of Mind: A Decentralized Diffusion Architecture for Cooperative Manipulation**|Guillaume Sartoretti Team|[2505.09144](http://arxiv.org/abs/2505.09144)|null|\n", "2505.09109": "|**2025-05-14**|**FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis**|He Wang Team|[2505.09109](http://arxiv.org/abs/2505.09109)|null|\n", "2505.09099": "|**2025-05-14**|**Imitation Learning for Adaptive Control of a Virtual Soft Exoglove**|Letizia Gionfrida Team|[2505.09099](http://arxiv.org/abs/2505.09099)|null|\n", "2505.08986": "|**2025-05-13**|**ChicGrasp: Imitation-Learning based Customized Dual-Jaw Gripper Control for Delicate, Irregular Bio-products Manipulation**|Dongyi Wang Team|[2505.08986](http://arxiv.org/abs/2505.08986)|null|\n", "2505.10522": "|**2025-05-15**|**Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation**|Yan Jin Team|[2505.10522](http://arxiv.org/abs/2505.10522)|null|\n", "2505.10442": "|**2025-05-15**|**IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning**|Junshan Zhang Team|[2505.10442](http://arxiv.org/abs/2505.10442)|null|\n", "2505.10359": "|**2025-05-15**|**NVSPolicy: Adaptive Novel-View Synthesis for Generalizable Language-Conditioned Policy Learning**|Chengyuan Chen Team|[2505.10359](http://arxiv.org/abs/2505.10359)|null|\n", "2505.10251": "|**2025-05-15**|**SRT-H: A Hierarchical Framework for Autonomous Surgery via Language Conditioned Imitation Learning**|Axel Krieger Team|[2505.10251](http://arxiv.org/abs/2505.10251)|null|\n", "2505.10151": "|**2025-05-15**|**Training People to Reward Robots**|Matthew Howard Team|[2505.10151](http://arxiv.org/abs/2505.10151)|null|\n", "2505.10105": "|**2025-05-15**|**EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation**|Jianye Hao Team|[2505.10105](http://arxiv.org/abs/2505.10105)|null|\n", "2505.10075": "|**2025-05-15**|**FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation**|Qing Li Team|[2505.10075](http://arxiv.org/abs/2505.10075)|null|\n", "2505.10022": "|**2025-05-15**|**APEX: Action Priors Enable Efficient Exploration for Skill Imitation on Articulated Robots**|Guillaume Sartoretti Team|[2505.10022](http://arxiv.org/abs/2505.10022)|null|\n", "2505.10010": "|**2025-05-15**|**ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts**|Yang Yu Team|[2505.10010](http://arxiv.org/abs/2505.10010)|**[link](https://github.com/lamda-rl/imaginebench)**|\n", "2505.09990": "|**2025-05-16**|**PointArena: Probing Multimodal Grounding Through Language-Guided Pointing**|Ranjay Krishna Team|[2505.09990](http://arxiv.org/abs/2505.09990)|null|\n", "2505.09979": "|**2025-05-15**|**Learning Diverse Natural Behaviors for Enhancing the Agility of Quadrupedal Robots**|Chunlin Chen Team|[2505.09979](http://arxiv.org/abs/2505.09979)|null|\n", "2505.09833": "|**2025-05-14**|**Learning Rock Pushability on Rough Planetary Terrain**|Cagri Kilic Team|[2505.09833](http://arxiv.org/abs/2505.09833)|null|\n", "2505.09739": "|**2025-05-14**|**Trailblazer: Learning offroad costmaps for long range planning**|Srikanth Saripalli Team|[2505.09739](http://arxiv.org/abs/2505.09739)|null|\n", "2505.09723": "|**2025-05-14**|**EnerVerse-AC: Envisioning Embodied Environments with Action Condition**|Guanghui Ren Team|[2505.09723](http://arxiv.org/abs/2505.09723)|null|\n", "2505.09698": "|**2025-05-14**|**ManipBench: Benchmarking Vision-Language Models for Low-Level Robot Manipulation**|Daniel Seita Team|[2505.09698](http://arxiv.org/abs/2505.09698)|null|\n", "2505.11494": "|**2025-05-16**|**SHIELD: Safety on Humanoids via CBFs In Expectation on Learned Dynamics**|Aaron D. Ames Team|[2505.11494](http://arxiv.org/abs/2505.11494)|null|\n", "2505.11467": "|**2025-05-16**|**Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views**|Todor Stoyanov Team|[2505.11467](http://arxiv.org/abs/2505.11467)|null|\n", "2505.10911": "|**2025-05-16**|**ReWiND: Language-Guided Rewards Teach Robot Policies without New Demonstrations**|Jesse Zhang Team|[2505.10911](http://arxiv.org/abs/2505.10911)|null|\n", "2505.10760": "|**2025-05-16**|**Counterfactual Behavior Cloning: Offline Imitation Learning from Imperfect Human Demonstrations**|Dylan P. Losey Team|[2505.10760](http://arxiv.org/abs/2505.10760)|null|\n", "2505.10755": "|**2025-05-15**|**Infinigen-Sim: Procedural Generation of Articulated Simulation Assets**|Jia Deng Team|[2505.10755](http://arxiv.org/abs/2505.10755)|null|\n", "2505.13441": "|**2025-05-19**|**GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation**|Rose Hendrix Team|[2505.13441](http://arxiv.org/abs/2505.13441)|null|\n", "2505.13436": "|**2025-05-19**|**KinTwin: Imitation Learning with Torque and Muscle Driven Biomechanical Models Enables Precise Replication of Able-Bodied and Impaired Movement from Markerless Motion Capture**|R. James Cotton Team|[2505.13436](http://arxiv.org/abs/2505.13436)|null|\n", "2505.12748": "|**2025-05-19**|**TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation**|Jiangmiao Pang Team|[2505.12748](http://arxiv.org/abs/2505.12748)|null|\n", "2505.12744": "|**2025-05-19**|**Incentivizing Multimodal Reasoning in Large Models for Direct Robot Manipulation**|Chi-Wing Fu Team|[2505.12744](http://arxiv.org/abs/2505.12744)|null|\n", "2505.12737": "|**2025-05-19**|**Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning**|Taesup Moon Team|[2505.12737](http://arxiv.org/abs/2505.12737)|null|\n", "2505.12705": "|**2025-05-19**|**DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories**|Linxi Fan Team|[2505.12705](http://arxiv.org/abs/2505.12705)|null|\n", "2505.12679": "|**2025-05-19**|**Dribble Master: Learning Agile Humanoid Dribbling Through Legged Locomotion**|Qi Wu Team|[2505.12679](http://arxiv.org/abs/2505.12679)|null|\n", "2505.12619": "|**2025-05-19**|**HIL: Hybrid Imitation Learning of Diverse Parkour Skills from Videos**|Xue Bin Peng Team|[2505.12619](http://arxiv.org/abs/2505.12619)|null|\n", "2505.12410": "|**2025-05-18**|**MTIL: Encoding Full History with Mamba for Temporal Imitation Learning**|Zhouping Yin Team|[2505.12410](http://arxiv.org/abs/2505.12410)|**[link](https://github.com/yulinzhouzyl/mtil)**|\n", "2505.12294": "|**2025-05-18**|**PartDexTOG: Generating Dexterous Task-Oriented Grasping via Language-driven Part Analysis**|Zhipong Cai Team|[2505.12294](http://arxiv.org/abs/2505.12294)|null|\n", "2505.12224": "|**2025-05-20**|**RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction**|Bo Zhao Team|[2505.12224](http://arxiv.org/abs/2505.12224)|null|\n", "2505.12222": "|**2025-05-20**|**Learning Impact-Rich Rotational Maneuvers via Centroidal Velocity Rewards and Sim-to-Real Techniques: A One-Leg Hopper Flip Case Study**|Hae-Won Park Team|[2505.12222](http://arxiv.org/abs/2505.12222)|null|\n", "2505.12072": "|**2025-05-17**|**L2D2: Robot Learning from 2D Drawings**|Dylan P. Losey Team|[2505.12072](http://arxiv.org/abs/2505.12072)|null|\n", "2505.11920": "|**2025-05-17**|**H2R: A Human-to-Robot Data Augmentation for Robot Pre-training from Videos**|Shanghang Zhang Team|[2505.11920](http://arxiv.org/abs/2505.11920)|null|\n", "2505.11865": "|**2025-05-17**|**GLOVER++: Unleashing the Potential of Affordance Learning from Human Behaviors for Robotic Manipulation**|Junwei Liang Team|[2505.11865](http://arxiv.org/abs/2505.11865)|null|\n", "2505.11763": "|**2025-05-17**|**Learning IMU Bias with Diffusion Model**|Guoquan Huang Team|[2505.11763](http://arxiv.org/abs/2505.11763)|null|\n", "2505.11719": "|**2025-05-16**|**Zero-Shot Visual Generalization in Robot Manipulation**|Gaurav Sukhatme Team|[2505.11719](http://arxiv.org/abs/2505.11719)|null|\n", "2505.11716": "|**2025-05-16**|**Employing Laban Shape for Generating Emotionally and Functionally Expressive Trajectories in Robotic Manipulators**|Alessandro Roncone Team|[2505.11716](http://arxiv.org/abs/2505.11716)|null|\n", "2505.11709": "|**2025-05-16**|**EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video**|Jian Zhang Team|[2505.11709](http://arxiv.org/abs/2505.11709)|null|\n", "2505.11680": "|**2025-05-16**|**Grounded Task Axes: Zero-Shot Semantic Skill Generalization via Task-Axis Controllers and Visual Foundation Models**|Oliver Kroemer Team|[2505.11680](http://arxiv.org/abs/2505.11680)|null|\n", "2505.14357": "|**2025-05-20**|**Vid2World: Crafting Video Diffusion Models to Interactive World Models**|Mingsheng Long Team|[2505.14357](http://arxiv.org/abs/2505.14357)|null|\n", "2505.14030": "|**2025-05-20**|**AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory**|Ping Luo Team|[2505.14030](http://arxiv.org/abs/2505.14030)|null|\n", "2505.13934": "|**2025-05-20**|**RLVR-World: Training World Models with Reinforcement Learning**|Mingsheng Long Team|[2505.13934](http://arxiv.org/abs/2505.13934)|**[link](https://github.com/thuml/RLVR-World)**|\n", "2505.13925": "|**2025-05-20**|**Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning**|Yutong Ban Team|[2505.13925](http://arxiv.org/abs/2505.13925)|null|\n", "2505.13904": "|**2025-05-20**|**Learning to Insert for Constructive Neural Vehicle Routing Solver**|Qingfu Zhang Team|[2505.13904](http://arxiv.org/abs/2505.13904)|null|\n", "2505.13820": "|**2025-05-20**|**Structured Agent Distillation for Large Language Model**|Yanzhi Wang Team|[2505.13820](http://arxiv.org/abs/2505.13820)|null|\n", "2505.13667": "|**2025-05-21**|**Adaptive Diffusion Constrained Sampling for Bimanual Robot Manipulation**|Georgia Chalvatzaki Team|[2505.13667](http://arxiv.org/abs/2505.13667)|null|\n", "2505.13549": "|**2025-05-19**|**TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion**|Minh Nhat Vu Team|[2505.13549](http://arxiv.org/abs/2505.13549)|null|\n", "2505.15725": "|**2025-05-21**|**UAV-Flow Colosseo: A Real-World Benchmark for Flying-on-a-Word UAV Imitation Learning**|Si Liu Team|[2505.15725](http://arxiv.org/abs/2505.15725)|null|\n", "2505.15660": "|**2025-05-21**|**Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization**|Junwei Liang Team|[2505.15660](http://arxiv.org/abs/2505.15660)|null|\n", "2505.15659": "|**2025-05-21**|**FLARE: Robot Learning with Implicit World Modeling**|Linxi Fan Team|[2505.15659](http://arxiv.org/abs/2505.15659)|null|\n", "2505.15517": "|**2025-05-21**|**Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets**|Ken Goldberg Team|[2505.15517](http://arxiv.org/abs/2505.15517)|null|\n", "2505.15418": "|**2025-05-21**|**Guided Policy Optimization under Partial Observability**|Zongqing Lu Team|[2505.15418](http://arxiv.org/abs/2505.15418)|**[link](https://github.com/liyheng/GPO)**|\n", "2505.15304": "|**2025-05-21**|**Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control**|Jungwook Choi Team|[2505.15304](http://arxiv.org/abs/2505.15304)|null|\n", "2505.15275": "|**2025-05-21**|**Learning-based Autonomous Oversteer Control and Collision Avoidance**|Seung-Hyun Kong Team|[2505.15275](http://arxiv.org/abs/2505.15275)|null|\n", "2505.15143": "|**2025-05-21**|**Filtering Learning Histories Enhances In-Context Reinforcement Learning**|Santiago Paternain Team|[2505.15143](http://arxiv.org/abs/2505.15143)|null|\n", "2505.15098": "|**2025-05-21**|**Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation**|Xiaodong He Team|[2505.15098](http://arxiv.org/abs/2505.15098)|null|\n", "2505.14941": "|**2025-05-20**|**RoboCulture: A Robotics Platform for Automated Biological Experimentation**|Milica Radisic Team|[2505.14941](http://arxiv.org/abs/2505.14941)|null|\n", "2505.14820": "|**2025-05-20**|**Imitation Learning via Focused Satisficing**|Brian Ziebart Team|[2505.14820](http://arxiv.org/abs/2505.14820)|null|\n", "2505.14819": "|**2025-05-20**|**DORA: Object Affordance-Guided Reinforcement Learning for Dexterous Robotic Manipulation**|Jianwei Zhang Team|[2505.14819](http://arxiv.org/abs/2505.14819)|null|\n", "2505.17006": "|**2025-05-22**|**CoMo: Learning Continuous Latent Motion from Internet Videos for Scalable Robot Learning**|Limin Wang Team|[2505.17006](http://arxiv.org/abs/2505.17006)|null|\n", "2505.16969": "|**2025-05-22**|**3D Equivariant Visuomotor Policy Learning via Spherical Projection**|Robin Walters Team|[2505.16969](http://arxiv.org/abs/2505.16969)|null|\n", "2505.16856": "|**2025-05-22**|**Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only**|Donglin Wang Team|[2505.16856](http://arxiv.org/abs/2505.16856)|null|\n", "2505.16547": "|**2025-05-22**|**Find the Fruit: Designing a Zero-Shot Sim2Real Deep RL Planner for Occlusion Aware Plant Manipulation**|Soumik Sarkar Team|[2505.16547](http://arxiv.org/abs/2505.16547)|null|\n", "2505.16517": "|**2025-05-24**|**ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models**|Xiuying Chen Team|[2505.16517](http://arxiv.org/abs/2505.16517)|null|\n", "2505.16394": "|**2025-05-22**|**Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)**|Junchi Yan Team|[2505.16394](http://arxiv.org/abs/2505.16394)|null|\n", "2505.16289": "|**2025-05-22**|**TacCompress: A Benchmark for Multi-Point Tactile Data Compression in Dexterous Manipulation**|Hengdi Zhang Team|[2505.16289](http://arxiv.org/abs/2505.16289)|null|\n", "2505.16196": "|**2025-05-22**|**SEM: Enhancing Spatial Understanding for Robust Robot Manipulation**|Zhizhong Su Team|[2505.16196](http://arxiv.org/abs/2505.16196)|null|\n", "2505.16167": "|**2025-05-22**|**Tactile-based Reinforcement Learning for Adaptive Grasping under Observation Uncertainties**|Yang Ye Team|[2505.16167](http://arxiv.org/abs/2505.16167)|null|\n", "2505.16062": "|**2025-05-21**|**WaveTouch: Active Tactile Sensing Using Vibro-Feedback for Classification of Variable Stiffness and Infill Density Objects**|Bakhtiyar Orazbayev Team|[2505.16062](http://arxiv.org/abs/2505.16062)|null|\n", "2505.16055": "|**2025-05-25**|**Proactive Hierarchical Control Barrier Function-Based Safety Prioritization in Close Human-Robot Interaction Scenarios**|Prashanth Krishnamurthy Team|[2505.16055](http://arxiv.org/abs/2505.16055)|null|\n", "2505.18121": "|**2025-05-23**|**ProgRM: Build Better GUI Agents with Progress Rewards**|Kai Yu Team|[2505.18121](http://arxiv.org/abs/2505.18121)|null|\n", "2505.18012": "|**2025-05-23**|**Classification of assembly tasks combining multiple primitive actions using Transformers and xLSTMs**|Pedro Neto Team|[2505.18012](http://arxiv.org/abs/2505.18012)|null|\n", "2505.17966": "|**2025-05-23**|**Is Single-View Mesh Reconstruction Ready for Robotics?**|Ingmar Posner Team|[2505.17966](http://arxiv.org/abs/2505.17966)|null|\n", "2505.17695": "|**2025-05-23**|**SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data**|Donghyun Kim Team|[2505.17695](http://arxiv.org/abs/2505.17695)|null|\n", "2505.17610": "|**2025-05-23**|**Learning Equilibria from Data: Provably Efficient Multi-Agent Imitation Learning**|Giorgia Ramponi Team|[2505.17610](http://arxiv.org/abs/2505.17610)|null|\n", "2505.17434": "|**2025-05-23**|**Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy**|Bin Zhao Team|[2505.17434](http://arxiv.org/abs/2505.17434)|null|\n", "2505.17389": "|**2025-05-23**|**Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space**|Hui Cheng Team|[2505.17389](http://arxiv.org/abs/2505.17389)|null|\n", "2505.17295": "|**2025-05-22**|**ScanBot: Towards Intelligent Surface Scanning in Embodied Robotic Systems**|Farhad Imani Team|[2505.17295](http://arxiv.org/abs/2505.17295)|null|\n", "2505.20148": "|**2025-05-27**|**MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents**|Xiaodan Liang Team|[2505.20148](http://arxiv.org/abs/2505.20148)|**[link](https://github.com/mineanybuild/mineanybuild)**|\n", "2505.20024": "|**2025-05-26**|**ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving**|Dongbin Zhao Team|[2505.20024](http://arxiv.org/abs/2505.20024)|**[link](https://github.com/liuxueyi/reasonplan)**|\n", "2505.19946": "|**2025-05-26**|**Inverse Q-Learning Done Right: Offline Imitation Learning in $Q^\u03c0$-Realizable MDPs**|Luca Viano Team|[2505.19946](http://arxiv.org/abs/2505.19946)|null|\n", "2505.19769": "|**2025-05-26**|**TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning**|Dongbin Zhao Team|[2505.19769](http://arxiv.org/abs/2505.19769)|null|\n", "2505.19717": "|**2025-05-26**|**Extremum Flow Matching for Offline Goal Conditioned Reinforcement Learning**|Jean-Baptiste Mouret Team|[2505.19717](http://arxiv.org/abs/2505.19717)|null|\n", "2505.19053": "|**2025-05-25**|**Structured Reinforcement Learning for Combinatorial Decision-Making**|Maximilian Schiffer Team|[2505.19053](http://arxiv.org/abs/2505.19053)|**[link](https://github.com/tumbais/structured-rl)**|\n", "2505.19017": "|**2025-05-25**|**WorldEval: World Model as Real-World Robot Policies Evaluator**|Yi Xu Team|[2505.19017](http://arxiv.org/abs/2505.19017)|null|\n", "2505.18952": "|**2025-05-25**|**Online Knowledge Distillation with Reward Guidance**|Chen Jia Team|[2505.18952](http://arxiv.org/abs/2505.18952)|null|\n", "2505.18858": "|**2025-05-24**|**Guided by Guardrails: Control Barrier Functions as Safety Instructors for Robotic Learning**|Giovanni Beltrame Team|[2505.18858](http://arxiv.org/abs/2505.18858)|null|\n", "2505.18792": "|**2025-05-24**|**On the Dual-Use Dilemma in Physical Reasoning and Force**|Nikolaus Correll Team|[2505.18792](http://arxiv.org/abs/2505.18792)|null|\n", "2505.18719": "|**2025-05-24**|**VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning**|Ziwei Wang Team|[2505.18719](http://arxiv.org/abs/2505.18719)|null|\n", "2505.18595": "|**2025-05-24**|**MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality Demonstrations**|Hong Thanh Nguyen Team|[2505.18595](http://arxiv.org/abs/2505.18595)|null|\n", "2505.18487": "|**2025-05-24**|**Grounding Bodily Awareness in Visual Representations for Efficient Policy Learning**|Zhiyun Lin Team|[2505.18487](http://arxiv.org/abs/2505.18487)|null|\n", "2505.18474": "|**2025-05-24**|**Canonical Policy: Learning Canonical 3D Representation for Equivariant Policy**|Yu She Team|[2505.18474](http://arxiv.org/abs/2505.18474)|null|\n", "2505.18472": "|**2025-05-24**|**ManiFeel: Benchmarking and Understanding Visuotactile Manipulation Policy Learning**|Yu She Team|[2505.18472](http://arxiv.org/abs/2505.18472)|null|\n", "2505.20175": "|**2025-05-26**|**URPlanner: A Universal Paradigm For Collision-Free Robotic Motion Planning Based on Deep Reinforcement Learning**|Marcelo H. Ang Jr Team|[2505.20175](http://arxiv.org/abs/2505.20175)|null|\n", "2505.21495": "|**2025-05-27**|**CLAMP: Crowdsourcing a LArge-scale in-the-wild haptic dataset with an open-source device for Multimodal robot Perception**|Tapomayukh Bhattacharjee Team|[2505.21495](http://arxiv.org/abs/2505.21495)|null|\n", "2505.21351": "|**2025-05-27**|**EquAct: An SE(3)-Equivariant Multi-Task Transformer for Open-Loop Robotic Manipulation**|Robert Platt Team|[2505.21351](http://arxiv.org/abs/2505.21351)|null|\n", "2505.21282": "|**2025-05-27**|**EgoWalk: A Multimodal Dataset for Robot Navigation in the Wild**|Gonzalo Ferrer Team|[2505.21282](http://arxiv.org/abs/2505.21282)|null|\n", "2505.21182": "|**2025-05-27**|**Learning What to Do and What Not To Do: Offline Imitation from Expert and Undesirable Demonstrations**|Tanvi Verma Team|[2505.21182](http://arxiv.org/abs/2505.21182)|null|\n", "2505.20962": "|**2025-05-27**|**Object-Centric Action-Enhanced Representations for Robot Visuo-Motor Policy Learning**|George Retsinas Team|[2505.20962](http://arxiv.org/abs/2505.20962)|null|\n", "2505.20829": "|**2025-05-27**|**Learning Unified Force and Position Control for Legged Loco-Manipulation**|Siyuan Huang Team|[2505.20829](http://arxiv.org/abs/2505.20829)|null|\n", "2505.20814": "|**2025-05-27**|**Spatial RoboGrasp: Generalized Robotic Grasping Control Policy**|Luhui Hu Team|[2505.20814](http://arxiv.org/abs/2505.20814)|null|\n", "2505.20795": "|**2025-05-27**|**Learning Generalizable Robot Policy with Human Demonstration Video as a Prompt**|Jianyu Chen Team|[2505.20795](http://arxiv.org/abs/2505.20795)|null|\n", "2505.20498": "|**2025-05-28**|**ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image**|Ruohan Gao Team|[2505.20498](http://arxiv.org/abs/2505.20498)|null|\n", "2505.20425": "|**2025-05-26**|**OSVI-WM: One-Shot Visual Imitation for Unseen Tasks using World-Model-Guided Trajectory Generation**|Farshad Khorrami Team|[2505.20425](http://arxiv.org/abs/2505.20425)|null|\n", "2505.20404": "|**2025-05-26**|**Co-Design of Soft Gripper with Neural Physics**|Xiaolong Wang Team|[2505.20404](http://arxiv.org/abs/2505.20404)|null|\n", "2505.20290": "|**2025-05-26**|**EgoZero: Robot Learning from Smart Glasses**|Lerrel Pinto Team|[2505.20290](http://arxiv.org/abs/2505.20290)|null|\n", "2505.22626": "|**2025-05-28**|**SCIZOR: A Self-Supervised Approach to Data Curation for Large-Scale Imitation Learning**|Yuke Zhu Team|[2505.22626](http://arxiv.org/abs/2505.22626)|null|\n", "2505.22424": "|**2025-05-28**|**Hybrid Learning for Cold-Start-Aware Microservice Scheduling in Dynamic Edge Environments**|Weijia Jia Team|[2505.22424](http://arxiv.org/abs/2505.22424)|**[link](https://github.com/Blacktower27/CSDCRMDE)**|\n", "2505.22404": "|**2025-05-28**|**Efficient Precision-Scalable Hardware for Microscaling (MX) Processing in Robotics Learning**|Marian Verhelst Team|[2505.22404](http://arxiv.org/abs/2505.22404)|null|\n", "2505.22352": "|**2025-05-28**|**State and Input Constrained Adaptive Tracking Control of Uncertain Euler-Lagrange Systems with Robustness and Feasibility Analysis**|Shubhendu Bhasin Team|[2505.22352](http://arxiv.org/abs/2505.22352)|null|\n", "2505.22159": "|**2025-05-28**|**ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation**|Wenqiang Zhang Team|[2505.22159](http://arxiv.org/abs/2505.22159)|null|\n", "2505.21981": "|**2025-05-28**|**Learning Compositional Behaviors from Demonstration and Language**|Jiajun Wu Team|[2505.21981](http://arxiv.org/abs/2505.21981)|null|\n", "2505.21906": "|**2025-05-29**|**ChatVLA-2: Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge**|Yi Xu Team|[2505.21906](http://arxiv.org/abs/2505.21906)|null|\n", "2505.21851": "|**2025-05-28**|**Streaming Flow Policy: Simplifying diffusion$/$flow-matching policies by treating action trajectories as flow trajectories**|Siddharth Ancha Team|[2505.21851](http://arxiv.org/abs/2505.21851)|null|\n", "2505.21652": "|**2025-05-27**|**PartInstruct: Part-level Instruction Following for Fine-grained Robot Manipulation**|Tianmin Shu Team|[2505.21652](http://arxiv.org/abs/2505.21652)|null|\n", "2505.21649": "|**2025-05-30**|**Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks**|Bryan A. Plummer Team|[2505.21649](http://arxiv.org/abs/2505.21649)|null|\n", "2505.23692": "|**2025-05-29**|**Mobi-$\u03c0$: Mobilizing Your Robot Learning Policy**|Jeannette Bohg Team|[2505.23692](http://arxiv.org/abs/2505.23692)|null|\n", "2505.23527": "|**2025-05-30**|**Normalizing Flows are Capable Models for RL**|Benjamin Eysenbach Team|[2505.23527](http://arxiv.org/abs/2505.23527)|null|\n", "2505.23501": "|**2025-05-29**|**Optimization-based Posture Generation for Whole-body Contact Motion by Contact Point Search on the Body Surface**|Masayuki Inaba Team|[2505.23501](http://arxiv.org/abs/2505.23501)|null|\n", "2505.23450": "|**2025-05-29**|**Agentic Robot: A Brain-Inspired Framework for Vision-Language-Action Models in Embodied Agents**|Lichao Sun Team|[2505.23450](http://arxiv.org/abs/2505.23450)|null|\n", "2505.23426": "|**2025-05-29**|**Enhanced DACER Algorithm with High Diffusion Efficiency**|Shengbo Eben Li Team|[2505.23426](http://arxiv.org/abs/2505.23426)|null|\n", "2505.23171": "|**2025-05-29**|**RoboTransfer: Geometry-Consistent Video Diffusion for Robotic Visual Policy Transfer**|Zhizhong Su Team|[2505.23171](http://arxiv.org/abs/2505.23171)|null|\n", "2505.24819": "|**2025-05-30**|**Bi-Manual Joint Camera Calibration and Scene Representation**|Weiming Zhi Team|[2505.24819](http://arxiv.org/abs/2505.24819)|null|\n", "2505.24382": "|**2025-05-30**|**MagicGripper: A Multimodal Sensor-Integrated Gripper for Contact-Rich Robotic Manipulation**|Dandan Zhang Team|[2505.24382](http://arxiv.org/abs/2505.24382)|null|\n", "2505.24339": "|**2025-05-30**|**Imitation Learning-Based Path Generation for the Complex Assembly of Deformable Objects**|Christoffer Sloth Team|[2505.24339](http://arxiv.org/abs/2505.24339)|null|\n", "2505.24305": "|**2025-05-30**|**SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping**|Hao Dong Team|[2505.24305](http://arxiv.org/abs/2505.24305)|null|\n", "2505.24209": "|**2025-05-30**|**Safety-Aware Robust Model Predictive Control for Robotic Arms in Dynamic Environments**|Suwoong Lee Team|[2505.24209](http://arxiv.org/abs/2505.24209)|null|\n", "2505.24198": "|**2025-05-30**|**Learning Gentle Humanoid Locomotion and End-Effector Stabilization Control**|Guanya Shi Team|[2505.24198](http://arxiv.org/abs/2505.24198)|null|\n", "2506.03079": "|**2025-06-03**|**ORV: 4D Occupancy-centric Robot Video Generation**|Hao Zhao Team|[2506.03079](http://arxiv.org/abs/2506.03079)|null|\n", "2506.02768": "|**2025-06-03**|**Geometric Visual Servo Via Optimal Transport**|Ashutosh Tiwari Team|[2506.02768](http://arxiv.org/abs/2506.02768)|null|\n", "2506.02618": "|**2025-06-03**|**Rodrigues Network for Learning Robot Actions**|Leonidas Guibas Team|[2506.02618](http://arxiv.org/abs/2506.02618)|null|\n", "2506.02577": "|**2025-06-03**|**Reachability Weighted Offline Goal-conditioned Resampling**|Joni Pajarinen Team|[2506.02577](http://arxiv.org/abs/2506.02577)|null|\n", "2506.01953": "|**2025-06-02**|**Fast-in-Slow: A Dual-System Foundation Model Unifying Fast Manipulation within Slow Reasoning**|Pheng-Ann Heng Team|[2506.01953](http://arxiv.org/abs/2506.01953)|null|\n", "2506.01944": "|**2025-06-02**|**Feel the Force: Contact-Driven Learning from Humans**|Lerrel Pinto Team|[2506.01944](http://arxiv.org/abs/2506.01944)|null|\n", "2506.01943": "|**2025-06-02**|**Learning Video Generation for Robotic Manipulation with Collaborative Trajectory Control**|Dahua Lin Team|[2506.01943](http://arxiv.org/abs/2506.01943)|null|\n", "2506.01941": "|**2025-06-02**|**FreeTacMan: Robot-free Visuo-Tactile Data Collection System for Contact-rich Manipulation**|Hongyang Li Team|[2506.01941](http://arxiv.org/abs/2506.01941)|null|\n", "2506.01756": "|**2025-06-02**|**Learning with pyCub: A New Simulation and Exercise Framework for Humanoid Robotics**|Matej Hoffmann Team|[2506.01756](http://arxiv.org/abs/2506.01756)|null|\n", "2506.01710": "|**2025-06-02**|**Reasoning-Table: Exploring Reinforcement Learning for Table Reasoning**|Kang Liu Team|[2506.01710](http://arxiv.org/abs/2506.01710)|**[link](https://github.com/MJinXiang/Reasoning-Table)**|\n", "2506.01600": "|**2025-06-02**|**WoMAP: World Models For Embodied Open-Vocabulary Object Localization**|Anirudha Majumdar Team|[2506.01600](http://arxiv.org/abs/2506.01600)|null|\n", "2506.01583": "|**2025-06-02**|**FreqPolicy: Frequency Autoregressive Visuomotor Policy with Continuous Tokens**|Yuexin Ma Team|[2506.01583](http://arxiv.org/abs/2506.01583)|null|\n", "2506.01568": "|**2025-06-02**|**Trajectory First: A Curriculum for Discovering Diverse Policies**|Marc Toussaint Team|[2506.01568](http://arxiv.org/abs/2506.01568)|null|\n", "2506.01350": "|**2025-06-02**|**Variational Adaptive Noise and Dropout towards Stable Recurrent Neural Networks**|Shingo Murata Team|[2506.01350](http://arxiv.org/abs/2506.01350)|null|\n", "2506.01196": "|**2025-06-01**|**OG-VLA: 3D-Aware Vision Language Action Model via Orthographic Image Generation**|Valts Blukis Team|[2506.01196](http://arxiv.org/abs/2506.01196)|null|\n", "2506.01185": "|**2025-06-01**|**HoMeR: Learning In-the-Wild Mobile Manipulation via Hybrid Imitation and Whole-Body Control**|Jeannette Bohg Team|[2506.01185](http://arxiv.org/abs/2506.01185)|null|\n", "2506.00782": "|**2025-06-01**|**Jailbreak-R1: Exploring the Jailbreak Capabilities of LLMs via Reinforcement Learning**|Jing Li Team|[2506.00782](http://arxiv.org/abs/2506.00782)|null|\n", "2506.00599": "|**2025-05-31**|**XYZ-IBD: High-precision Bin-picking Dataset for Object 6D Pose Estimation Capturing Real-world Industrial Complexity**|Benjamin Busam Team|[2506.00599](http://arxiv.org/abs/2506.00599)|null|\n", "2506.00320": "|**2025-05-31**|**Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents**|Zhou Yu Team|[2506.00320](http://arxiv.org/abs/2506.00320)|null|\n", "2506.00280": "|**2025-05-30**|**3D Gaussian Splat Vulnerabilities**|Polo Chau Team|[2506.00280](http://arxiv.org/abs/2506.00280)|null|\n", "2506.04227": "|**2025-06-04**|**Object-centric 3D Motion Field for Robot Learning from Human Videos**|Pieter Abbeel Team|[2506.04227](http://arxiv.org/abs/2506.04227)|null|\n", "2506.04120": "|**2025-06-04**|**Splatting Physical Scenes: End-to-End Real-to-Sim from Imperfect Robot Data**|Leonard Hasenclever Team|[2506.04120](http://arxiv.org/abs/2506.04120)|null|\n", "2506.03863": "|**2025-06-04**|**STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization**|Liqiang Nie Team|[2506.03863](http://arxiv.org/abs/2506.03863)|**[link](https://github.com/jiutian-vl/star)**|\n", "2506.03574": "|**2025-06-04**|**SwitchVLA: Execution-Aware Task Switching for Vision-Language-Action Models**|Jian Tang Team|[2506.03574](http://arxiv.org/abs/2506.03574)|null|\n", "2506.03568": "|**2025-06-05**|**Confidence-Guided Human-AI Collaboration: Reinforcement Learning with Distributional Proxy Value Propagation for Autonomous Driving**|Hu Chuan Team|[2506.03568](http://arxiv.org/abs/2506.03568)|**[link](https://github.com/lzqw/c-hac)**|\n", "2506.05294": "|**2025-06-05**|**A Smooth Sea Never Made a Skilled $\\texttt{SAILOR}$: Robust Imitation via Learning to Search**|Gokul Swamy Team|[2506.05294](http://arxiv.org/abs/2506.05294)|null|\n", "2506.05165": "|**2025-06-05**|**LiPo: A Lightweight Post-optimization Framework for Smoothing Action Chunks Generated by Learned Policies**|Suhan Park Team|[2506.05165](http://arxiv.org/abs/2506.05165)|null|\n", "2506.05064": "|**2025-06-05**|**DemoSpeedup: Accelerating Visuomotor Policies via Entropy-Guided Demonstration Acceleration**|Huazhe Xu Team|[2506.05064](http://arxiv.org/abs/2506.05064)|null|\n", "2506.04941": "|**2025-06-06**|**ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning**|Jian Tang Team|[2506.04941](http://arxiv.org/abs/2506.04941)|null|\n", "2506.04716": "|**2025-06-05**|**Learning dissection trajectories from expert surgical videos via imitation learning with equivariant diffusion**|Qi Dou Team|[2506.04716](http://arxiv.org/abs/2506.04716)|null|\n", "2506.04625": "|**2025-06-05**|**Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning**|Wanxiang Che Team|[2506.04625](http://arxiv.org/abs/2506.04625)|null|\n", "2506.04505": "|**2025-06-04**|**SGN-CIRL: Scene Graph-based Navigation with Curriculum, Imitation, and Reinforcement Learning**|Aleksandr Panov Team|[2506.04505](http://arxiv.org/abs/2506.04505)|null|\n", "2506.06199": "|**2025-06-06**|**3DFlowAction: Learning Cross-Embodiment Manipulation from 3D Flow World Model**|Mingkui Tan Team|[2506.06199](http://arxiv.org/abs/2506.06199)|null|\n", "2506.06196": "|**2025-06-06**|**Bridging Perception and Action: Spatially-Grounded Mid-Level Representations for Robot Generalization**|Tingnan Zhang Team|[2506.06196](http://arxiv.org/abs/2506.06196)|null|\n", "2506.06072": "|**2025-06-10**|**BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning**|Rudolf Lioutikov Team|[2506.06072](http://arxiv.org/abs/2506.06072)|null|\n", "2506.05985": "|**2025-06-06**|**Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning**|Ping Luo Team|[2506.05985](http://arxiv.org/abs/2506.05985)|null|\n", "2506.05812": "|**2025-06-06**|**Optimal Robotic Velcro Peeling with Force Feedback**|Volkan Isler Team|[2506.05812](http://arxiv.org/abs/2506.05812)|null|\n", "2506.05808": "|**2025-06-06**|**Where Do We Look When We Teach? Analyzing Human Gaze Behavior Across Demonstration Devices in Robot Imitation Learning**|Hiroshi Bito Team|[2506.05808](http://arxiv.org/abs/2506.05808)|null|\n", "2506.05755": "|**2025-06-06**|**FlowOE: Imitation Learning with Flow Policy from Ensemble RL Experts for Optimal Execution under Heston Volatility and Concave Market Impacts**|Zhi Chen Team|[2506.05755](http://arxiv.org/abs/2506.05755)|null|\n", "2506.05719": "|**2025-06-06**|**You Only Estimate Once: Unified, One-stage, Real-Time Category-level Articulated Object 6D Pose Estimation for Robotic Grasping**|Xiangyang Xue Team|[2506.05719](http://arxiv.org/abs/2506.05719)|null|\n", "2506.07961": "|**2025-06-09**|**BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models**|Tieniu Tan Team|[2506.07961](http://arxiv.org/abs/2506.07961)|null|\n", "2506.07530": "|**2025-06-09**|**BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation**|Xilin Chen Team|[2506.07530](http://arxiv.org/abs/2506.07530)|null|\n", "2506.07505": "|**2025-06-09**|**Reinforcement Learning via Implicit Imitation Guidance**|Chelsea Finn Team|[2506.07505](http://arxiv.org/abs/2506.07505)|null|\n", "2506.07490": "|**2025-06-09**|**RAPID Hand: A Robust, Affordable, Perception-Integrated, Dexterous Manipulation Platform for Generalist Robot Autonomy**|Hui Cheng Team|[2506.07490](http://arxiv.org/abs/2506.07490)|null|\n", "2506.07006": "|**2025-06-08**|**CARoL: Context-aware Adaptation for Robot Learning**|Xuan Wang Team|[2506.07006](http://arxiv.org/abs/2506.07006)|null|\n", "2506.06690": "|**2025-06-07**|**SpikePingpong: High-Frequency Spike Vision-based Robot Learning for Precise Striking in Table Tennis Game**|Shanghang Zhang Team|[2506.06690](http://arxiv.org/abs/2506.06690)|null|\n", "2506.06677": "|**2025-06-07**|**RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation**|Si Liu Team|[2506.06677](http://arxiv.org/abs/2506.06677)|null|\n", "2506.06658": "|**2025-06-07**|**Self-Adapting Improvement Loops for Robotic Learning**|Chen Sun Team|[2506.06658](http://arxiv.org/abs/2506.06658)|null|\n", "2506.06570": "|**2025-06-06**|**Enhancing Robot Safety via MLLM-Based Semantic Interpretation of Failure Data**|Somil Bansal Team|[2506.06570](http://arxiv.org/abs/2506.06570)|null|\n", "2506.06567": "|**2025-06-06**|**NeSyPack: A Neuro-Symbolic Framework for Bimanual Logistics Packing**|Changliu Liu Team|[2506.06567](http://arxiv.org/abs/2506.06567)|null|\n", "2506.06535": "|**2025-06-06**|**MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping**|Farshad Khorrami Team|[2506.06535](http://arxiv.org/abs/2506.06535)|null|\n", "2506.08822": "|**2025-06-10**|**FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency**|Jian Tang Team|[2506.08822](http://arxiv.org/abs/2506.08822)|null|\n", "2506.08795": "|**2025-06-10**|**Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning**|Xianta Jiang Team|[2506.08795](http://arxiv.org/abs/2506.08795)|null|\n", "2506.08756": "|**2025-06-10**|**Bayesian Inverse Physics for Neuro-Symbolic Robot Learning**|Frank Kirchner Team|[2506.08756](http://arxiv.org/abs/2506.08756)|null|\n", "2506.08639": "|**2025-06-10**|**Deep Reinforcement Learning-Based Motion Planning and PDE Control for Flexible Manipulators**|Jouni Mattila Team|[2506.08639](http://arxiv.org/abs/2506.08639)|null|\n", "2506.08632": "|**2025-06-10**|**RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping**|Gitta Kutyniok Team|[2506.08632](http://arxiv.org/abs/2506.08632)|null|\n", "2506.08416": "|**2025-06-10**|**Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots**|Lijun Zhu Team|[2506.08416](http://arxiv.org/abs/2506.08416)|null|\n", "2506.08296": "|**2025-06-11**|**HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation**|Cong Wang Team|[2506.08296](http://arxiv.org/abs/2506.08296)|null|\n", "2506.08052": "|**2025-06-09**|**ReCogDrive: A Reinforced Cognitive Framework for End-to-End Autonomous Driving**|Xinggang Wang Team|[2506.08052](http://arxiv.org/abs/2506.08052)|null|\n", "2506.09994": "|**2025-06-11**|**eFlesh: Highly customizable Magnetic Touch Sensing using Cut-Cell Microstructures**|Raunaq Bhirangi Team|[2506.09994](http://arxiv.org/abs/2506.09994)|null|\n", "2506.09990": "|**2025-06-11**|**Chain-of-Action: Trajectory Autoregressive Modeling for Robotic Manipulation**|Xiao Ma Team|[2506.09990](http://arxiv.org/abs/2506.09990)|null|\n", "2506.09930": "|**2025-06-11**|**From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models**|Chen Feng Team|[2506.09930](http://arxiv.org/abs/2506.09930)|null|\n", "2506.09800": "|**2025-06-11**|**Reinforced Refinement with Self-Aware Expansion for End-to-End Autonomous Driving**|Chen Lv Team|[2506.09800](http://arxiv.org/abs/2506.09800)|null|\n", "2506.09699": "|**2025-06-11**|**CHIP: A multi-sensor dataset for 6D pose estimation of chairs in industrial settings**|Davide Boscaini Team|[2506.09699](http://arxiv.org/abs/2506.09699)|null|\n", "2506.09494": "|**2025-06-11**|**Advances on Affordable Hardware Platforms for Human Demonstration Acquisition in Agricultural Applications**|N\u00e9stor Garc\u00eda Team|[2506.09494](http://arxiv.org/abs/2506.09494)|null|\n", "2506.09491": "|**2025-06-11**|**DCIRNet: Depth Completion with Iterative Refinement for Dexterous Grasping of Transparent and Reflective Objects**|Hong Liu Team|[2506.09491](http://arxiv.org/abs/2506.09491)|null|\n", "2506.09422": "|**2025-06-11**|**Time-Unified Diffusion Policy with Action Discrimination for Robotic Manipulation**|Le Wang Team|[2506.09422](http://arxiv.org/abs/2506.09422)|null|\n", "2506.09384": "|**2025-06-11**|**Analyzing Key Objectives in Human-to-Robot Retargeting for Dexterous Manipulation**|Xiang Li Team|[2506.09384](http://arxiv.org/abs/2506.09384)|null|\n", "2506.09365": "|**2025-06-11**|**ContextBuddy: AI-Enhanced Contextual Insights for Security Alert Investigation (Applied to Intrusion Detection)**|Cecile Paris Team|[2506.09365](http://arxiv.org/abs/2506.09365)|null|\n", "2506.09284": "|**2025-06-10**|**UAD: Unsupervised Affordance Distillation for Generalization in Robotic Manipulation**|Li Fei-Fei Team|[2506.09284](http://arxiv.org/abs/2506.09284)|null|\n", "2506.09176": "|**2025-06-10**|**Robot-Gated Interactive Imitation Learning with Adaptive Intervention Mechanism**|Bolei Zhou Team|[2506.09176](http://arxiv.org/abs/2506.09176)|null|\n", "2506.10968": "|**2025-06-12**|**Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop**|Angjoo Kanazawa Team|[2506.10968](http://arxiv.org/abs/2506.10968)|null|\n", "2506.10966": "|**2025-06-12**|**GENMANIP: LLM-driven Simulation for Generalizable Instruction-Following Manipulation**|Jiangmiao Pang Team|[2506.10966](http://arxiv.org/abs/2506.10966)|null|\n", "2506.10790": "|**2025-06-12**|**Human-Robot Navigation using Event-based Cameras and Reinforcement Learning**|Rodrigo Verschae Team|[2506.10790](http://arxiv.org/abs/2506.10790)|null|\n", "2506.10359": "|**2025-06-12**|**Demonstrating Multi-Suction Item Picking at Scale via Multi-Modal Learning of Pick Success**|Kapil Katyal Team|[2506.10359](http://arxiv.org/abs/2506.10359)|null|\n", "2506.10240": "|**2025-06-11**|**Innovative Adaptive Imaged Based Visual Servoing Control of 6 DoFs Industrial Robot Manipulators**|Francis Assadian Team|[2506.10240](http://arxiv.org/abs/2506.10240)|null|\n", "2506.10106": "|**2025-06-11**|**One For All: LLM-based Heterogeneous Mission Planning in Precision Agriculture**|Stefano Carpin Team|[2506.10106](http://arxiv.org/abs/2506.10106)|null|\n", "2506.11948": "|**2025-06-13**|**SAIL: Faster-than-Demonstration Execution of Imitation Learning Policies**|Danfei Xu Team|[2506.11948](http://arxiv.org/abs/2506.11948)|null|\n", "2506.11916": "|**2025-06-13**|**mimic-one: a Scalable Model Recipe for General Purpose Robot Dexterity**|Robert K. Katzschmann Team|[2506.11916](http://arxiv.org/abs/2506.11916)|null|\n", "2506.11775": "|**2025-06-13**|**ExoStart: Efficient learning for dexterous manipulation with sensorized exoskeleton demonstrations**|Maria Bauza Villalonga Team|[2506.11775](http://arxiv.org/abs/2506.11775)|null|\n", "2506.11387": "|**2025-06-13**|**Control Architecture and Design for a Multi-robotic Visual Servoing System in Automated Manufacturing Environment**|Rongfei Li Team|[2506.11387](http://arxiv.org/abs/2506.11387)|null|\n", "2506.11293": "|**2025-06-12**|**Influence Functions for Data Attribution in Linear System Identification and LQR Control**|Dongmei Chen Team|[2506.11293](http://arxiv.org/abs/2506.11293)|null|\n", "2506.11261": "|**2025-06-12**|**Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation**|Cordelia Schmid Team|[2506.11261](http://arxiv.org/abs/2506.11261)|null|\n", "2506.13762": "|**2025-06-16**|**Touch begins where vision ends: Generalizable policies for contact-rich manipulation**|Raunaq Bhirangi Team|[2506.13762](http://arxiv.org/abs/2506.13762)|null|\n", "2506.13761": "|**2025-06-16**|**Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins**|Wei-Chiu Ma Team|[2506.13761](http://arxiv.org/abs/2506.13761)|null|\n", "2506.13536": "|**2025-06-16**|**What Matters in Learning from Large-Scale Datasets for Robot Manipulation**|Danfei Xu Team|[2506.13536](http://arxiv.org/abs/2506.13536)|null|\n", "2506.13498": "|**2025-06-16**|**A Survey on Imitation Learning for Contact-Rich Tasks in Robotics**|Arash Ajoudani Team|[2506.13498](http://arxiv.org/abs/2506.13498)|null|\n", "2506.13478": "|**2025-06-16**|**Learning Swing-up Maneuvers for a Suspended Aerial Manipulation Platform in a Hierarchical Control Framework**|Christian Ott Team|[2506.13478](http://arxiv.org/abs/2506.13478)|null|\n", "2506.13428": "|**2025-06-16**|**VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation**|Wei Pan Team|[2506.13428](http://arxiv.org/abs/2506.13428)|null|\n", "2506.12723": "|**2025-06-15**|**SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration**|Wenwu Zhu Team|[2506.12723](http://arxiv.org/abs/2506.12723)|null|\n", "2506.12678": "|**2025-06-15**|**Adapting by Analogy: OOD Generalization of Visuomotor Policies via Functional Correspondence**|Andrea Bajcsy Team|[2506.12678](http://arxiv.org/abs/2506.12678)|null|\n", "2506.12676": "|**2025-06-15**|**Goal-based Self-Adaptive Generative Adversarial Imitation Learning (Goal-SAGAIL) for Multi-goal Robotic Manipulation Tasks**|George Vogiatzis Team|[2506.12676](http://arxiv.org/abs/2506.12676)|null|\n", "2506.12374": "|**2025-06-14**|**AntiGrounding: Lifting Robotic Actions into VLM Representation Space for Decision Making**|Qingyao Wu Team|[2506.12374](http://arxiv.org/abs/2506.12374)|null|\n", "2506.12273": "|**2025-06-13**|**Role of Uncertainty in Model Development and Control Design for a Manufacturing Process**|Francis Assadian Team|[2506.12273](http://arxiv.org/abs/2506.12273)|null|\n", "2506.14763": "|**2025-06-17**|**RobotSmith: Generative Robotic Tool Design for Acquisition of Complex Manipulation Skills**|Chuang Gan Team|[2506.14763](http://arxiv.org/abs/2506.14763)|null|\n", "2506.14754": "|**2025-06-17**|**Tactile Beyond Pixels: Multisensory Touch Representations for Robot Manipulation**|Mustafa Mukadam Team|[2506.14754](http://arxiv.org/abs/2506.14754)|null|\n", "2506.14648": "|**2025-06-17**|**SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning**|Shuo Wang Team|[2506.14648](http://arxiv.org/abs/2506.14648)|null|\n", "2506.14608": "|**2025-06-17**|**Latent Action Diffusion for Cross-Embodiment Manipulation**|Robert K. Katzschmann Team|[2506.14608](http://arxiv.org/abs/2506.14608)|null|\n", "2506.14317": "|**2025-06-19**|**ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes**|Hao Dong Team|[2506.14317](http://arxiv.org/abs/2506.14317)|null|\n", "2506.14287": "|**2025-06-17**|**Steering Robots with Inference-Time Interactions**|Yanwei Wang Team|[2506.14287](http://arxiv.org/abs/2506.14287)|null|\n", "2506.14198": "|**2025-06-17**|**AMPLIFY: Actionless Motion Priors for Robot Learning from Videos**|Animesh Garg Team|[2506.14198](http://arxiv.org/abs/2506.14198)|null|\n", "2506.14180": "|**2025-06-17**|**Non-Overlap-Aware Egocentric Pose Estimation for Collaborative Perception in Connected Autonomy**|Peng Gao Team|[2506.14180](http://arxiv.org/abs/2506.14180)|null|\n", "2506.14135": "|**2025-06-17**|**GAF: Gaussian Action Field as a Dvnamic World Model for Robotic Mlanipulation**|Yebin Liu Team|[2506.14135](http://arxiv.org/abs/2506.14135)|null|\n", "2506.13867": "|**2025-06-16**|**ATK: Automatic Task-driven Keypoint Selection for Robust Policy Learning**|Abhishek Gupta Team|[2506.13867](http://arxiv.org/abs/2506.13867)|null|\n", "2506.15666": "|**2025-06-18**|**Vision in Action: Learning Active Perception from Human Demonstrations**|Shuran Song Team|[2506.15666](http://arxiv.org/abs/2506.15666)|null|\n", "2506.15190": "|**2025-06-18**|**Learning Task-Agnostic Skill Bases to Uncover Motor Primitives in Animal Behaviors**|Anqi Wu Team|[2506.15190](http://arxiv.org/abs/2506.15190)|null|\n", "2506.15157": "|**2025-06-18**|**Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation**|Yukiyasu Domae Team|[2506.15157](http://arxiv.org/abs/2506.15157)|null|\n", "2506.15146": "|**2025-06-18**|**TACT: Humanoid Whole-body Contact Manipulation through Deep Imitation Learning with Tactile Modality**|Eiichi Yoshida Team|[2506.15146](http://arxiv.org/abs/2506.15146)|null|\n", "2506.17110": "|**2025-06-20**|**Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping**|Jingjin Yu Team|[2506.17110](http://arxiv.org/abs/2506.17110)|null|\n", "2506.16986": "|**2025-06-24**|**Learning Accurate Whole-body Throwing with High-frequency Residual Policy and Pullback Tube Acceleration**|Marco Hutter Team|[2506.16986](http://arxiv.org/abs/2506.16986)|null|\n", "2506.16685": "|**2025-06-20**|**Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections**|Shuran Song Team|[2506.16685](http://arxiv.org/abs/2506.16685)|null|\n", "2506.16652": "|**2025-06-19**|**CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity**|Yunzhu Li Team|[2506.16652](http://arxiv.org/abs/2506.16652)|null|\n", "2506.16565": "|**2025-06-19**|**Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control**|Ran Tian Team|[2506.16565](http://arxiv.org/abs/2506.16565)|null|\n", "2506.16555": "|**2025-06-19**|**An Optimization-Augmented Control Framework for Single and Coordinated Multi-Arm Robotic Manipulation**|Ozgur S. Oguz Team|[2506.16555](http://arxiv.org/abs/2506.16555)|null|\n", "2506.16475": "|**2025-06-19**|**Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining**|Ding Zhao Team|[2506.16475](http://arxiv.org/abs/2506.16475)|null|\n", "2506.16396": "|**2025-06-19**|**GoalLadder: Incremental Goal Discovery with Vision-Language Models**|Shimon Whiteson Team|[2506.16396](http://arxiv.org/abs/2506.16396)|null|\n", "2506.16263": "|**2025-06-19**|**CapsDT: Diffusion-Transformer for Capsule Robot Manipulation**|Hongliang Ren Team|[2506.16263](http://arxiv.org/abs/2506.16263)|null|\n", "2506.16211": "|**2025-06-19**|**ControlVLA: Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models**|Siyuan Huang Team|[2506.16211](http://arxiv.org/abs/2506.16211)|null|\n", "2506.16201": "|**2025-06-19**|**FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation**|Wei Tang Team|[2506.16201](http://arxiv.org/abs/2506.16201)|null|\n", "2506.15953": "|**2025-06-19**|**ViTacFormer: Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation**|Jitendra Malik Team|[2506.15953](http://arxiv.org/abs/2506.15953)|null|\n", "2506.15920": "|**2025-06-18**|**Learning from Planned Data to Improve Robotic Pick-and-Place Planning Efficiency**|Kensuke Harada Team|[2506.15920](http://arxiv.org/abs/2506.15920)|null|\n", "2506.15865": "|**2025-06-18**|**Improving Robotic Manipulation: Techniques for Object Pose Estimation, Accommodating Positional Uncertainty, and Disassembly Tasks from Examples**|Viral Rasik Galaiya Team|[2506.15865](http://arxiv.org/abs/2506.15865)|null|\n", "2506.18856": "|**2025-06-23**|**RAG-6DPose: Retrieval-Augmented 6D Pose Estimation via Leveraging CAD as Knowledge Base**|Xiangyang Xue Team|[2506.18856](http://arxiv.org/abs/2506.18856)|null|\n", "2506.18825": "|**2025-06-23**|**SViP: Sequencing Bimanual Visuomotor Policies with Object-Centric Motion Primitives**|Jia Pan Team|[2506.18825](http://arxiv.org/abs/2506.18825)|null|\n", "2506.18580": "|**2025-06-23**|**Learning Point Correspondences In Radar 3D Point Clouds For Radar-Inertial Odometry**|Jan Steinbrener Team|[2506.18580](http://arxiv.org/abs/2506.18580)|null|\n", "2506.18365": "|**2025-06-23**|**Robots and Children that Learn Together : Improving Knowledge Retention by Teaching Peer-Like Interactive Robots**|Alessandro Di Nuovo Team|[2506.18365](http://arxiv.org/abs/2506.18365)|null|\n", "2506.18355": "|**2025-06-23**|**Robotic Manipulation of a Rotating Chain with Bottom End Fixed**|Quang-Cuong Pham Team|[2506.18355](http://arxiv.org/abs/2506.18355)|null|\n", "2506.18304": "|**2025-06-23**|**Sharpening the Spear: Adaptive Expert-Guided Adversarial Attack Against DRL-based Autonomous Driving Policies**|Xiaolin Chang Team|[2506.18304](http://arxiv.org/abs/2506.18304)|null|\n", "2506.18264": "|**2025-06-23**|**Learning Approach to Efficient Vision-based Active Tracking of a Flying Target by an Unmanned Aerial Vehicle**|Souma Chowdhury Team|[2506.18264](http://arxiv.org/abs/2506.18264)|null|\n", "2506.18088": "|**2025-06-22**|**RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation**|Yao Mu Team|[2506.18088](http://arxiv.org/abs/2506.18088)|null|\n", "2506.17639": "|**2025-06-21**|**RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models**|Xiao Li Team|[2506.17639](http://arxiv.org/abs/2506.17639)|null|\n", "2506.17624": "|**2025-06-21**|**Imitation Learning for Active Neck Motion Enabling Robot Manipulation beyond the Field of View**|Yasuo Kuniyoshi Team|[2506.17624](http://arxiv.org/abs/2506.17624)|null|\n", "2506.17458": "|**2025-06-20**|**Kinematic Model Optimization via Differentiable Contact Manifold for In-Space Manipulation**|Satyandra K. Gupta Team|[2506.17458](http://arxiv.org/abs/2506.17458)|null|\n", "2506.19850": "|**2025-06-24**|**Unified Vision-Language-Action Model**|Zhaoxiang Zhang Team|[2506.19850](http://arxiv.org/abs/2506.19850)|null|\n", "2506.19498": "|**2025-06-24**|**T-Rex: Task-Adaptive Spatial Representation Extraction for Robotic Manipulation with Vision-Language Models**|Qingyao Wu Team|[2506.19498](http://arxiv.org/abs/2506.19498)|null|\n", "2506.19408": "|**2025-06-24**|**Is an object-centric representation beneficial for robotic manipulation ?**|Liming Chen Team|[2506.19408](http://arxiv.org/abs/2506.19408)|null|\n", "2506.19303": "|**2025-06-24**|**Robotic Perception with a Large Tactile-Vision-Language Model for Physical Property Inference**|Nutan Chen Team|[2506.19303](http://arxiv.org/abs/2506.19303)|null|\n", "2506.19269": "|**2025-06-25**|**AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation**|Hui Shen Team|[2506.19269](http://arxiv.org/abs/2506.19269)|null|\n", "2506.19250": "|**2025-06-24**|**Robust Behavior Cloning Via Global Lipschitz Regularization**|Sean B. Andersson Team|[2506.19250](http://arxiv.org/abs/2506.19250)|null|\n", "2506.19121": "|**2025-06-23**|**CUPID: Curating Data your Robot Loves with Influence Functions**|Jeannette Bohg Team|[2506.19121](http://arxiv.org/abs/2506.19121)|null|\n", "2506.19077": "|**2025-06-23**|**Multimodal Anomaly Detection with a Mixture-of-Experts**|Dongheui Lee Team|[2506.19077](http://arxiv.org/abs/2506.19077)|null|\n", "2506.18960": "|**2025-06-25**|**FORTE: Tactile Force and Slip Sensing on Compliant Fingers for Delicate Manipulation**|Lillian Chin Team|[2506.18960](http://arxiv.org/abs/2506.18960)|null|\n", "2506.20586": "|**2025-06-25**|**Learning-Based Distance Estimation for 360\u00b0 Single-Sensor Setups**|Andreas Zell Team|[2506.20586](http://arxiv.org/abs/2506.20586)|null|\n", "2506.20445": "|**2025-06-25**|**Learn to Position -- A Novel Meta Method for Robotic Positioning**|Xiaoming Tao Team|[2506.20445](http://arxiv.org/abs/2506.20445)|null|\n", "2506.20307": "|**2025-06-25**|**Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration**|Quanquan Gu Team|[2506.20307](http://arxiv.org/abs/2506.20307)|null|\n", "2506.21250": "|**2025-06-26**|**ACTLLM: Action Consistency Tuned Large Language Model**|Chenliang Xu Team|[2506.21250](http://arxiv.org/abs/2506.21250)|null|\n", "2506.21230": "|**2025-07-02**|**World-aware Planning Narratives Enhance Large Vision-Language Model Planner**|Xipeng Qiu Team|[2506.21230](http://arxiv.org/abs/2506.21230)|null|\n", "2506.21178": "|**2025-06-26**|**UAIbot: Beginner-friendly web-based simulator for interactive robotics learning and research**|Vinicius Mariano Gon\u00e7alves Team|[2506.21178](http://arxiv.org/abs/2506.21178)|null|\n", "2506.21057": "|**2025-06-26**|**Knowledge-Driven Imitation Learning: Enabling Generalization Across Diverse Conditions**|Cewu Lu Team|[2506.21057](http://arxiv.org/abs/2506.21057)|null|\n", "2506.20966": "|**2025-06-26**|**Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends**|Zeng-Guang Hou Team|[2506.20966](http://arxiv.org/abs/2506.20966)|null|\n", "2506.22410": "|**2025-06-27**|**Spherical Pendulum with Quad-Rotor Thrust Vectoring Actuation -- A Novel Mechatronics and Control Benchmark Platform**|Tsu-Chin Tsao Team|[2506.22410](http://arxiv.org/abs/2506.22410)|null|\n", "2506.22007": "|**2025-06-27**|**RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation**|Abhinav Valada Team|[2506.22007](http://arxiv.org/abs/2506.22007)|null|\n", "2506.21732": "|**2025-06-26**|**Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation**|Venkat Krovi Team|[2506.21732](http://arxiv.org/abs/2506.21732)|null|\n", "2506.21628": "|**2025-06-24**|**Ark: An Open-source Python-based Framework for Robot Learning**|Haitham Bou-Ammar Team|[2506.21628](http://arxiv.org/abs/2506.21628)|null|\n", "2506.21627": "|**2025-06-24**|**FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models**|Huiping Zhuang Team|[2506.21627](http://arxiv.org/abs/2506.21627)|null|\n", "2506.23944": "|**2025-07-01**|**Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning**|Yang Gao Team|[2506.23944](http://arxiv.org/abs/2506.23944)|null|\n", "2506.23919": "|**2025-06-30**|**World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation**|Lin Shao Team|[2506.23919](http://arxiv.org/abs/2506.23919)|null|\n", "2506.23793": "|**2025-06-30**|**Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning**|Alexey Skrynnik Team|[2506.23793](http://arxiv.org/abs/2506.23793)|null|\n", "2506.23725": "|**2025-06-30**|**PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?**|Ransalu Senanayake Team|[2506.23725](http://arxiv.org/abs/2506.23725)|null|\n", "2506.23126": "|**2025-07-04**|**ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation**|Mac Schwager Team|[2506.23126](http://arxiv.org/abs/2506.23126)|null|\n", "2506.23125": "|**2025-06-29**|**Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots**|Yue Gao Team|[2506.23125](http://arxiv.org/abs/2506.23125)|null|\n", "2506.22827": "|**2025-06-28**|**Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation**|Navid Azizan Team|[2506.22827](http://arxiv.org/abs/2506.22827)|null|\n", "2506.22788": "|**2025-06-28**|**SPI-BoTER: Error Compensation for Industrial Robots via Sparse Attention Masking and Hybrid Loss with Spatial-Physical Information**|Yuqiang Wu Team|[2506.22788](http://arxiv.org/abs/2506.22788)|null|\n", "2506.22769": "|**2025-06-28**|**Learning Efficient Robotic Garment Manipulation with Standardization**|Bin He Team|[2506.22769](http://arxiv.org/abs/2506.22769)|null|\n", "2506.22756": "|**2025-06-28**|**RoboPearls: Editable Video Simulation for Robot Manipulation**|Xiaodan Liang Team|[2506.22756](http://arxiv.org/abs/2506.22756)|null|\n", "2507.01857": "|**2025-07-02**|**TypeTele: Releasing Dexterity in Teleoperation by Dexterous Manipulation Types**|Wei-Shi Zheng Team|[2507.01857](http://arxiv.org/abs/2507.01857)|null|\n", "2507.01779": "|**2025-07-02**|**S3D: A Spatial Steerable Surgical Drilling Framework for Robotic Spinal Fixation Procedures**|Farshid Alambeigi Team|[2507.01779](http://arxiv.org/abs/2507.01779)|null|\n", "2507.01424": "|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Yanwei Fu Team|[2507.01424](http://arxiv.org/abs/2507.01424)|null|\n", "2507.01198": "|**2025-07-01**|**Search-Based Robot Motion Planning With Distance-Based Adaptive Motion Primitives**|Bakir Lacevic Team|[2507.01198](http://arxiv.org/abs/2507.01198)|null|\n", "2507.01161": "|**2025-07-01**|**Imitation Learning for Satellite Attitude Control under Unknown Perturbations**|Xiaoli Bai Team|[2507.01161](http://arxiv.org/abs/2507.01161)|null|\n", "2507.01152": "|**2025-07-01**|**SonoGym: High Performance Simulation for Challenging Surgical Tasks with Robotic Ultrasound**|Philipp F\u00fcrnstahl Team|[2507.01152](http://arxiv.org/abs/2507.01152)|null|\n", "2507.01099": "|**2025-07-01**|**Geometry-aware 4D Video Generation for Robot Manipulation**|Shuran Song Team|[2507.01099](http://arxiv.org/abs/2507.01099)|null|\n", "2507.01008": "|**2025-07-01**|**DexWrist: A Robotic Wrist for Constrained and Dynamic Manipulation**|Pulkit Agrawal Team|[2507.01008](http://arxiv.org/abs/2507.01008)|null|\n", "2507.00990": "|**2025-07-04**|**Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations**|Yunzhu Li Team|[2507.00990](http://arxiv.org/abs/2507.00990)|null|\n", "2507.00833": "|**2025-07-01**|**HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning**|Chenjia Bai Team|[2507.00833](http://arxiv.org/abs/2507.00833)|null|\n", "2507.00677": "|**2025-07-01**|**Learning Steerable Imitation Controllers from Unstructured Animal Motions**|Stelian Coros Team|[2507.00677](http://arxiv.org/abs/2507.00677)|null|\n", "2507.00435": "|**2025-07-01**|**RoboEval: Where Robotic Manipulation Meets Structured and Scalable Evaluation**|Siddhartha Srinivasa Team|[2507.00435](http://arxiv.org/abs/2507.00435)|null|\n", "2507.02190": "|**2025-07-02**|**cVLA: Towards Efficient Camera-Space VLAs**|Thomas Brox Team|[2507.02190](http://arxiv.org/abs/2507.02190)|null|\n", "2507.02171": "|**2025-07-02**|**Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN**|Matthias Kerzel Team|[2507.02171](http://arxiv.org/abs/2507.02171)|null|\n", "2507.05116": "|**2025-07-07**|**VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting**|Yanzhi Wang Team|[2507.05116](http://arxiv.org/abs/2507.05116)|null|\n", "2507.05011": "|**2025-07-07**|**When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning**|Sebastien Ourselin Team|[2507.05011](http://arxiv.org/abs/2507.05011)|null|\n", "2507.04789": "|**2025-07-07**|**Training-free Generation of Temporally Consistent Rewards from VLMs**|Jian Tang Team|[2507.04789](http://arxiv.org/abs/2507.04789)|null|\n", "2507.04661": "|**2025-07-07**|**DRAE: Dynamic Retrieval-Augmented Expert Networks for Lifelong Learning and Task Adaptation in Robotics**|Mingsheng Shang Team|[2507.04661](http://arxiv.org/abs/2507.04661)|null|\n", "2507.04633": "|**2025-07-07**|**PRISM: Pointcloud Reintegrated Inference via Segmentation and Cross-attention for Manipulation**|Chee-Meng Chew Team|[2507.04633](http://arxiv.org/abs/2507.04633)|null|\n", "2507.04631": "|**2025-07-07**|**Learning Robust Stereo Matching in the Wild with Selective Mixture-of-Experts**|Junjie Hu Team|[2507.04631](http://arxiv.org/abs/2507.04631)|null|\n", "2507.04524": "|**2025-07-06**|**VLM-TDP: VLM-guided Trajectory-conditioned Diffusion Policy for Robust Long-Horizon Manipulation**|Lei Han Team|[2507.04524](http://arxiv.org/abs/2507.04524)|null|\n", "2507.04447": "|**2025-07-06**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Xin Jin Team|[2507.04447](http://arxiv.org/abs/2507.04447)|null|\n", "2507.04331": "|**2025-07-06**|**Wavelet Policy: Lifting Scheme for Policy Learning in Long-Horizon Tasks**|Yi Fang Team|[2507.04331](http://arxiv.org/abs/2507.04331)|null|\n", "2507.04086": "|**2025-07-05**|**Are Learning-Based Approaches Ready for Real-World Indoor Navigation? A Case for Imitation Learning**|Sebastian Houben Team|[2507.04086](http://arxiv.org/abs/2507.04086)|null|\n", "2507.04049": "|**2025-07-05**|**Breaking Imitation Bottlenecks: Reinforced Diffusion Powers Diverse Trajectory Generation**|Yadan Luo Team|[2507.04049](http://arxiv.org/abs/2507.04049)|null|\n", "2507.03930": "|**2025-07-08**|**RwoR: Generating Robot Demonstrations from Human Hand Collection for Policy Learning without Robot**|Hao Dong Team|[2507.03930](http://arxiv.org/abs/2507.03930)|null|\n", "2507.03878": "|**2025-07-05**|**DK-RRT: Deep Koopman RRT for Collision-Aware Motion Planning of Space Manipulators in Dynamic Debris Environments**|Dezhi Yu Team|[2507.03878](http://arxiv.org/abs/2507.03878)|null|\n", "2507.03227": "|**2025-07-04**|**Dexterous Teleoperation of 20-DoF ByteDexter Hand via Human Motion Retargeting**|Zeyu Ren Team|[2507.03227](http://arxiv.org/abs/2507.03227)|null|\n", "2507.06224": "|**2025-07-08**|**EC-Flow: Enabling Versatile Robotic Manipulation from Action-Unlabeled Videos via Embodiment-Centric Flow**|Liang Wang Team|[2507.06224](http://arxiv.org/abs/2507.06224)|null|\n", "2507.06219": "|**2025-07-08**|**Is Diversity All You Need for Scalable Robotic Manipulation?**|Hongyang Li Team|[2507.06219](http://arxiv.org/abs/2507.06219)|null|\n", "2507.06174": "|**2025-07-08**|**Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model**|Toshiaki Tsuji Team|[2507.06174](http://arxiv.org/abs/2507.06174)|null|\n", "2507.06172": "|**2025-07-08**|**Learning Agile Tensile Perching for Aerial Robots from Demonstrations**|Basaran Bahadir Kocer Team|[2507.06172](http://arxiv.org/abs/2507.06172)|null|\n", "2507.06053": "|**2025-07-08**|**SCCRUB: Surface Cleaning Compliant Robot Utilizing Bristles**|Jeffrey Ian Lipton Team|[2507.06053](http://arxiv.org/abs/2507.06053)|null|\n", "2507.05754": "|**2025-07-08**|**LeAD: The LLM Enhanced Planning System Converged with End-to-end Autonomous Driving**|Jian Sun Team|[2507.05754](http://arxiv.org/abs/2507.05754)|null|\n", "2507.05695": "|**2025-07-08**|**Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning**|Daniel Rakita Team|[2507.05695](http://arxiv.org/abs/2507.05695)|null|\n", "2507.05674": "|**2025-07-08**|**Integrating Diffusion-based Multi-task Learning with Online Reinforcement Learning for Robust Quadruped Robot Control**|Bin Liang Team|[2507.05674](http://arxiv.org/abs/2507.05674)|null|\n", "2507.05663": "|**2025-07-08**|**Stable Tracking-in-the-Loop Control of Cable-Driven Surgical Manipulators under Erroneous Kinematic Chains**|Michael C. Yip Team|[2507.05663](http://arxiv.org/abs/2507.05663)|null|\n", "2507.05627": "|**2025-07-08**|**DreamGrasp: Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation**|Frank Chongwoo Park Team|[2507.05627](http://arxiv.org/abs/2507.05627)|null|\n", "2507.05522": "|**2025-07-07**|**Gaussian Process-Based Active Exploration Strategies in Vision and Touch**|Nadia Figueroa Team|[2507.05522](http://arxiv.org/abs/2507.05522)|null|\n", "2507.05331": "|**2025-07-07**|**A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation**|Russ Tedrake Team|[2507.05331](http://arxiv.org/abs/2507.05331)|null|\n", "2507.06822": "|**2025-07-09**|**Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand**|Xinjun Sheng Team|[2507.06822](http://arxiv.org/abs/2507.06822)|null|\n", "2507.06780": "|**2025-07-09**|**Learning safe, constrained policies via imitation learning: Connection to Probabilistic Inference and a Naive Algorithm**|George A. Vouros Team|[2507.06780](http://arxiv.org/abs/2507.06780)|null|\n", "2507.06710": "|**2025-07-13**|**Spatial-Temporal Aware Visuomotor Diffusion Policy Learning**|Yanwei Fu Team|[2507.06710](http://arxiv.org/abs/2507.06710)|null|\n", "2507.06701": "|**2025-07-09**|**Value from Observations: Towards Large-Scale Imitation Learning via Self-Improvement**|Martin Riedmiller Team|[2507.06701](http://arxiv.org/abs/2507.06701)|null|\n", "2507.06628": "|**2025-07-09**|**Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning**|Jian Cheng Team|[2507.06628](http://arxiv.org/abs/2507.06628)|null|\n", "2507.06625": "|**2025-07-09**|**Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic**|Fabio Ramos Team|[2507.06625](http://arxiv.org/abs/2507.06625)|null|\n", "2507.06543": "|**2025-07-09**|**Token Bottleneck: One Token to Remember Dynamics**|Sangdoo Yun Team|[2507.06543](http://arxiv.org/abs/2507.06543)|null|\n", "2507.06404": "|**2025-07-08**|**Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction**|Alessio Del Bue Team|[2507.06404](http://arxiv.org/abs/2507.06404)|null|\n", "2507.07986": "|**2025-07-15**|**EXPO: Stable Reinforcement Learning with Expressive Policies**|Chelsea Finn Team|[2507.07986](http://arxiv.org/abs/2507.07986)|null|\n", "2507.07969": "|**2025-07-15**|**Reinforcement Learning with Action Chunking**|Sergey Levine Team|[2507.07969](http://arxiv.org/abs/2507.07969)|null|\n", "2507.07221": "|**2025-07-09**|**Self-Wearing Adaptive Garments via Soft Robotic Unfurling**|Allison M. Okamura Team|[2507.07221](http://arxiv.org/abs/2507.07221)|null|\n", "2507.08726": "|**2025-07-11**|**Learning human-to-robot handovers through 3D scene reconstruction**|Changjae Oh Team|[2507.08726](http://arxiv.org/abs/2507.08726)|null|\n", "2507.08303": "|**2025-07-11**|**Learning Robust Motion Skills via Critical Adversarial Attacks for Humanoid Robots**|Yue Gao Team|[2507.08303](http://arxiv.org/abs/2507.08303)|null|\n", "2507.08262": "|**2025-07-11**|**CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations**|He Wang Team|[2507.08262](http://arxiv.org/abs/2507.08262)|null|\n", "2507.08112": "|**2025-07-10**|**Imitation Learning for Obstacle Avoidance Using End-to-End CNN-Based Sensor Fusion**|Raafat E. Shalaby Team|[2507.08112](http://arxiv.org/abs/2507.08112)|null|\n", "2507.10543": "|**2025-07-14**|**MP1: Mean Flow Tames Policy Learning in 1-step for Robotic Manipulation**|Mengyuan Liu Team|[2507.10543](http://arxiv.org/abs/2507.10543)|null|\n", "2507.10284": "|**2025-07-14**|**Prompt Informed Reinforcement Learning for Visual Coverage Path Planning**|Venkat Margapuri Team|[2507.10284](http://arxiv.org/abs/2507.10284)|null|\n", "2507.10174": "|**2025-07-14**|**Should We Ever Prefer Decision Transformer for Offline Reinforcement Learning?**|Keith Ross Team|[2507.10174](http://arxiv.org/abs/2507.10174)|null|\n", "2507.10158": "|**2025-07-16**|**MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping**|Monowar Bhuyan Team|[2507.10158](http://arxiv.org/abs/2507.10158)|null|\n", "2507.09540": "|**2025-07-13**|**Learning to Control Dynamical Agents via Spiking Neural Networks and Metropolis-Hastings Sampling**|Ali Al-Zawqari Team|[2507.09540](http://arxiv.org/abs/2507.09540)|null|\n", "2507.09537": "|**2025-07-13**|**Self-supervised Pretraining for Integrated Prediction and Planning of Automated Vehicles**|Keqiang Li Team|[2507.09537](http://arxiv.org/abs/2507.09537)|null|\n", "2507.09459": "|**2025-07-13**|**SegVec3D: A Method for Vector Embedding of 3D Objects Oriented Towards Robot manipulation**|Boyu Wang Team|[2507.09459](http://arxiv.org/abs/2507.09459)|null|\n", "2507.09305": "|**2025-07-12**|**DAA*: Deep Angular A Star for Image-based Path Planning**|Zhiwei Xu Team|[2507.09305](http://arxiv.org/abs/2507.09305)|null|\n", "2507.09180": "|**2025-07-15**|**Learning and Transferring Better with Depth Information in Visual Reinforcement Learning**|Jingdong Zhao Team|[2507.09180](http://arxiv.org/abs/2507.09180)|null|\n", "2507.09167": "|**2025-07-12**|**PRAG: Procedural Action Generator**|Karla Stepanova Team|[2507.09167](http://arxiv.org/abs/2507.09167)|null|\n", "2507.09117": "|**2025-07-12**|**Towards Human-level Dexterity via Robot Learning**|Gagan Khandate Team|[2507.09117](http://arxiv.org/abs/2507.09117)|null|\n", "2507.09061": "|**2025-07-11**|**Imitation Learning in Continuous Action Spaces: Mitigating Compounding Error without Interaction**|Max Simchowitz Team|[2507.09061](http://arxiv.org/abs/2507.09061)|null|\n", "2507.09041": "|**2025-07-11**|**Behavioral Exploration: Learning to Explore via In-Context Adaptation**|Sergey Levine Team|[2507.09041](http://arxiv.org/abs/2507.09041)|null|\n", "2507.11211": "|**2025-07-15**|**MPC-based Coarse-to-Fine Motion Planning for Robotic Object Transportation in Cluttered Environments**|Steven Liu Team|[2507.11211](http://arxiv.org/abs/2507.11211)|null|\n", "2507.11170": "|**2025-07-15**|**A Robust Controller based on Gaussian Processes for Robotic Manipulators with Unknown Uncertainty**|Ruggero Carli Team|[2507.11170](http://arxiv.org/abs/2507.11170)|null|\n", "2507.11006": "|**2025-07-15**|**Enhancing Autonomous Manipulator Control with Human-in-loop for Uncertain Assembly Environments**|Kazuya Yoshida Team|[2507.11006](http://arxiv.org/abs/2507.11006)|null|\n", "2507.10899": "|**2025-07-15**|**Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning**|Jun Morimoto Team|[2507.10899](http://arxiv.org/abs/2507.10899)|null|\n", "2507.10814": "|**2025-07-14**|**Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection**|Colin Bellinger Team|[2507.10814](http://arxiv.org/abs/2507.10814)|null|\n", "2507.10776": "|**2025-07-14**|**rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding**|Kaiyu Hang Team|[2507.10776](http://arxiv.org/abs/2507.10776)|null|\n", "2507.10775": "|**2025-07-14**|**A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers**|Arko Barman Team|[2507.10775](http://arxiv.org/abs/2507.10775)|null|\n", "2507.10672": "|**2025-07-14**|**Vision Language Action Models in Robotic Manipulation: A Systematic Review**|Irfan Hussain Team|[2507.10672](http://arxiv.org/abs/2507.10672)|null|\n", "2507.10628": "|**2025-07-16**|**GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning**|Dandan Tu Team|[2507.10628](http://arxiv.org/abs/2507.10628)|null|\n", "2507.12440": "|**2025-07-18**|**EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos**|Xiaolong Wang Team|[2507.12440](http://arxiv.org/abs/2507.12440)|null|\n", "2507.11840": "|**2025-07-16**|**The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey**|Jiming Chen Team|[2507.11840](http://arxiv.org/abs/2507.11840)|null|\n", "2507.11662": "|**2025-07-15**|**Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification**|Zsolt Kira Team|[2507.11662](http://arxiv.org/abs/2507.11662)|null|\n", "2507.13332": "|**2025-07-17**|**The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner**|Kai Chen Team|[2507.13332](http://arxiv.org/abs/2507.13332)|null|\n", "2507.13088": "|**2025-07-17**|**ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning**|Johannes A. Stork Team|[2507.13088](http://arxiv.org/abs/2507.13088)|null|\n", "2507.12898": "|**2025-07-17**|**Generalist Bimanual Manipulation via Foundation Video Diffusion Models**|Jun Zhu Team|[2507.12898](http://arxiv.org/abs/2507.12898)|null|\n", "2507.12856": "|**2025-07-17**|**Supervised Fine Tuning on Curated Data is Reinforcement Learning (and can be improved)**|Jost Tobias Springenberg Team|[2507.12856](http://arxiv.org/abs/2507.12856)|null|\n", "2507.12855": "|**2025-07-17**|**DEMONSTRATE: Zero-shot Language to Robotic Control via Multi-task Demonstration Learning**|Melanie N. Zeilinger Team|[2507.12855](http://arxiv.org/abs/2507.12855)|null|\n", "2507.12731": "|**2025-07-17**|**Learning to Predict Mobile Robot Stability in Off-Road Environments**|Parikshit Maini Team|[2507.12731](http://arxiv.org/abs/2507.12731)|null|\n", "2507.13602": "|**2025-07-18**|**Improving Low-Cost Teleoperation: Augmenting GELLO with Force**|Kai Arulkumaran Team|[2507.13602](http://arxiv.org/abs/2507.13602)|null|\n", "2507.15833": "|**2025-07-21**|**Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers**|Iman Soltani Team|[2507.15833](http://arxiv.org/abs/2507.15833)|null|\n", "2507.15693": "|**2025-07-21**|**Strong, Accurate, and Low-Cost Robot Manipulator**|Donghyun Kim Team|[2507.15693](http://arxiv.org/abs/2507.15693)|null|\n", "2507.15597": "|**2025-07-21**|**Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos**|Zongqing Lu Team|[2507.15597](http://arxiv.org/abs/2507.15597)|null|\n", "2507.15493": "|**2025-07-22**|**GR-3 Technical Report**|Yichu Yang Team|[2507.15493](http://arxiv.org/abs/2507.15493)|null|\n", "2507.15155": "|**2025-07-20**|**Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions**|Eric Diller Team|[2507.15155](http://arxiv.org/abs/2507.15155)|null|\n", "2507.15073": "|**2025-07-20**|**Reinforcement Learning for Flow-Matching Policies**|Somayeh Sojoudi Team|[2507.15073](http://arxiv.org/abs/2507.15073)|null|\n", "2507.15062": "|**2025-07-20**|**Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper**|Yunzhu Li Team|[2507.15062](http://arxiv.org/abs/2507.15062)|null|\n", "2507.14995": "|**2025-07-20**|**LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading**|Lu Zhang Team|[2507.14995](http://arxiv.org/abs/2507.14995)|null|\n", "2507.14967": "|**2025-07-20**|**Heterogeneous object manipulation on nonlinear soft surface through linear controller**|Andres Fai\u00f1a Team|[2507.14967](http://arxiv.org/abs/2507.14967)|null|\n", "2507.14820": "|**2025-07-20**|**KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning**|Guangyao Zhai Team|[2507.14820](http://arxiv.org/abs/2507.14820)|null|\n", "2507.14582": "|**2025-07-19**|**BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives**|Yongchun Fang Team|[2507.14582](http://arxiv.org/abs/2507.14582)|null|\n", "2507.16815": "|**2025-07-22**|**ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning**|Fu-En Yang Team|[2507.16815](http://arxiv.org/abs/2507.16815)|null|\n", "2507.16139": "|**2025-07-22**|**Equivariant Goal Conditioned Contrastive Reinforcement Learning**|Robert Platt Team|[2507.16139](http://arxiv.org/abs/2507.16139)|null|\n", "2507.17462": "|**2025-07-23**|**ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents**|Hesheng Wang Team|[2507.17462](http://arxiv.org/abs/2507.17462)|null|\n", "2507.17418": "|**2025-07-23**|**Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning**|Byeongjoon Noh Team|[2507.17418](http://arxiv.org/abs/2507.17418)|null|\n", "2507.17309": "|**2025-07-23**|**Confounded Causal Imitation Learning with Instrumental Variables**|Zhi Geng Team|[2507.17309](http://arxiv.org/abs/2507.17309)|null|\n", "2507.17275": "|**2025-07-23**|**Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning**|Takamitsu Matsubara Team|[2507.17275](http://arxiv.org/abs/2507.17275)|null|\n", "2507.17141": "|**2025-07-23**|**Towards Human-level Intelligence via Human-like Whole-Body Manipulation**|Zhaohui An Team|[2507.17141](http://arxiv.org/abs/2507.17141)|null|\n", "2507.17049": "|**2025-07-22**|**Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots**|Aitor Arrieta Team|[2507.17049](http://arxiv.org/abs/2507.17049)|null|\n", "2507.16842": "|**2025-07-19**|**Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning**|Charlie C. L. Wang Team|[2507.16842](http://arxiv.org/abs/2507.16842)|null|\n", "2508.00697": "|**2025-08-01**|**On-Device Diffusion Transformer Policy for Efficient Robot Manipulation**|Dong Xu Team|[2508.00697](http://arxiv.org/abs/2508.00697)|null|\n", "2508.00491": "|**2025-08-01**|**HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning**|Lorenzo Natale Team|[2508.00491](http://arxiv.org/abs/2508.00491)|null|\n", "2508.00261": "|**2025-08-01**|**Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning**|Dusit Niyato Team|[2508.00261](http://arxiv.org/abs/2508.00261)|null|\n", "2507.23734": "|**2025-07-31**|**RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping**|Jianbing Shen Team|[2507.23734](http://arxiv.org/abs/2507.23734)|**[link](https://github.com/wudongming97/AffordanceNet)**|\n", "2507.23682": "|**2025-07-31**|**villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models**|Jiang Bian Team|[2507.23682](http://arxiv.org/abs/2507.23682)|**[link](https://aka.ms/villa-x)**|\n", "2507.23523": "|**2025-08-01**|**H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation**|Jun Zhu Team|[2507.23523](http://arxiv.org/abs/2507.23523)|null|\n", "2507.23391": "|**2025-07-31**|**Policy Learning from Large Vision-Language Model Feedback without Reward Modeling**|Chang D. Yoo Team|[2507.23391](http://arxiv.org/abs/2507.23391)|null|\n", "2507.23053": "|**2025-07-30**|**In-between Motion Generation Based Multi-Style Quadruped Robot Locomotion**|Peng Lu Team|[2507.23053](http://arxiv.org/abs/2507.23053)|null|\n", "2507.22380": "|**2025-07-30**|**Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations**|Brendan Tidd Team|[2507.22380](http://arxiv.org/abs/2507.22380)|null|\n", "2507.22219": "|**2025-07-29**|**RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation**|Pengcheng He Team|[2507.22219](http://arxiv.org/abs/2507.22219)|null|\n", "2507.22042": "|**2025-07-29**|**A Nonlinear MPC Framework for Loco-Manipulation of Quadrupedal Robots with Non-Negligible Manipulator Dynamics**|Kaveh Akbari Hamed Team|[2507.22042](http://arxiv.org/abs/2507.22042)|null|\n", "2507.22028": "|**2025-07-29**|**From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning**|Bolei Zhou Team|[2507.22028](http://arxiv.org/abs/2507.22028)|null|\n", "2507.21981": "|**2025-07-29**|**DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments**|Guyue Zhou Team|[2507.21981](http://arxiv.org/abs/2507.21981)|null|\n", "2507.21796": "|**2025-07-29**|**MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects**|Joni Pajarinen Team|[2507.21796](http://arxiv.org/abs/2507.21796)|null|\n", "2507.21545": "|**2025-07-29**|**Pretraining a Unified PDDL Domain from Real-World Demonstrations for Generalizable Robot Task Planning**|Panpan Cai Team|[2507.21545](http://arxiv.org/abs/2507.21545)|null|\n", "2507.21533": "|**2025-07-29**|**Model Predictive Adversarial Imitation Learning for Planning from Observation**|Byron Boots Team|[2507.21533](http://arxiv.org/abs/2507.21533)|null|\n", "2507.21452": "|**2025-07-29**|**Retrieve-Augmented Generation for Speeding up Diffusion Policy without Additional Training**|Yutaka Matsuo Team|[2507.21452](http://arxiv.org/abs/2507.21452)|null|\n", "2507.21225": "|**2025-07-28**|**Fluidically Innervated Lattices Make Versatile and Durable Tactile Sensors**|Daniela Rus Team|[2507.21225](http://arxiv.org/abs/2507.21225)|null|\n", "2507.20622": "|**2025-07-28**|**FMimic: Foundation Models are Fine-grained Action Learners from Human Videos**|Yufeng Yue Team|[2507.20622](http://arxiv.org/abs/2507.20622)|null|\n", "2507.20445": "|**2025-07-28**|**Learning Physical Interaction Skills from Human Demonstrations**|Kwonjoon Lee Team|[2507.20445](http://arxiv.org/abs/2507.20445)|null|\n", "2508.05635": "|**2025-08-07**|**Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation**|Guanghui Ren Team|[2508.05635](http://arxiv.org/abs/2508.05635)|**[link](https://genie-envisioner.github.io/)**|\n", "2508.05634": "|**2025-08-07**|**Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling**|Jiachen Li Team|[2508.05634](http://arxiv.org/abs/2508.05634)|**[link](https://gen-safe-nav.github.io/.)**|\n", "2508.05584": "|**2025-08-07**|**Robust adaptive fuzzy sliding mode control for trajectory tracking for of cylindrical manipulator**|Nga Nguyen Thi Team|[2508.05584](http://arxiv.org/abs/2508.05584)|null|\n", "2508.05415": "|**2025-08-07**|**Do Robots Really Need Anthropomorphic Hands?**|Nicol\u00e1s Navarro-Guerrero Team|[2508.05415](http://arxiv.org/abs/2508.05415)|null|\n", "2508.05396": "|**2025-08-07**|**Real-Time Iteration Scheme for Diffusion Policy**|Danica Kragic Team|[2508.05396](http://arxiv.org/abs/2508.05396)|null|\n", "2508.05310": "|**2025-08-07**|**ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning**|Jens Kober Team|[2508.05310](http://arxiv.org/abs/2508.05310)|null|\n", "2508.05186": "|**2025-08-07**|**Learning to See and Act: Task-Aware View Planning for Robotic Manipulation**|Liang Lin Team|[2508.05186](http://arxiv.org/abs/2508.05186)|**[link](https://hcplab-sysu.github.io/TAVP)**|\n", "2508.05081": "|**2025-08-07**|**Cognitive Duality for Adaptive Web Agents**|Zheng Hu Team|[2508.05081](http://arxiv.org/abs/2508.05081)|null|\n", "2508.05077": "|**2025-08-07**|**Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning**|Temitope Lukman Adebanjo Team|[2508.05077](http://arxiv.org/abs/2508.05077)|null|\n", "2508.04931": "|**2025-08-06**|**INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM**|Nikos Tsagarakis Team|[2508.04931](http://arxiv.org/abs/2508.04931)|**[link](https://robo-intention.github.io)**|\n", "2508.04009": "|**2025-08-06**|**Optimization of sliding control parameters for a 3-dof robot arm using genetic algorithm (GA)**|Le Tieu Nien Team|[2508.04009](http://arxiv.org/abs/2508.04009)|null|\n", "2508.03944": "|**2025-08-05**|**Constraint-Preserving Data Generation for Visuomotor Policy Learning**|Jeannette Bohg Team|[2508.03944](http://arxiv.org/abs/2508.03944)|**[link](https://cp-gen.github.io)**|\n", "2508.03645": "|**2025-08-05**|**DiWA: Diffusion Policy Adaptation with World Models**|Abhinav Valada Team|[2508.03645](http://arxiv.org/abs/2508.03645)|null|\n", "2508.03218": "|**2025-08-05**|**ActionSink: Toward Precise Robot Manipulation with Dynamic Integration of Action Flow**|Xiaodan Liang Team|[2508.03218](http://arxiv.org/abs/2508.03218)|null|\n", "2508.03129": "|**2025-08-05**|**Safety-Aware Imitation Learning via MPC-Guided Disturbance Injection**|Somil Bansal Team|[2508.03129](http://arxiv.org/abs/2508.03129)|null|\n", "2508.03068": "|**2025-08-07**|**Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching**|C. Karen Liu Team|[2508.03068](http://arxiv.org/abs/2508.03068)|null|\n", "2508.03043": "|**2025-08-05**|**Aerobatic maneuvers in insect-scale flapping-wing aerial robots via deep-learned robust tube model predictive control**|YuFeng Chen Team|[2508.03043](http://arxiv.org/abs/2508.03043)|null|\n", "2508.02870": "|**2025-08-04**|**Learning User Interaction Forces using Vision for a Soft Finger Exosuit**|Thomas George Thuruthel Team|[2508.02870](http://arxiv.org/abs/2508.02870)|null|\n", "2508.02649": "|**2025-08-04**|**Manip4Care: Robotic Manipulation of Human Limbs for Solving Assistive Tasks**|Ahmed H. Qureshi Team|[2508.02649](http://arxiv.org/abs/2508.02649)|null|\n", "2508.02644": "|**2025-08-04**|**D2PPO: Diffusion Policy Policy Optimization with Dispersive Loss**|Haitao Wang Team|[2508.02644](http://arxiv.org/abs/2508.02644)|null|\n", "2508.06319": "|**2025-08-08**|**Towards Balanced Behavior Cloning from Imbalanced Datasets**|Dylan P. Losey Team|[2508.06319](http://arxiv.org/abs/2508.06319)|null|\n", "2508.06313": "|**2025-08-08**|**Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators**|Jouni Mattila Team|[2508.06313](http://arxiv.org/abs/2508.06313)|null|\n", "2508.06266": "|**2025-08-08**|**ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints**|Liming Chen Team|[2508.06266](http://arxiv.org/abs/2508.06266)|null|\n", "2508.06095": "|**2025-08-08**|**Incremental Language Understanding for Online Motion Planning of Robot Manipulators**|Matthias Scheutz Team|[2508.06095](http://arxiv.org/abs/2508.06095)|null|\n", "2508.06042": "|**2025-08-08**|**Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning**|Jonghyun Choi Team|[2508.06042](http://arxiv.org/abs/2508.06042)|null|\n", "2508.05976": "|**2025-08-08**|**PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation**|Yao Mu Team|[2508.05976](http://arxiv.org/abs/2508.05976)|null|\n", "2508.08170": "|**2025-08-11**|**ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction**|Wenjun Mei Team|[2508.08170](http://arxiv.org/abs/2508.08170)|null|\n", "2508.08113": "|**2025-08-11**|**AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies**|Joyce Chai Team|[2508.08113](http://arxiv.org/abs/2508.08113)|null|\n", "2508.07770": "|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Lei Han Team|[2508.07770](http://arxiv.org/abs/2508.07770)|null|\n", "2508.07650": "|**2025-08-11**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Hong Zhang Team|[2508.07650](http://arxiv.org/abs/2508.07650)|null|\n", "2508.07626": "|**2025-08-11**|**AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning**|Yang Liu Team|[2508.07626](http://arxiv.org/abs/2508.07626)|null|\n", "2508.07323": "|**2025-08-10**|**Collision-Free Trajectory Planning and control of Robotic Manipulator using Energy-Based Artificial Potential Field (E-APF)**|Manoranjan Sinha Team|[2508.07323](http://arxiv.org/abs/2508.07323)|null|\n", "2508.07287": "|**2025-08-10**|**Multimodal Spiking Neural Network for Space Robotic Manipulation**|Guanghui Sun Team|[2508.07287](http://arxiv.org/abs/2508.07287)|null|\n", "2508.07118": "|**2025-08-09**|**DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit**|Monroe Kennedy III Team|[2508.07118](http://arxiv.org/abs/2508.07118)|null|\n", "2508.07029": "|**2025-08-09**|**From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving**|Antonio Guillen-Perez Team|[2508.07029](http://arxiv.org/abs/2508.07029)|null|\n", "2508.06969": "|**2025-08-09**|**Manipulator for people with limited abilities**|Arkady Yuschenko Team|[2508.06969](http://arxiv.org/abs/2508.06969)|null|\n", "2508.06779": "|**2025-08-09**|**Learning a Vision-Based Footstep Planner for Hierarchical Walking Control**|Michael Posa Team|[2508.06779](http://arxiv.org/abs/2508.06779)|null|\n", "2508.09071": "|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Jiale Cao Team|[2508.09071](http://arxiv.org/abs/2508.09071)|**[link](https://linsun449.github.io/GeoVLA/)**|\n", "2508.08982": "|**2025-08-12**|**Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion**|Sehoon Ha Team|[2508.08982](http://arxiv.org/abs/2508.08982)|null|\n", "2508.08882": "|**2025-08-12**|**Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation**|Yang Li Team|[2508.08882](http://arxiv.org/abs/2508.08882)|null|\n", "2508.08748": "|**2025-08-12**|**Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT**|Yukiyasu Domae Team|[2508.08748](http://arxiv.org/abs/2508.08748)|null|\n", "2508.08707": "|**2025-08-12**|**Towards Safe Imitation Learning via Potential Field-Guided Flow Matching**|Yoshihiko Nakamura Team|[2508.08707](http://arxiv.org/abs/2508.08707)|null|\n", "2508.08706": "|**2025-08-12**|**OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing**|Hengdi Zhang Team|[2508.08706](http://arxiv.org/abs/2508.08706)|null|\n", "2508.10511": "|**2025-08-15**|**KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection**|Lorenzo Natale Team|[2508.10511](http://arxiv.org/abs/2508.10511)|null|\n", "2508.10399": "|**2025-08-14**|**Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning**|Ping Kuang Team|[2508.10399](http://arxiv.org/abs/2508.10399)|null|\n", "2508.10259": "|**2025-08-14**|**Leveraging OS-Level Primitives for Robotic Action Management**|Haibo Chen Team|[2508.10259](http://arxiv.org/abs/2508.10259)|null|\n", "2508.09976": "|**2025-08-13**|**Masquerade: Learning from In-the-wild Human Videos using Data-Editing**|Jeannette Bohg Team|[2508.09976](http://arxiv.org/abs/2508.09976)|**[link](https://masquerade-robot.github.io/)**|\n", "2508.09855": "|**2025-08-13**|**Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes**|Changjae Oh Team|[2508.09855](http://arxiv.org/abs/2508.09855)|null|\n", "2508.09822": "|**2025-08-13**|**Physical Autoregressive Model for Robotic Manipulation without Action Pretraining**|Guangrun Wang Team|[2508.09822](http://arxiv.org/abs/2508.09822)|null|\n", "2508.09700": "|**2025-08-13**|**Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions**|Jouni Mattila Team|[2508.09700](http://arxiv.org/abs/2508.09700)|null|\n", "2508.09558": "|**2025-08-13**|**CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail**|Fumin Zhang Team|[2508.09558](http://arxiv.org/abs/2508.09558)|null|\n", "2508.09502": "|**2025-08-13**|**Reactive Model Predictive Contouring Control for Robot Manipulators**|Jaeheung Park Team|[2508.09502](http://arxiv.org/abs/2508.09502)|null|\n", "2508.09444": "|**2025-08-13**|**DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation**|Liqiang Nie Team|[2508.09444](http://arxiv.org/abs/2508.09444)|null|\n", "2508.11537": "|**2025-08-15**|**MultiPark: Multimodal Parking Transformer with Next-Segment Prediction**|Tong Qin Team|[2508.11537](http://arxiv.org/abs/2508.11537)|null|\n", "2508.11275": "|**2025-08-15**|**Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation**|Fumio Kanehiro Team|[2508.11275](http://arxiv.org/abs/2508.11275)|null|\n", "2508.11204": "|**2025-08-15**|**Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation**|Kwok Wai Samuel Au Team|[2508.11204](http://arxiv.org/abs/2508.11204)|null|\n", "2508.11143": "|**2025-08-15**|**Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward**|Yu-Gang Jiang Team|[2508.11143](http://arxiv.org/abs/2508.11143)|null|\n", "2508.11117": "|**2025-08-14**|**Robot Policy Evaluation for Sim-to-Real Transfer: A Benchmarking Perspective**|Fabio Ramos Team|[2508.11117](http://arxiv.org/abs/2508.11117)|null|\n", "2508.11049": "|**2025-08-14**|**GenFlowRL: Shaping Rewards with Generative Object-Centric Flow in Visual Reinforcement Learning**|Ruohan Gao Team|[2508.11049](http://arxiv.org/abs/2508.11049)|null|\n", "2508.11002": "|**2025-08-14**|**3D FlowMatch Actor: Unified 3D Policy for Single- and Dual-Arm Manipulation**|Katerina Fragkiadaki Team|[2508.11002](http://arxiv.org/abs/2508.11002)|null|\n", "2508.13104": "|**2025-08-18**|**Precise Action-to-Video Generation Through Visual Action Prompts**|Ruizhen Hu Team|[2508.13104](http://arxiv.org/abs/2508.13104)|**[link](https://zju3dv.github.io/VAP/)**|\n", "2508.13103": "|**2025-08-18**|**Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy**|Zhi Hou Team|[2508.13103](http://arxiv.org/abs/2508.13103)|null|\n", "2508.13073": "|**2025-08-18**|**Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey**|Liqiang Nie Team|[2508.13073](http://arxiv.org/abs/2508.13073)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|\n", "2508.12554": "|**2025-08-18**|**PROD: Palpative Reconstruction of Deformable Objects through Elastostatic Signed Distance Functions**|Hamza El-Kebir Team|[2508.12554](http://arxiv.org/abs/2508.12554)|null|\n", "2508.12349": "|**2025-08-17**|**EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos**|Hesheng Wang Team|[2508.12349](http://arxiv.org/abs/2508.12349)|null|\n", "2508.12274": "|**2025-08-17**|**Bimanual Robot-Assisted Dressing: A Spherical Coordinate-Based Strategy for Tight-Fitting Garments**|Jihong Zhu Team|[2508.12274](http://arxiv.org/abs/2508.12274)|null|\n", "2508.12252": "|**2025-08-17**|**Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids**|Shuran Song Team|[2508.12252](http://arxiv.org/abs/2508.12252)|null|\n", "2508.12166": "|**2025-08-16**|**Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing**|Melkior Ornik Team|[2508.12166](http://arxiv.org/abs/2508.12166)|null|\n", "2508.12071": "|**2025-08-16**|**OASIS: Real-Time Opti-Acoustic Sensing for Intervention Systems in Unstructured Environments**|Richard Camilli Team|[2508.12071](http://arxiv.org/abs/2508.12071)|null|\n", "2508.12038": "|**2025-08-16**|**Fully Spiking Actor-Critic Neural Network for Robotic Manipulation**|Guanghui Sun Team|[2508.12038](http://arxiv.org/abs/2508.12038)|null|\n", "2508.11898": "|**2025-08-16**|**OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation**|Xiaozhu Ju Team|[2508.11898](http://arxiv.org/abs/2508.11898)|null|\n", "2508.11767": "|**2025-08-15**|**Limitation Learning: Catching Adverse Dialog with GAIL**|Rahul Zalkikar Team|[2508.11767](http://arxiv.org/abs/2508.11767)|null|\n", "2508.14042": "|**2025-08-19**|**Train Once, Deploy Anywhere: Realize Data-Efficient Dynamic Object Manipulation**|Hengshuang Zhao Team|[2508.14042](http://arxiv.org/abs/2508.14042)|null|\n", "2508.13998": "|**2025-08-19**|**Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation**|Jianye Hao Team|[2508.13998](http://arxiv.org/abs/2508.13998)|null|\n", "2508.13877": "|**2025-08-19**|**Toward Deployable Multi-Robot Collaboration via a Symbolically-Guided Decision Transformer**|Paul Asunda Team|[2508.13877](http://arxiv.org/abs/2508.13877)|null|\n", "2508.13326": "|**2025-08-18**|**Decoding Communications with Partial Information**|Peter McBurney Team|[2508.13326](http://arxiv.org/abs/2508.13326)|null|\n", "2508.14441": "|**2025-08-20**|**FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy**|Cewu Lu Team|[2508.14441](http://arxiv.org/abs/2508.14441)|null|\n", "2508.14383": "|**2025-08-20**|**Offline Imitation Learning upon Arbitrary Demonstrations by Pre-Training Dynamics Representations**|Na Li Team|[2508.14383](http://arxiv.org/abs/2508.14383)|null|\n", "2508.14379": "|**2025-08-20**|**Action-Constrained Imitation Learning**|Ping-Chun Hsieh Team|[2508.14379](http://arxiv.org/abs/2508.14379)|null|\n", "2508.14358": "|**2025-08-20**|**Learning Point Cloud Representations with Pose Continuity for Depth-Based Category-Level 6D Object Pose Estimation**|Ioannis Stamos Team|[2508.14358](http://arxiv.org/abs/2508.14358)|null|\n", "2508.15327": "|**2025-08-21**|**Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning**|Houqiang Li Team|[2508.15327](http://arxiv.org/abs/2508.15327)|null|\n", "2508.14994": "|**2025-08-20**|**A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot**|Marcelo Becker Team|[2508.14994](http://arxiv.org/abs/2508.14994)|null|\n", "2508.14926": "|**2025-08-19**|**Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving**|Ostap Okhrin Team|[2508.14926](http://arxiv.org/abs/2508.14926)|null|\n", "2508.15972": "|**2025-08-21**|**UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation**|Binbin Xu Team|[2508.15972](http://arxiv.org/abs/2508.15972)|**[link](https://frankzhaodong.github.io/UnPose)**|\n", "2508.15874": "|**2025-08-21**|**Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning**|Wenwu Zhu Team|[2508.15874](http://arxiv.org/abs/2508.15874)|null|\n", "2508.18269": "|**2025-08-26**|**FlowVLA: Thinking in Motion with a Visual Chain of Thought**|Haoang Li Team|[2508.18269](http://arxiv.org/abs/2508.18269)|null|\n", "2508.17986": "|**2025-08-25**|**No Need to Look! Locating and Grasping Objects by a Robot Arm Covered with Sensitive Skin**|Matej Hoffmann Team|[2508.17986](http://arxiv.org/abs/2508.17986)|null|\n", "2508.17643": "|**2025-08-25**|**SEBVS: Synthetic Event-based Visual Servoing for Robot Navigation and Manipulation**|Bharatesh Chakravarthi Team|[2508.17643](http://arxiv.org/abs/2508.17643)|null|\n", "2508.17600": "|**2025-08-25**|**GWM: Towards Scalable Gaussian World Models for Robotic Manipulation**|Siyuan Huang Team|[2508.17600](http://arxiv.org/abs/2508.17600)|**[link](https://gaussian-world-model.github.io/)**|\n", "2508.17547": "|**2025-08-24**|**LodeStar: Long-horizon Dexterity via Synthetic Data Augmentation from Human Demonstrations**|Hao Su Team|[2508.17547](http://arxiv.org/abs/2508.17547)|null|\n", "2508.17482": "|**2025-08-24**|**Variational Shape Inference for Grasp Diffusion on SE(3)**|Aniket Bera Team|[2508.17482](http://arxiv.org/abs/2508.17482)|null|\n", "2508.17452": "|**2025-08-24**|**ReviBranch: Deep Reinforcement Learning for Branch-and-Bound with Revived Trajectories**|Jiaping Xiao Team|[2508.17452](http://arxiv.org/abs/2508.17452)|null|\n", "2508.17449": "|**2025-08-24**|**Robotic Manipulation via Imitation Learning: Taxonomy, Evolution, Benchmark, and Challenges**|Liming Chen Team|[2508.17449](http://arxiv.org/abs/2508.17449)|null|\n", "2508.17260": "|**2025-08-24**|**OVITA: Open-Vocabulary Interpretable Trajectory Adaptations**|Ravi Prakash Team|[2508.17260](http://arxiv.org/abs/2508.17260)|**[link](https://github.com/anurag1000101/OVITA)**|\n", "2508.17230": "|**2025-08-24**|**4D Visual Pre-training for Robot Learning**|Huazhe Xu Team|[2508.17230](http://arxiv.org/abs/2508.17230)|null|\n", "2508.19236": "|**2025-08-26**|**MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation**|Gao Huang Team|[2508.19236](http://arxiv.org/abs/2508.19236)|**[link](https://shihao1895.github.io/MemoryVLA)**|\n", "2508.19204": "|**2025-08-26**|**LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding**|Felix Heide Team|[2508.19204](http://arxiv.org/abs/2508.19204)|**[link](https://light.princeton.edu/LSD-3D)**|\n", "2508.19191": "|**2025-08-27**|**AutoRing: Imitation Learning--based Autonomous Intraocular Foreign Body Removal Manipulation with Eye Surgical Robot**|Jian Wu Team|[2508.19191](http://arxiv.org/abs/2508.19191)|null|\n", "2508.19172": "|**2025-08-28**|**From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity**|Antoine Cully Team|[2508.19172](http://arxiv.org/abs/2508.19172)|null|\n", "2508.19152": "|**2025-08-26**|**Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games**|Chiu-Chou Lin Team|[2508.19152](http://arxiv.org/abs/2508.19152)|null|\n", "2508.18820": "|**2025-08-26**|**AS2FM: Enabling Statistical Model Checking of ROS 2 Systems for Robust Autonomy**|Matteo Morelli Team|[2508.18820](http://arxiv.org/abs/2508.18820)|null|\n", "2508.18802": "|**2025-08-26**|**HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation**|Yanchao Yang Team|[2508.18802](http://arxiv.org/abs/2508.18802)|null|\n", "2508.18691": "|**2025-08-26**|**Deep Sensorimotor Control by Imitating Predictive Models of Human Motion**|Antonio Loquercio Team|[2508.18691](http://arxiv.org/abs/2508.18691)|**[link](https://hgaurav2k.github.io/trackr/)**|\n", "2508.18627": "|**2025-08-26**|**Integration of Robot and Scene Kinematics for Sequential Mobile Manipulation Planning**|Song-Chun Zhu Team|[2508.18627](http://arxiv.org/abs/2508.18627)|null|\n", "2508.18443": "|**2025-08-25**|**PneuGelSight: Soft Robotic Vision-Based Proprioception and Tactile Sensing**|Wenzhen Yuan Team|[2508.18443](http://arxiv.org/abs/2508.18443)|null|\n", "2508.18399": "|**2025-08-25**|**Maintenance automation: methods for robotics manipulation planning and execution**|Alexander Verl Team|[2508.18399](http://arxiv.org/abs/2508.18399)|null|\n", "2508.20085": "|**2025-08-31**|**HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation**|Huazhe Xu Team|[2508.20085](http://arxiv.org/abs/2508.20085)|null|\n", "2508.19958": "|**2025-08-28**|**Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation**|Donglin Wang Team|[2508.19958](http://arxiv.org/abs/2508.19958)|**[link](https://long-vla.github.io)**|\n", "2508.19852": "|**2025-08-28**|**Ego-centric Predictive Model Conditioned on Hand Trajectories**|Mike Zheng Shou Team|[2508.19852](http://arxiv.org/abs/2508.19852)|null|\n", "2508.19790": "|**2025-08-27**|**APT*: Asymptotically Optimal Motion Planning via Adaptively Prolated Elliptical R-Nearest Neighbors**|Alois Knoll Team|[2508.19790](http://arxiv.org/abs/2508.19790)|null|\n", "2508.19607": "|**2025-08-27**|**Impedance Primitive-augmented Hierarchical Reinforcement Learning for Sequential Tasks**|Jens Kober Team|[2508.19607](http://arxiv.org/abs/2508.19607)|null|\n", "2508.19476": "|**2025-08-26**|**Gentle Object Retraction in Dense Clutter Using Multimodal Force Sensing and Imitation Learning**|Mark Cutkosky Team|[2508.19476](http://arxiv.org/abs/2508.19476)|null|\n", "2508.19391": "|**2025-08-26**|**LaVA-Man: Learning Visual Action Representations for Robot Manipulation**|Changjae Oh Team|[2508.19391](http://arxiv.org/abs/2508.19391)|null|\n", "2508.19367": "|**2025-08-26**|**Inference of Human-derived Specifications of Object Placement via Demonstration**|Julie A Shah Team|[2508.19367](http://arxiv.org/abs/2508.19367)|null|\n", "2508.21065": "|**2025-08-28**|**Learning on the Fly: Rapid Policy Adaptation via Differentiable Simulation**|Davide Scaramuzza Team|[2508.21065](http://arxiv.org/abs/2508.21065)|null|\n", "2508.21007": "|**2025-08-28**|**Rapid Mismatch Estimation via Neural Network Informed Variational Inference**|Nadia Figueroa Team|[2508.21007](http://arxiv.org/abs/2508.21007)|**[link](https://mateusz-jaszczuk.github.io/rme/)**|\n", "2508.20982": "|**2025-08-29**|**UltraTac: Integrated Ultrasound-Augmented Visuotactile Sensor for Enhanced Robotic Perception**|Wenbo Ding Team|[2508.20982](http://arxiv.org/abs/2508.20982)|null|\n", "2508.20884": "|**2025-08-28**|**Deep Fuzzy Optimization for Batch-Size and Nearest Neighbors in Optimal Robot Motion Planning**|Alois Knoll Team|[2508.20884](http://arxiv.org/abs/2508.20884)|null|\n", "2508.20840": "|**2025-08-28**|**Learning Primitive Embodied World Models: Towards Scalable Robotic Learning**|Qinying Gu Team|[2508.20840](http://arxiv.org/abs/2508.20840)|null|\n", "2508.20740": "|**2025-08-28**|**Non-expert to Expert Motion Translation Using Generative Adversarial Networks**|Seiichiro Katsura Team|[2508.20740](http://arxiv.org/abs/2508.20740)|null|\n", "2508.20561": "|**2025-08-28**|**SimShear: Sim-to-Real Shear-based Tactile Servoing**|Nathan F. Lepora Team|[2508.20561](http://arxiv.org/abs/2508.20561)|null|\n", "2508.21690": "|**2025-08-29**|**Can a mobile robot learn from a pedestrian model to prevent the sidewalk salsa?**|David Abbink Team|[2508.21690](http://arxiv.org/abs/2508.21690)|null|\n", "2508.21677": "|**2025-08-29**|**Robust Convex Model Predictive Control with collision avoidance guarantees for robot manipulators**|Thomas B. Sch\u00f6n Team|[2508.21677](http://arxiv.org/abs/2508.21677)|null|\n", "2508.21592": "|**2025-08-29**|**Learning Agile Gate Traversal via Analytical Optimal Policy Gradient**|Lin Zhao Team|[2508.21592](http://arxiv.org/abs/2508.21592)|null|\n", "2508.21549": "|**2025-08-29**|**Estimated Informed Anytime Search for Sampling-Based Planning via Adaptive Sampler**|Alois Knoll Team|[2508.21549](http://arxiv.org/abs/2508.21549)|null|\n", "2508.21501": "|**2025-08-29**|**Few-Shot Neuro-Symbolic Imitation Learning for Long-Horizon Planning and Acting**|Matthias Scheutz Team|[2508.21501](http://arxiv.org/abs/2508.21501)|null|\n", "2508.21378": "|**2025-08-29**|**RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation**|Yuanchao Shu Team|[2508.21378](http://arxiv.org/abs/2508.21378)|null|\n", "2508.21375": "|**2025-08-29**|**Dynamics-Compliant Trajectory Diffusion for Super-Nominal Payload Manipulation**|Alessandro Roncone Team|[2508.21375](http://arxiv.org/abs/2508.21375)|null|\n", "2508.21272": "|**2025-08-29**|**Learning to Assemble the Soma Cube with Legal-Action Masked DQN and Safe ZYZ Regrasp on a Doosan M0609**|Sawoong Kim Team|[2508.21272](http://arxiv.org/abs/2508.21272)|null|\n", "2509.03222": "|**2025-09-03**|**The Role of Embodiment in Intuitive Whole-Body Teleoperation for Mobile Manipulation**|Georgia Chalvatzaki Team|[2509.03222](http://arxiv.org/abs/2509.03222)|null|\n", "2509.03206": "|**2025-09-03**|**Autonomous Learning From Success and Failure: Goal-Conditioned Supervised Learning with Negative Feedback**|Daniel A. Braun Team|[2509.03206](http://arxiv.org/abs/2509.03206)|null|\n", "2509.03119": "|**2025-09-03**|**Forbal: Force Balanced 2-5 Degree of Freedom Robot Manipulator Built from a Five Bar Linkage**|Matteo Bottin Team|[2509.03119](http://arxiv.org/abs/2509.03119)|null|\n", "2509.02876": "|**2025-09-02**|**Generalizable Skill Learning for Construction Robots with Crowdsourced Natural Language Instructions, Composable Skills Standardization, and Large Language Model**|Carol C. Menassa Team|[2509.02876](http://arxiv.org/abs/2509.02876)|null|\n", "2509.02861": "|**2025-09-02**|**Power Grid Control with Graph-Based Distributed Reinforcement Learning**|Marcello Restelli Team|[2509.02861](http://arxiv.org/abs/2509.02861)|null|\n", "2509.02761": "|**2025-09-04**|**Plan Verification for LLM-Based Embodied Task Completion Agents**|Gokhan Tur Team|[2509.02761](http://arxiv.org/abs/2509.02761)|null|\n", "2509.02530": "|**2025-09-02**|**Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots**|Bingyi Kang Team|[2509.02530](http://arxiv.org/abs/2509.02530)|**[link](https://manipulation-as-in-simulation.github.io/)**|\n", "2509.02437": "|**2025-09-02**|**U-ARM : Ultra low-cost general teleoperation interface for robot manipulation**|Bo Zhao Team|[2509.02437](http://arxiv.org/abs/2509.02437)|null|\n", "2509.02055": "|**2025-09-05**|**Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance**|Xuelong Li Team|[2509.02055](http://arxiv.org/abs/2509.02055)|null|\n", "2509.01819": "|**2025-09-01**|**ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training**|Dieter Fox Team|[2509.01819](http://arxiv.org/abs/2509.01819)|null|\n", "2509.01765": "|**2025-09-01**|**Non-conflicting Energy Minimization in Reinforcement Learning based Robot Control**|Stefan Lee Team|[2509.01765](http://arxiv.org/abs/2509.01765)|null|\n", "2509.01746": "|**2025-09-01**|**Fail2Progress: Learning from Real-World Robot Failures with Stein Variational Inference**|Tucker Hermans Team|[2509.01746](http://arxiv.org/abs/2509.01746)|null|\n", "2509.01708": "|**2025-09-01**|**Articulated Object Estimation in the Wild**|Abhinav Valada Team|[2509.01708](http://arxiv.org/abs/2509.01708)|null|\n", "2509.01657": "|**2025-09-01**|**Data Retrieval with Importance Weights for Few-Shot Imitation Learning**|Joey Hejna Team|[2509.01657](http://arxiv.org/abs/2509.01657)|null|\n", "2509.01297": "|**2025-09-01**|**Disentangled Multi-Context Meta-Learning: Unlocking robust and Generalized Task Learning**|Seongil Hong Team|[2509.01297](http://arxiv.org/abs/2509.01297)|null|\n", "2509.00836": "|**2025-08-31**|**One-Step Model Predictive Path Integral for Manipulator Motion Planning Using Configuration Space Distance Fields**|Kenji Kawashima Team|[2509.00836](http://arxiv.org/abs/2509.00836)|null|\n", "2509.00828": "|**2025-08-31**|**An Effective Trajectory Planning and an Optimized Path Planning for a 6-Degree-of-Freedom Robot Manipulator**|Masahiko Mikawa Team|[2509.00828](http://arxiv.org/abs/2509.00828)|null|\n", "2509.00823": "|**2025-08-31**|**Inverse Kinematics for a 6-Degree-of-Freedom Robot Manipulator Using Comprehensive Gr\u00f6bner Systems**|Masahiko Mikawa Team|[2509.00823](http://arxiv.org/abs/2509.00823)|null|\n", "2509.00574": "|**2025-08-30**|**Learning Dolly-In Filming From Demonstration Using a Ground-Based Robot**|Wenbin Li Team|[2509.00574](http://arxiv.org/abs/2509.00574)|null|\n", "2509.00499": "|**2025-08-30**|**NeuralSVCD for Efficient Swept Volume Collision Detection**|Beomjoon Kim Team|[2509.00499](http://arxiv.org/abs/2509.00499)|null|\n", "2509.04443": "|**2025-09-04**|**EMMA: Scaling Mobile Manipulation via Egocentric Human Data**|Danfei Xu Team|[2509.04443](http://arxiv.org/abs/2509.04443)|null|\n", "2509.04063": "|**2025-09-04**|**Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models**|Donglin Wang Team|[2509.04063](http://arxiv.org/abs/2509.04063)|null|\n", "2509.04018": "|**2025-09-04**|**FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction**|Jingtai Liu Team|[2509.04018](http://arxiv.org/abs/2509.04018)|null|\n", "2509.03893": "|**2025-09-04**|**Weakly-Supervised Learning of Dense Functional Correspondences**|Jiajun Wu Team|[2509.03893](http://arxiv.org/abs/2509.03893)|**[link](https://dense-functional-correspondence.github.io/)**|\n", "2509.03859": "|**2025-09-05**|**Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator**|Wei Xu Team|[2509.03859](http://arxiv.org/abs/2509.03859)|null|\n", "2509.05007": "|**2025-09-08**|**Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework**|Ji-Rong Wen Team|[2509.05007](http://arxiv.org/abs/2509.05007)|null|\n", "2509.04737": "|**2025-09-05**|**Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics**|Toshiaki Tsuji Team|[2509.04737](http://arxiv.org/abs/2509.04737)|null|\n", "2509.04658": "|**2025-09-04**|**Surformer v2: A Multimodal Classifier for Surface Understanding from Touch and Vision**|Noorbakhsh Amiri Golilarz Team|[2509.04658](http://arxiv.org/abs/2509.04658)|null|\n", "2509.04645": "|**2025-09-04**|**Planning from Point Clouds over Continuous Actions for Multi-object Rearrangement**|David Held Team|[2509.04645](http://arxiv.org/abs/2509.04645)|**[link](https://planning-from-point-clouds.github.io/))**|\n", "2509.04628": "|**2025-09-04**|**Action Chunking with Transformers for Image-Based Spacecraft Guidance and Control**|Richard Linares Team|[2509.04628](http://arxiv.org/abs/2509.04628)|null|\n", "2509.04535": "|**2025-09-04**|**In-Context Policy Adaptation via Cross-Domain Skill Diffusion**|Honguk Woo Team|[2509.04535](http://arxiv.org/abs/2509.04535)|null|\n", "2509.06953": "|**2025-09-08**|**Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments**|Deepak Pathak Team|[2509.06953](http://arxiv.org/abs/2509.06953)|null|\n", "2509.06932": "|**2025-09-10**|**LLaDA-VLA: Vision Language Diffusion Action Models**|Xiaoyan Sun Team|[2509.06932](http://arxiv.org/abs/2509.06932)|null|\n", "2509.06705": "|**2025-09-08**|**Cortex-Synth: Differentiable Topology-Aware 3D Skeleton Synthesis with Hierarchical Graph Attention**|Mohamed Zayaan S Team|[2509.06705](http://arxiv.org/abs/2509.06705)|null|\n", "2509.06656": "|**2025-09-08**|**Group Effect Enhanced Generative Adversarial Imitation Learning for Individual Travel Behavior Modeling under Incentives**|Zhenliang Ma Team|[2509.06656](http://arxiv.org/abs/2509.06656)|null|\n", "2509.06426": "|**2025-09-08**|**Musculoskeletal simulation of limb movement biomechanics in Drosophila melanogaster**|Pavan Ramdya Team|[2509.06426](http://arxiv.org/abs/2509.06426)|null|\n", "2509.06233": "|**2025-09-07**|**O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation**|Yen-Ling Kuo Team|[2509.06233](http://arxiv.org/abs/2509.06233)|**[link](https://o3afford.github.io/)**|\n", "2509.06048": "|**2025-09-07**|**Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness**|Zhendong Dai Team|[2509.06048](http://arxiv.org/abs/2509.06048)|**[link](https://authors.elsevier.com/c/1lgjX3HdG3supQ)**|\n", "2509.05547": "|**2025-09-06**|**TeleopLab: Accessible and Intuitive Teleoperation of a Robotic Manipulator for Remote Labs**|John Liu Team|[2509.05547](http://arxiv.org/abs/2509.05547)|null|\n", "2509.05513": "|**2025-09-05**|**OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation**|Yu Xiang Team|[2509.05513](http://arxiv.org/abs/2509.05513)|null|\n", "2509.05368": "|**2025-09-04**|**Long-Horizon Visual Imitation Learning via Plan and Code Reflection**|Yunde Jia Team|[2509.05368](http://arxiv.org/abs/2509.05368)|null|\n", "2509.07962": "|**2025-09-09**|**TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models**|Hao Zhao Team|[2509.07962](http://arxiv.org/abs/2509.07962)|**[link](https://zzongzheng0918.github.io/Torque-Aware-VLA.github.io/})**|\n", "2509.07957": "|**2025-09-09**|**Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation**|Yingbai Hu Team|[2509.07957](http://arxiv.org/abs/2509.07957)|null|\n", "2509.07953": "|**2025-09-09**|**RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction**|Aviral Kumar Team|[2509.07953](http://arxiv.org/abs/2509.07953)|null|\n", "2509.07445": "|**2025-09-09**|**Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions**|Nathan F. Lepora Team|[2509.07445](http://arxiv.org/abs/2509.07445)|null|\n", "2509.07216": "|**2025-09-08**|**Quantum Machine Learning and Grover's Algorithm for Quantum Optimization of Robotic Manipulators**|Howard Li Team|[2509.07216](http://arxiv.org/abs/2509.07216)|null|\n", "2509.07201": "|**2025-09-08**|**Design of Input-Output Observers for a Population of Systems with Bounded Frequency-Domain Variation using $DK$-iteration**|James Richard Forbes Team|[2509.07201](http://arxiv.org/abs/2509.07201)|null|\n", "2509.07162": "|**2025-09-08**|**First Plan Then Evaluate: Use a Vectorized Motion Planner for Grasping**|Tucker Hermans Team|[2509.07162](http://arxiv.org/abs/2509.07162)|null|\n", "2509.08775": "|**2025-09-11**|**Joint Model-based Model-free Diffusion for Planning with Constraints**|Shreyas Kousik Team|[2509.08775](http://arxiv.org/abs/2509.08775)|null|\n", "2509.08757": "|**2025-09-10**|**SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation**|Peter Stone Team|[2509.08757](http://arxiv.org/abs/2509.08757)|**[link](https://larg.github.io/socialnav-sub)**|\n", "2509.08435": "|**2025-09-10**|**PegasusFlow: Parallel Rolling-Denoising Score Sampling for Robot Diffusion Planner Flow Matching**|Liang Ding Team|[2509.08435](http://arxiv.org/abs/2509.08435)|null|\n", "2509.08354": "|**2025-09-10**|**Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration**|Huimin Lu Team|[2509.08354](http://arxiv.org/abs/2509.08354)|null|\n", "2509.08226": "|**2025-09-10**|**Input-gated Bilateral Teleoperation: An Easy-to-implement Force Feedback Teleoperation Method for Low-cost Hardware**|Tetsuya Ogata Team|[2509.08226](http://arxiv.org/abs/2509.08226)|null|\n", "2509.09674": "|**2025-09-11**|**SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning**|Ning Ding Team|[2509.09674](http://arxiv.org/abs/2509.09674)|null|\n", "2509.09671": "|**2025-09-11**|**Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration**|Wei Yang Team|[2509.09671](http://arxiv.org/abs/2509.09671)|null|\n", "2509.09546": "|**2025-09-11**|**A Neuromorphic Incipient Slip Detection System using Papillae Morphology**|Benjamin Ward-Cherrier Team|[2509.09546](http://arxiv.org/abs/2509.09546)|null|\n", "2509.09074": "|**2025-09-11**|**KoopMotion: Learning Almost Divergence Free Koopman Flow Fields for Motion Planning**|M. Ani Hsieh Team|[2509.09074](http://arxiv.org/abs/2509.09074)|null|\n", "2509.09893": "|**2025-09-11**|**Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision**|Yukiyasu Domae Team|[2509.09893](http://arxiv.org/abs/2509.09893)|null|\n", "2509.09863": "|**2025-09-11**|**Off Policy Lyapunov Stability in Reinforcement Learning**|Daniela Constantinescu Team|[2509.09863](http://arxiv.org/abs/2509.09863)|null|\n", "2509.09769": "|**2025-09-11**|**MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos**|Yuke Zhu Team|[2509.09769](http://arxiv.org/abs/2509.09769)|null|\n", "2509.12081": "|**2025-09-15**|**Deceptive Risk Minimization: Out-of-Distribution Generalization by Deceiving Distribution Shift Detectors**|Anirudha Majumdar Team|[2509.12081](http://arxiv.org/abs/2509.12081)|null|\n", "2509.12026": "|**2025-09-15**|**Imitation Learning as Return Distribution Matching**|Alberto Maria Metelli Team|[2509.12026](http://arxiv.org/abs/2509.12026)|null|\n", "2509.12008": "|**2025-09-15**|**Gesture-Based Robot Control Integrating Mm-wave Radar and Behavior Trees**|Stephan Sigg Team|[2509.12008](http://arxiv.org/abs/2509.12008)|null|\n", "2509.11959": "|**2025-09-15**|**Learning to Generate 4D LiDAR Sequences**|Wei Tsang Ooi Team|[2509.11959](http://arxiv.org/abs/2509.11959)|**[link](https://lidarcrafter.github.io/)**|\n", "2509.11880": "|**2025-09-15**|**Learning Representations in Video Game Agents with Supervised Contrastive Imitation Learning**|Tim Bradley Team|[2509.11880](http://arxiv.org/abs/2509.11880)|null|\n", "2509.11865": "|**2025-09-15**|**Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer**|Luhui Hu Team|[2509.11865](http://arxiv.org/abs/2509.11865)|null|\n", "2509.11839": "|**2025-09-17**|**TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning**|Donglin Wang Team|[2509.11839](http://arxiv.org/abs/2509.11839)|null|\n", "2509.11621": "|**2025-09-15**|**Inference-stage Adaptation-projection Strategy Adapts Diffusion Policy to Cross-manipulators Scenarios**|Alois Knoll Team|[2509.11621](http://arxiv.org/abs/2509.11621)|null|\n", "2509.11481": "|**2025-09-15**|**RAPTOR: A Foundation Policy for Quadrotor Control**|Giuseppe Loianno Team|[2509.11481](http://arxiv.org/abs/2509.11481)|null|\n", "2509.11417": "|**2025-09-17**|**Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations**|Xuanlin Li Team|[2509.11417](http://arxiv.org/abs/2509.11417)|**[link](https://gen-vla.github.io/)**|\n", "2509.11364": "|**2025-09-14**|**ActivePose: Active 6D Object Pose Estimation and Tracking for Robotic Manipulation**|Yizhao Wang Team|[2509.11364](http://arxiv.org/abs/2509.11364)|null|\n", "2509.11225": "|**2025-09-14**|**MEMBOT: Memory-Based Robot in Intermittent POMDP**|Eyan Noronha Team|[2509.11225](http://arxiv.org/abs/2509.11225)|null|\n", "2509.11185": "|**2025-09-14**|**SAMP: Spatial Anchor-based Motion Policy for Collision-Aware Robotic Manipulators**|Jun Ma Team|[2509.11185](http://arxiv.org/abs/2509.11185)|null|\n", "2509.11125": "|**2025-09-14**|**ManiVID-3D: Generalizable View-Invariant Reinforcement Learning for Robotic Manipulation via Disentangled 3D Representations**|Jun Ma Team|[2509.11125](http://arxiv.org/abs/2509.11125)|null|\n", "2509.11109": "|**2025-09-16**|**FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers**|Zhigong Song Team|[2509.11109](http://arxiv.org/abs/2509.11109)|null|\n", "2509.11090": "|**2025-09-14**|**End-to-End Visual Autonomous Parking via Control-Aided Attention**|Chen Feng Team|[2509.11090](http://arxiv.org/abs/2509.11090)|null|\n", "2509.11044": "|**2025-09-14**|**FragmentGPT: A Unified GPT Model for Fragment Growing, Linking, and Merging in Molecular Design**|Rick Stevens Team|[2509.11044](http://arxiv.org/abs/2509.11044)|null|\n", "2509.10952": "|**2025-09-13**|**ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation**|Danfei Xu Team|[2509.10952](http://arxiv.org/abs/2509.10952)|null|\n", "2509.13200": "|**2025-09-18**|**StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening**|Shayegan Omidshafiei Team|[2509.13200](http://arxiv.org/abs/2509.13200)|null|\n", "2509.13077": "|**2025-09-16**|**A Design Co-Pilot for Task-Tailored Manipulators**|Matthias Althoff Team|[2509.13077](http://arxiv.org/abs/2509.13077)|null|\n", "2509.12739": "|**2025-09-16**|**Deep Learning for Model-Free Prediction of Thermal States of Robot Joint Motors**|Eric Guiffo Kaigom Team|[2509.12739](http://arxiv.org/abs/2509.12739)|null|\n", "2509.12674": "|**2025-09-16**|**Safety filtering of robotic manipulation under environment uncertainty: a computational approach**|Martin Servin Team|[2509.12674](http://arxiv.org/abs/2509.12674)|null|\n", "2509.12618": "|**2025-09-16**|**ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation**|Feng Zheng Team|[2509.12618](http://arxiv.org/abs/2509.12618)|null|\n", "2509.12562": "|**2025-09-16**|**Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling**|Donglin Wang Team|[2509.12562](http://arxiv.org/abs/2509.12562)|null|\n", "2509.12531": "|**2025-09-16**|**Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning**|Sebastian W. Pattinson Team|[2509.12531](http://arxiv.org/abs/2509.12531)|null|\n", "2509.12379": "|**2025-09-15**|**Geometric Red-Teaming for Robotic Manipulation**|Zackory Erickson Team|[2509.12379](http://arxiv.org/abs/2509.12379)|null|\n", "2509.14159": "|**2025-09-17**|**MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies**|Negar Mehr Team|[2509.14159](http://arxiv.org/abs/2509.14159)|null|\n", "2509.14138": "|**2025-09-17**|**SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model**|Yiming Feng Team|[2509.14138](http://arxiv.org/abs/2509.14138)|null|\n", "2509.13903": "|**2025-09-17**|**PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models**|Dzmitry Tsetserukou Team|[2509.13903](http://arxiv.org/abs/2509.13903)|null|\n", "2509.13774": "|**2025-09-17**|**Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach**|Yangwei You Team|[2509.13774](http://arxiv.org/abs/2509.13774)|null|\n", "2509.13736": "|**2025-09-17**|**Motion Adaptation Across Users and Tasks for Exoskeletons via Meta-Learning**|Houcheng Li Team|[2509.13736](http://arxiv.org/abs/2509.13736)|null|\n", "2509.13731": "|**2025-09-17**|**Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings**|Changjoo Nam Team|[2509.13731](http://arxiv.org/abs/2509.13731)|null|\n", "2509.13692": "|**2025-09-17**|**HGACNet: Hierarchical Graph Attention Network for Cross-Modal Point Cloud Completion**|I-Ming Chen Team|[2509.13692](http://arxiv.org/abs/2509.13692)|null|\n", "2509.13579": "|**2025-09-16**|**TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning**|Yunqing Hu Team|[2509.13579](http://arxiv.org/abs/2509.13579)|null|\n", "2509.15212": "|**2025-09-18**|**RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation**|Xin Li Team|[2509.15212](http://arxiv.org/abs/2509.15212)|**[link](https://github.com/alibaba-damo-academy/RynnVLA-001)**|\n", "2509.15155": "|**2025-09-18**|**Self-Improving Embodied Foundation Models**|Igor Mordatch Team|[2509.15155](http://arxiv.org/abs/2509.15155)|null|\n", "2509.15071": "|**2025-09-18**|**A Nonlinear Scaling-based Design of Control Lyapunov-barrier Function for Relative Degree 2 Case and its Application to Safe Feedback Linearization**|Gyunghoon Park Team|[2509.15071](http://arxiv.org/abs/2509.15071)|null|\n", "2509.15042": "|**2025-09-18**|**Reinforcement Learning Agent for a 2D Shooter Game**|Hamza A. A. Gardi Team|[2509.15042](http://arxiv.org/abs/2509.15042)|null|\n", "2509.14967": "|**2025-09-19**|**Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery**|Yasuhisa Hasegawa Team|[2509.14967](http://arxiv.org/abs/2509.14967)|null|\n", "2509.14932": "|**2025-09-18**|**Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale**|Florian Walter Team|[2509.14932](http://arxiv.org/abs/2509.14932)|null|\n", "2509.14688": "|**2025-09-18**|**exUMI: Extensible Robot Teaching System with Action-aware Task-agnostic Tactile Representation**|Yong-Lu Li Team|[2509.14688](http://arxiv.org/abs/2509.14688)|null|\n", "2509.14548": "|**2025-09-18**|**SimCoachCorpus: A naturalistic dataset with language and trajectories for embodied teaching**|Guy Rosman Team|[2509.14548](http://arxiv.org/abs/2509.14548)|null|\n", "2509.14530": "|**2025-09-18**|**Learning to Pick: A Visuomotor Policy for Clustered Strawberry Picking**|Chen Peng Team|[2509.14530](http://arxiv.org/abs/2509.14530)|null|\n", "2509.14460": "|**2025-09-17**|**Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring**|Constantinos Chamzas Team|[2509.14460](http://arxiv.org/abs/2509.14460)|null|\n", "2509.14349": "|**2025-09-17**|**LeVR: A Modular VR Teleoperation Framework for Imitation Learning in Dexterous Manipulation**|Han Liu Team|[2509.14349](http://arxiv.org/abs/2509.14349)|null|\n", "2509.16122": "|**2025-09-19**|**Efficient Detection of Objects Near a Robot Manipulator via Miniature Time-of-Flight Sensors**|Michael Gleicher Team|[2509.16122](http://arxiv.org/abs/2509.16122)|null|\n", "2509.16072": "|**2025-09-19**|**I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models**|Mohamed Chetouani Team|[2509.16072](http://arxiv.org/abs/2509.16072)|null|\n", "2509.16053": "|**2025-09-19**|**Compose by Focus: Scene Graph-based Atomic Skills**|Heng Yang Team|[2509.16053](http://arxiv.org/abs/2509.16053)|null|\n", "2509.16037": "|**2025-09-19**|**Learning Safety for Obstacle Avoidance via Control Barrier Functions**|Calin A. Belta Team|[2509.16037](http://arxiv.org/abs/2509.16037)|null|\n", "2509.15880": "|**2025-09-19**|**Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder**|Ian Reid Team|[2509.15880](http://arxiv.org/abs/2509.15880)|**[link](https://evggt.github.io/)**|\n", "2509.15778": "|**2025-09-19**|**All-Electric Heavy-Duty Robotic Manipulator: Actuator Configuration Optimization and Sensorless Control**|Jouni Mattila Team|[2509.15778](http://arxiv.org/abs/2509.15778)|null|\n", "2509.15733": "|**2025-09-19**|**GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation**|Deli Zhao Team|[2509.15733](http://arxiv.org/abs/2509.15733)|null|\n", "2509.15717": "|**2025-09-19**|**Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference**|Yoshihiko Nakamura Team|[2509.15717](http://arxiv.org/abs/2509.15717)|null|\n", "2509.15443": "|**2025-09-18**|**Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning**|Haodong Zhang Team|[2509.15443](http://arxiv.org/abs/2509.15443)|null|\n", "2509.18084": "|**2025-09-22**|**ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces**|Zeyu Ren Team|[2509.18084](http://arxiv.org/abs/2509.18084)|**[link](https://bytewrist.github.io/)**|\n", "2509.18043": "|**2025-09-22**|**Prepare Before You Act: Learning From Humans to Rearrange Initial States**|Dylan P. Losey Team|[2509.18043](http://arxiv.org/abs/2509.18043)|null|\n", "2509.17964": "|**2025-09-22**|**FinFlowRL: An Imitation-Reinforcement Learning Framework for Adaptive Stochastic Control in Finance**|Ruixun Zhang Team|[2509.17964](http://arxiv.org/abs/2509.17964)|null|\n", "2509.17941": "|**2025-09-22**|**ComposableNav: Instruction-Following Navigation in Dynamic Environments via Composable Diffusion**|Joydeep Biswas Team|[2509.17941](http://arxiv.org/abs/2509.17941)|**[link](https://amrl.cs.utexas.edu/ComposableNav/)**|\n", "2509.17940": "|**2025-09-22**|**DriveDPO: Policy Learning via Safety DPO For End-to-End Autonomous Driving**|Zhaoxiang Zhang Team|[2509.17940](http://arxiv.org/abs/2509.17940)|null|\n", "2509.17783": "|**2025-09-23**|**RoboSeek: You Need to Interact with Your Objects**|Yatong Han Team|[2509.17783](http://arxiv.org/abs/2509.17783)|null|\n", "2509.17759": "|**2025-09-22**|**MotionTrans: Human VR Data Enable Motion-Level Learning for Robotic Manipulation Policies**|Yang Gao Team|[2509.17759](http://arxiv.org/abs/2509.17759)|null|\n", "2509.17750": "|**2025-09-22**|**EigenSafe: A Spectral Framework for Learning-Based Stochastic Safety Filtering**|H. Jin Kim Team|[2509.17750](http://arxiv.org/abs/2509.17750)|null|\n", "2509.17684": "|**2025-09-22**|**DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning**|Zidong Chen Team|[2509.17684](http://arxiv.org/abs/2509.17684)|null|\n", "2509.17450": "|**2025-09-22**|**Learning Dexterous Manipulation with Quantized Hand State**|Cewu Lu Team|[2509.17450](http://arxiv.org/abs/2509.17450)|null|\n", "2509.17381": "|**2025-09-22**|**Fast Trajectory Planner with a Reinforcement Learning-based Controller for Robotic Manipulators**|Hamidreza Kasaei Team|[2509.17381](http://arxiv.org/abs/2509.17381)|**[link](https://sites.google.com/view/ftp4rm/home)**|\n", "2509.17244": "|**2025-09-21**|**Scalable Multi Agent Diffusion Policies for Coverage Control**|Alejandro Ribeiro Team|[2509.17244](http://arxiv.org/abs/2509.17244)|null|\n", "2509.17204": "|**2025-09-21**|**Ratatouille: Imitation Learning Ingredients for Real-world Social Robot Navigation**|Timothy D. Barfoot Team|[2509.17204](http://arxiv.org/abs/2509.17204)|null|\n", "2509.17195": "|**2025-09-21**|**MAST: Multi-Agent Spatial Transformer for Learning to Collaborate**|Alejandro Ribeiro Team|[2509.17195](http://arxiv.org/abs/2509.17195)|null|\n", "2509.17125": "|**2025-09-21**|**Imagine2Act: Leveraging Object-Action Motion Consistency from Imagined Goals for Robotic Manipulation**|Hao Dong Team|[2509.17125](http://arxiv.org/abs/2509.17125)|null|\n", "2509.17057": "|**2025-09-21**|**RoboManipBaselines: A Unified Framework for Imitation Learning in Robotic Manipulation across Real and Simulated Environments**|Yukiyasu Domae Team|[2509.17057](http://arxiv.org/abs/2509.17057)|null|\n", "2509.17053": "|**2025-09-21**|**FILIC: Dual-Loop Force-Guided Imitation Learning with Impedance Torque Control for Contact-Rich Manipulation Tasks**|Guyue Zhou Team|[2509.17053](http://arxiv.org/abs/2509.17053)|null|\n", "2509.17010": "|**2025-09-21**|**Generalized Momenta-Based Koopman Formalism for Robust Control of Euler-Lagrangian Systems**|Jishnu Keshavan Team|[2509.17010](http://arxiv.org/abs/2509.17010)|null|\n", "2509.16894": "|**2025-09-21**|**End2Race: Efficient End-to-End Imitation Learning for Real-Time F1Tenth Racing**|Henry X. Liu Team|[2509.16894](http://arxiv.org/abs/2509.16894)|null|\n", "2509.16834": "|**2025-09-20**|**Robot Learning with Sparsity and Scarcity**|Jingxi Xu Team|[2509.16834](http://arxiv.org/abs/2509.16834)|null|\n", "2509.19292": "|**2025-09-23**|**SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration**|Cewu Lu Team|[2509.19292](http://arxiv.org/abs/2509.19292)|null|\n", "2509.19261": "|**2025-09-23**|**Imitation-Guided Bimanual Planning for Stable Manipulation under Changing External Forces**|Arash Ajoudani Team|[2509.19261](http://arxiv.org/abs/2509.19261)|null|\n", "2509.19102": "|**2025-09-23**|**FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation**|Jianwei Zhang Team|[2509.19102](http://arxiv.org/abs/2509.19102)|**[link](https://sites.google.com/view/funcanon)**|\n", "2509.19080": "|**2025-09-23**|**World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation**|Dongbin Zhao Team|[2509.19080](http://arxiv.org/abs/2509.19080)|null|\n", "2509.19047": "|**2025-09-23**|**ManipForce: Force-Guided Policy Learning with Frequency-Aware Representation for Contact-Rich Manipulation**|Kyoobin Lee Team|[2509.19047](http://arxiv.org/abs/2509.19047)|null|\n", "2509.18953": "|**2025-09-23**|**Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations**|Wen Yao Team|[2509.18953](http://arxiv.org/abs/2509.18953)|null|\n", "2509.18865": "|**2025-09-23**|**Bi-VLA: Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation**|Thanpimon Buamanee Team|[2509.18865](http://arxiv.org/abs/2509.18865)|null|\n", "2509.18830": "|**2025-09-23**|**DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation**|Jiajun Wu Team|[2509.18830](http://arxiv.org/abs/2509.18830)|null|\n", "2509.18778": "|**2025-09-23**|**VGGT-DP: Generalizable Robot Control via Vision Foundation Models**|Zhi Wang Team|[2509.18778](http://arxiv.org/abs/2509.18778)|null|\n", "2509.18757": "|**2025-09-23**|**MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning**|Fares Abu-Dakka Team|[2509.18757](http://arxiv.org/abs/2509.18757)|**[link](https://mv-umi.github.io)**|\n", "2509.18734": "|**2025-09-23**|**Learning Obstacle Avoidance using Double DQN for Quadcopter Navigation**|Sanket Gujar Team|[2509.18734](http://arxiv.org/abs/2509.18734)|null|\n", "2509.18676": "|**2025-09-23**|**3D Flow Diffusion Policy: Visuomotor Policy Learning via Generating Flow in 3D Space**|Kyoobin Lee Team|[2509.18676](http://arxiv.org/abs/2509.18676)|null|\n", "2509.18644": "|**2025-09-24**|**Do You Need Proprioceptive States in Visuomotor Policies?**|Yang Gao Team|[2509.18644](http://arxiv.org/abs/2509.18644)|**[link](https://statefreepolicy.github.io)**|\n", "2509.18631": "|**2025-09-23**|**Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training**|Danfei Xu Team|[2509.18631](http://arxiv.org/abs/2509.18631)|null|\n", "2509.18610": "|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Mac Schwager Team|[2509.18610](http://arxiv.org/abs/2509.18610)|null|\n", "2509.18597": "|**2025-09-23**|**Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills**|Alois Knoll Team|[2509.18597](http://arxiv.org/abs/2509.18597)|null|\n", "2509.18581": "|**2025-09-23**|**A scaling law for large-deformation contact in soft materials**|Huajian Gao Team|[2509.18581](http://arxiv.org/abs/2509.18581)|null|\n", "2509.18463": "|**2025-09-22**|**Robotic Skill Diversification via Active Mutation of Reward Functions in Reinforcement Learning During a Liquid Pouring Task**|Luka Peternel Team|[2509.18463](http://arxiv.org/abs/2509.18463)|null|\n", "2509.18455": "|**2025-09-22**|**Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands**|Daniel Seita Team|[2509.18455](http://arxiv.org/abs/2509.18455)|null|\n", "2509.18447": "|**2025-09-22**|**PrioriTouch: Adapting to User Contact Preferences for Whole-Arm Physical Human-Robot Interaction**|Tapomayukh Bhattacharjee Team|[2509.18447](http://arxiv.org/abs/2509.18447)|null|\n", "2509.20297": "|**2025-09-26**|**mindmap: Spatial Memory in Deep Feature Maps for 3D Action Policies**|Shiwei Sheng Team|[2509.20297](http://arxiv.org/abs/2509.20297)|null|\n", "2509.20109": "|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Xianpeng Lang Team|[2509.20109](http://arxiv.org/abs/2509.20109)|null|\n", "2509.20070": "|**2025-09-24**|**LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs**|Amir Barati Farimani Team|[2509.20070](http://arxiv.org/abs/2509.20070)|null|\n", "2509.19958": "|**2025-09-24**|**Generalist Robot Manipulation beyond Action Labeled Data**|Danda Pani Paudel Team|[2509.19958](http://arxiv.org/abs/2509.19958)|null|\n", "2509.19853": "|**2025-09-24**|**SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process**|JingYuan Wang Team|[2509.19853](http://arxiv.org/abs/2509.19853)|null|\n", "2509.19712": "|**2025-09-24**|**TopoCut: Learning Multi-Step Cutting with Spectral Rewards and Discrete Diffusion Policies**|Animesh Garg Team|[2509.19712](http://arxiv.org/abs/2509.19712)|null|\n", "2509.19658": "|**2025-09-24**|**RoboSSM: Scalable In-context Imitation Learning via State-Space Models**|Peter Stone Team|[2509.19658](http://arxiv.org/abs/2509.19658)|null|\n", "2509.19626": "|**2025-09-23**|**EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data**|Danfei Xu Team|[2509.19626](http://arxiv.org/abs/2509.19626)|null|\n", "2509.19597": "|**2025-09-23**|**From Space to Time: Enabling Adaptive Safety with Learned Value Functions via Disturbance Recasting**|Sylvia L. Herbert Team|[2509.19597](http://arxiv.org/abs/2509.19597)|null|\n", "2509.19571": "|**2025-09-23**|**Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action**|Liam Paull Team|[2509.19571](http://arxiv.org/abs/2509.19571)|**[link](https://montrealrobotics.ca/agentic-scene-policies.github.io/)**|\n", "2509.19524": "|**2025-09-23**|**Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation**|Chi-Guhn Lee Team|[2509.19524](http://arxiv.org/abs/2509.19524)|null|\n", "2509.19460": "|**2025-09-23**|**Self-evolved Imitation Learning in Simulated World**|Zhihe Lu Team|[2509.19460](http://arxiv.org/abs/2509.19460)|null|\n", "2509.19454": "|**2025-09-23**|**ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation**|Daniel Seita Team|[2509.19454](http://arxiv.org/abs/2509.19454)|null|\n", "2509.21172": "|**2025-09-25**|**Inverse Reinforcement Learning Using Just Classification and a Few Regressions**|Aur\u00e9lien Bibaut Team|[2509.21172](http://arxiv.org/abs/2509.21172)|null|\n", "2509.20841": "|**2025-09-25**|**ImaginationPolicy: Towards Generalizable, Precise and Reliable End-to-End Policy for Robotic Manipulation**|Kui Jia Team|[2509.20841](http://arxiv.org/abs/2509.20841)|**[link](https://sites.google.com/view/imaginationpolicy)**|\n", "2509.20703": "|**2025-09-25**|**Joint Flow Trajectory Optimization For Feasible Robot Motion Generation from Video Demonstrations**|Weiming Zhi Team|[2509.20703](http://arxiv.org/abs/2509.20703)|null|\n", "2509.20579": "|**2025-09-24**|**Large Pre-Trained Models for Bimanual Manipulation in 3D**|David Meger Team|[2509.20579](http://arxiv.org/abs/2509.20579)|null|\n", "2509.20541": "|**2025-09-24**|**Selective Progress-Aware Querying for Human-in-the-Loop Reinforcement Learning**|Anamika J H Team|[2509.20541](http://arxiv.org/abs/2509.20541)|null|\n", "2509.22652": "|**2025-09-26**|**Pixel Motion Diffusion is What We Need for Robot Control**|Michael S. Ryoo Team|[2509.22652](http://arxiv.org/abs/2509.22652)|null|\n", "2509.22643": "|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Ziwei Wang Team|[2509.22643](http://arxiv.org/abs/2509.22643)|null|\n", "2509.22601": "|**2025-09-26**|**Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning**|Xing Sun Team|[2509.22601](http://arxiv.org/abs/2509.22601)|null|\n", "2509.22578": "|**2025-09-26**|**EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation**|Liang Wang Team|[2509.22578](http://arxiv.org/abs/2509.22578)|null|\n", "2509.22442": "|**2025-09-26**|**Learning to Ball: Composing Policies for Long-Horizon Basketball Moves**|C. Karen Liu Team|[2509.22442](http://arxiv.org/abs/2509.22442)|**[link](http://pei-xu.github.io/basketball.)**|\n", "2509.22407": "|**2025-09-26**|**EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer**|Guan Huang Team|[2509.22407](http://arxiv.org/abs/2509.22407)|null|\n", "2509.22402": "|**2025-09-26**|**ReLAM: Learning Anticipation Model for Rewarding Visual Robotic Manipulation**|Yang Yu Team|[2509.22402](http://arxiv.org/abs/2509.22402)|null|\n", "2509.22356": "|**2025-09-26**|**RoboView-Bias: Benchmarking Visual Bias in Embodied Agents for Robotic Manipulation**|Shuchao Pang Team|[2509.22356](http://arxiv.org/abs/2509.22356)|null|\n", "2509.22149": "|**2025-09-26**|**DemoGrasp: Universal Dexterous Grasping from a Single Demonstration**|Zongqing Lu Team|[2509.22149](http://arxiv.org/abs/2509.22149)|null|\n", "2509.22093": "|**2025-09-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Chang Xu Team|[2509.22093](http://arxiv.org/abs/2509.22093)|null|\n", "2509.22023": "|**2025-09-26**|**Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error**|Christos Tzamos Team|[2509.22023](http://arxiv.org/abs/2509.22023)|null|\n", "2509.21878": "|**2025-09-26**|**WAVE: Worm Gear-based Adaptive Variable Elasticity for Decoupling Actuators from External Forces**|Kazutoshi Tanaka Team|[2509.21878](http://arxiv.org/abs/2509.21878)|null|\n", "2509.21810": "|**2025-09-26**|**Learning Multi-Skill Legged Locomotion Using Conditional Adversarial Motion Priors**|Qinchuan Li Team|[2509.21810](http://arxiv.org/abs/2509.21810)|null|\n", "2509.21776": "|**2025-09-26**|**The Turkish Ice Cream Robot: Examining Playful Deception in Social Human-Robot Interactions**|Matthew Pan Team|[2509.21776](http://arxiv.org/abs/2509.21776)|**[link](https://hyeonseong-kim98.github.io/turkish-ice-cream-robot/)**|\n", "2509.21664": "|**2025-09-25**|**Generating Stable Placements via Physics-guided Diffusion Models**|Jonathan Kelly Team|[2509.21664](http://arxiv.org/abs/2509.21664)|null|\n", "2509.25097": "|**2025-10-01**|**Curriculum Imitation Learning of Distributed Multi-Robot Policies**|Eduardo Montijano Team|[2509.25097](http://arxiv.org/abs/2509.25097)|null|\n", "2509.24972": "|**2025-09-29**|**Annotation-Free One-Shot Imitation Learning for Multi-Step Manipulation Tasks**|Ruchi Choudhary Team|[2509.24972](http://arxiv.org/abs/2509.24972)|null|\n", "2509.24956": "|**2025-09-29**|**MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation**|Abhinav Valada Team|[2509.24956](http://arxiv.org/abs/2509.24956)|null|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Qing Zhang Team|[2509.24948](http://arxiv.org/abs/2509.24948)|null|\n", "2509.24917": "|**2025-09-29**|**From Code to Action: Hierarchical Learning of Diffusion-VLM Policies**|Daniel Dijkman Team|[2509.24917](http://arxiv.org/abs/2509.24917)|null|\n", "2509.24784": "|**2025-09-29**|**Quantifying Generalisation in Imitation Learning**|Odinaldo Rodrigues Team|[2509.24784](http://arxiv.org/abs/2509.24784)|null|\n", "2509.24768": "|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Ville Kyrki Team|[2509.24768](http://arxiv.org/abs/2509.24768)|null|\n", "2509.24697": "|**2025-09-29**|**Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering**|Daniele Pucci Team|[2509.24697](http://arxiv.org/abs/2509.24697)|null|\n", "2509.24661": "|**2025-09-29**|**CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations**|Shan Luo Team|[2509.24661](http://arxiv.org/abs/2509.24661)|null|\n", "2509.24579": "|**2025-09-29**|**U-DiT Policy: U-shaped Diffusion Transformers for Robotic Manipulation**|Zhongxue Gan Team|[2509.24579](http://arxiv.org/abs/2509.24579)|null|\n", "2509.24539": "|**2025-09-29**|**Unlocking the Potential of Soft Actor-Critic for Imitation Learning**|Frank Kirchner Team|[2509.24539](http://arxiv.org/abs/2509.24539)|null|\n", "2509.24313": "|**2025-09-29**|**Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning**|Johannes Betz Team|[2509.24313](http://arxiv.org/abs/2509.24313)|null|\n", "2509.24241": "|**2025-09-29**|**FreeAction: Training-Free Techniques for Enhanced Fidelity of Trajectory-to-Video Generation**|Minsu Cho Team|[2509.24241](http://arxiv.org/abs/2509.24241)|null|\n", "2509.24219": "|**2025-09-29**|**ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning**|Yang You Team|[2509.24219](http://arxiv.org/abs/2509.24219)|null|\n", "2509.24163": "|**2025-09-29**|**Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models**|Sethu Vijayakumar Team|[2509.24163](http://arxiv.org/abs/2509.24163)|null|\n", "2509.24160": "|**2025-09-29**|**Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation**|Yang You Team|[2509.24160](http://arxiv.org/abs/2509.24160)|null|\n", "2509.24129": "|**2025-09-28**|**Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress**|Kristen Grauman Team|[2509.24129](http://arxiv.org/abs/2509.24129)|null|\n", "2509.23829": "|**2025-09-28**|**DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation**|Yuanpei Chen Team|[2509.23829](http://arxiv.org/abs/2509.23829)|null|\n", "2509.23823": "|**2025-09-28**|**Control Your Robot: A Unified System for Robot Control and Policy Deployment**|Bingshan Hu Team|[2509.23823](http://arxiv.org/abs/2509.23823)|**[link](https://github.com/Tian-Nian/control_your_robot)**|\n", "2509.23778": "|**2025-09-30**|**Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse**|Ying Wen Team|[2509.23778](http://arxiv.org/abs/2509.23778)|null|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Shanghang Zhang Team|[2509.26642](http://arxiv.org/abs/2509.26642)|null|\n", "2509.26513": "|**2025-09-30**|**Learning from Hallucinating Critical Points for Navigation in Dynamic Environments**|Xuesu Xiao Team|[2509.26513](http://arxiv.org/abs/2509.26513)|null|\n", "2509.26308": "|**2025-09-30**|**Anomaly detection for generic failure monitoring in robotic assembly, screwing and manipulation**|Kevin Haninger Team|[2509.26308](http://arxiv.org/abs/2509.26308)|null|\n", "2509.26294": "|**2025-09-30**|**Noise-Guided Transport for Imitation Learning**|Alexandros Kalousis Team|[2509.26294](http://arxiv.org/abs/2509.26294)|null|\n", "2509.25852": "|**2025-09-30**|**Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation**|Hao Chen Team|[2509.25852](http://arxiv.org/abs/2509.25852)|null|\n", "2509.25822": "|**2025-10-01**|**Act to See, See to Act: Diffusion-Driven Perception-Action Interplay for Adaptive Policies**|Li Cheng Team|[2509.25822](http://arxiv.org/abs/2509.25822)|null|\n", "2509.25794": "|**2025-09-30**|**Point-It-Out: Benchmarking Embodied Reasoning for Vision Language Models in Multi-Stage Visual Grounding**|Jiaojiao Fan Team|[2509.25794](http://arxiv.org/abs/2509.25794)|null|\n", "2509.25756": "|**2025-09-30**|**SAC Flow: Sample-Efficient Reinforcement Learning of Flow-Based Policies via Velocity-Reparameterized Sequential Modeling**|Wenbo Ding Team|[2509.25756](http://arxiv.org/abs/2509.25756)|null|\n", "2509.25747": "|**2025-09-30**|**Best of Sim and Real: Decoupled Visuomotor Manipulation via Learning Control in Simulation and Perception in Real**|Yang Gao Team|[2509.25747](http://arxiv.org/abs/2509.25747)|null|\n", "2509.25411": "|**2025-09-29**|**Boolean Satisfiability via Imitation Learning**|Xiangyu Xu Team|[2509.25411](http://arxiv.org/abs/2509.25411)|null|\n", "2509.25402": "|**2025-09-29**|**Parallel Heuristic Search as Inference for Actor-Critic Reinforcement Learning Models**|Maxim Likhachev Team|[2509.25402](http://arxiv.org/abs/2509.25402)|null|\n", "2509.25358": "|**2025-09-29**|**SARM: Stage-Aware Reward Modeling for Long Horizon Robot Manipulation**|Philipp Wu Team|[2509.25358](http://arxiv.org/abs/2509.25358)|null|\n", "2509.25352": "|**2025-09-29**|**SRMP: Search-Based Robot Motion Planning Library**|Maxim Likhachev Team|[2509.25352](http://arxiv.org/abs/2509.25352)|null|\n", "2510.02298": "|**2025-10-02**|**ARMADA: Autonomous Online Failure Detection and Human Shared Control Empower Scalable Real-world Deployment and Adaptation**|Cewu Lu Team|[2510.02298](http://arxiv.org/abs/2510.02298)|null|\n", "2510.02268": "|**2025-10-02**|**Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning**|Matthew R. Walter Team|[2510.02268](http://arxiv.org/abs/2510.02268)|null|\n", "2510.02180": "|**2025-10-02**|**GRACE: A Language Model Framework for Explainable Inverse Reinforcement Learning**|Bogdan Mazoure Team|[2510.02180](http://arxiv.org/abs/2510.02180)|null|\n", "2510.02081": "|**2025-10-02**|**Fine-Tuning Flow Matching via Maximum Likelihood Estimation of Reconstructions**|Shihua Li Team|[2510.02081](http://arxiv.org/abs/2510.02081)|null|\n", "2510.01711": "|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Jinwoo Shin Team|[2510.01711](http://arxiv.org/abs/2510.01711)|null|\n", "2510.01661": "|**2025-10-02**|**Symskill: Symbol and Skill Co-Invention for Data-Efficient and Real-Time Long-Horizon Manipulation**|Nadia Figueroa Team|[2510.01661](http://arxiv.org/abs/2510.01661)|**[link](https://sites.google.com/view/symskill))**|\n", "2510.01642": "|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Bihan Wen Team|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|\n", "2510.01635": "|**2025-10-02**|**MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model**|Lili Wei Team|[2510.01635](http://arxiv.org/abs/2510.01635)|null|\n", "2510.01607": "|**2025-10-02**|**ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations**|Yi Xu Team|[2510.01607](http://arxiv.org/abs/2510.01607)|**[link](https://activeumi.github.io)**|\n", "2510.01603": "|**2025-10-02**|**MiniBEE: A New Form Factor for Compact Bimanual Dexterity**|Matei Ciocarlie Team|[2510.01603](http://arxiv.org/abs/2510.01603)|null|\n", "2510.01545": "|**2025-10-02**|**Predictive Preference Learning from Human Interventions**|Bolei Zhou Team|[2510.01545](http://arxiv.org/abs/2510.01545)|**[link](https://metadriverse.github.io/ppl)**|\n", "2510.01531": "|**2025-10-02**|**Information Seeking for Robust Decision Making under Partial Observability**|Tsung-Wei Ke Team|[2510.01531](http://arxiv.org/abs/2510.01531)|**[link](https://infoseekerllm.github.io)**|\n", "2510.01519": "|**2025-10-01**|**Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments**|Ahmed H. Qureshi Team|[2510.01519](http://arxiv.org/abs/2510.01519)|null|\n", "2510.01479": "|**2025-10-01**|**Density-Ratio Weighted Behavioral Cloning: Learning Control Policies from Corrupted Datasets**|Ali Baheri Team|[2510.01479](http://arxiv.org/abs/2510.01479)|null|\n", "2510.01433": "|**2025-10-01**|**AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation**|Pratap Tokekar Team|[2510.01433](http://arxiv.org/abs/2510.01433)|null|\n", "2510.01404": "|**2025-10-01**|**How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?**|Russ Tedrake Team|[2510.01404](http://arxiv.org/abs/2510.01404)|**[link](https://diffusion-learns-kinematic.github.io)**|\n", "2510.01184": "|**2025-10-01**|**Temporal Score Rescaling for Temperature Sampling in Diffusion and Flow Models**|Shubham Tulsiani Team|[2510.01184](http://arxiv.org/abs/2510.01184)|null|\n", "2510.01023": "|**2025-10-01**|**Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning**|D. Tsetserukou Team|[2510.01023](http://arxiv.org/abs/2510.01023)|null|\n", "2510.00922": "|**2025-10-01**|**On Discovering Algorithms for Adversarial Imitation Learning**|Pradeep Varakantham Team|[2510.00922](http://arxiv.org/abs/2510.00922)|null|\n", "2510.00906": "|**2025-10-01**|**TubeDAgger: Reducing the Number of Expert Interventions with Stochastic Reach-Tubes**|Sophie A. Neubauer Team|[2510.00906](http://arxiv.org/abs/2510.00906)|null|\n", "2510.03135": "|**2025-10-03**|**Mask2IV: Interaction-Centric Video Generation via Mask Trajectories**|Laura Sevilla-Lara Team|[2510.03135](http://arxiv.org/abs/2510.03135)|**[link](https://reagan1311.github.io/mask2iv)**|\n", "2510.03123": "|**2025-10-03**|**Learning Stability Certificate for Robotics in Real-World Environments**|Zhe Shen Team|[2510.03123](http://arxiv.org/abs/2510.03123)|null|\n", "2510.03013": "|**2025-10-06**|**Distributional Inverse Reinforcement Learning**|Anqi Wu Team|[2510.03013](http://arxiv.org/abs/2510.03013)|null|\n", "2510.02851": "|**2025-10-03**|**Action Deviation-Aware Inference for Low-Latency Wireless Robots**|Seong-Lyun Kim Team|[2510.02851](http://arxiv.org/abs/2510.02851)|null|\n", "2510.02738": "|**2025-10-03**|**Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data**|Nadia Figueroa Team|[2510.02738](http://arxiv.org/abs/2510.02738)|null|\n", "2510.02538": "|**2025-10-02**|**A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models**|Hao Su Team|[2510.02538](http://arxiv.org/abs/2510.02538)|null|\n", "2510.02526": "|**2025-10-02**|**U-LAG: Uncertainty-Aware, Lag-Adaptive Goal Retargeting for Robotic Manipulation**|Anujith Muraleedharan Team|[2510.02526](http://arxiv.org/abs/2510.02526)|null|\n", "2510.02493": "|**2025-10-02**|**Beyond Imitation: Recovering Dense Rewards from Demonstrations**|Gholamreza Haffari Team|[2510.02493](http://arxiv.org/abs/2510.02493)|null|\n", "2510.05013": "|**2025-10-06**|**Curiosity-Driven Co-Development of Action and Language in Robots Through Self-Exploration**|Jun Tani Team|[2510.05013](http://arxiv.org/abs/2510.05013)|null|\n", "2510.04781": "|**2025-10-06**|**Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization**|Arianna Traviglia Team|[2510.04781](http://arxiv.org/abs/2510.04781)|null|\n", "2510.04592": "|**2025-10-06**|**MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation**|Wenjie Song Team|[2510.04592](http://arxiv.org/abs/2510.04592)|null|\n", "2510.04354": "|**2025-10-05**|**Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators**|Anirudha Majumdar Team|[2510.04354](http://arxiv.org/abs/2510.04354)|null|\n", "2510.04333": "|**2025-10-05**|**RAP: 3D Rasterization Augmented End-to-End Planning**|Alexandre Alahi Team|[2510.04333](http://arxiv.org/abs/2510.04333)|null|\n", "2510.03895": "|**2025-10-04**|**NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation**|Chunhua Shen Team|[2510.03895](http://arxiv.org/abs/2510.03895)|null|\n", "2510.03706": "|**2025-10-04**|**EmbodiSwap for Zero-Shot Robot Imitation Learning**|Yiannis Aloimonos Team|[2510.03706](http://arxiv.org/abs/2510.03706)|**[link](https://drive.google.com/file/d/1UccngwgPqUwPMhBja7JrXfZoTquCx_Qe/view?usp=sharing)**|\n", "2510.03699": "|**2025-10-04**|**Dissecting Larval Zebrafish Hunting using Deep Reinforcement Learning Trained RNN Agents**|Kanaka Rajan Team|[2510.03699](http://arxiv.org/abs/2510.03699)|null|\n", "2510.03599": "|**2025-10-04**|**Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning**|Majid Khadiv Team|[2510.03599](http://arxiv.org/abs/2510.03599)|null|\n", "2510.03460": "|**2025-10-03**|**Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching**|Xiao Liang Team|[2510.03460](http://arxiv.org/abs/2510.03460)|null|\n", "2510.06207": "|**2025-10-07**|**EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model**|Zhaoxiang Zhang Team|[2510.06207](http://arxiv.org/abs/2510.06207)|**[link](https://anonymous.4open.science/w/Embodied-Coder/)**|\n", "2510.06179": "|**2025-10-07**|**Differentiable Model Predictive Control on the GPU**|Thomas Lew Team|[2510.06179](http://arxiv.org/abs/2510.06179)|null|\n", "2510.06127": "|**2025-10-07**|**Towards Autonomous Tape Handling for Robotic Wound Redressing**|Michael Yip Team|[2510.06127](http://arxiv.org/abs/2510.06127)|null|\n", "2510.05957": "|**2025-10-07**|**Learning to Crawl: Latent Model-Based Reinforcement Learning for Soft Robotic Adaptive Locomotion**|Robin Chhabra Team|[2510.05957](http://arxiv.org/abs/2510.05957)|null|\n", "2510.05827": "|**2025-10-07**|**VCoT-Grasp: Grasp Foundation Models with Visual Chain-of-Thought Reasoning for Language-driven Grasp Generation**|Badong Chen Team|[2510.05827](http://arxiv.org/abs/2510.05827)|null|\n", "2510.05662": "|**2025-10-07**|**DeLTa: Demonstration and Language-Guided Novel Transparent Object Manipulation**|Kuk-Jin Yoon Team|[2510.05662](http://arxiv.org/abs/2510.05662)|**[link](https://sites.google.com/view/DeLTa25/)**|\n", "2510.05619": "|**2025-10-07**|**Teaching Machines to Speak Using Articulatory Control**|Gopala Anumanchipalli Team|[2510.05619](http://arxiv.org/abs/2510.05619)|null|\n", "2510.05536": "|**2025-10-07**|**Correlation-Aware Dual-View Pose and Velocity Estimation for Dynamic Robotic Manipulation**|Farrokh Janabi-Sharifi Team|[2510.05536](http://arxiv.org/abs/2510.05536)|null|\n", "2510.05213": "|**2025-10-06**|**VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing**|Masayoshi Tomizuka Team|[2510.05213](http://arxiv.org/abs/2510.05213)|null|\n", "2510.07313": "|**2025-10-08**|**WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation**|Shanghang Zhang Team|[2510.07313](http://arxiv.org/abs/2510.07313)|null|\n", "2510.07181": "|**2025-10-09**|**TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics**|Shanghang Zhang Team|[2510.07181](http://arxiv.org/abs/2510.07181)|null|\n", "2510.06913": "|**2025-10-08**|**DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning**|Chen Lv Team|[2510.06913](http://arxiv.org/abs/2510.06913)|null|\n", "2510.06499": "|**2025-10-07**|**Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels**|Weiran Yao Team|[2510.06499](http://arxiv.org/abs/2510.06499)|null|\n", "2510.08558": "|**2025-10-09**|**Agent Learning via Early Experience**|Yifan Wu Team|[2510.08558](http://arxiv.org/abs/2510.08558)|null|\n", "2510.08547": "|**2025-10-09**|**R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation**|Jiwen Lu Team|[2510.08547](http://arxiv.org/abs/2510.08547)|**[link](https://r2rgen.github.io/)**|\n", "2510.08316": "|**2025-10-09**|**Unlocking 3D Affordance Segmentation with 2D Semantic Knowledge**|Wei Shen Team|[2510.08316](http://arxiv.org/abs/2510.08316)|null|\n", "2510.08022": "|**2025-10-09**|**FastUMI-100K: Advancing Data-driven Robotic Manipulation with a Large-scale UMI-style Dataset**|Xuelong Li Team|[2510.08022](http://arxiv.org/abs/2510.08022)|null|\n", "2510.07865": "|**2025-10-09**|**DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation**|Weibing Li Team|[2510.07865](http://arxiv.org/abs/2510.07865)|**[link](https://guowei-zou.github.io/dm1/)**|\n", "2510.07773": "|**2025-10-09**|**Trajectory Conditioned Cross-embodiment Skill Transfer**|Bin Zhao Team|[2510.07773](http://arxiv.org/abs/2510.07773)|null|\n", "2510.07674": "|**2025-10-11**|**Differentiable Particle Optimization for Fast Sequential Manipulation**|Zachary Kingston Team|[2510.07674](http://arxiv.org/abs/2510.07674)|null|\n", "2510.09607": "|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Caifeng Shan Team|[2510.09607](http://arxiv.org/abs/2510.09607)|**[link](https://ltbai.github.io/VITA-VLA/)**|\n", "2510.09543": "|**2025-10-13**|**Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards**|Alireza Ramezani Team|[2510.09543](http://arxiv.org/abs/2510.09543)|null|\n", "2510.09497": "|**2025-10-10**|**Autonomous Soft Robotic Guidewire Navigation via Imitation Learning**|Axel Krieger Team|[2510.09497](http://arxiv.org/abs/2510.09497)|null|\n", "2510.09487": "|**2025-10-13**|**Near-Optimal Second-Order Guarantees for Model-Based Adversarial Imitation Learning**|Weitong Zhang Team|[2510.09487](http://arxiv.org/abs/2510.09487)|null|\n", "2510.09459": "|**2025-10-13**|**Failure Prediction at Runtime for Generative Robot Policies**|Angela P. Schoellig Team|[2510.09459](http://arxiv.org/abs/2510.09459)|**[link](https://tum-lsy.github.io/fiper_website.)**|\n", "2510.09325": "|**2025-10-10**|**Rate optimal learning of equilibria from data**|Giorgia Ramponi Team|[2510.09325](http://arxiv.org/abs/2510.09325)|null|\n", "2510.09229": "|**2025-10-10**|**Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System**|Pai Zheng Team|[2510.09229](http://arxiv.org/abs/2510.09229)|null|\n", "2510.09222": "|**2025-10-10**|**FM-IRL: Flow-Matching for Reward Modeling and Policy Regularization in Reinforcement Learning**|Ivor Tsang Team|[2510.09222](http://arxiv.org/abs/2510.09222)|null|\n", "2510.09096": "|**2025-10-10**|**When a Robot is More Capable than a Human: Learning from Constrained Demonstrators**|Erdem B\u0131y\u0131k Team|[2510.09096](http://arxiv.org/abs/2510.09096)|null|\n", "2510.09036": "|**2025-10-10**|**iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation**|Ziwei Wang Team|[2510.09036](http://arxiv.org/abs/2510.09036)|null|\n", "2510.08807": "|**2025-10-09**|**Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation**|Yue Wang Team|[2510.08807](http://arxiv.org/abs/2510.08807)|null|\n", "2510.08787": "|**2025-10-09**|**Geometry-aware Policy Imitation**|Sylvain Calinon Team|[2510.08787](http://arxiv.org/abs/2510.08787)|null|\n", "2510.08753": "|**2025-10-09**|**Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics**|M. Jagersand Team|[2510.08753](http://arxiv.org/abs/2510.08753)|null|\n", "2510.11689": "|**2025-10-13**|**Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation**|Mac Schwager Team|[2510.11689](http://arxiv.org/abs/2510.11689)|null|\n", "2510.11660": "|**2025-10-14**|**ManiAgent: An Agentic Framework for General Robotic Manipulation**|Xudong Liu Team|[2510.11660](http://arxiv.org/abs/2510.11660)|null|\n", "2510.11321": "|**2025-10-13**|**HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data**|Yanchao Yang Team|[2510.11321](http://arxiv.org/abs/2510.11321)|null|\n", "2510.11307": "|**2025-10-13**|**FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks**|Alessandro Suglia Team|[2510.11307](http://arxiv.org/abs/2510.11307)|null|\n", "2510.11258": "|**2025-10-13**|**DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation**|Zongqing Lu Team|[2510.11258](http://arxiv.org/abs/2510.11258)|null|\n", "2510.11083": "|**2025-10-13**|**Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling**|Jingjing Liu Team|[2510.11083](http://arxiv.org/abs/2510.11083)|null|\n", "2510.10903": "|**2025-10-13**|**Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey**|Badong Chen Team|[2510.10903](http://arxiv.org/abs/2510.10903)|null|\n", "2510.10637": "|**2025-10-12**|**High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting**|Hua Zou Team|[2510.10637](http://arxiv.org/abs/2510.10637)|null|\n", "2510.10516": "|**2025-10-12**|**Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control**|Jeethu Sreenivas Amuthan Team|[2510.10516](http://arxiv.org/abs/2510.10516)|null|\n", "2510.10451": "|**2025-10-12**|**Data-driven simulator of multi-animal behavior with unknown dynamics via offline and online reinforcement learning**|Yoshinobu Kawahara Team|[2510.10451](http://arxiv.org/abs/2510.10451)|null|\n", "2510.10274": "|**2025-10-11**|**X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model**|Xianyuan Zhan Team|[2510.10274](http://arxiv.org/abs/2510.10274)|null|\n", "2510.10221": "|**2025-10-11**|**A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots**|Tetsuya Ogata Team|[2510.10221](http://arxiv.org/abs/2510.10221)|null|\n", "2510.10217": "|**2025-10-11**|**UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction**|Tetsuya Ogata Team|[2510.10217](http://arxiv.org/abs/2510.10217)|null|\n", "2510.10125": "|**2025-10-15**|**Ctrl-World: A Controllable Generative World Model for Robot Manipulation**|Chelsea Finn Team|[2510.10125](http://arxiv.org/abs/2510.10125)|null|\n", "2510.12560": "|**2025-10-14**|**CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving**|Jiangtao Gong Team|[2510.12560](http://arxiv.org/abs/2510.12560)|null|\n", "2510.12509": "|**2025-10-14**|**Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot Manipulators: Addressing the Behavior Planning Challenge**|Bram Vanderborght Team|[2510.12509](http://arxiv.org/abs/2510.12509)|null|\n", "2510.12483": "|**2025-10-14**|**Fast Visuomotor Policy for Robotic Manipulation**|Wenqiang Zhang Team|[2510.12483](http://arxiv.org/abs/2510.12483)|null|\n", "2510.12403": "|**2025-10-14**|**Robot Learning: A Tutorial**|Michel Aractingi Team|[2510.12403](http://arxiv.org/abs/2510.12403)|null|\n", "2510.12392": "|**2025-10-14**|**Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking**|Eunhyeok Park Team|[2510.12392](http://arxiv.org/abs/2510.12392)|null|\n", "2510.12215": "|**2025-10-14**|**Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications**|Sungjoon Choi Team|[2510.12215](http://arxiv.org/abs/2510.12215)|**[link](https://chanwookim971024.github.io/PioneeR/)**|\n", "2510.13626": "|**2025-10-15**|**LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models**|Xipeng Qiu Team|[2510.13626](http://arxiv.org/abs/2510.13626)|null|\n", "2510.13616": "|**2025-10-15**|**Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor**|Xiaobo Tan Team|[2510.13616](http://arxiv.org/abs/2510.13616)|**[link](https://drive.google.com/drive/folders/1jol-_z6gaUfjpL1Qi7EG420usTbVSodv?usp=sharing)**|\n", "2510.13595": "|**2025-10-15**|**Active Tactile Exploration for Rigid Body Pose and Shape Estimation**|Michael Posa Team|[2510.13595](http://arxiv.org/abs/2510.13595)|null|\n", "2510.13324": "|**2025-10-15**|**Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation**|Jan Peters Team|[2510.13324](http://arxiv.org/abs/2510.13324)|null|\n", "2510.13237": "|**2025-10-15**|**Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models**|Jingfeng Zhang Team|[2510.13237](http://arxiv.org/abs/2510.13237)|null|\n", "2510.13229": "|**2025-10-15**|**Beyond Static LLM Policies: Imitation-Enhanced Reinforcement Learning for Recommendation**|Sen Wang Team|[2510.13229](http://arxiv.org/abs/2510.13229)|null|\n", "2510.13054": "|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Fabio Ramos Team|[2510.13054](http://arxiv.org/abs/2510.13054)|null|\n", "2510.13005": "|**2025-10-14**|**Development of a Linear Guide-Rail Testbed for Physically Emulating ISAM Operations**|Christopher Petersen Team|[2510.13005](http://arxiv.org/abs/2510.13005)|null|\n", "2510.12971": "|**2025-10-14**|**Actron3D: Learning Actionable Neural Functions from Videos for Transferable Robotic Manipulation**|Stefan Leutenegger Team|[2510.12971](http://arxiv.org/abs/2510.12971)|null|\n", "2510.12866": "|**2025-10-14**|**Learning to Grasp Anything by Playing with Random Toys**|Roei Herzig Team|[2510.12866](http://arxiv.org/abs/2510.12866)|null|\n", "2510.14930": "|**2025-10-18**|**VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tuning**|Yunzhu Li Team|[2510.14930](http://arxiv.org/abs/2510.14930)|**[link](https://binghao-huang.github.io/vt_refine/)**|\n", "2510.14851": "|**2025-10-16**|**SADCHER: Scheduling using Attention-based Dynamic Coalitions of Heterogeneous Robots in Real-Time**|Javier Alonso-Mora Team|[2510.14851](http://arxiv.org/abs/2510.14851)|**[link](https://autonomousrobots.nl/paper_websites/sadcher_MRTA/)**|\n", "2510.14830": "|**2025-10-16**|**RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning**|Huazhe Xu Team|[2510.14830](http://arxiv.org/abs/2510.14830)|**[link](https://lei-kun.github.io/RL-100/)**|\n", "2510.14771": "|**2025-10-16**|**Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation**|Shan An Team|[2510.14771](http://arxiv.org/abs/2510.14771)|null|\n", "2510.14615": "|**2025-10-16**|**Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models**|Wilm Decr\u00e9 Team|[2510.14615](http://arxiv.org/abs/2510.14615)|null|\n", "2510.14467": "|**2025-10-16**|**Restoring Noisy Demonstration for Imitation Learning With Diffusion Models**|Shao-Hua Sun Team|[2510.14467](http://arxiv.org/abs/2510.14467)|null|\n", "2510.14300": "|**2025-10-16**|**Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning**|Yao Mu Team|[2510.14300](http://arxiv.org/abs/2510.14300)|null|\n", "2510.14117": "|**2025-10-15**|**ViTacGen: Robotic Pushing with Vision-to-Touch Generation**|Shan Luo Team|[2510.14117](http://arxiv.org/abs/2510.14117)|null|\n", "2510.14065": "|**2025-10-15**|**Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning**|Bram Vanderborght Team|[2510.14065](http://arxiv.org/abs/2510.14065)|null|\n", "2510.14049": "|**2025-10-17**|**CausalVerse: Benchmarking Causal Representation Learning with Configurable High-Fidelity Simulations**|Kun Zhang Team|[2510.14049](http://arxiv.org/abs/2510.14049)|null|\n", "2510.15786": "|**2025-10-17**|**DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation**|Yiwen Lu Team|[2510.15786](http://arxiv.org/abs/2510.15786)|null|\n", "2510.15530": "|**2025-10-22**|**VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation**|Bin He Team|[2510.15530](http://arxiv.org/abs/2510.15530)|null|\n", "2510.15510": "|**2025-10-17**|**Exploring Conditions for Diffusion models in Robotic Control**|Taekyung Kim Team|[2510.15510](http://arxiv.org/abs/2510.15510)|**[link](https://orca-rc.github.io/)**|\n", "2510.15505": "|**2025-10-17**|**Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving**|Joschka Boedecker Team|[2510.15505](http://arxiv.org/abs/2510.15505)|null|\n", "2510.15464": "|**2025-10-17**|**Learning to Answer from Correct Demonstrations**|Nathan Srebro Team|[2510.15464](http://arxiv.org/abs/2510.15464)|null|\n", "2510.15352": "|**2025-10-17**|**GaussGym: An open-source real-to-sim framework for learning locomotion from pixels**|Pieter Abbeel Team|[2510.15352](http://arxiv.org/abs/2510.15352)|null|\n", "2510.15189": "|**2025-10-16**|**RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation**|Jianfei Yang Team|[2510.15189](http://arxiv.org/abs/2510.15189)|null|\n", "2510.17640": "|**2025-10-20**|**RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation**|Ziwei Wang Team|[2510.17640](http://arxiv.org/abs/2510.17640)|null|\n", "2510.17604": "|**2025-10-20**|**Learned Inertial Odometry for Cycling Based on Mixture of Experts Algorithm**|Xiaoji Niu Team|[2510.17604](http://arxiv.org/abs/2510.17604)|null|\n", "2510.17531": "|**2025-10-20**|**Plasma Shape Control via Zero-shot Generative Reinforcement Learning**|Wulyu Zhong Team|[2510.17531](http://arxiv.org/abs/2510.17531)|null|\n", "2510.17448": "|**2025-10-20**|**A Generalization of Input-Output Linearization via Dynamic Switching Between Melds of Output Functions**|Antonio Franchi Team|[2510.17448](http://arxiv.org/abs/2510.17448)|null|\n", "2510.17150": "|**2025-10-22**|**OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation**|Arash Ajoudani Team|[2510.17150](http://arxiv.org/abs/2510.17150)|**[link](https://sites.google.com/view/omni-vic})**|\n", "2510.17143": "|**2025-10-20**|**Decentralized Real-Time Planning for Multi-UAV Cooperative Manipulation via Imitation Learning**|Sihao Sun Team|[2510.17143](http://arxiv.org/abs/2510.17143)|null|\n", "2510.17086": "|**2025-10-20**|**Learning to Design Soft Hands using Reward Models**|Sha Yi Team|[2510.17086](http://arxiv.org/abs/2510.17086)|null|\n", "2510.16756": "|**2025-10-19**|**End-to-end Listen, Look, Speak and Act**|Chao Zhang Team|[2510.16756](http://arxiv.org/abs/2510.16756)|null|\n", "2510.16617": "|**2025-10-18**|**MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation**|Ufuk Topcu Team|[2510.16617](http://arxiv.org/abs/2510.16617)|null|\n", "2510.16462": "|**2025-10-18**|**Buzz, Choose, Forget: A Meta-Bandit Framework for Bee-Like Decision Making**|Jean-Michel Loubes Team|[2510.16462](http://arxiv.org/abs/2510.16462)|null|\n", "2510.16424": "|**2025-10-18**|**Learning to Optimize Edge Robotics: A Fast Integrated Perception-Motion-Communication Approach**|Chengzhong Xu Team|[2510.16424](http://arxiv.org/abs/2510.16424)|null|\n", "2510.16231": "|**2025-10-17**|**DeGrip: A Compact Cable-driven Robotic Gripper for Desktop Disassembly**|Minghui Zheng Team|[2510.16231](http://arxiv.org/abs/2510.16231)|null|\n", "2510.18518": "|**2025-10-21**|**Efficient Model-Based Reinforcement Learning for Robot Control via Online Learning**|Marco Hutter Team|[2510.18518](http://arxiv.org/abs/2510.18518)|null|\n", "2510.18337": "|**2025-10-23**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Heng Yang Team|[2510.18337](http://arxiv.org/abs/2510.18337)|null|\n", "2510.18316": "|**2025-10-21**|**MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation**|Li Fei-Fei Team|[2510.18316](http://arxiv.org/abs/2510.18316)|null|\n", "2510.18137": "|**2025-10-20**|**Quality Over Quantity: Curating Contact-Based Robot Datasets Improves Learning**|Ian Abraham Team|[2510.18137](http://arxiv.org/abs/2510.18137)|null|\n", "2510.18085": "|**2025-10-20**|**R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations**|Daniel S. Brown Team|[2510.18085](http://arxiv.org/abs/2510.18085)|null|\n", "2510.18060": "|**2025-10-20**|**SPACeR: Self-Play Anchoring with Centralized Reference Models**|Wei Zhan Team|[2510.18060](http://arxiv.org/abs/2510.18060)|**[link](https://spacer-ai.github.io/)**|\n", "2510.19495": "|**2025-10-25**|**Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning**|Abhishek Gupta Team|[2510.19495](http://arxiv.org/abs/2510.19495)|null|\n", "2510.19400": "|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Baining Guo Team|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|\n", "2510.19373": "|**2025-10-22**|**Using Temperature Sampling to Effectively Train Robot Learning Policies on Imbalanced Datasets**|Bernadette Bucher Team|[2510.19373](http://arxiv.org/abs/2510.19373)|null|\n", "2510.19356": "|**2025-10-22**|**Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model**|Jie Zhao Team|[2510.19356](http://arxiv.org/abs/2510.19356)|null|\n", "2510.19307": "|**2025-10-22**|**Unified Reinforcement and Imitation Learning for Vision-Language Models**|Yueh-Hua Wu Team|[2510.19307](http://arxiv.org/abs/2510.19307)|**[link](https://byungkwanlee.github.io/RIL-page)**|\n", "2510.19289": "|**2025-10-22**|**TARMAC: A Taxonomy for Robot Manipulation in Chemistry**|Jihong Zhu Team|[2510.19289](http://arxiv.org/abs/2510.19289)|null|\n", "2510.19128": "|**2025-10-21**|**A Cross-Environment and Cross-Embodiment Path Planning Framework via a Conditional Diffusion Model**|Homayoun Najjaran Team|[2510.19128](http://arxiv.org/abs/2510.19128)|null|\n", "2510.20813": "|**2025-10-23**|**GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation**|Xiaolong Wang Team|[2510.20813](http://arxiv.org/abs/2510.20813)|null|\n", "2510.20774": "|**2025-10-23**|**FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation**|Yao Mu Team|[2510.20774](http://arxiv.org/abs/2510.20774)|**[link](https://fieldgen.github.io/)**|\n", "2510.20496": "|**2025-10-23**|**A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator**|Andreas Mueller Team|[2510.20496](http://arxiv.org/abs/2510.20496)|null|\n", "2510.20483": "|**2025-10-23**|**Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty**|Tom Lefebvre Team|[2510.20483](http://arxiv.org/abs/2510.20483)|null|\n", "2510.20406": "|**2025-10-23**|**PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning**|Gerhard Neumann Team|[2510.20406](http://arxiv.org/abs/2510.20406)|null|\n", "2510.20390": "|**2025-10-23**|**NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control**|Nathan F. Lepora Team|[2510.20390](http://arxiv.org/abs/2510.20390)|null|\n", "2510.20328": "|**2025-10-23**|**MemER: Scaling Up Memory for Robot Control via Experience Retrieval**|Chelsea Finn Team|[2510.20328](http://arxiv.org/abs/2510.20328)|**[link](https://jen-pan.github.io/memer/)**|\n", "2510.20040": "|**2025-10-22**|**Approximate Model Predictive Control for Microgrid Energy Management via Imitation Learning**|Bart De Schutter Team|[2510.20040](http://arxiv.org/abs/2510.20040)|null|\n", "2510.19944": "|**2025-10-22**|**Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets**|Xuanmeng Zhang Team|[2510.19944](http://arxiv.org/abs/2510.19944)|**[link](https://seed.bytedance.com/seed3d)**|\n", "2510.21691": "|**2025-10-27**|**On Uncertainty Calibration for Equivariant Functions**|Robin Walters Team|[2510.21691](http://arxiv.org/abs/2510.21691)|**[link](https://github.com/EdwardBerman/EquiUQ)**|\n", "2510.21609": "|**2025-10-24**|**Enhancing Tactile-based Reinforcement Learning for Robotic Control**|Sethu Vijayakumar Team|[2510.21609](http://arxiv.org/abs/2510.21609)|null|\n", "2510.21571": "|**2025-10-24**|**Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos**|Baining Guo Team|[2510.21571](http://arxiv.org/abs/2510.21571)|**[link](https://microsoft.github.io/VITRA/)**|\n", "2510.21560": "|**2025-10-24**|**Learning Neural Control Barrier Functions from Expert Demonstrations using Inverse Constraint Learning**|Hussein Sibai Team|[2510.21560](http://arxiv.org/abs/2510.21560)|null|\n", "2510.21121": "|**2025-10-24**|**Generalizable Hierarchical Skill Learning via Object-Centric Representation**|Robert Platt Team|[2510.21121](http://arxiv.org/abs/2510.21121)|null|\n", "2510.21000": "|**2025-10-23**|**BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies**|Benjamin Busam Team|[2510.21000](http://arxiv.org/abs/2510.21000)|null|\n", "2510.20965": "|**2025-10-23**|**SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing**|Axel Krieger Team|[2510.20965](http://arxiv.org/abs/2510.20965)|null|\n", "2510.23571": "|**2025-10-27**|**RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation**|Katerina Fragkiadaki Team|[2510.23571](http://arxiv.org/abs/2510.23571)|**[link](https://robotarenainf.github.io)**|\n", "2510.23234": "|**2025-10-27**|**Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation**|Andreas Mueller Team|[2510.23234](http://arxiv.org/abs/2510.23234)|null|\n", "2510.23227": "|**2025-10-27**|**Workspace Registration and Collision Detection for Industrial Robotics Applications**|Andreas Mueller Team|[2510.23227](http://arxiv.org/abs/2510.23227)|null|\n", "2510.23184": "|**2025-10-27**|**Finding 3D Scene Analogies with Multimodal Foundation Models**|Young Min Kim Team|[2510.23184](http://arxiv.org/abs/2510.23184)|null|\n", "2510.23016": "|**2025-10-27**|**ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation**|Fei Chen Team|[2510.23016](http://arxiv.org/abs/2510.23016)|null|\n", "2510.22789": "|**2025-10-26**|**Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning**|Guoquan Huang Team|[2510.22789](http://arxiv.org/abs/2510.22789)|null|\n", "2510.22718": "|**2025-10-26**|**Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication**|Chengzhong Xu Team|[2510.22718](http://arxiv.org/abs/2510.22718)|null|\n", "2510.22641": "|**2025-10-26**|**FastVLM: Self-Speculative Decoding for Fast Vision-Language Model Inference**|Manjesh Kumar Hanawal Team|[2510.22641](http://arxiv.org/abs/2510.22641)|null|\n", "2510.22420": "|**2025-10-25**|**A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems**|Benyamin Safizadeh Team|[2510.22420](http://arxiv.org/abs/2510.22420)|null|\n", "2510.22201": "|**2025-10-25**|**ACG: Action Coherence Guidance for Flow-based VLA models**|Jaegul Choo Team|[2510.22201](http://arxiv.org/abs/2510.22201)|null|\n", "2510.22113": "|**2025-10-25**|**RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation**|Yang Ye Team|[2510.22113](http://arxiv.org/abs/2510.22113)|null|\n", "2510.21991": "|**2025-10-24**|**Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising**|Yinchuan Li Team|[2510.21991](http://arxiv.org/abs/2510.21991)|null|\n", "2510.24680": "|**2025-10-28**|**Fare: Failure Resilience in Learned Visual Navigation Control**|David Hsu Team|[2510.24680](http://arxiv.org/abs/2510.24680)|null|\n", "2510.24650": "|**2025-10-28**|**Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning**|Arnold W. Schumann Team|[2510.24650](http://arxiv.org/abs/2510.24650)|null|\n", "2510.24261": "|**2025-10-28**|**DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation**|Gang Hua Team|[2510.24261](http://arxiv.org/abs/2510.24261)|null|\n", "2510.24257": "|**2025-10-28**|**Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors**|Yue Gao Team|[2510.24257](http://arxiv.org/abs/2510.24257)|null|\n", "2510.24194": "|**2025-10-28**|**Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames**|Aviv Tamar Team|[2510.24194](http://arxiv.org/abs/2510.24194)|null|\n", "2510.24109": "|**2025-10-28**|**PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI**|Philip Dames Team|[2510.24109](http://arxiv.org/abs/2510.24109)|null|\n", "2510.24108": "|**2025-10-28**|**ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring**|Jose M. Alvarez Team|[2510.24108](http://arxiv.org/abs/2510.24108)|null|\n", "2510.24095": "|**2025-10-28**|**Learning Parameterized Skills from Demonstrations**|George Konidaris Team|[2510.24095](http://arxiv.org/abs/2510.24095)|null|\n", "2510.24055": "|**2025-10-28**|**Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation**|Jiashuo Bai Team|[2510.24055](http://arxiv.org/abs/2510.24055)|null|\n", "2510.23928": "|**2025-10-27**|**Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments**|Giuseppe Loianno Team|[2510.23928](http://arxiv.org/abs/2510.23928)|null|\n", "2510.23763": "|**2025-10-29**|**RoboOmni: Proactive Robot Manipulation in Omni-modal Context**|Xipeng Qiu Team|[2510.23763](http://arxiv.org/abs/2510.23763)|null|\n", "2510.25405": "|**2025-10-29**|**Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning**|Florian T. Pokorny Team|[2510.25405](http://arxiv.org/abs/2510.25405)|null|\n", "2510.25268": "|**2025-10-29**|**SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation**|Dan Guo Team|[2510.25268](http://arxiv.org/abs/2510.25268)|null|\n", "2510.25255": "|**2025-10-29**|**Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths**|Andreas Mueller Team|[2510.25255](http://arxiv.org/abs/2510.25255)|null|\n", "2510.25233": "|**2025-10-29**|**Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery**|Jongseong Brad Choi Team|[2510.25233](http://arxiv.org/abs/2510.25233)|null|\n", "2510.25138": "|**2025-10-29**|**Learning Spatial-Aware Manipulation Ordering**|Jian Pu Team|[2510.25138](http://arxiv.org/abs/2510.25138)|null|\n", "2510.25122": "|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jinghui Lu Team|[2510.25122](http://arxiv.org/abs/2510.25122)|null|\n", "2510.25725": "|**2025-10-28**|**A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation**|Kyung-Joong Kim Team|[2510.25725](http://arxiv.org/abs/2510.25725)|null|\n", "2510.26670": "|**2025-10-30**|**Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation**|Qiaojun Yu Team|[2510.26670](http://arxiv.org/abs/2510.26670)|null|\n", "2510.26438": "|**2025-10-31**|**An Impulse Control Approach to Market Making in a Hawkes LOB Market**|Philip Treleaven Team|[2510.26438](http://arxiv.org/abs/2510.26438)|null|\n", "2510.26406": "|**2025-10-30**|**Human-in-the-loop Online Rejection Sampling for Robotic Manipulation**|Yansong Tang Team|[2510.26406](http://arxiv.org/abs/2510.26406)|null|\n", "2510.26292": "|**2025-10-30**|**Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving**|Yandan Luo Team|[2510.26292](http://arxiv.org/abs/2510.26292)|null|\n", "2510.26165": "|**2025-10-30**|**Learning to Manage Investment Portfolios beyond Simple Utility Functions**|J. Doyne Farmer Team|[2510.26165](http://arxiv.org/abs/2510.26165)|null|\n", "2510.27666": "|**2025-10-31**|**Whole-Body Proprioceptive Morphing: A Modular Soft Gripper for Robust Cross-Scale Grasping**|Xiaonan Huang Team|[2510.27666](http://arxiv.org/abs/2510.27666)|null|\n", "2510.27558": "|**2025-10-31**|**Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs**|Shinkyu Park Team|[2510.27558](http://arxiv.org/abs/2510.27558)|null|\n", "2510.27334": "|**2025-10-31**|**When AI Trading Agents Compete: Adverse Selection of Meta-Orders by Reinforcement Learning-Based Market Making**|Nick Firoozye Team|[2510.27334](http://arxiv.org/abs/2510.27334)|null|\n", "2510.27114": "|**2025-10-31**|**Learning Generalizable Visuomotor Policy through Dynamics-Alignment**|Jungwoo Lee Team|[2510.27114](http://arxiv.org/abs/2510.27114)|null|\n", "2511.02807": "|**2025-11-04**|**Audience Amplified: Virtual Audiences in Asynchronously Performed AR Theater**|Tobias H\u00f6llerer Team|[2511.02807](http://arxiv.org/abs/2511.02807)|null|\n", "2511.02504": "|**2025-11-04**|**Dexterous Robotic Piano Playing at Scale**|Dieter B\u00fcchler Team|[2511.02504](http://arxiv.org/abs/2511.02504)|null|\n", "2511.02239": "|**2025-11-04**|**LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation**|Changhyun Choi Team|[2511.02239](http://arxiv.org/abs/2511.02239)|**[link](https://vla2026.github.io/LACY/)**|\n", "2511.01999": "|**2025-11-03**|**TRACE: Textual Reasoning for Affordance Coordinate Extraction**|Matthew S. Brown Team|[2511.01999](http://arxiv.org/abs/2511.01999)|null|\n", "2511.01501": "|**2025-11-03**|**SE(3)-PoseFlow: Estimating 6D Pose Distributions for Uncertainty-Aware Robotic Manipulation**|Georgia Chalvatzaki Team|[2511.01501](http://arxiv.org/abs/2511.01501)|null|\n", "2511.01331": "|**2025-11-03**|**RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models**|Donglin Wang Team|[2511.01331](http://arxiv.org/abs/2511.01331)|null|\n", "2511.01256": "|**2025-11-03**|**Improving Needle Penetration via Precise Rotational Insertion Using Iterative Learning Control**|Tsu-Chin Tsao Team|[2511.01256](http://arxiv.org/abs/2511.01256)|null|\n", "2511.01224": "|**2025-11-03**|**Embodiment Transfer Learning for Vision-Language-Action Models**|Yaxin Peng Team|[2511.01224](http://arxiv.org/abs/2511.01224)|null|\n", "2511.01083": "|**2025-11-02**|**Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment**|Nina Mahmoudian Team|[2511.01083](http://arxiv.org/abs/2511.01083)|null|\n", "2511.00998": "|**2025-11-02**|**GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies**|Ruimao Zhang Team|[2511.00998](http://arxiv.org/abs/2511.00998)|**[link](https://ziyeeee.github.io/gaudp.io/)**|\n", "2511.00555": "|**2025-11-01**|**Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy**|Zhongliang Jiang Team|[2511.00555](http://arxiv.org/abs/2511.00555)|null|\n", "2511.01914": "|**2025-11-01**|**iFlyBot-VLA Technical Report**|Jia Pan Team|[2511.01914](http://arxiv.org/abs/2511.01914)|null|\n", "2511.00153": "|**2025-10-31**|**EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations**|Philipp Wu Team|[2511.00153](http://arxiv.org/abs/2511.00153)|null|\n", "2511.02097": "|**2025-10-31**|**A Step Toward World Models: A Survey on Robotic Manipulation**|Heng Tao Shen Team|[2511.02097](http://arxiv.org/abs/2511.02097)|null|\n", "2512.15715": "|**2025-12-17**|**In Pursuit of Pixel Supervision for Visual Pre-training**|Hu Xu Team|[2512.15715](http://arxiv.org/abs/2512.15715)|**[link](https://github.com/facebookresearch/pixio)**|\n", "2512.15692": "|**2025-12-17**|**mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs**|Elvis Nava Team|[2512.15692](http://arxiv.org/abs/2512.15692)|null|\n", "2512.15020": "|**2025-12-17**|**ISS Policy : Scalable Diffusion Policy with Implicit Scene Supervision**|Jie Mei Team|[2512.15020](http://arxiv.org/abs/2512.15020)|null|\n", "2512.14895": "|**2025-12-16**|**Imitation Learning for Multi-turn LM Agents via On-policy Expert Corrections**|Jeff Da Team|[2512.14895](http://arxiv.org/abs/2512.14895)|null|\n", "2512.14666": "|**2025-12-16**|**EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models**|Mike Zheng Shou Team|[2512.14666](http://arxiv.org/abs/2512.14666)|null|\n", "2512.14329": "|**2025-12-16**|**A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data**|Shuo Gao Team|[2512.14329](http://arxiv.org/abs/2512.14329)|null|\n", "2512.14217": "|**2025-12-16**|**DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos**|Gitta Kutyniok Team|[2512.14217](http://arxiv.org/abs/2512.14217)|null|\n", "2512.14057": "|**2025-12-17**|**Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning**|Homayoun Najjaran Team|[2512.14057](http://arxiv.org/abs/2512.14057)|null|\n", "2512.13670": "|**2025-12-15**|**NL2SpaTiaL: Generating Geometric Spatio-Temporal Logic Specifications from Natural Language for Manipulation Tasks**|Mingyu Cai Team|[2512.13670](http://arxiv.org/abs/2512.13670)|null|\n", "2512.13636": "|**2025-12-16**|**MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning**|Xiang Bai Team|[2512.13636](http://arxiv.org/abs/2512.13636)|**[link](https://xiaomi-mlab.github.io/MindDrive/)**|\n", "2512.13262": "|**2025-12-15**|**Post-Training and Test-Time Scaling of Generative Agent Behavior Models for Interactive Autonomous Driving**|Monu Surana Team|[2512.13262](http://arxiv.org/abs/2512.13262)|null|\n", "2512.13094": "|**2025-12-15**|**Sequence of Expert: Boosting Imitation Planners for Autonomous Driving through Temporal Alternation**|Zhong Cao Team|[2512.13094](http://arxiv.org/abs/2512.13094)|null|\n", "2512.13093": "|**2025-12-15**|**PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations**|Wenjun Zeng Team|[2512.13093](http://arxiv.org/abs/2512.13093)|null|\n", "2512.13080": "|**2025-12-15**|**Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos**|Zongqing Lu Team|[2512.13080](http://arxiv.org/abs/2512.13080)|null|\n", "2512.11988": "|**2025-12-12**|**CARI4D: Category Agnostic 4D Reconstruction of Human-Object Interaction**|Stan Birchfield Team|[2512.11988](http://arxiv.org/abs/2512.11988)|**[link](https://nvlabs.github.io/CARI4D/)**|\n", "2512.11797": "|**2025-12-12**|**AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis**|Vitor Guizilini Team|[2512.11797](http://arxiv.org/abs/2512.11797)|**[link](https://jay-ye.github.io/AnchorDream/)**|\n", "2512.11609": "|**2025-12-12**|**UniBYD: A Unified Framework for Learning Robotic Manipulation Across Embodiments Beyond Imitation of Human Demonstrations**|Jinqiao Wang Team|[2512.11609](http://arxiv.org/abs/2512.11609)|null|\n", "2512.11944": "|**2025-12-12**|**A Review of Learning-Based Motion Planning: Toward a Data-Driven Optimal Control Approach**|Haoran Wang Team|[2512.11944](http://arxiv.org/abs/2512.11944)|null|\n", "2512.11275": "|**2025-12-12**|**Towards Logic-Aware Manipulation: A Knowledge Primitive for VLM-Based Assistants in Smart Manufacturing**|Daqiang Guo Team|[2512.11275](http://arxiv.org/abs/2512.11275)|null|\n", "2512.11173": "|**2025-12-11**|**Learning Category-level Last-meter Navigation from RGB Demonstrations of a Single-instance**|Karthik Desingh Team|[2512.11173](http://arxiv.org/abs/2512.11173)|null|\n", "2512.16724": "|**2025-12-18**|**VERM: Leveraging Foundation Models to Create a Virtual Eye for Efficient 3D Robotic Manipulation**|Liang Wang Team|[2512.16724](http://arxiv.org/abs/2512.16724)|null|\n", "2512.16449": "|**2025-12-18**|**Single-View Shape Completion for Robotic Grasping in Clutter**|Todor Stoyanov Team|[2512.16449](http://arxiv.org/abs/2512.16449)|null|\n", "2512.16302": "|**2025-12-18**|**ManiLong-Shot: Interaction-Aware One-Shot Imitation Learning for Long-Horizon Manipulation**|Yang Gao Team|[2512.16302](http://arxiv.org/abs/2512.16302)|null|\n", "2512.16023": "|**2025-12-17**|**CoVAR: Co-generation of Video and Action for Robotic Manipulation via Multi-Modal Diffusion**|Abhinav Valada Team|[2512.16023](http://arxiv.org/abs/2512.16023)|null|\n", "2512.15840": "|**2025-12-17**|**Large Video Planner Enables Generalizable Robot Control**|Yilun Du Team|[2512.15840](http://arxiv.org/abs/2512.15840)|null|\n", "2512.16911": "|**2025-12-18**|**Posterior Behavioral Cloning: Pretraining BC Policies for Efficient RL Finetuning**|Sergey Levine Team|[2512.16911](http://arxiv.org/abs/2512.16911)|null|\n", "2512.16881": "|**2025-12-18**|**PolaRiS: Scalable Real-to-Sim Evaluations for Generalist Robot Policies**|Karl Pertsch Team|[2512.16881](http://arxiv.org/abs/2512.16881)|**[link](https://polaris-evals.github.io/)**|\n", "2512.16861": "|**2025-12-18**|**ReinforceGen: Hybrid Skill Policies with Automated Data Generation and Reinforcement Learning**|Caelan Garrett Team|[2512.16861](http://arxiv.org/abs/2512.16861)|null|\n", "2512.16842": "|**2025-12-18**|**OPENTOUCH: Bringing Full-Hand Touch to Real-World Interaction**|Paul Pu Liang Team|[2512.16842](http://arxiv.org/abs/2512.16842)|**[link](https://opentouch-tactile.github.io/)**|\n", "2512.16811": "|**2025-12-18**|**GeoPredict: Leveraging Predictive Kinematics and 3D Gaussian Geometry for Precise VLA Manipulation**|Li Jiang Team|[2512.16811](http://arxiv.org/abs/2512.16811)|null|\n", "2512.16921": "|**2025-12-18**|**Differences That Matter: Auditing Models for Capability Gap Discovery and Rectification**|Wen-Sheng Chu Team|[2512.16921](http://arxiv.org/abs/2512.16921)|**[link](https://auditdm.github.io/)**|\n", "2512.16918": "|**2025-12-18**|**AdaTooler-V: Adaptive Tool-Use for Images and Videos**|Xiangyu Yue Team|[2512.16918](http://arxiv.org/abs/2512.16918)|**[link](https://github.com/CYWang735/AdaTooler-V)**|\n", "2512.16917": "|**2025-12-18**|**Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning**|Alan Yuille Team|[2512.16917](http://arxiv.org/abs/2512.16917)|null|\n", "2512.16912": "|**2025-12-18**|**Exploration v.s. Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward**|Tianyi Lin Team|[2512.16912](http://arxiv.org/abs/2512.16912)|null|\n", "2512.16909": "|**2025-12-18**|**MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning**|Koushil Sreenath Team|[2512.16909](http://arxiv.org/abs/2512.16909)|**[link](https://hybridrobotics.github.io/MomaGraph/)**|\n", "2512.16883": "|**2025-12-18**|**AdaSearch: Balancing Parametric Knowledge and Search in Large Language Models via Reinforcement Learning**|Yu Meng Team|[2512.16883](http://arxiv.org/abs/2512.16883)|**[link](https://github.com/hank0316/AdaSearch)**|\n", "2512.16865": "|**2025-12-18**|**A survey of the orienteering problem: model evolution, algorithmic advances, and future directions**|Zhibin Wu Team|[2512.16865](http://arxiv.org/abs/2512.16865)|null|\n", "2512.16864": "|**2025-12-18**|**RePlan: Reasoning-guided Region Planning for Complex Instruction-based Image Editing**|Jiaya Jia Team|[2512.16864](http://arxiv.org/abs/2512.16864)|**[link](https://replan-iv-edit.github.io)**|\n", "2512.16856": "|**2025-12-18**|**Distributional AGI Safety**|Simon Osindero Team|[2512.16856](http://arxiv.org/abs/2512.16856)|null|\n", "2512.16848": "|**2025-12-18**|**Meta-RL Induces Exploration in Language Agents**|Maria Brbic Team|[2512.16848](http://arxiv.org/abs/2512.16848)|null|\n", "2512.16813": "|**2025-12-18**|**Coordinated Anti-Jamming Resilience in Swarm Networks via Multi-Agent Reinforcement Learning**|Sastry Kompella Team|[2512.16813](http://arxiv.org/abs/2512.16813)|null|\n", "2512.16705": "|**2025-12-18**|**Olaf: Bringing an Animated Character to Life in the Physical World**|Moritz B\u00e4cher Team|[2512.16705](http://arxiv.org/abs/2512.16705)|null|\n", "2512.16649": "|**2025-12-18**|**JustRL: Scaling a 1.5B LLM with a Simple RL Recipe**|Zhiyuan Liu Team|[2512.16649](http://arxiv.org/abs/2512.16649)|null|\n", "2512.16644": "|**2025-12-18**|**Implementing a Sharia Chatbot as a Consultation Medium for Questions About Islam**|Anissya Auliani Supriadi Putri Team|[2512.16644](http://arxiv.org/abs/2512.16644)|null|\n", "2512.16626": "|**2025-12-18**|**Stackelberg Learning from Human Feedback: Preference Optimization as a Sequential Game**|Andreas Krause Team|[2512.16626](http://arxiv.org/abs/2512.16626)|null|\n", "2512.16565": "|**2025-12-18**|**Non-Asymptotic Global Convergence of PPO-Clip**|Zaiwen Wen Team|[2512.16565](http://arxiv.org/abs/2512.16565)|null|\n", "2512.16529": "|**2025-12-18**|**ParamExplorer: A framework for exploring parameters in generative art**|Guillaume Lagarde Team|[2512.16529](http://arxiv.org/abs/2512.16529)|null|\n", "2512.16484": "|**2025-12-18**|**Guiding Perception-Reasoning Closer to Human in Blind Image Quality Assessment**|Shin'ya Nishida Team|[2512.16484](http://arxiv.org/abs/2512.16484)|null|\n", "2512.16446": "|**2025-12-18**|**E-SDS: Environment-aware See it, Do it, Sorted - Automated Environment-Aware Reinforcement Learning for Humanoid Locomotion**|Dimitrios Kanoulas Team|[2512.16446](http://arxiv.org/abs/2512.16446)|null|\n", "2512.16444": "|**2025-12-18**|**StarCraft+: Benchmarking Multi-agent Algorithms in Adversary Paradigm**|Zhen Cui Team|[2512.16444](http://arxiv.org/abs/2512.16444)|null|\n", "2512.16408": "|**2025-12-18**|**NDRL: Cotton Irrigation and Nitrogen Application with Nested Dual-Agent Reinforcement Learning**|Liang He Team|[2512.16408](http://arxiv.org/abs/2512.16408)|null|\n", "2512.16406": "|**2025-12-18**|**Hypernetworks That Evolve Themselves**|Sebastian Risi Team|[2512.16406](http://arxiv.org/abs/2512.16406)|null|\n", "2512.16402": "|**2025-12-18**|**Machine Learning-based Optimal Control for Colloidal Self-Assembly**|Xun Tang Team|[2512.16402](http://arxiv.org/abs/2512.16402)|null|\n", "2512.16300": "|**2025-12-18**|**Code-in-the-Loop Forensics: Agentic Tool Use for Image Forgery Detection**|Kaipeng Zhang Team|[2512.16300](http://arxiv.org/abs/2512.16300)|null|\n", "2512.16224": "|**2025-12-18**|**Simultaneous Secrecy and Covert Communications (SSACC) in Mobility-Aware RIS-Aided Networks**|Dusit Niyato Team|[2512.16224](http://arxiv.org/abs/2512.16224)|null|\n", "2512.16201": "|**2025-12-18**|**Visual Alignment of Medical Vision-Language Models for Grounded Radiology Report Generation**|Srimat Chakradhar Team|[2512.16201](http://arxiv.org/abs/2512.16201)|null|\n", "2512.16145": "|**2025-12-18**|**MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation**|Jinman Kim Team|[2512.16145](http://arxiv.org/abs/2512.16145)|null|\n", "2512.16144": "|**2025-12-18**|**INTELLECT-3: Technical Report**|Johannes Hagemann Team|[2512.16144](http://arxiv.org/abs/2512.16144)|null|\n", "2512.16069": "|**2025-12-18**|**A Task-Driven, Planner-in-the-Loop Computational Design Framework for Modular Manipulators**|Nikos Tsagarakis Team|[2512.16069](http://arxiv.org/abs/2512.16069)|null|\n", "2512.16032": "|**2025-12-17**|**Techno-economic optimization of a heat-pipe microreactor, part I: theory and cost optimization**|Luis Nunez Team|[2512.16032](http://arxiv.org/abs/2512.16032)|null|\n", "2512.15973": "|**2025-12-17**|**Dynamic Rank Reinforcement Learning for Adaptive Low-Rank Multi-Head Self Attention in Large Language Models**|Caner Erden Team|[2512.15973](http://arxiv.org/abs/2512.15973)|null|\n", "2512.15943": "|**2025-12-17**|**Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning**|Neel Sendas Team|[2512.15943](http://arxiv.org/abs/2512.15943)|null|\n", "2512.15926": "|**2025-12-17**|**DSO: Direct Steering Optimization for Bias Mitigation**|Nicholas Apostoloff Team|[2512.15926](http://arxiv.org/abs/2512.15926)|null|\n", "2512.15867": "|**2025-12-17**|**HEPTAPOD: Orchestrating High Energy Physics Workflows Towards Autonomous Agency**|Prasanth Shyamsundar Team|[2512.15867](http://arxiv.org/abs/2512.15867)|null|\n", "2512.15687": "|**2025-12-17**|**Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning**|Dong Yu Team|[2512.15687](http://arxiv.org/abs/2512.15687)|null|\n", "2512.15662": "|**2025-12-17**|**Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning**|Yan LU Team|[2512.15662](http://arxiv.org/abs/2512.15662)|null|\n", "2512.15605": "|**2025-12-17**|**Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction**|Vincent Roulet Team|[2512.15605](http://arxiv.org/abs/2512.15605)|null|\n", "2512.15558": "|**2025-12-17**|**Deep Reinforcement Learning for EH-Enabled Cognitive-IoT Under Jamming Attacks**|Walaa Hamouda Team|[2512.15558](http://arxiv.org/abs/2512.15558)|null|\n", "2512.15521": "|**2025-12-17**|**Autonomous Pressure Control in MuVacAS via Deep Reinforcement Learning and Deep Learning Surrogate Models**|Roberto G\u00f3mez-Espinosa Mart\u00edn Team|[2512.15521](http://arxiv.org/abs/2512.15521)|null|\n", "2512.15439": "|**2025-12-17**|**Double Horizon Model-Based Policy Optimization**|Shin Ishii Team|[2512.15439](http://arxiv.org/abs/2512.15439)|**[link](https://github.com/4kubo/erl_lib)**|\n", "2512.15430": "|**2025-12-17**|**FM-EAC: Feature Model-based Enhanced Actor-Critic for Multi-Task Control in Dynamic Environments**|Yusheng Ji Team|[2512.15430](http://arxiv.org/abs/2512.15430)|null|\n", "2512.15422": "|**2025-12-17**|**Can AI Generate more Comprehensive Test Scenarios? Review on Automated Driving Systems Test Scenario Generation Methods**|Arno Eichberger Team|[2512.15422](http://arxiv.org/abs/2512.15422)|null|\n", "2512.15405": "|**2025-12-17**|**EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning**|Wee Sun Lee Team|[2512.15405](http://arxiv.org/abs/2512.15405)|null|\n", "2512.15813": "|**2025-12-17**|**CodeMem: Architecting Reproducible Agents via Dynamic MCP and Procedural Memory**|Manoj Bajaj Team|[2512.15813](http://arxiv.org/abs/2512.15813)|null|\n", "2512.15295": "|**2025-12-17**|**Graph Contextual Reinforcement Learning for Efficient Directed Controller Synthesis**|Kenji Tei Team|[2512.15295](http://arxiv.org/abs/2512.15295)|null|\n", "2512.15279": "|**2025-12-17**|**Learning-Based Phase Shift Optimization of Liquid Crystal RIS in Dynamic mmWave Networks**|Andrea Ortiz Team|[2512.15279](http://arxiv.org/abs/2512.15279)|null|\n", "2512.15274": "|**2025-12-17**|**Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning**|Chen Gong Team|[2512.15274](http://arxiv.org/abs/2512.15274)|null|\n", "2512.15160": "|**2025-12-17**|**EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence**|Yifan Yang Team|[2512.15160](http://arxiv.org/abs/2512.15160)|null|\n", "2512.15146": "|**2025-12-18**|**Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning**|Hui Huang Team|[2512.15146](http://arxiv.org/abs/2512.15146)|null|\n", "2512.15120": "|**2025-12-17**|**Automatic Reward Shaping from Multi-Objective Human Heuristics**|Yu Wang Team|[2512.15120](http://arxiv.org/abs/2512.15120)|null|\n", "2512.15119": "|**2025-12-17**|**QoS-Aware Hierarchical Reinforcement Learning for Joint Link Selection and Trajectory Optimization in SAGIN-Supported UAV Mobility Management**|Shi Jin Team|[2512.15119](http://arxiv.org/abs/2512.15119)|null|\n", "2512.15089": "|**2025-12-17**|**Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models**|Mingkui Tan Team|[2512.15089](http://arxiv.org/abs/2512.15089)|null|\n", "2512.15062": "|**2025-12-17**|**Deep Reinforcement Learning for Joint Time and Power Management in SWIPT-EH CIoT**|Iyad Dayoub Team|[2512.15062](http://arxiv.org/abs/2512.15062)|null|\n", "2512.15036": "|**2025-12-17**|**Spectral Representation-based Reinforcement Learning**|Bo Dai Team|[2512.15036](http://arxiv.org/abs/2512.15036)|null|\n", "2512.14992": "|**2025-12-17**|**Multi-Objective Bayesian Optimization of Deep Reinforcement Learning for Environmental, Social, and Governance (ESG) Financial Portfolio Management**|M. Coronado-Vaca Team|[2512.14992](http://arxiv.org/abs/2512.14992)|null|\n", "2512.14991": "|**2025-12-17**|**Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes**|Yanzhao Yang Team|[2512.14991](http://arxiv.org/abs/2512.14991)|null|\n", "2512.14944": "|**2025-12-16**|**Puzzle Curriculum GRPO for Vision-Centric Reasoning**|Radek Grzeszczuk Team|[2512.14944](http://arxiv.org/abs/2512.14944)|**[link](https://pcgrpo.github.io)**|\n", "2512.14879": "|**2025-12-16**|**Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse**|Jingwei Chen Team|[2512.14879](http://arxiv.org/abs/2512.14879)|null|\n", "2512.14698": "|**2025-12-16**|**TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs**|Limin Wang Team|[2512.14698](http://arxiv.org/abs/2512.14698)|**[link](https://timelens-arc-lab.github.io/)**|\n", "2512.14696": "|**2025-12-16**|**CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives**|Deva Ramanan Team|[2512.14696](http://arxiv.org/abs/2512.14696)|**[link](https://crisp-real2sim.github.io/CRISP-Real2Sim/)**|\n", "2512.14617": "|**2025-12-16**|**Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes**|Fabio Patrizi Team|[2512.14617](http://arxiv.org/abs/2512.14617)|null|\n", "2512.14503": "|**2025-12-16**|**RecGPT-V2 Technical Report**|Zile Zhou Team|[2512.14503](http://arxiv.org/abs/2512.14503)|null|\n", "2512.14488": "|**2025-12-16**|**Hybrid Cognitive IoT with Cooperative Caching and SWIPT-EH: A Hierarchical Reinforcement Learning Framework**|Walaa Hamouda Team|[2512.14488](http://arxiv.org/abs/2512.14488)|null|\n", "2512.14465": "|**2025-12-16**|**Context-Picker: Dynamic context selection using multi-stage reinforcement learning**|Chao Yu Team|[2512.14465](http://arxiv.org/abs/2512.14465)|null|\n", "2512.14321": "|**2025-12-16**|**Multi-Agent Medical Decision Consensus Matrix System: An Intelligent Collaborative Framework for Oncology MDT Consultations**|Zhenyu Yu Team|[2512.14321](http://arxiv.org/abs/2512.14321)|null|\n", "2512.14297": "|**2025-12-16**|**A Threshold-Triggered Deep Q-Network-Based Framework for Self-Healing in Autonomic Software-Defined IIoT-Edge Networks**|Madeleine Gibescu Team|[2512.14297](http://arxiv.org/abs/2512.14297)|null|\n", "2512.14291": "|**2025-12-16**|**GLM-TTS Technical Report**|Jie Tang Team|[2512.14291](http://arxiv.org/abs/2512.14291)|null|\n", "2512.14202": "|**2025-12-16**|**Understanding and Improving Hyperbolic Deep Reinforcement Learning**|Sebastian Tschiatschek Team|[2512.14202](http://arxiv.org/abs/2512.14202)|null|\n", "2512.14157": "|**2025-12-16**|**Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis**|Shihui Zhen Team|[2512.14157](http://arxiv.org/abs/2512.14157)|null|\n", "2512.14100": "|**2025-12-16**|**A First-Order Logic-Based Alternative to Reward Models in RLHF**|Xinhua Zhu Team|[2512.14100](http://arxiv.org/abs/2512.14100)|null|\n", "2512.14070": "|**2025-12-16**|**From Obfuscated to Obvious: A Comprehensive JavaScript Deobfuscation Tool for Security Analysis**|Dongbin Wang Team|[2512.14070](http://arxiv.org/abs/2512.14070)|null|\n", "2512.14069": "|**2025-12-16**|**RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees**|Jinlong Li Team|[2512.14069](http://arxiv.org/abs/2512.14069)|null|\n", "2512.14044": "|**2025-12-16**|**OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving**|Wuxiong Huang Team|[2512.14044](http://arxiv.org/abs/2512.14044)|null|\n", "2512.14031": "|**2025-12-16**|**Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model**|Ci-Jyun Liang Team|[2512.14031](http://arxiv.org/abs/2512.14031)|null|\n", "2512.14029": "|**2025-12-16**|**Cooperative Caching Towards Efficient Spectrum Utilization in Cognitive-IoT Networks**|Walaa Hamouda Team|[2512.14029](http://arxiv.org/abs/2512.14029)|null|\n", "2512.14013": "|**2025-12-16**|**Hierarchical Deep Reinforcement Learning for Robust Access in Cognitive IoT Networks under Smart Jamming Attacks**|Walaa Hamouda Team|[2512.14013](http://arxiv.org/abs/2512.14013)|null|\n", "2512.15790": "|**2025-12-15**|**Bilevel Optimization for Covert Memory Tampering in Heterogeneous Multi-Agent Architectures (XAMT)**|Ken Huang Team|[2512.15790](http://arxiv.org/abs/2512.15790)|null|\n", "2512.13919": "|**2025-12-15**|**Adaptive digital twins for predictive decision-making: Online Bayesian learning of transition dynamics**|Andrea Manzoni Team|[2512.13919](http://arxiv.org/abs/2512.13919)|null|\n", "2512.13890": "|**2025-12-15**|**Group-Theoretic Reinforcement Learning of Dynamical Decoupling Sequences**|Murray J. Holland Team|[2512.13890](http://arxiv.org/abs/2512.13890)|null|\n", "2512.14762": "|**2025-12-15**|**Workflows vs Agents for Code Translation**|Octavian Udrea Team|[2512.14762](http://arxiv.org/abs/2512.14762)|null|\n", "2512.13874": "|**2025-12-15**|**SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning**|Humphrey Shi Team|[2512.13874](http://arxiv.org/abs/2512.13874)|**[link](https://praeclarumjj3.github.io/sage/)**|\n", "2512.13860": "|**2025-12-15**|**Verification-Guided Context Optimization for Tool Calling via Hierarchical LLMs-as-Editors**|Ayush Jain Team|[2512.13860](http://arxiv.org/abs/2512.13860)|null|\n", "2512.13837": "|**2025-12-15**|**Explainable reinforcement learning from human feedback to improve alignment**|Minghui Zhu Team|[2512.13837](http://arxiv.org/abs/2512.13837)|null|\n", "2512.13671": "|**2025-12-15**|**AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection**|Yan Wang Team|[2512.13671](http://arxiv.org/abs/2512.13671)|null|\n", "2512.13668": "|**2025-12-15**|**A Scientific Reasoning Model for Organic Synthesis Procedure Generation**|Marwin Segler Team|[2512.13668](http://arxiv.org/abs/2512.13668)|null|\n", "2512.13656": "|**2025-12-15**|**Advancing Machine Learning Optimization of Chiral Photonic Metasurface: Comparative Study of Neural Network and Genetic Algorithm Approaches**|Arash Rahimi-Iman Team|[2512.13656](http://arxiv.org/abs/2512.13656)|null|\n", "2512.13635": "|**2025-12-15**|**SCR2-ST: Combine Single Cell with Spatial Transcriptomics for Efficient Active Sampling via Reinforcement Learning**|Yuankai Huo Team|[2512.13635](http://arxiv.org/abs/2512.13635)|null|\n", "2512.13607": "|**2025-12-15**|**Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models**|Wei Ping Team|[2512.13607](http://arxiv.org/abs/2512.13607)|**[link](https://huggingface.co/collections/nvidia/nemotron-cascade)**|\n", "2512.13592": "|**2025-12-15**|**Image Diffusion Preview with Consistency Solver**|Long Zhao Team|[2512.13592](http://arxiv.org/abs/2512.13592)|null|\n", "2512.13573": "|**2025-12-16**|**MMhops-R1: Multimodal Multi-hop Reasoning**|Weiming Hu Team|[2512.13573](http://arxiv.org/abs/2512.13573)|null|\n", "2512.13564": "|**2025-12-15**|**Memory in the Age of AI Agents**|Shuicheng Yan Team|[2512.13564](http://arxiv.org/abs/2512.13564)|null|\n", "2512.13524": "|**2025-12-15**|**How Low Can You Go? The Data-Light SE Challenge**|Tim Menzies Team|[2512.13524](http://arxiv.org/abs/2512.13524)|null|\n", "2512.13514": "|**2025-12-15**|**Reinforcement Learning based 6-DoF Maneuvers for Microgravity Intravehicular Docking: A Simulation Study with Int-Ball2 in ISS-JEM**|Miguel Olivares-Mendez Team|[2512.13514](http://arxiv.org/abs/2512.13514)|null|\n", "2512.13510": "|**2025-12-15**|**MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph**|Xiaofan Zhang Team|[2512.13510](http://arxiv.org/abs/2512.13510)|null|\n", "2512.13507": "|**2025-12-16**|**Seedance 1.5 pro: A Native Audio-Visual Joint Generation Foundation Model**|Feilong Zuo Team|[2512.13507](http://arxiv.org/abs/2512.13507)|null|\n", "2512.13399": "|**2025-12-15**|**Differentiable Evolutionary Reinforcement Learning**|Difan Zou Team|[2512.13399](http://arxiv.org/abs/2512.13399)|**[link](https://github.com/sitaocheng/DERL)**|\n", "2512.13393": "|**2025-12-15**|**QoS-Aware State-Augmented Learnable Framework for 5G NR-U/Wi-Fi Coexistence: Impact of Parameter Selection and Enhanced Collision Resolution**|Brian L. Mark Team|[2512.13393](http://arxiv.org/abs/2512.13393)|null|\n", "2512.13380": "|**2025-12-15**|**Universal Dexterous Functional Grasping via Demonstration-Editing Reinforcement Learning**|Zongqing Lu Team|[2512.13380](http://arxiv.org/abs/2512.13380)|null|\n", "2512.13359": "|**2025-12-15**|**Fast Policy Learning for 6-DOF Position Control of Underwater Vehicles**|Ignacio Carlucho Team|[2512.13359](http://arxiv.org/abs/2512.13359)|null|\n", "2512.13356": "|**2025-12-15**|**Control of a Twin Rotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)**|Ayman El-Badawy Team|[2512.13356](http://arxiv.org/abs/2512.13356)|null|\n", "2512.13293": "|**2025-12-16**|**Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration**|Shuai Zhou Team|[2512.13293](http://arxiv.org/abs/2512.13293)|null|\n", "2512.13278": "|**2025-12-15**|**AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning**|Mengdi Wang Team|[2512.13278](http://arxiv.org/abs/2512.13278)|null|\n", "2512.13268": "|**2025-12-15**|**SPARS: A Reinforcement Learning-Enabled Simulator for Power Management in HPC Job Scheduling**|Hiroyuki Takizawa Team|[2512.13268](http://arxiv.org/abs/2512.13268)|null|\n", "2512.13240": "|**2025-12-15**|**Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection**|Zechang Li Team|[2512.13240](http://arxiv.org/abs/2512.13240)|null|\n", "2512.13165": "|**2025-12-15**|**SACn: Soft Actor-Critic with n-step Returns**|Pawe\u0142 Wawrzy\u0144ski Team|[2512.13165](http://arxiv.org/abs/2512.13165)|null|\n", "2512.13159": "|**2025-12-15**|**SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning**|Xing Fan Team|[2512.13159](http://arxiv.org/abs/2512.13159)|null|\n", "2512.13106": "|**2025-12-15**|**TraPO: A Semi-Supervised Reinforcement Learning Framework for Boosting LLM Reasoning**|Haobo Wang Team|[2512.13106](http://arxiv.org/abs/2512.13106)|null|\n", "2512.13096": "|**2025-12-15**|**Toward Self-Healing Networks-on-Chip: RL-Driven Routing in 2D Torus Architectures**|Zaid Hussain Team|[2512.13096](http://arxiv.org/abs/2512.13096)|null|\n", "2512.13095": "|**2025-12-15**|**ADHint: Adaptive Hints with Difficulty Priors for Reinforcement Learning**|Yang Yang Team|[2512.13095](http://arxiv.org/abs/2512.13095)|null|\n", "2512.13070": "|**2025-12-15**|**M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization**|Tao Chen Team|[2512.13070](http://arxiv.org/abs/2512.13070)|null|\n", "2512.13060": "|**2025-12-15**|**Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments**|Wei Li Team|[2512.13060](http://arxiv.org/abs/2512.13060)|null|\n", "2512.13043": "|**2025-12-15**|**GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training**|Deheng Ye Team|[2512.13043](http://arxiv.org/abs/2512.13043)|null|\n", "2512.13015": "|**2025-12-15**|**What Happens Next? Next Scene Prediction with a Unified Video Model**|Vimal Bhat Team|[2512.13015](http://arxiv.org/abs/2512.13015)|null|\n", "2512.12993": "|**2025-12-15**|**Learning Terrain Aware Bipedal Locomotion via Reduced Dimensional Perceptual Representations**|Ayonga Hereid Team|[2512.12993](http://arxiv.org/abs/2512.12993)|null|\n", "2512.12987": "|**2025-12-15**|**Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning**|Ali Kamali Iglie Team|[2512.12987](http://arxiv.org/abs/2512.12987)|null|\n", "2512.12967": "|**2025-12-15**|**QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management**|Ming Yan Team|[2512.12967](http://arxiv.org/abs/2512.12967)|null|\n", "2512.12924": "|**2025-12-15**|**Interpretable Hypothesis-Driven Trading:A Rigorous Walk-Forward Validation Framework for Market Microstructure Signals**|William Lamptey Team|[2512.12924](http://arxiv.org/abs/2512.12924)|null|\n", "2512.12922": "|**2025-12-15**|**LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization**|Ziyang Ding Team|[2512.12922](http://arxiv.org/abs/2512.12922)|null|\n", "2512.12888": "|**2025-12-15**|**Meta-GPT: Decoding the Metasurface Genome with Generative Artificial Intelligence**|Wilton J. M. Kort-Kamp Team|[2512.12888](http://arxiv.org/abs/2512.12888)|null|\n", "2512.12858": "|**2025-12-14**|**Information-Consistent Language Model Recommendations through Group Relative Policy Optimization**|Kaushik Dutta Team|[2512.12858](http://arxiv.org/abs/2512.12858)|null|\n", "2512.12855": "|**2025-12-14**|**MPC-Guided Safe Reinforcement Learning and Lipschitz-Based Filtering for Structured Nonlinear Systems**|Anahita Jamshidnejad Team|[2512.12855](http://arxiv.org/abs/2512.12855)|null|\n", "2512.12803": "|**2025-12-14**|**Distributed Reinforcement Learning using Local Smart Meter Data for Voltage Regulation in Distribution Networks**|Pedro P. Vergara Team|[2512.12803](http://arxiv.org/abs/2512.12803)|null|\n", "2512.12716": "|**2025-12-14**|**CoDA: A Context-Decoupled Hierarchical Agent with Reinforcement Learning**|Pan Li Team|[2512.12716](http://arxiv.org/abs/2512.12716)|null|\n", "2512.12713": "|**2025-12-14**|**Self-Motivated Growing Neural Network for Adaptive Architecture via Local Structural Plasticity**|Chengxu Zhou Team|[2512.12713](http://arxiv.org/abs/2512.12713)|null|\n", "2512.12706": "|**2025-12-14**|**Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning**|Jialong Li Team|[2512.12706](http://arxiv.org/abs/2512.12706)|null|\n", "2512.12690": "|**2025-12-14**|**Reassessing the Role of Supervised Fine-Tuning: An Empirical Study in VLM Reasoning**|Jian Liang Team|[2512.12690](http://arxiv.org/abs/2512.12690)|null|\n", "2512.12658": "|**2025-12-14**|**CogDoc: Towards Unified thinking in Documents**|Wenhu Chen Team|[2512.12658](http://arxiv.org/abs/2512.12658)|null|\n", "2512.12576": "|**2025-12-14**|**Coupled Variational Reinforcement Learning for Language Model General Reasoning**|Debing Zhang Team|[2512.12576](http://arxiv.org/abs/2512.12576)|null|\n", "2512.12548": "|**2025-12-14**|**World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents**|Luis F. Giraldo Team|[2512.12548](http://arxiv.org/abs/2512.12548)|null|\n", "2512.12492": "|**2025-12-16**|**Adaptive Detector-Verifier Framework for Zero-Shot Polyp Detection in Open-World Settings**|Yuqi Ouyang Team|[2512.12492](http://arxiv.org/abs/2512.12492)|null|\n", "2512.12487": "|**2025-12-13**|**More Than the Final Answer: Improving Visual Extraction and Logical Consistency in Vision-Language Models**|Jing Shi Team|[2512.12487](http://arxiv.org/abs/2512.12487)|null|\n", "2512.12476": "|**2025-12-13**|**HetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments**|George Karypis Team|[2512.12476](http://arxiv.org/abs/2512.12476)|null|\n", "2512.12468": "|**2025-12-13**|**Autonomously Unweaving Multiple Cables Using Visual Feedback**|Howie Choset Team|[2512.12468](http://arxiv.org/abs/2512.12468)|null|\n", "2512.13727": "|**2025-12-13**|**RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing**|Jinhua Zhao Team|[2512.13727](http://arxiv.org/abs/2512.13727)|null|\n", "2512.13726": "|**2025-12-13**|**Time-Constrained Recommendations: Reinforcement Learning Strategies for E-Commerce**|Souradip Pal Team|[2512.13726](http://arxiv.org/abs/2512.13726)|null|\n", "2512.12437": "|**2025-12-13**|**Sim2Real Reinforcement Learning for Soccer skills**|Jonathan Spraggett Team|[2512.12437](http://arxiv.org/abs/2512.12437)|null|\n", "2512.12420": "|**2025-12-13**|**Deep Hedging with Reinforcement Learning: A Practical Framework for Option Risk Management**|Carrie Hu Team|[2512.12420](http://arxiv.org/abs/2512.12420)|**[link](https://github.com/tlucius16/deep-hedging-rl)**|\n", "2512.12389": "|**2025-12-13**|**Diagrammatics in the Dual Space, or There and Back Again**|Evgeny A. Stepanov Team|[2512.12389](http://arxiv.org/abs/2512.12389)|null|\n", "2512.12366": "|**2025-12-13**|**ElasticVR: Elastic Task Computing in Multi-User Multi-Connectivity Wireless Virtual Reality (VR) Systems**|Morteza Hashemi Team|[2512.12366](http://arxiv.org/abs/2512.12366)|null|\n", "2512.12326": "|**2025-12-13**|**The Role of AI in Modern Penetration Testing**|Nasir U. Eisty Team|[2512.12326](http://arxiv.org/abs/2512.12326)|null|\n", "2512.12299": "|**2025-12-13**|**A Conflict-Aware Resource Management Framework for the Computing Continuum**|Schahram Dustdar Team|[2512.12299](http://arxiv.org/abs/2512.12299)|null|\n", "2512.12246": "|**2025-12-13**|**Moment and Highlight Detection via MLLM Frame Segmentation**|Ayu Purwarianti Team|[2512.12246](http://arxiv.org/abs/2512.12246)|null|\n", "2512.12230": "|**2025-12-13**|**Learning to Get Up Across Morphologies: Zero-Shot Recovery with a Unified Humanoid Policy**|Jonathan Spraggett Team|[2512.12230](http://arxiv.org/abs/2512.12230)|null|\n", "2512.12046": "|**2025-12-12**|**Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning**|Ahmed H. Qureshi Team|[2512.12046](http://arxiv.org/abs/2512.12046)|null|\n", "2512.11990": "|**2025-12-12**|**Policy Gradient Algorithms for Age-of-Information Cost Minimization**|Israel Leyva-Mayorga Team|[2512.11990](http://arxiv.org/abs/2512.11990)|null|\n", "2512.11986": "|**2025-12-12**|**Learning to Extract Context for Context-Aware LLM Inference**|Alessandro Sordoni Team|[2512.11986](http://arxiv.org/abs/2512.11986)|null|\n", "2512.11781": "|**2025-12-12**|**Agile Flight Emerges from Multi-Agent Competitive Racing**|Antonio Loquercio Team|[2512.11781](http://arxiv.org/abs/2512.11781)|null|\n", "2512.11755": "|**2025-12-12**|**SUMFORU: An LLM-Based Review Summarization Framework for Personalized Purchase Decision Support**|Xinrui Jiang Team|[2512.11755](http://arxiv.org/abs/2512.11755)|**[link](https://github.com/Harry20030331/SumForU)**|\n", "2512.11632": "|**2025-12-12**|**Basis dependence of Neural Quantum States for the Transverse Field Ising Model**|Nils Niggemann Team|[2512.11632](http://arxiv.org/abs/2512.11632)|null|\n", "2512.11587": "|**2025-12-12**|**Gradient Descent as a Perceptron Algorithm: Understanding Dynamics and Implicit Acceleration**|Alexander Tyurin Team|[2512.11587](http://arxiv.org/abs/2512.11587)|null|\n", "2512.11558": "|**2025-12-12**|**DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry**|Benyou Wang Team|[2512.11558](http://arxiv.org/abs/2512.11558)|null|\n", "2512.11470": "|**2025-12-12**|**Rethinking Expert Trajectory Utilization in LLM Post-training**|Tao Lin Team|[2512.11470](http://arxiv.org/abs/2512.11470)|null|\n", "2512.11469": "|**2025-12-12**|**Three methods, one problem: Classical and AI approaches to no-three-in-line**|Sreedath Panat Team|[2512.11469](http://arxiv.org/abs/2512.11469)|null|\n", "2512.11421": "|**2025-12-12**|**Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance**|Gonca G\u00fcrsun Team|[2512.11421](http://arxiv.org/abs/2512.11421)|null|\n", "2512.11391": "|**2025-12-12**|**Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization**|Jia Li Team|[2512.11391](http://arxiv.org/abs/2512.11391)|null|\n", "2512.11345": "|**2025-12-12**|**Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits**|Roberto Horowitz Team|[2512.11345](http://arxiv.org/abs/2512.11345)|null|\n", "2512.11342": "|**2025-12-12**|**DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning**|Wei Zhang Team|[2512.11342](http://arxiv.org/abs/2512.11342)|null|\n", "2512.11315": "|**2025-12-12**|**Benchmarking the Generality of Vision-Language-Action Models**|Yangyue Wang Team|[2512.11315](http://arxiv.org/abs/2512.11315)|null|\n", "2512.11306": "|**2025-12-15**|**RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training**|Wei Wang Team|[2512.11306](http://arxiv.org/abs/2512.11306)|null|\n", "2512.11277": "|**2025-12-12**|**When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents**|Roberto Pieraccini Team|[2512.11277](http://arxiv.org/abs/2512.11277)|null|\n", "2512.11270": "|**2025-12-12**|**A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation**|Hyun-Suk Lee Team|[2512.11270](http://arxiv.org/abs/2512.11270)|null|\n", "2512.11247": "|**2025-12-12**|**Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control**|Weizi Li Team|[2512.11247](http://arxiv.org/abs/2512.11247)|null|\n", "2512.11930": "|**2025-12-12**|**Evolutionary Reinforcement Learning based AI tutor for Socratic Interdisciplinary Instruction**|Aimin Zhou Team|[2512.11930](http://arxiv.org/abs/2512.11930)|null|\n", "2512.11179": "|**2025-12-11**|**Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning**|Junyu Xuan Team|[2512.11179](http://arxiv.org/abs/2512.11179)|null|\n", "2512.11169": "|**2025-12-11**|**CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound**|Sebastien Gros Team|[2512.11169](http://arxiv.org/abs/2512.11169)|null|\n", "2512.11161": "|**2025-12-11**|**Benchmarking RL-Enhanced Spatial Indices Against Traditional, Advanced, and Learned Counterparts**|Zhifeng Bao Team|[2512.11161](http://arxiv.org/abs/2512.11161)|null|\n", "2512.11114": "|**2025-12-11**|**In-Context Multi-Objective Optimization**|Samuel Kaski Team|[2512.11114](http://arxiv.org/abs/2512.11114)|null|\n", "2512.10949": "|**2025-12-11**|**Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation**|Bin Zhao Team|[2512.10949](http://arxiv.org/abs/2512.10949)|**[link](https://github.com/Ivan-Tang-3D/3DGen-R1)**|\n", "2512.10934": "|**2025-12-11**|**Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit**|Julien Seinturier Team|[2512.10934](http://arxiv.org/abs/2512.10934)|null|\n", "2512.10925": "|**2025-12-11**|**Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation**|Pierre Drap Team|[2512.10925](http://arxiv.org/abs/2512.10925)|null|\n"}, "VLM": {"2504.02823": "|**2025-04-03**|**STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection**|Naoufel Werghi Team|[2504.02823](http://arxiv.org/abs/2504.02823)|null|\n", "2504.02821": "|**2025-04-03**|**Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models**|Zeynep Akata Team|[2504.02821](http://arxiv.org/abs/2504.02821)|null|\n", "2504.02799": "|**2025-04-03**|**Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence**|Serena Yeung-Levy Team|[2504.02799](http://arxiv.org/abs/2504.02799)|null|\n", "2504.02765": "|**2025-04-03**|**Robot-Led Vision Language Model Wellbeing Assessment of Children**|Hatice Gunes Team|[2504.02765](http://arxiv.org/abs/2504.02765)|null|\n", "2504.02587": "|**2025-04-04**|**Rethinking RL Scaling for Vision Language Models: A Transparent, From-Scratch Framework and Comprehensive Evaluation Scheme**|Pengfei Liu Team|[2504.02587](http://arxiv.org/abs/2504.02587)|null|\n", "2504.02477": "|**2025-04-03**|**Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision**|Shibiao Xu Team|[2504.02477](http://arxiv.org/abs/2504.02477)|null|\n", "2504.02438": "|**2025-04-03**|**Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation**|Rui Yan Team|[2504.02438](http://arxiv.org/abs/2504.02438)|null|\n", "2504.02357": "|**2025-04-03**|**ReuseDroid: A VLM-empowered Android UI Test Migrator Boosted by Active Feedback**|Hailong Wang Team|[2504.02357](http://arxiv.org/abs/2504.02357)|null|\n", "2504.02349": "|**2025-04-03**|**Large (Vision) Language Models are Unsupervised In-Context Learners**|Maria Brbic Team|[2504.02349](http://arxiv.org/abs/2504.02349)|**[link](https://github.com/mlbio-epfl/joint-inference)**|\n", "2504.02259": "|**2025-04-03**|**Re-thinking Temporal Search for Long-Form Video Understanding**|Manling Li Team|[2504.02259](http://arxiv.org/abs/2504.02259)|null|\n", "2504.02244": "|**2025-04-03**|**SocialGesture: Delving into Multi-person Gesture Understanding**|James M. Rehg Team|[2504.02244](http://arxiv.org/abs/2504.02244)|null|\n", "2504.01916": "|**2025-04-02**|**FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer Text Inputs**|Fatima Albreiki Team|[2504.01916](http://arxiv.org/abs/2504.01916)|**[link](https://github.com/tiiuae/FineLIP)**|\n", "2504.01890": "|**2025-04-02**|**Is Temporal Prompting All We Need For Limited Labeled Action Recognition?**|Xiaobo Jin Team|[2504.01890](http://arxiv.org/abs/2504.01890)|null|\n", "2504.01838": "|**2025-04-02**|**Prompting Medical Vision-Language Models to Mitigate Diagnosis Bias by Generating Realistic Dermoscopic Images**|Abdullah-Al-Zubaer Imran Team|[2504.01838](http://arxiv.org/abs/2504.01838)|**[link](https://github.com/munia03/dermdit)**|\n", "2504.01786": "|**2025-04-02**|**BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing**|Leonidas Guibas Team|[2504.01786](http://arxiv.org/abs/2504.01786)|null|\n", "2504.01735": "|**2025-04-02**|**AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization**|Linli Xu Team|[2504.01735](http://arxiv.org/abs/2504.01735)|null|\n", "2504.01700": "|**2025-04-02**|**Reasoning LLMs for User-Aware Multimodal Conversational Agents**|Mohamed Chetouani Team|[2504.01700](http://arxiv.org/abs/2504.01700)|null|\n", "2504.01666": "|**2025-04-02**|**CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign Language Recognition**|Hamzah Luqman Team|[2504.01666](http://arxiv.org/abs/2504.01666)|**[link](https://github.com/snalyami/CLIP-SLA)**|\n", "2504.01662": "|**2025-04-02**|**BioAtt: Anatomical Prior Driven Low-Dose CT Denoising**|UiHyun Cho Team|[2504.01662](http://arxiv.org/abs/2504.01662)|null|\n", "2504.01589": "|**2025-04-02**|**Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in Vision-Language Models**|Ming-Hsuan Yang Team|[2504.01589](http://arxiv.org/abs/2504.01589)|null|\n", "2504.03440": "|**2025-04-04**|**Know What You do Not Know: Verbalized Uncertainty Estimation Robustness on Corrupted Images in Vision-Language Models**|Matias Valdenegro-Toro Team|[2504.03440](http://arxiv.org/abs/2504.03440)|null|\n", "2504.03254": "|**2025-04-04**|**SARLANG-1M: A Benchmark for Vision-Language Modeling in SAR Image Understanding**|Naoto Yokoya Team|[2504.03254](http://arxiv.org/abs/2504.03254)|null|\n", "2504.03245": "|**2025-04-04**|**Seeing is Believing: Belief-Space Planning with Foundation Models as Uncertainty Estimators**|Lawson L. S. Wong Team|[2504.03245](http://arxiv.org/abs/2504.03245)|null|\n", "2504.03193": "|**2025-04-04**|**Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation**|Robby T. Tan Team|[2504.03193](http://arxiv.org/abs/2504.03193)|null|\n", "2504.03164": "|**2025-04-04**|**NuScenes-SpatialQA: A Spatial Understanding and Reasoning Benchmark for Vision-Language Models in Autonomous Driving**|Zhengzhong Tu Team|[2504.03164](http://arxiv.org/abs/2504.03164)|null|\n", "2504.03154": "|**2025-04-04**|**TokenFLEX: Unified VLM Training for Flexible Visual Tokens Inference**|Xianpeng Lang Team|[2504.03154](http://arxiv.org/abs/2504.03154)|null|\n", "2504.03153": "|**2025-04-04**|**MORAL: A Multimodal Reinforcement Learning Framework for Decision Making in Autonomous Laboratories**|Arvind Ramanathan Team|[2504.03153](http://arxiv.org/abs/2504.03153)|null|\n", "2504.02971": "|**2025-04-03**|**QID: Efficient Query-Informed ViTs in Data-Scarce Regimes for OCR-free Visual Document Understanding**|Bryan Wang Team|[2504.02971](http://arxiv.org/abs/2504.02971)|null|\n", "2504.05303": "|**2025-04-07**|**InteractVLM: 3D Interaction Reasoning from 2D Foundational Models**|Dimitrios Tzionas Team|[2504.05303](http://arxiv.org/abs/2504.05303)|null|\n", "2504.05299": "|**2025-04-07**|**SmolVLM: Redefining small and efficient multimodal models**|Thomas Wolf Team|[2504.05299](http://arxiv.org/abs/2504.05299)|null|\n", "2504.05227": "|**2025-04-07**|**A Reality Check of Vision-Language Pre-training in Radiology: Have We Progressed Using Text?**|Ismail Ben Ayed Team|[2504.05227](http://arxiv.org/abs/2504.05227)|null|\n", "2504.05225": "|**2025-04-07**|**Vision-Language Model Predictive Control for Manipulation Planning and Trajectory Generation**|Wei Zhang Team|[2504.05225](http://arxiv.org/abs/2504.05225)|null|\n", "2504.04939": "|**2025-04-08**|**A Taxonomy of Self-Handover**|Katsushi Ikeuchi Team|[2504.04939](http://arxiv.org/abs/2504.04939)|null|\n", "2504.04893": "|**2025-04-07**|**SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models**|Lorenz Hufe Team|[2504.04893](http://arxiv.org/abs/2504.04893)|null|\n", "2504.04858": "|**2025-04-07**|**Don't Lag, RAG: Training-Free Adversarial Detection Using RAG**|Ofer Hadar Team|[2504.04858](http://arxiv.org/abs/2504.04858)|null|\n", "2504.04781": "|**2025-04-07**|**OCC-MLLM-CoT-Alpha: Towards Multi-stage Occlusion Recognition Based on Large Language Models via 3D-Aware Supervision and Chain-of-Thoughts Guidance**|Xinhan Di Team|[2504.04781](http://arxiv.org/abs/2504.04781)|null|\n", "2504.04772": "|**2025-04-07**|**Feedback-Enhanced Hallucination-Resistant Vision-Language Model for Real-Time Scene Understanding**|Zahir Alsulaimawi Team|[2504.04772](http://arxiv.org/abs/2504.04772)|null|\n", "2504.04744": "|**2025-04-07**|**Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions**|Yue Wang Team|[2504.04744](http://arxiv.org/abs/2504.04744)|null|\n", "2504.04740": "|**2025-04-07**|**Enhancing Compositional Reasoning in Vision-Language Models with Synthetic Preference Data**|Venkatesh Saligrama Team|[2504.04740](http://arxiv.org/abs/2504.04740)|null|\n", "2504.04633": "|**2025-04-06**|**M2IV: Towards Efficient and Fine-grained Multimodal In-Context Learning in Large Vision-Language Models**|Ruixiang Tang Team|[2504.04633](http://arxiv.org/abs/2504.04633)|null|\n", "2504.04630": "|**2025-04-06**|**Foundation Models for Software Engineering of Cyber-Physical Systems: the Road Ahead**|Shaukat Ali Team|[2504.04630](http://arxiv.org/abs/2504.04630)|null|\n", "2504.04517": "|**2025-04-06**|**Enhance Then Search: An Augmentation-Search Strategy with Foundation Models for Cross-Domain Few-Shot Object Detection**|Xiaomeng Huang Team|[2504.04517](http://arxiv.org/abs/2504.04517)|**[link](https://github.com/jaychempan/ETS)**|\n", "2504.04348": "|**2025-04-06**|**OmniDrive: A Holistic Vision-Language Dataset for Autonomous Driving with Counterfactual Reasoning**|Jose M. Alvarez Team|[2504.04348](http://arxiv.org/abs/2504.04348)|null|\n", "2504.04323": "|**2025-04-06**|**MedM-VL: What Makes a Good Medical LVLM?**|Ji Wu Team|[2504.04323](http://arxiv.org/abs/2504.04323)|null|\n", "2504.04191": "|**2025-04-05**|**GROVE: A Generalized Reward for Learning Open-Vocabulary Physical Skill**|Siyuan Huang Team|[2504.04191](http://arxiv.org/abs/2504.04191)|null|\n", "2504.04103": "|**2025-04-05**|**LATTE: Lightweight Attention-based Traffic Accident Anticipation Engine**|Zhenning Li Team|[2504.04103](http://arxiv.org/abs/2504.04103)|null|\n", "2504.04099": "|**2025-04-05**|**TARAC: Mitigating Hallucination in LVLMs via Temporal Attention Real-time Accumulative Connection**|Xiaohua Xu Team|[2504.04099](http://arxiv.org/abs/2504.04099)|null|\n", "2504.03970": "|**2025-04-04**|**VideoComp: Advancing Fine-Grained Compositional and Temporal Alignment in Video-Text Models**|Anelia Angelova Team|[2504.03970](http://arxiv.org/abs/2504.03970)|null|\n", "2504.06263": "|**2025-04-08**|**OmniSVG: A Unified Scalable Vector Graphics Generation Model**|Yu-Gang Jiang Team|[2504.06263](http://arxiv.org/abs/2504.06263)|null|\n", "2504.06010": "|**2025-04-08**|**Latent Multimodal Reconstruction for Misinformation Detection**|Panagiotis C. Petrantonakis Team|[2504.06010](http://arxiv.org/abs/2504.06010)|**[link](https://github.com/stevejpapad/miscaptioned-image-reconstruction)**|\n", "2504.05651": "|**2025-04-08**|**Measuring D\u00e9j\u00e0 vu Memorization Efficiently**|Kamalika Chaudhuri Team|[2504.05651](http://arxiv.org/abs/2504.05651)|null|\n", "2504.05575": "|**2025-04-08**|**A Lightweight Large Vision-language Model for Multimodal Medical Images**|Navid Toosy Saidy Team|[2504.05575](http://arxiv.org/abs/2504.05575)|null|\n", "2504.05506": "|**2025-04-10**|**ChartQAPro: A More Diverse and Challenging Benchmark for Chart Question Answering**|Shafiq Joty Team|[2504.05506](http://arxiv.org/abs/2504.05506)|null|\n", "2504.05477": "|**2025-04-07**|**Trust Through Transparency: Explainable Social Navigation for Autonomous Mobile Robots via Vision-Language Models**|Aliasghar Arab Team|[2504.05477](http://arxiv.org/abs/2504.05477)|null|\n", "2504.05457": "|**2025-04-07**|**Taxonomy-Aware Evaluation of Vision-Language Models**|Stella Frank Team|[2504.05457](http://arxiv.org/abs/2504.05457)|null|\n", "2504.05445": "|**2025-04-07**|**Probing the Visualization Literacy of Vision Language Models: the Good, the Bad, and the Ugly**|Anamaria Crisan Team|[2504.05445](http://arxiv.org/abs/2504.05445)|null|\n", "2504.07072": "|**2025-04-09**|**Kaleidoscope: In-language Exams for Massively Multilingual Vision Evaluation**|Marzieh Fadaee Team|[2504.07072](http://arxiv.org/abs/2504.07072)|null|\n", "2504.06925": "|**2025-04-09**|**Are Vision-Language Models Ready for Dietary Assessment? Exploring the Next Frontier in AI-Powered Food Image Recognition**|Aythami Morales Team|[2504.06925](http://arxiv.org/abs/2504.06925)|null|\n", "2504.06863": "|**2025-04-09**|**MovSAM: A Single-image Moving Object Segmentation Framework Based on Deep Thinking**|Hesheng Wang Team|[2504.06863](http://arxiv.org/abs/2504.06863)|null|\n", "2504.06838": "|**2025-04-09**|**ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box Vision-Language Models**|Namhoon Lee Team|[2504.06838](http://arxiv.org/abs/2504.06838)|null|\n", "2504.06835": "|**2025-04-09**|**LVC: A Lightweight Compression Framework for Enhancing VLMs in Long Video Understanding**|Bo XU Team|[2504.06835](http://arxiv.org/abs/2504.06835)|null|\n", "2504.06397": "|**2025-04-08**|**PromptHMR: Promptable Human Mesh Recovery**|Muhammed Kocabas Team|[2504.06397](http://arxiv.org/abs/2504.06397)|null|\n", "2504.06389": "|**2025-04-08**|**SemiDAViL: Semi-supervised Domain Adaptation with Vision-Language Guidance for Semantic Segmentation**|Zhaozheng Yin Team|[2504.06389](http://arxiv.org/abs/2504.06389)|null|\n", "2504.07956": "|**2025-04-10**|**VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning**|Feng Zhao Team|[2504.07956](http://arxiv.org/abs/2504.07956)|null|\n", "2504.07867": "|**2025-04-10**|**SAMJAM: Zero-Shot Video Scene Graph Generation for Egocentric Kitchen Videos**|Yuhao Chen Team|[2504.07867](http://arxiv.org/abs/2504.07867)|null|\n", "2504.07643": "|**2025-04-10**|**CollEX -- A Multimodal Agentic RAG System Enabling Interactive Exploration of Scientific Collections**|Chris Biemann Team|[2504.07643](http://arxiv.org/abs/2504.07643)|null|\n", "2504.07615": "|**2025-04-10**|**VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model**|Tiancheng Zhao Team|[2504.07615](http://arxiv.org/abs/2504.07615)|**[link](https://github.com/om-ai-lab/vlm-r1)**|\n", "2504.07556": "|**2025-04-10**|**TokenFocus-VQA: Enhancing Text-to-Image Alignment with Position-Aware Focus and Multi-Perspective Aggregations on LVLMs**|Xuezhi Cao Team|[2504.07556](http://arxiv.org/abs/2504.07556)|null|\n", "2504.07521": "|**2025-04-10**|**Why We Feel: Breaking Boundaries in Emotional Reasoning with Multimodal Large Language Models**|Xian-Sheng Hua Team|[2504.07521](http://arxiv.org/abs/2504.07521)|**[link](https://github.com/lum1104/eibench)**|\n", "2504.07491": "|**2025-04-10**|**Kimi-VL Technical Report**|Ziwei Chen Team|[2504.07491](http://arxiv.org/abs/2504.07491)|**[link](https://github.com/moonshotai/kimi-vl)**|\n", "2504.07165": "|**2025-04-09**|**Perception in Reflection**|Vishal M. Patel Team|[2504.07165](http://arxiv.org/abs/2504.07165)|null|\n", "2504.08583": "|**2025-04-11**|**AstroLLaVA: towards the unification of astronomical data and natural language**|Dimitrios Tanoglidis Team|[2504.08583](http://arxiv.org/abs/2504.08583)|null|\n", "2504.08205": "|**2025-04-11**|**EO-VLM: VLM-Guided Energy Overload Attacks on Vision Models**|Jinwoo Kim Team|[2504.08205](http://arxiv.org/abs/2504.08205)|null|\n", "2504.08154": "|**2025-04-10**|**Investigating Vision-Language Model for Point Cloud-based Vehicle Classification**|Camille Kamga Team|[2504.08154](http://arxiv.org/abs/2504.08154)|null|\n", "2504.08066": "|**2025-04-10**|**The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search**|David Ha Team|[2504.08066](http://arxiv.org/abs/2504.08066)|null|\n", "2504.10465": "|**2025-04-14**|**Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding**|Jiashi Feng Team|[2504.10465](http://arxiv.org/abs/2504.10465)|null|\n", "2504.10458": "|**2025-04-15**|**GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents**|Run Luo Team|[2504.10458](http://arxiv.org/abs/2504.10458)|null|\n", "2504.10320": "|**2025-04-14**|**SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model**|Yanning Zhang Team|[2504.10320](http://arxiv.org/abs/2504.10320)|null|\n", "2504.10127": "|**2025-04-15**|**Breaking the Data Barrier -- Building GUI Agents Through Task Generalization**|Junxian He Team|[2504.10127](http://arxiv.org/abs/2504.10127)|null|\n", "2504.10117": "|**2025-04-14**|**AGO: Adaptive Grounding for Open World 3D Occupancy Prediction**|Andreas Zell Team|[2504.10117](http://arxiv.org/abs/2504.10117)|null|\n", "2504.10090": "|**2025-04-14**|**CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography**|Jun-Cheng Chen Team|[2504.10090](http://arxiv.org/abs/2504.10090)|null|\n", "2504.10049": "|**2025-04-14**|**Summarization of Multimodal Presentations with Vision-Language Models: Study of the Effect of Modalities and Structure**|Fr\u00e9d\u00e9ric Dufaux Team|[2504.10049](http://arxiv.org/abs/2504.10049)|null|\n", "2504.10044": "|**2025-04-14**|**Aligning Anime Video Generation with Human Feedback**|Zuxuan Wu Team|[2504.10044](http://arxiv.org/abs/2504.10044)|null|\n", "2504.10011": "|**2025-04-14**|**KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks**|Takamitsu Matsubara Team|[2504.10011](http://arxiv.org/abs/2504.10011)|null|\n", "2504.09997": "|**2025-04-14**|**GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control**|Xiaoqiang Ji Team|[2504.09997](http://arxiv.org/abs/2504.09997)|null|\n", "2504.09979": "|**2025-04-14**|**Resampling Benchmark for Efficient Comprehensive Evaluation of Large Vision-Language Models**|Keisuke Ozawa Team|[2504.09979](http://arxiv.org/abs/2504.09979)|null|\n", "2504.09859": "|**2025-04-14**|**Can VLMs Assess Similarity Between Graph Visualizations?**|Jinwook Seo Team|[2504.09859](http://arxiv.org/abs/2504.09859)|null|\n", "2504.09795": "|**2025-04-14**|**VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents**|Jun Suzuki Team|[2504.09795](http://arxiv.org/abs/2504.09795)|null|\n", "2504.09724": "|**2025-04-13**|**A Survey on Efficient Vision-Language Models**|Nirmalya Roy Team|[2504.09724](http://arxiv.org/abs/2504.09724)|null|\n", "2504.09620": "|**2025-04-13**|**Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models via Decentralized Bayesian Inference**|Tadahiro Taniguchi Team|[2504.09620](http://arxiv.org/abs/2504.09620)|null|\n", "2504.09598": "|**2025-04-13**|**DualPrompt-MedCap: A Dual-Prompt Enhanced Approach for Medical Image Captioning**|Mukesh Prasad Team|[2504.09598](http://arxiv.org/abs/2504.09598)|null|\n", "2504.09480": "|**2025-04-13**|**Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation**|Yunhong Wang Team|[2504.09480](http://arxiv.org/abs/2504.09480)|null|\n", "2504.09439": "|**2025-04-13**|**Identity-Aware Vision-Language Model for Explainable Face Forgery Detection**|Yu-Gang Jiang Team|[2504.09439](http://arxiv.org/abs/2504.09439)|null|\n", "2504.09426": "|**2025-04-13**|**BabyVLM: Data-Efficient Pretraining of VLMs Inspired by Infant Learning**|Boqing Gong Team|[2504.09426](http://arxiv.org/abs/2504.09426)|null|\n", "2504.09258": "|**2025-04-12**|**PathVLM-R1: A Reinforcement Learning-Driven Reasoning Model for Pathology Visual-Language Tasks**|Yang Liu Team|[2504.09258](http://arxiv.org/abs/2504.09258)|null|\n", "2504.11368": "|**2025-04-15**|**From Gaze to Insight: Bridging Human Visual Attention and Vision Language Model Explanation for Weakly-Supervised Medical Image Segmentation**|Jungong Han Team|[2504.11368](http://arxiv.org/abs/2504.11368)|null|\n", "2504.11257": "|**2025-04-17**|**UI-E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction Synthesis**|Yan Lu Team|[2504.11257](http://arxiv.org/abs/2504.11257)|null|\n", "2504.11195": "|**2025-04-15**|**R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning**|Ran He Team|[2504.11195](http://arxiv.org/abs/2504.11195)|null|\n", "2504.11108": "|**2025-04-15**|**Benchmarking Vision Language Models on German Factual Data**|Vincent Tischler Team|[2504.11108](http://arxiv.org/abs/2504.11108)|null|\n", "2504.11101": "|**2025-04-16**|**Consensus Entropy: Harnessing Multi-VLM Agreement for Self-Verifying and Self-Improving OCR**|Gongshen Liu Team|[2504.11101](http://arxiv.org/abs/2504.11101)|null|\n", "2504.11038": "|**2025-04-15**|**QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models**|Yu Wang Team|[2504.11038](http://arxiv.org/abs/2504.11038)|null|\n", "2504.10873": "|**2025-04-15**|**Can Vision-Language Models Understand and Interpret Dynamic Gestures from Pedestrians? Pilot Datasets and Exploration Towards Instructive Nonverbal Commands for Cooperative Autonomous Vehicles**|Ross Greer Team|[2504.10873](http://arxiv.org/abs/2504.10873)|null|\n", "2504.10854": "|**2025-04-15**|**LVLM_CSP: Accelerating Large Vision Language Models via Clustering, Scattering, and Pruning for Reasoning Segmentation**|Mohsen Imani Team|[2504.10854](http://arxiv.org/abs/2504.10854)|null|\n", "2504.10852": "|**2025-04-15**|**Enhancing Features in Long-tailed Data Using Large Vision Mode**|Xuesong Li Team|[2504.10852](http://arxiv.org/abs/2504.10852)|null|\n", "2504.10757": "|**2025-04-14**|**ReasonDrive: Efficient Visual Question Answering for Autonomous Vehicles with Reasoning-Enhanced Small Vision-Language Models**|Lifeng Zhou Team|[2504.10757](http://arxiv.org/abs/2504.10757)|null|\n", "2504.10568": "|**2025-04-14**|**AgMMU: A Comprehensive Agricultural Multimodal Understanding and Reasoning Benchmark**|Yu-Xiong Wang Team|[2504.10568](http://arxiv.org/abs/2504.10568)|null|\n", "2504.12256": "|**2025-04-16**|**FLIP Reasoning Challenge**|Roger Wattenhofer Team|[2504.12256](http://arxiv.org/abs/2504.12256)|null|\n", "2504.12137": "|**2025-04-16**|**Efficient Contrastive Decoding with Probabilistic Hallucination Detection - Mitigating Hallucinations in Large Vision Language Models -**|Hanno Gottschalk Team|[2504.12137](http://arxiv.org/abs/2504.12137)|null|\n", "2504.11967": "|**2025-04-17**|**Securing the Skies: A Comprehensive Survey on Anti-UAV Methods, Benchmarking, and Future Directions**|Zhi-Qi Cheng Team|[2504.11967](http://arxiv.org/abs/2504.11967)|null|\n", "2504.11930": "|**2025-04-16**|**Beyond Words: Augmenting Discriminative Richness via Diffusions in Unsupervised Prompt Learning**|Yi Chang Team|[2504.11930](http://arxiv.org/abs/2504.11930)|null|\n", "2504.11838": "|**2025-04-16**|**A Visual RAG Pipeline for Few-Shot Fine-Grained Product Classification**|Janis Keuper Team|[2504.11838](http://arxiv.org/abs/2504.11838)|null|\n", "2504.11733": "|**2025-04-17**|**DVLTA-VQA: Decoupled Vision-Language Modeling with Text-Guided Adaptation for Blind Video Quality Assessment**|Moncef Gabbouj Team|[2504.11733](http://arxiv.org/abs/2504.11733)|null|\n", "2504.11695": "|**2025-04-16**|**Interpreting the Linear Structure of Vision-language Model Embedding Spaces**|Stephanie Gil Team|[2504.11695](http://arxiv.org/abs/2504.11695)|null|\n", "2504.11675": "|**2025-04-16**|**VLM-Fuzz: Vision Language Model Assisted Recursive Depth-first Search Exploration for Effective UI Testing of Android Apps**|Mariano Ceccato Team|[2504.11675](http://arxiv.org/abs/2504.11675)|null|\n", "2504.11669": "|**2025-04-15**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Majid Mirmehdi Team|[2504.11669](http://arxiv.org/abs/2504.11669)|null|\n", "2504.11509": "|**2025-04-17**|**PATFinger: Prompt-Adapted Transferable Fingerprinting against Unauthorized Multimodal Dataset Usage**|Lina Wang Team|[2504.11509](http://arxiv.org/abs/2504.11509)|null|\n", "2504.13180": "|**2025-04-17**|**PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding**|Christoph Feichtenhofer Team|[2504.13180](http://arxiv.org/abs/2504.13180)|null|\n", "2504.13169": "|**2025-04-17**|**Generate, but Verify: Reducing Hallucination in Vision-Language Models with Retrospective Resampling**|David M. Chan Team|[2504.13169](http://arxiv.org/abs/2504.13169)|**[link](https://github.com/tsunghan-wu/reverse_vlm)**|\n", "2504.13123": "|**2025-04-17**|**Low-hallucination Synthetic Captions for Large-Scale Vision-Language Model Pre-training**|Zhanhui Kang Team|[2504.13123](http://arxiv.org/abs/2504.13123)|null|\n", "2504.13120": "|**2025-04-17**|**Probing and Inducing Combinational Creativity in Vision-Language Models**|Zilong Zheng Team|[2504.13120](http://arxiv.org/abs/2504.13120)|null|\n", "2504.13119": "|**2025-04-17**|**Object-Driven Narrative in AR: A Scenario-Metaphor Framework with VLM Integration**|Yong Hong Kuo Team|[2504.13119](http://arxiv.org/abs/2504.13119)|null|\n", "2504.13069": "|**2025-04-17**|**Early Accessibility: Automating Alt-Text Generation for UI Icons During App Development**|Christoph Csallner Team|[2504.13069](http://arxiv.org/abs/2504.13069)|null|\n", "2504.13055": "|**2025-04-17**|**NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation**|Michael Qizhe Shieh Team|[2504.13055](http://arxiv.org/abs/2504.13055)|null|\n", "2504.12680": "|**2025-04-17**|**Embodied-R: Collaborative Framework for Activating Embodied Spatial Reasoning in Foundation Models via Reinforcement Learning**|Wenwu Zhu Team|[2504.12680](http://arxiv.org/abs/2504.12680)|**[link](https://github.com/embodiedcity/embodied-r.code)**|\n", "2504.12661": "|**2025-04-17**|**VLMGuard-R1: Proactive Safety Alignment for VLMs via Reasoning-Driven Prompt Optimization**|Siheng Chen Team|[2504.12661](http://arxiv.org/abs/2504.12661)|null|\n", "2504.12436": "|**2025-04-16**|**Sparsity Outperforms Low-Rank Projections in Few-Shot Adaptation**|\u00c9ric Granger Team|[2504.12436](http://arxiv.org/abs/2504.12436)|**[link](https://github.com/nairouz/SO)**|\n", "2504.13690": "|**2025-04-21**|**Analysing the Robustness of Vision-Language-Models to Common Corruptions**|Umair Bin Mansoor Team|[2504.13690](http://arxiv.org/abs/2504.13690)|null|\n", "2504.13650": "|**2025-04-18**|**EyecareGPT: Boosting Comprehensive Ophthalmology Understanding with Tailored Dataset, Benchmark and Model**|Beng Chin Ooi Team|[2504.13650](http://arxiv.org/abs/2504.13650)|**[link](https://github.com/dcdmllm/eyecaregpt)**|\n", "2504.13624": "|**2025-04-18**|**PV-VLM: A Multimodal Vision-Language Approach Incorporating Sky Images for Intra-Hour Photovoltaic Power Forecasting**|Miao Yu Team|[2504.13624](http://arxiv.org/abs/2504.13624)|null|\n", "2504.13460": "|**2025-04-18**|**Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization**|Huadong Ma Team|[2504.13460](http://arxiv.org/abs/2504.13460)|null|\n", "2504.13399": "|**2025-04-18**|**Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety**|Ross Greer Team|[2504.13399](http://arxiv.org/abs/2504.13399)|null|\n", "2504.13365": "|**2025-04-17**|**VLLFL: A Vision-Language Model Based Lightweight Federated Learning Framework for Smart Agriculture**|Yanbo Huang Team|[2504.13365](http://arxiv.org/abs/2504.13365)|null|\n", "2504.13351": "|**2025-04-17**|**Chain-of-Modality: Learning Manipulation Programs from Multimodal Human Videos with Vision-Language-Models**|Jacky Liang Team|[2504.13351](http://arxiv.org/abs/2504.13351)|null|\n", "2504.13231": "|**2025-04-17**|**WildFireCan-MMD: A Multimodal dataset for Classification of User-generated Content During Wildfires in Canada**|Marzieh Amini Team|[2504.13231](http://arxiv.org/abs/2504.13231)|null|\n", "2504.15271": "|**2025-04-21**|**Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models**|Guilin Liu Team|[2504.15271](http://arxiv.org/abs/2504.15271)|null|\n", "2504.15135": "|**2025-04-21**|**KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking**|Kijung Shin Team|[2504.15135](http://arxiv.org/abs/2504.15135)|**[link](https://github.com/juyeonnn/kgmel)**|\n", "2504.14988": "|**2025-04-21**|**Benchmarking Large Vision-Language Models on Fine-Grained Image Tasks: A Comprehensive Evaluation**|Serge Belongie Team|[2504.14988](http://arxiv.org/abs/2504.14988)|**[link](https://github.com/seu-vipgroup/fg-bmk)**|\n", "2504.14904": "|**2025-04-21**|**VLM as Policy: Common-Law Content Moderation Framework for Short Video Platform**|Kun Gai Team|[2504.14904](http://arxiv.org/abs/2504.14904)|null|\n", "2504.14848": "|**2025-04-21**|**Object-Level Verbalized Confidence Calibration in Vision-Language Models via Semantic Perturbation**|Yunji Chen Team|[2504.14848](http://arxiv.org/abs/2504.14848)|null|\n", "2504.14692": "|**2025-04-20**|**OmniV-Med: Scaling Medical Vision-Language Model for Universal Visual Understanding**|Zuozhu Liu Team|[2504.14692](http://arxiv.org/abs/2504.14692)|null|\n", "2504.14638": "|**2025-04-20**|**NVSMask3D: Hard Visual Prompting with Camera Pose Interpolation for 3D Open Vocabulary Instance Segmentation**|Juho Kannala Team|[2504.14638](http://arxiv.org/abs/2504.14638)|null|\n", "2504.14467": "|**2025-04-20**|**LGD: Leveraging Generative Descriptions for Zero-Shot Referring Image Segmentation**|Yongsheng Gao Team|[2504.14467](http://arxiv.org/abs/2504.14467)|null|\n", "2504.14446": "|**2025-04-20**|**Neglected Risks: The Disturbing Reality of Children's Images in Datasets and the Urgent Call for Accountability**|Sandra Avila Team|[2504.14446](http://arxiv.org/abs/2504.14446)|null|\n", "2504.14395": "|**2025-04-19**|**Hydra: An Agentic Reasoning Approach for Enhancing Adversarial Robustness and Mitigating Hallucinations in Vision-Language Models**|Nathaniel D. Bastian Team|[2504.14395](http://arxiv.org/abs/2504.14395)|null|\n", "2504.14391": "|**2025-04-19**|**How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?**|James Zou Team|[2504.14391](http://arxiv.org/abs/2504.14391)|null|\n", "2504.14359": "|**2025-04-19**|**A Multimodal Recaptioning Framework to Account for Perceptual Diversity in Multilingual Vision-Language Modeling**|Adriana Kovashka Team|[2504.14359](http://arxiv.org/abs/2504.14359)|null|\n", "2504.14326": "|**2025-04-19**|**Diffusion-based Dynamic Contract for Federated AI Agent Construction in Mobile Metaverses**|Chau Yuen Team|[2504.14326](http://arxiv.org/abs/2504.14326)|null|\n", "2504.14200": "|**2025-04-19**|**Enhancing Multimodal In-Context Learning for Image Classification through Coreset Optimization**|Xu Yang Team|[2504.14200](http://arxiv.org/abs/2504.14200)|null|\n", "2504.14123": "|**2025-04-19**|**Bayesian Principles Improve Prompt Learning In Vision-Language Models**|Mijung Park Team|[2504.14123](http://arxiv.org/abs/2504.14123)|null|\n", "2504.14117": "|**2025-04-19**|**PEFT A2Z: Parameter-Efficient Fine-Tuning Survey for Large Language and Vision Models**|Ozlem Ozmen Garibay Team|[2504.14117](http://arxiv.org/abs/2504.14117)|null|\n", "2504.16083": "|**2025-04-22**|**MMInference: Accelerating Pre-filling for Long-Context VLMs via Modality-Aware Permutation Sparse Attention**|Lili Qiu Team|[2504.16083](http://arxiv.org/abs/2504.16083)|null|\n", "2504.16082": "|**2025-04-22**|**MR. Video: \"MapReduce\" is the Principle for Long Video Understanding**|Yu-Xiong Wang Team|[2504.16082](http://arxiv.org/abs/2504.16082)|null|\n", "2504.16072": "|**2025-04-22**|**Describe Anything: Detailed Localized Image and Video Captioning**|Yin Cui Team|[2504.16072](http://arxiv.org/abs/2504.16072)|null|\n", "2504.16061": "|**2025-04-22**|**Vision language models are unreliable at trivial spatial cognition**|J. Gregory Trafton Team|[2504.16061](http://arxiv.org/abs/2504.16061)|null|\n", "2504.16060": "|**2025-04-22**|**Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation**|Joyce Chai Team|[2504.16060](http://arxiv.org/abs/2504.16060)|null|\n", "2504.16047": "|**2025-04-22**|**Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis**|Judy Gichoya Team|[2504.16047](http://arxiv.org/abs/2504.16047)|null|\n", "2504.16030": "|**2025-04-22**|**LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale**|Mike Zheng Shou Team|[2504.16030](http://arxiv.org/abs/2504.16030)|null|\n", "2504.15929": "|**2025-04-24**|**Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models**|Tolga \u00c7ukur Team|[2504.15929](http://arxiv.org/abs/2504.15929)|null|\n", "2504.15485": "|**2025-04-21**|**CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting**|Mohit Bansal Team|[2504.15485](http://arxiv.org/abs/2504.15485)|null|\n", "2504.16727": "|**2025-04-24**|**V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations**|Yi R. Fung Team|[2504.16727](http://arxiv.org/abs/2504.16727)|null|\n", "2504.16538": "|**2025-04-23**|**Streetscape Analysis with Generative AI (SAGAI): Vision-Language Assessment and Mapping of Urban Scenes**|Giovanni Fusco Team|[2504.16538](http://arxiv.org/abs/2504.16538)|null|\n", "2504.16505": "|**2025-04-23**|**TraveLLaMA: Facilitating Multi-modal Large Language Models to Understand Urban Scenes and Provide Travel Assistance**|Jiaya Jia Team|[2504.16505](http://arxiv.org/abs/2504.16505)|null|\n", "2504.16433": "|**2025-04-23**|**FrogDogNet: Fourier frequency Retained visual prompt Output Guidance for Domain Generalization of CLIP in Remote Sensing**|Biplab Banerjee Team|[2504.16433](http://arxiv.org/abs/2504.16433)|null|\n", "2504.16181": "|**2025-04-22**|**CLIP-IT: CLIP-based Pairing for Histology Images Classification**|Eric Granger Team|[2504.16181](http://arxiv.org/abs/2504.16181)|null|\n", "2504.17671": "|**2025-04-25**|**Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction**|Weiyan Wen Team|[2504.17671](http://arxiv.org/abs/2504.17671)|null|\n", "2504.17395": "|**2025-04-24**|**SDVPT: Semantic-Driven Visual Prompt Tuning for Open-World Object Counting**|Qingming Huang Team|[2504.17395](http://arxiv.org/abs/2504.17395)|null|\n", "2504.17353": "|**2025-04-24**|**M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction**|Tatsunori Mori Team|[2504.17353](http://arxiv.org/abs/2504.17353)|null|\n", "2504.17315": "|**2025-04-24**|**DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation System Leveraging Large Vision-Language Model**|Hao Yang Team|[2504.17315](http://arxiv.org/abs/2504.17315)|null|\n", "2504.17282": "|**2025-04-24**|**Cracking the Code of Action: a Generative Approach to Affordances for Reinforcement Learning**|Khimya Khetarpal Team|[2504.17282](http://arxiv.org/abs/2504.17282)|null|\n", "2504.17207": "|**2025-04-24**|**Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation**|Minhyuk Sung Team|[2504.17207](http://arxiv.org/abs/2504.17207)|null|\n", "2504.17069": "|**2025-04-23**|**Distilling semantically aware orders for autoregressive image generation**|Marco Pedersoli Team|[2504.17069](http://arxiv.org/abs/2504.17069)|null|\n", "2504.17040": "|**2025-04-23**|**DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs**|Ran Xu Team|[2504.17040](http://arxiv.org/abs/2504.17040)|null|\n", "2504.18538": "|**2025-04-25**|**Generalization Capability for Imitation Learning**|Yixiao Wang Team|[2504.18538](http://arxiv.org/abs/2504.18538)|null|\n", "2504.18458": "|**2025-04-25**|**Fast-Slow Thinking for Large Vision-Language Model Reasoning**|Fei Wu Team|[2504.18458](http://arxiv.org/abs/2504.18458)|null|\n", "2504.18453": "|**2025-04-25**|**Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation**|Guang Yang Team|[2504.18453](http://arxiv.org/abs/2504.18453)|null|\n", "2504.18349": "|**2025-04-25**|**Revisiting Data Auditing in Large Vision-Language Models**|Zhuosheng Zhang Team|[2504.18349](http://arxiv.org/abs/2504.18349)|null|\n", "2504.18027": "|**2025-04-25**|**A Large Vision-Language Model based Environment Perception System for Visually Impaired People**|Shiguo Lian Team|[2504.18027](http://arxiv.org/abs/2504.18027)|null|\n", "2504.17902": "|**2025-04-24**|**CAMU: Context Augmentation for Meme Understanding**|Aditya Joshi Team|[2504.17902](http://arxiv.org/abs/2504.17902)|null|\n", "2504.17826": "|**2025-04-24**|**FashionM3: Multimodal, Multitask, and Multiround Fashion Assistant based on Unified Vision-Language Model**|Waikeung Wong Team|[2504.17826](http://arxiv.org/abs/2504.17826)|null|\n", "2504.20024": "|**2025-04-28**|**SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning**|Alan Yuille Team|[2504.20024](http://arxiv.org/abs/2504.20024)|null|\n", "2504.19742": "|**2025-04-28**|**EcoWikiRS: Learning Ecological Representation of Satellite Images from Weak Supervision with Species Observations and Wikipedia**|Diego Marcos Team|[2504.19742](http://arxiv.org/abs/2504.19742)|null|\n", "2504.19739": "|**2025-04-28**|**Contrastive Language-Image Learning with Augmented Textual Prompts for 3D/4D FER Using Vision-Language Model**|Guoying Zhao Team|[2504.19739](http://arxiv.org/abs/2504.19739)|null|\n", "2504.19627": "|**2025-04-28**|**VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning**|Xiaobo Xia Team|[2504.19627](http://arxiv.org/abs/2504.19627)|null|\n", "2504.19524": "|**2025-04-28**|**LR-IAD:Mask-Free Industrial Anomaly Detection with Logical Reasoning**|Aimin Yang Team|[2504.19524](http://arxiv.org/abs/2504.19524)|null|\n", "2504.19127": "|**2025-04-27**|**DeepSPG: Exploring Deep Semantic Prior Guidance for Low-light Image Enhancement with Multimodal Learning**|Shini Han Team|[2504.19127](http://arxiv.org/abs/2504.19127)|null|\n", "2504.19086": "|**2025-04-27**|**Boosting Single-domain Generalized Object Detection via Vision-Language Knowledge Interaction**|Jian Liu Team|[2504.19086](http://arxiv.org/abs/2504.19086)|null|\n", "2504.18856": "|**2025-04-26**|**Multi-Resolution Pathology-Language Pre-training Model with Text-Guided Visual Representation**|Arif Mahmood Team|[2504.18856](http://arxiv.org/abs/2504.18856)|null|\n", "2504.18800": "|**2025-04-26**|**Video CLIP Model for Multi-View Echocardiography Interpretation**|Norihiko Takeda Team|[2504.18800](http://arxiv.org/abs/2504.18800)|null|\n", "2504.18738": "|**2025-04-25**|**A Review of 3D Object Detection with Vision-Language Models**|Manoj Karkee Team|[2504.18738](http://arxiv.org/abs/2504.18738)|null|\n", "2504.18671": "|**2025-04-25**|**Proof-of-TBI -- Fine-Tuned Vision Language Model Consortium and OpenAI-o3 Reasoning LLM-Based Medical Diagnosis Support System for Mild Traumatic Brain Injury (TBI) Prediction**|Donna Broshek Team|[2504.18671](http://arxiv.org/abs/2504.18671)|null|\n", "2504.20976": "|**2025-04-29**|**Real-Time Wayfinding Assistant for Blind and Low-Vision Users**|Farhan Sadaf Team|[2504.20976](http://arxiv.org/abs/2504.20976)|null|\n", "2504.20860": "|**2025-04-29**|**FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language Models**|Elisa Ricci Team|[2504.20860](http://arxiv.org/abs/2504.20860)|null|\n", "2504.20690": "|**2025-04-29**|**In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer**|Yi Yang Team|[2504.20690](http://arxiv.org/abs/2504.20690)|null|\n", "2504.20648": "|**2025-04-29**|**SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data**|Freda Shi Team|[2504.20648](http://arxiv.org/abs/2504.20648)|null|\n", "2504.20520": "|**2025-04-29**|**PRISM: Projection-based Reward Integration for Scene-Aware Real-to-Sim-to-Real Transfer with Few Demonstrations**|Xuguang Lan Team|[2504.20520](http://arxiv.org/abs/2504.20520)|null|\n", "2504.20468": "|**2025-04-29**|**Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception**|Xiaoqiang Li Team|[2504.20468](http://arxiv.org/abs/2504.20468)|null|\n", "2504.20419": "|**2025-04-29**|**Plant Disease Detection through Multimodal Large Language Models and Convolutional Neural Networks**|Dimitrios K. Nasiopoulos Team|[2504.20419](http://arxiv.org/abs/2504.20419)|null|\n", "2504.20384": "|**2025-04-29**|**FiLA-Video: Spatio-Temporal Compression for Fine-Grained Long Video Understanding**|Bo Zheng Team|[2504.20384](http://arxiv.org/abs/2504.20384)|null|\n", "2504.20220": "|**2025-04-28**|**A Multimodal Pipeline for Clinical Data Extraction: Applying Vision-Language Models to Scans of Transfusion Reaction Reports**|Christoph M. Friedrich Team|[2504.20220](http://arxiv.org/abs/2504.20220)|null|\n", "2504.20199": "|**2025-04-28**|**Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains**|Rui Yan Team|[2504.20199](http://arxiv.org/abs/2504.20199)|null|\n", "2504.21831": "|**2025-04-30**|**Early Exit and Multi Stage Knowledge Distillation in VLMs for Video Summarization**|Ganesh Ramakrishnan Team|[2504.21831](http://arxiv.org/abs/2504.21831)|null|\n", "2504.21559": "|**2025-04-30**|**Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models**|Lin Lee Cheong Team|[2504.21559](http://arxiv.org/abs/2504.21559)|null|\n", "2504.21530": "|**2025-04-30**|**RoboGround: Robotic Manipulation with Grounded Vision-Language Priors**|Zhou Zhao Team|[2504.21530](http://arxiv.org/abs/2504.21530)|null|\n", "2504.21344": "|**2025-04-30**|**Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early Lung Cancer Detection**|William Hsu Team|[2504.21344](http://arxiv.org/abs/2504.21344)|null|\n", "2504.21226": "|**2025-04-29**|**MemeBLIP2: A novel lightweight multimodal system to detect harmful memes**|Lisha Xu Team|[2504.21226](http://arxiv.org/abs/2504.21226)|null|\n", "2504.21186": "|**2025-04-29**|**GLIP-OOD: Zero-Shot Graph OOD Detection with Foundation Model**|Yue Zhao Team|[2504.21186](http://arxiv.org/abs/2504.21186)|null|\n", "2504.21063": "|**2025-04-29**|**Token-Level Prompt Mixture with Parameter-Free Routing for Federated Domain Generalization**|Xiaojun Chang Team|[2504.21063](http://arxiv.org/abs/2504.21063)|null|\n", "2505.00693": "|**2025-05-01**|**Robotic Visual Instruction**|Xianzheng Ma Team|[2505.00693](http://arxiv.org/abs/2505.00693)|null|\n", "2505.00684": "|**2025-05-01**|**Visual Test-time Scaling for GUI Agent Grounding**|Honglak Lee Team|[2505.00684](http://arxiv.org/abs/2505.00684)|null|\n", "2505.00527": "|**2025-05-01**|**DeCo: Task Decomposition and Skill Composition for Zero-Shot Generalization in Long-Horizon 3D Manipulation**|Yang Gao Team|[2505.00527](http://arxiv.org/abs/2505.00527)|null|\n", "2505.00284": "|**2025-05-01**|**LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous Driving**|Henry X. Liu Team|[2505.00284](http://arxiv.org/abs/2505.00284)|null|\n", "2505.00275": "|**2025-05-01**|**AdCare-VLM: Leveraging Large Vision Language Model (LVLM) to Monitor Long-Term Medication Adherence and Care**|Tianming Liu Team|[2505.00275](http://arxiv.org/abs/2505.00275)|null|\n", "2505.00156": "|**2025-04-30**|**V3LMA: Visual 3D-enhanced Language Model for Autonomous Driving**|Markus Lienkamp Team|[2505.00156](http://arxiv.org/abs/2505.00156)|null|\n", "2505.00150": "|**2025-04-30**|**Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models**|Xintao Wu Team|[2505.00150](http://arxiv.org/abs/2505.00150)|null|\n", "2505.00134": "|**2025-04-30**|**Investigating Zero-Shot Diagnostic Pathology in Vision-Language Models with Efficient Prompt Design**|Mahdi S. Hosseini Team|[2505.00134](http://arxiv.org/abs/2505.00134)|null|\n", "2505.01399": "|**2025-05-02**|**Dynamic Robot Tool Use with Vision Language Models**|Ahmed H. Qureshi Team|[2505.01399](http://arxiv.org/abs/2505.01399)|null|\n", "2505.01096": "|**2025-05-02**|**Evaluating Vision Language Model Adaptations for Radiology Report Generation in Low-Resource Languages**|Valerio Guarrasi Team|[2505.01096](http://arxiv.org/abs/2505.01096)|null|\n", "2505.01091": "|**2025-05-02**|**Any-to-Any Vision-Language Model for Multimodal X-ray Imaging and Radiological Report Generation**|Valerio Guarrasi Team|[2505.01091](http://arxiv.org/abs/2505.01091)|null|\n", "2505.01050": "|**2025-05-02**|**Transferable Adversarial Attacks on Black-Box Vision-Language Models**|Matt Fredrikson Team|[2505.01050](http://arxiv.org/abs/2505.01050)|null|\n", "2505.00746": "|**2025-04-30**|**Entropy Heat-Mapping: Localizing GPT-Based OCR Errors with Sliding-Window Shannon Analysis**|Alexei Kaltchenko Team|[2505.00746](http://arxiv.org/abs/2505.00746)|null|\n", "2505.02829": "|**2025-05-05**|**LISAT: Language-Instructed Segmentation Assistant for Satellite Imagery**|David M. Chan Team|[2505.02829](http://arxiv.org/abs/2505.02829)|null|\n", "2505.02569": "|**2025-05-05**|**HapticVLM: VLM-Driven Texture Recognition Aimed at Intelligent Haptic Interaction**|Dzmitry Tsetserukou Team|[2505.02569](http://arxiv.org/abs/2505.02569)|null|\n", "2505.02466": "|**2025-05-05**|**Tevatron 2.0: Unified Document Retrieval Toolkit across Scale, Language, and Modality**|Jimmy Lin Team|[2505.02466](http://arxiv.org/abs/2505.02466)|null|\n", "2505.02448": "|**2025-05-05**|**Recent Advances in Out-of-Distribution Detection with CLIP-Like Models: A Survey**|Songcan Chen Team|[2505.02448](http://arxiv.org/abs/2505.02448)|null|\n", "2505.02370": "|**2025-05-05**|**SuperEdit: Rectifying and Facilitating Supervision for Instruction-Based Image Editing**|Sijie Zhu Team|[2505.02370](http://arxiv.org/abs/2505.02370)|**[link](https://github.com/bytedance/superedit)**|\n", "2505.02325": "|**2025-05-05**|**TeDA: Boosting Vision-Lanuage Models for Zero-Shot 3D Object Retrieval via Testing-time Distribution Alignment**|Xinwei He Team|[2505.02325](http://arxiv.org/abs/2505.02325)|null|\n", "2505.02278": "|**2025-05-04**|**Compositional Image-Text Matching and Retrieval by Grounding Entities**|Jana Ko\u0161eck\u00e1 Team|[2505.02278](http://arxiv.org/abs/2505.02278)|null|\n", "2505.02056": "|**2025-05-04**|**Handling Imbalanced Pseudolabels for Vision-Language Models with Concept Alignment and Confusion-Aware Calibrated Margin**|Xinyang Chen Team|[2505.02056](http://arxiv.org/abs/2505.02056)|null|\n", "2505.01958": "|**2025-05-04**|**A Comprehensive Analysis for Visual Object Hallucination in Large Vision-Language Models**|Xinya Du Team|[2505.01958](http://arxiv.org/abs/2505.01958)|null|\n", "2505.01881": "|**2025-05-03**|**PhysNav-DG: A Novel Adaptive Framework for Robust VLM-Sensor Fusion in Navigation Applications**|Santosh Patapati Team|[2505.01881](http://arxiv.org/abs/2505.01881)|null|\n", "2505.01790": "|**2025-05-03**|**Enhancing the Learning Experience: Using Vision-Language Models to Generate Questions for Educational Videos**|Anett Hoppe Team|[2505.01790](http://arxiv.org/abs/2505.01790)|null|\n", "2505.01743": "|**2025-05-03**|**An LLM-Empowered Low-Resolution Vision System for On-Device Human Behavior Understanding**|Guoliang Xing Team|[2505.01743](http://arxiv.org/abs/2505.01743)|null|\n", "2505.01713": "|**2025-05-03**|**Vision and Intention Boost Large Language Model in Long-Term Action Anticipation**|Yanning Zhang Team|[2505.01713](http://arxiv.org/abs/2505.01713)|null|\n", "2505.01709": "|**2025-05-03**|**RoBridge: A Hierarchical Architecture Bridging Cognition and Execution for General Robotic Manipulation**|Xiaodan Liang Team|[2505.01709](http://arxiv.org/abs/2505.01709)|null|\n", "2505.01694": "|**2025-05-03**|**Topology-Aware CLIP Few-Shot Learning**|Dazhi Huang Team|[2505.01694](http://arxiv.org/abs/2505.01694)|null|\n", "2505.01583": "|**2025-05-02**|**TEMPURA: Temporal Event Masked Prediction and Understanding for Reasoning in Action**|Jenq-Neng Hwang Team|[2505.01583](http://arxiv.org/abs/2505.01583)|null|\n", "2505.01578": "|**2025-05-02**|**Grounding Task Assistance with Multimodal Cues from a Single Demonstration**|Andrew D. Wilson Team|[2505.01578](http://arxiv.org/abs/2505.01578)|null|\n", "2505.03703": "|**2025-05-06**|**Fill the Gap: Quantifying and Reducing the Modality Gap in Image-Text Representation Learning**|Victor Amblard Team|[2505.03703](http://arxiv.org/abs/2505.03703)|null|\n", "2505.03667": "|**2025-05-06**|**Distribution-Conditional Generation: From Class Distribution to Creative Generation**|Xin Geng Team|[2505.03667](http://arxiv.org/abs/2505.03667)|null|\n", "2505.03611": "|**2025-05-06**|**Learning Unknown Spoof Prompts for Generalized Face Anti-Spoofing Using Only Real Face Images**|Zhenan Sun Team|[2505.03611](http://arxiv.org/abs/2505.03611)|null|\n", "2505.03610": "|**2025-05-06**|**Learning Knowledge-based Prompts for Robust 3D Mask Presentation Attack Detection**|Ming-Hsuan Yang Team|[2505.03610](http://arxiv.org/abs/2505.03610)|null|\n", "2505.03420": "|**2025-05-06**|**Mitigating Image Captioning Hallucinations in Vision-Language Models**|Xi Li Team|[2505.03420](http://arxiv.org/abs/2505.03420)|null|\n", "2505.03414": "|**2025-05-07**|**Enhancing Target-unspecific Tasks through a Features Matrix**|Jun Yu Team|[2505.03414](http://arxiv.org/abs/2505.03414)|null|\n", "2505.03374": "|**2025-05-06**|**Reducing Annotation Burden in Physical Activity Research Using Vision-Language Models**|Aiden Doherty Team|[2505.03374](http://arxiv.org/abs/2505.03374)|null|\n", "2505.03350": "|**2025-05-06**|**A Vision-Language Model for Focal Liver Lesion Classification**|Chen Yen-Wei Team|[2505.03350](http://arxiv.org/abs/2505.03350)|null|\n", "2505.03334": "|**2025-05-06**|**From Word to Sentence: A Large-Scale Multi-Instance Dataset for Open-Set Aerial Detection**|Rong Xiao Team|[2505.03334](http://arxiv.org/abs/2505.03334)|null|\n", "2505.03242": "|**2025-05-06**|**Seeing the Abstract: Translating the Abstract Language for Vision Language Models**|Yiming Wang Team|[2505.03242](http://arxiv.org/abs/2505.03242)|**[link](https://github.com/davidetalon/fashionact)**|\n", "2505.03181": "|**2025-05-06**|**VLM Q-Learning: Aligning Vision-Language Models for Interactive Decision-Making**|Juan Carlos Niebles Team|[2505.03181](http://arxiv.org/abs/2505.03181)|null|\n", "2505.03153": "|**2025-05-06**|**Robust Fairness Vision-Language Learning for Medical Image Analysis**|Shu Hu Team|[2505.03153](http://arxiv.org/abs/2505.03153)|**[link](https://github.com/purdue-m2/robust_fairness_for_medical_image)**|\n", "2505.02971": "|**2025-05-05**|**Adversarial Robustness Analysis of Vision-Language Models in Medical Image Segmentation**|Manish Dhakal Team|[2505.02971](http://arxiv.org/abs/2505.02971)|null|\n", "2505.04488": "|**2025-05-07**|**\"I Can See Forever!\": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments**|Xinlei He Team|[2505.04488](http://arxiv.org/abs/2505.04488)|null|\n", "2505.04410": "|**2025-05-07**|**DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception**|Zhuotao Tian Team|[2505.04410](http://arxiv.org/abs/2505.04410)|**[link](https://github.com/xiaomoguhz/declip)**|\n", "2505.04214": "|**2025-05-07**|**CM1 -- A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models**|Gernot A. Fink Team|[2505.04214](http://arxiv.org/abs/2505.04214)|null|\n", "2505.04147": "|**2025-05-07**|**R^3-VQA: \"Read the Room\" by Video Social Reasoning**|Lifeng Fan Team|[2505.04147](http://arxiv.org/abs/2505.04147)|null|\n", "2505.03981": "|**2025-05-06**|**X-Reasoner: Towards Generalizable Reasoning Across Modalities and Domains**|Hoifung Poon Team|[2505.03981](http://arxiv.org/abs/2505.03981)|null|\n", "2505.05464": "|**2025-05-08**|**Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging**|Junxian He Team|[2505.05464](http://arxiv.org/abs/2505.05464)|**[link](https://github.com/shiqichen17/vlm_merging)**|\n", "2505.05456": "|**2025-05-08**|**SITE: towards Spatial Intelligence Thorough Evaluation**|Boqing Gong Team|[2505.05456](http://arxiv.org/abs/2505.05456)|null|\n", "2505.05360": "|**2025-05-08**|**DSDrive: Distilling Large Language Model for Lightweight End-to-End Autonomous Driving with Unified Reasoning and Planning**|Jun Ma Team|[2505.05360](http://arxiv.org/abs/2505.05360)|null|\n", "2505.05343": "|**2025-05-08**|**Hearing and Seeing Through CLIP: A Framework for Self-Supervised Sound Source Localization**|Joon Son Chung Team|[2505.05343](http://arxiv.org/abs/2505.05343)|**[link](https://github.com/swimmiing/ACL-SSL)**|\n", "2505.05318": "|**2025-05-08**|**Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects**|Matteo Matteucci Team|[2505.05318](http://arxiv.org/abs/2505.05318)|null|\n", "2505.05189": "|**2025-05-08**|**Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language Models**|Meng Zhang Team|[2505.05189](http://arxiv.org/abs/2505.05189)|null|\n", "2505.05180": "|**2025-05-08**|**OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world Prompt Tuning**|Qingming Huang Team|[2505.05180](http://arxiv.org/abs/2505.05180)|**[link](https://github.com/huacong/openworldauc)**|\n", "2505.05163": "|**2025-05-08**|**Probabilistic Embeddings for Frozen Vision-Language Models: Uncertainty Quantification with Gaussian Process Latent Variable Models**|Joachim Denzler Team|[2505.05163](http://arxiv.org/abs/2505.05163)|null|\n", "2505.05130": "|**2025-05-08**|**CacheFL: Efficient Federated Cache Model Fine-Tuning for Vision-Language Models**|Furao Shen Team|[2505.05130](http://arxiv.org/abs/2505.05130)|null|\n", "2505.05098": "|**2025-05-08**|**X-Driver: Explainable Autonomous Driving with Vision-Language Models**|Zengfeng Zeng Team|[2505.05098](http://arxiv.org/abs/2505.05098)|null|\n", "2505.05040": "|**2025-05-08**|**Image-Text Relation Prediction for Multilingual Tweets**|Edison Marrese-Taylor Team|[2505.05040](http://arxiv.org/abs/2505.05040)|null|\n", "2505.05026": "|**2025-05-09**|**G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness**|Youngjae Yu Team|[2505.05026](http://arxiv.org/abs/2505.05026)|null|\n", "2505.05023": "|**2025-05-08**|**Split Matching for Inductive Zero-shot Semantic Segmentation**|Daisuke Deguchi Team|[2505.05023](http://arxiv.org/abs/2505.05023)|null|\n", "2505.04980": "|**2025-05-08**|**LVLM-MPC Collaboration for Autonomous Driving: A Safety-Aware and Task-Scalable Control Architecture**|Tatsuya Suzuki Team|[2505.04980](http://arxiv.org/abs/2505.04980)|null|\n", "2505.04769": "|**2025-05-07**|**Vision-Language-Action Models: Concepts, Progress, Applications and Challenges**|Manoj Karkee Team|[2505.04769](http://arxiv.org/abs/2505.04769)|null|\n", "2505.06152": "|**2025-05-09**|**MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks**|Bo Yan Team|[2505.06152](http://arxiv.org/abs/2505.06152)|**[link](https://github.com/zwq803/mm-skin)**|\n", "2505.05895": "|**2025-05-09**|**Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI**|Dominik Bollmann Team|[2505.05895](http://arxiv.org/abs/2505.05895)|null|\n", "2505.05804": "|**2025-05-09**|**Describe Anything in Medical Images**|Min Xu Team|[2505.05804](http://arxiv.org/abs/2505.05804)|null|\n", "2505.05800": "|**2025-05-09**|**3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks**|Farshad Khorrami Team|[2505.05800](http://arxiv.org/abs/2505.05800)|null|\n", "2505.05681": "|**2025-05-08**|**Fine-Tuning Video-Text Contrastive Model for Primate Behavior Retrieval from Unlabeled Raw Videos**|Nina S. T. Hirata Team|[2505.05681](http://arxiv.org/abs/2505.05681)|null|\n", "2505.05528": "|**2025-05-08**|**X-Transfer Attacks: Towards Super Transferable Adversarial Attacks on CLIP**|James Bailey Team|[2505.05528](http://arxiv.org/abs/2505.05528)|**[link](https://github.com/HanxunH/XTransferBench)**|\n", "2505.07815": "|**2025-05-12**|**Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models**|Jia-Bin Huang Team|[2505.07815](http://arxiv.org/abs/2505.07815)|null|\n", "2505.07730": "|**2025-05-12**|**Reproducibility, Replicability, and Insights into Visual Document Retrieval with Late Interaction**|Andrew Yates Team|[2505.07730](http://arxiv.org/abs/2505.07730)|null|\n", "2505.07704": "|**2025-05-12**|**Through the Looking Glass: Common Sense Consistency Evaluation of Weird Images**|Vasily Konovalov Team|[2505.07704](http://arxiv.org/abs/2505.07704)|null|\n", "2505.07690": "|**2025-05-12**|**Beyond CLIP Generalization: Against Forward&Backward Forgetting Adapter for Continual Learning of Vision-Language Models**|Yihong Gong Team|[2505.07690](http://arxiv.org/abs/2505.07690)|null|\n", "2505.07675": "|**2025-05-12**|**Simple Semi-supervised Knowledge Distillation from Vision-Language Models via $\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead $\\mathbf{\\texttt{O}}$ptimization**|Sung Ju Hwang Team|[2505.07675](http://arxiv.org/abs/2505.07675)|null|\n", "2505.07538": "|**2025-05-12**|**Discrete Visual Tokens of Autoregression, by Diffusion, and for Reasoning**|Hanwang Zhang Team|[2505.07538](http://arxiv.org/abs/2505.07538)|null|\n", "2505.07347": "|**2025-05-12**|**AI-Enabled Accurate Non-Invasive Assessment of Pulmonary Hypertension Progression via Multi-Modal Echocardiography**|Xiaomeng Li Team|[2505.07347](http://arxiv.org/abs/2505.07347)|null|\n", "2505.07263": "|**2025-05-12**|**Skywork-VL Reward: An Effective Reward Model for Multimodal Understanding and Reasoning**|Yahui Zhou Team|[2505.07263](http://arxiv.org/abs/2505.07263)|null|\n", "2505.07251": "|**2025-05-12**|**Incomplete In-context Learning**|Yangshijie Zhang Team|[2505.07251](http://arxiv.org/abs/2505.07251)|null|\n", "2505.07236": "|**2025-05-12**|**UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning**|Dzmitry Tsetserukou Team|[2505.07236](http://arxiv.org/abs/2505.07236)|null|\n", "2505.07219": "|**2025-05-12**|**Language-Driven Dual Style Mixing for Single-Domain Generalized Object Detection**|Ningjiang Chen Team|[2505.07219](http://arxiv.org/abs/2505.07219)|**[link](https://github.com/qinhongda8/ldds)**|\n", "2505.07176": "|**2025-05-12**|**Internet of Agents: Fundamentals, Applications, and Challenges**|Dusit Niyato Team|[2505.07176](http://arxiv.org/abs/2505.07176)|null|\n", "2505.07172": "|**2025-05-12**|**Critique Before Thinking: Mitigating Hallucination through Rationale-Augmented Instruction Tuning**|Weiping Wang Team|[2505.07172](http://arxiv.org/abs/2505.07172)|null|\n", "2505.07164": "|**2025-05-12**|**EmoVLM-KD: Fusing Distilled Expertise with Vision-Language Models for Visual Emotion Analysis**|Eunil Park Team|[2505.07164](http://arxiv.org/abs/2505.07164)|null|\n", "2505.07019": "|**2025-05-11**|**A Vision-Language Foundation Model for Leaf Disease Identification**|Luyl-Da Quach Team|[2505.07019](http://arxiv.org/abs/2505.07019)|null|\n", "2505.07001": "|**2025-05-11**|**Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models**|Binod Bhattarai Team|[2505.07001](http://arxiv.org/abs/2505.07001)|null|\n", "2505.06832": "|**2025-05-11**|**UniDiffGrasp: A Unified Framework Integrating VLM Reasoning and VLM-Guided Part Diffusion for Open-Vocabulary Constrained Grasping with Dual Arms**|Zhenze Liu Team|[2505.06832](http://arxiv.org/abs/2505.06832)|null|\n", "2505.06729": "|**2025-05-10**|**STRIVE: Structured Representation Integrating VLM Reasoning for Efficient Object Navigation**|Jean Oh Team|[2505.06729](http://arxiv.org/abs/2505.06729)|null|\n", "2505.06663": "|**2025-05-10**|**METOR: A Unified Framework for Mutual Enhancement of Objects and Relationships in Open-vocabulary Video Visual Relationship Detection**|Shuo Yang Team|[2505.06663](http://arxiv.org/abs/2505.06663)|**[link](https://github.com/wangyongqi558/METOR)**|\n", "2505.06594": "|**2025-05-10**|**Integrating Video and Text: A Balanced Approach to Multimodal Summary Generation and Evaluation**|Nancy F. Chen Team|[2505.06594](http://arxiv.org/abs/2505.06594)|null|\n", "2505.08725": "|**2025-05-13**|**Extending Large Vision-Language Model for Diverse Interactive Tasks in Autonomous Driving**|Xiang Bai Team|[2505.08725](http://arxiv.org/abs/2505.08725)|**[link](https://github.com/zc-zhao/drivemonkey)**|\n", "2505.08617": "|**2025-05-13**|**OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning**|Yu Cheng Team|[2505.08617](http://arxiv.org/abs/2505.08617)|**[link](https://github.com/zhaochen0110/openthinkimg)**|\n", "2505.08548": "|**2025-05-13**|**From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation**|Jianye Hao Team|[2505.08548](http://arxiv.org/abs/2505.08548)|null|\n", "2505.08468": "|**2025-05-13**|**Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?**|Jimmy Huang Team|[2505.08468](http://arxiv.org/abs/2505.08468)|**[link](https://github.com/tahmedge/chart_lvlm_judge)**|\n", "2505.08367": "|**2025-05-13**|**MA-ROESL: Motion-aware Rapid Reward Optimization for Efficient Robot Skill Learning from Single Videos**|Wei Zhang Team|[2505.08367](http://arxiv.org/abs/2505.08367)|null|\n", "2505.08234": "|**2025-05-13**|**Removing Watermarks with Partial Regeneration using Semantic Information**|Michael W. Mahoney Team|[2505.08234](http://arxiv.org/abs/2505.08234)|**[link](https://github.com/krtit/semanticregen)**|\n", "2505.08194": "|**2025-05-13**|**CLTP: Contrastive Language-Tactile Pre-training for 3D Contact Geometry Understanding**|Shuo Wang Team|[2505.08194](http://arxiv.org/abs/2505.08194)|null|\n", "2505.08189": "|**2025-05-13**|**DSADF: Thinking Fast and Slow for Decision Making**|Shufei Zhang Team|[2505.08189](http://arxiv.org/abs/2505.08189)|null|\n", "2505.09591": "|**2025-05-14**|**Variational Visual Question Answering**|Marcus Rohrbach Team|[2505.09591](http://arxiv.org/abs/2505.09591)|null|\n", "2505.09577": "|**2025-05-14**|**VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation**|Shuo Wang Team|[2505.09577](http://arxiv.org/abs/2505.09577)|null|\n", "2505.09498": "|**2025-05-14**|**Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput**|Lin Ma Team|[2505.09498](http://arxiv.org/abs/2505.09498)|null|\n", "2505.09336": "|**2025-05-14**|**Unsupervised Multiview Contrastive Language-Image Joint Learning with Pseudo-Labeled Prompts Via Vision-Language Model for 3D/4D Facial Expression Recognition**|Muzammil Behzad Team|[2505.09336](http://arxiv.org/abs/2505.09336)|null|\n", "2505.09265": "|**2025-05-14**|**MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning**|Bin-Bin Gao Team|[2505.09265](http://arxiv.org/abs/2505.09265)|null|\n", "2505.09139": "|**2025-05-14**|**Beyond General Prompts: Automated Prompt Refinement using Contrastive Class Alignment Scores for Disambiguating Objects in Vision-Language Models**|Ross Greer Team|[2505.09139](http://arxiv.org/abs/2505.09139)|null|\n", "2505.09118": "|**2025-05-14**|**Seeing Beyond the Scene: Enhancing Vision-Language Models with Interactional Reasoning**|Qing Li Team|[2505.09118](http://arxiv.org/abs/2505.09118)|null|\n", "2505.09092": "|**2025-05-14**|**OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions**|Hao Zhou Team|[2505.09092](http://arxiv.org/abs/2505.09092)|**[link](https://github.com/openlka/openlka)**|\n", "2505.08971": "|**2025-05-13**|**Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training**|Heng Ji Team|[2505.08971](http://arxiv.org/abs/2505.08971)|**[link](https://github.com/yangyi-chen/prior)**|\n", "2505.08910": "|**2025-05-15**|**Behind Maya: Building a Multilingual Vision Language Model**|Alham Fikri Aji Team|[2505.08910](http://arxiv.org/abs/2505.08910)|**[link](https://github.com/nahidalam/maya)**|\n", "2505.08818": "|**2025-05-12**|**Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare**|Imon Banerjee Team|[2505.08818](http://arxiv.org/abs/2505.08818)|null|\n", "2505.10526": "|**2025-05-18**|**MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models**|Vithursan Thangarasa Team|[2505.10526](http://arxiv.org/abs/2505.10526)|null|\n", "2505.10468": "|**2025-05-16**|**AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges**|Manoj Karkee Team|[2505.10468](http://arxiv.org/abs/2505.10468)|null|\n", "2505.10453": "|**2025-05-15**|**Vision language models have difficulty recognizing virtual objects**|J. G. Trafton Team|[2505.10453](http://arxiv.org/abs/2505.10453)|null|\n", "2505.10088": "|**2025-05-15**|**MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models**|Xiaodong Gu Team|[2505.10088](http://arxiv.org/abs/2505.10088)|**[link](https://github.com/yunncheng/MMRL)**|\n", "2505.09926": "|**2025-05-15**|**AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection**|Chengjie Wang Team|[2505.09926](http://arxiv.org/abs/2505.09926)|**[link](https://github.com/gaobb/AdaptCLIP)**|\n", "2505.09731": "|**2025-05-14**|**Unfettered Forceful Skill Acquisition with Physical Reasoning and Coordinate Frame Labeling**|Nikolaus Correll Team|[2505.09731](http://arxiv.org/abs/2505.09731)|null|\n", "2505.09698": "|**2025-05-14**|**ManipBench: Benchmarking Vision-Language Models for Low-Level Robot Manipulation**|Daniel Seita Team|[2505.09698](http://arxiv.org/abs/2505.09698)|null|\n", "2505.09659": "|**2025-05-14**|**LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models**|Yanan Sun Team|[2505.09659](http://arxiv.org/abs/2505.09659)|**[link](https://github.com/lc783/las)**|\n", "2505.11404": "|**2025-05-16**|**Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner**|Hong Bu Team|[2505.11404](http://arxiv.org/abs/2505.11404)|null|\n", "2505.11350": "|**2025-05-16**|**Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild**|Guillaume Sartoretti Team|[2505.11350](http://arxiv.org/abs/2505.11350)|null|\n", "2505.11326": "|**2025-05-16**|**Temporally-Grounded Language Generation: A Benchmark for Real-Time Vision-Language Models**|Joyce Chai Team|[2505.11326](http://arxiv.org/abs/2505.11326)|null|\n", "2505.11221": "|**2025-05-16**|**Sample Efficient Reinforcement Learning via Large Vision Language Model Distillation**|Chang D. Yoo Team|[2505.11221](http://arxiv.org/abs/2505.11221)|null|\n", "2505.11121": "|**2025-05-16**|**Redundancy-Aware Pretraining of Vision-Language Foundation Models in Remote Sensing**|Beg\u00fcm Demir Team|[2505.11121](http://arxiv.org/abs/2505.11121)|null|\n", "2505.11060": "|**2025-05-16**|**CUBIC: Concept Embeddings for Unsupervised Bias Identification using VLMs**|Natalia D\u00edaz-Rodr\u00edguez Team|[2505.11060](http://arxiv.org/abs/2505.11060)|null|\n", "2505.11029": "|**2025-05-16**|**Exploiting the Asymmetric Uncertainty Structure of Pre-trained VLMs on the Unit Hypersphere**|Prashant Singh Team|[2505.11029](http://arxiv.org/abs/2505.11029)|null|\n", "2505.10860": "|**2025-05-16**|**On DeepSeekMoE: Statistical Benefits of Shared Experts and Normalized Sigmoid Gating**|Alessandro Rinaldo Team|[2505.10860](http://arxiv.org/abs/2505.10860)|null|\n", "2505.10764": "|**2025-05-16**|**Benchmarking performance, explainability, and evaluation strategies of vision-language models for surgery: Challenges and opportunities**|Shan Lin Team|[2505.10764](http://arxiv.org/abs/2505.10764)|null|\n", "2505.10714": "|**2025-05-15**|**GeoGrid-Bench: Can Foundation Models Understand Multimodal Gridded Geo-Spatial Data?**|Tanwi Mallick Team|[2505.10714](http://arxiv.org/abs/2505.10714)|null|\n", "2505.10672": "|**2025-05-15**|**MOSAIC: A Multi-View 2.5D Organ Slice Selector with Cross-Attentional Reasoning for Anatomically-Aware CT Localization in Medical Organ Segmentation**|Muzammil Behzad Team|[2505.10672](http://arxiv.org/abs/2505.10672)|null|\n", "2505.10664": "|**2025-05-15**|**CLIP Embeddings for AI-Generated Image Detection: A Few-Shot Study with Lightweight Classifier**|Ziyang Ou Team|[2505.10664](http://arxiv.org/abs/2505.10664)|null|\n", "2505.10634": "|**2025-05-15**|**Mitigate Language Priors in Large Vision-Language Models by Cross-Images Contrastive Decoding**|Chong Feng Team|[2505.10634](http://arxiv.org/abs/2505.10634)|null|\n", "2505.10610": "|**2025-05-15**|**MMLongBench: Benchmarking Long-Context Vision-Language Models Effectively and Thoroughly**|Mark Steedman Team|[2505.10610](http://arxiv.org/abs/2505.10610)|null|\n", "2505.13444": "|**2025-05-19**|**ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models**|Greg Durrett Team|[2505.13444](http://arxiv.org/abs/2505.13444)|null|\n", "2505.13426": "|**2025-05-19**|**G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language Model via Reinforcement Learning**|Baobao Chang Team|[2505.13426](http://arxiv.org/abs/2505.13426)|**[link](https://github.com/chenllliang/g1)**|\n", "2505.13376": "|**2025-05-19**|**Seeing, Saying, Solving: An LLM-to-TL Framework for Cooperative Robots**|Shreyas Kousik Team|[2505.13376](http://arxiv.org/abs/2505.13376)|null|\n", "2505.13317": "|**2025-05-20**|**Unlabeled Data or Pre-trained Model: Rethinking Semi-Supervised Learning and Pretrain-Finetuning**|Lan-Zhe Guo Team|[2505.13317](http://arxiv.org/abs/2505.13317)|null|\n", "2505.13302": "|**2025-05-19**|**I'll believe it when I see it: Images increase misinformation sharing in Vision-Language Models**|R. Maria del Rio-Chanona Team|[2505.13302](http://arxiv.org/abs/2505.13302)|**[link](https://github.com/3lis/misinfo_vlm)**|\n", "2505.13281": "|**2025-05-19**|**Computer Vision Models Show Human-Like Sensitivity to Geometric and Topological Concepts**|Sashank Varma Team|[2505.13281](http://arxiv.org/abs/2505.13281)|null|\n", "2505.13233": "|**2025-05-19**|**From Local Details to Global Context: Advancing Vision-Language Models with Attention-Based Selection**|Jian Liang Team|[2505.13233](http://arxiv.org/abs/2505.13233)|**[link](https://github.com/bit-da/abs)**|\n", "2505.13180": "|**2025-05-19**|**ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and Vision-Language Models**|Pekka Marttinen Team|[2505.13180](http://arxiv.org/abs/2505.13180)|**[link](https://github.com/merlerm/viplan)**|\n", "2505.13062": "|**2025-05-19**|**Hearing from Silence: Reasoning Audio Descriptions from Silent Videos via Vision-Language Model**|Dong Yu Team|[2505.13062](http://arxiv.org/abs/2505.13062)|null|\n", "2505.13061": "|**2025-05-20**|**3D Visual Illusion Depth Estimation**|Yunde Jia Team|[2505.13061](http://arxiv.org/abs/2505.13061)|**[link](https://github.com/yaochengtang/3d-visual-illusion-depth-estimation)**|\n", "2505.13031": "|**2025-05-19**|**MindOmni: Unleashing Reasoning Generation in Vision Language Models with RGPO**|Ying Shan Team|[2505.13031](http://arxiv.org/abs/2505.13031)|**[link](https://github.com/easonxiao-888/mindomni)**|\n", "2505.12912": "|**2025-05-19**|**Uniformity First: Uniformity-aware Test-time Adaptation of Vision-language Models against Image Corruption**|Tomoki Hamagami Team|[2505.12912](http://arxiv.org/abs/2505.12912)|**[link](https://github.com/kzkadc/uninfo)**|\n", "2505.12884": "|**2025-05-19**|**TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks**|Jin Dong Team|[2505.12884](http://arxiv.org/abs/2505.12884)|null|\n", "2505.12835": "|**2025-05-19**|**FlightGPT: Towards Generalizable and Interpretable UAV Vision-and-Language Navigation with Vision-Language Models**|Renxin Zhong Team|[2505.12835](http://arxiv.org/abs/2505.12835)|null|\n", "2505.12715": "|**2025-05-19**|**VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection**|Ransalu Senanayake Team|[2505.12715](http://arxiv.org/abs/2505.12715)|null|\n", "2505.12670": "|**2025-05-19**|**TS-VLM: Text-Guided SoftSort Pooling for Vision-Language Models in Multi-View Driving Reasoning**|Soodeh Nikan Team|[2505.12670](http://arxiv.org/abs/2505.12670)|null|\n", "2505.12660": "|**2025-05-19**|**Predicting Reaction Time to Comprehend Scenes with Foveated Scene Understanding Maps**|Miguel P. Eckstein Team|[2505.12660](http://arxiv.org/abs/2505.12660)|null|\n", "2505.12650": "|**2025-05-19**|**AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use**|Fei Wei Team|[2505.12650](http://arxiv.org/abs/2505.12650)|**[link](https://github.com/yyt-2378/automat)**|\n", "2505.12644": "|**2025-05-19**|**Use as Many Surrogates as You Want: Selective Ensemble Attack to Unleash Transferability without Sacrificing Resource Efficiency**|Zhengyu Zhao Team|[2505.12644](http://arxiv.org/abs/2505.12644)|null|\n", "2505.12632": "|**2025-05-19**|**Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents**|Honglak Lee Team|[2505.12632](http://arxiv.org/abs/2505.12632)|null|\n", "2505.14671": "|**2025-05-20**|**UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens**|Wentao Zhang Team|[2505.14671](http://arxiv.org/abs/2505.14671)|null|\n", "2505.14646": "|**2025-05-20**|**CAD-Coder: An Open-Source Vision-Language Model for Computer-Aided Design Code Generation**|Faez Ahmed Team|[2505.14646](http://arxiv.org/abs/2505.14646)|null|\n", "2505.14627": "|**2025-05-20**|**Debating for Better Reasoning: An Unsupervised Multimodal Approach**|Mirella Lapata Team|[2505.14627](http://arxiv.org/abs/2505.14627)|null|\n", "2505.14481": "|**2025-05-21**|**PlanGPT-VL: Enhancing Urban Planning with Domain-Specific Vision-Language Models**|Wenjia Zhang Team|[2505.14481](http://arxiv.org/abs/2505.14481)|null|\n", "2505.14462": "|**2025-05-20**|**RAVENEA: A Benchmark for Multimodal Retrieval-Augmented Visual Culture Understanding**|Serge Belongie Team|[2505.14462](http://arxiv.org/abs/2505.14462)|**[link](https://github.com/yfyuan01/ravenea)**|\n", "2505.14381": "|**2025-05-20**|**SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation**|Masafumi Oyamada Team|[2505.14381](http://arxiv.org/abs/2505.14381)|null|\n", "2505.14366": "|**2025-05-20**|**Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds**|Agnieszka Wykowska Team|[2505.14366](http://arxiv.org/abs/2505.14366)|null|\n", "2505.14362": "|**2025-05-20**|**DeepEyes: Incentivizing \"Thinking with Images\" via Reinforcement Learning**|Xing Yu Team|[2505.14362](http://arxiv.org/abs/2505.14362)|**[link](https://github.com/visual-agent/deepeyes)**|\n", "2505.14361": "|**2025-05-20**|**Vision-Language Modeling Meets Remote Sensing: Models, Datasets and Perspectives**|Gui-Song Xia Team|[2505.14361](http://arxiv.org/abs/2505.14361)|null|\n", "2505.14340": "|**2025-05-20**|**Plane Geometry Problem Solving with Multi-modal Reasoning: A Survey**|Dongwoo Kim Team|[2505.14340](http://arxiv.org/abs/2505.14340)|null|\n", "2505.14257": "|**2025-05-20**|**Aligning Attention Distribution to Information Flow for Hallucination Mitigation in Large Vision-Language Models**|Chong Feng Team|[2505.14257](http://arxiv.org/abs/2505.14257)|null|\n", "2505.14246": "|**2025-05-20**|**Visual Agentic Reinforcement Fine-Tuning**|Jiaqi Wang Team|[2505.14246](http://arxiv.org/abs/2505.14246)|**[link](https://github.com/liuziyu77/visual-rft)**|\n", "2505.14227": "|**2025-05-20**|**VoQA: Visual-only Question Answering**|Lei Huang Team|[2505.14227](http://arxiv.org/abs/2505.14227)|null|\n", "2505.14160": "|**2025-05-20**|**Breaking Language Barriers or Reinforcing Bias? A Study of Gender and Racial Disparities in Multilingual Contrastive Vision Language Models**|Matthew Purver Team|[2505.14160](http://arxiv.org/abs/2505.14160)|null|\n", "2505.14141": "|**2025-05-20**|**Building a Stable Planner: An Extended Finite State Machine Based Planning Module for Mobile GUI Agent**|Xuming Hu Team|[2505.14141](http://arxiv.org/abs/2505.14141)|null|\n", "2505.14064": "|**2025-05-20**|**NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in Brain MRI**|Benedikt Wiestler Team|[2505.14064](http://arxiv.org/abs/2505.14064)|null|\n", "2505.14035": "|**2025-05-20**|**ShieldVLM: Safeguarding the Multimodal Implicit Toxicity via Deliberative Reasoning with LVLMs**|Minlie Huang Team|[2505.14035](http://arxiv.org/abs/2505.14035)|null|\n", "2505.13973": "|**2025-05-20**|**Toward Effective Reinforcement Learning Fine-Tuning for Medical VQA in Vision-Language Models**|Yalin Wang Team|[2505.13973](http://arxiv.org/abs/2505.13973)|null|\n", "2505.13921": "|**2025-05-20**|**APEX: Empowering LLMs with Physics-Based Task Planning for Real-time Insight**|Ambuj Singh Team|[2505.13921](http://arxiv.org/abs/2505.13921)|**[link](https://github.com/hwj20/apex_exp)**|\n", "2505.13888": "|**2025-05-20**|**InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning**|Jingkuan Song Team|[2505.13888](http://arxiv.org/abs/2505.13888)|null|\n", "2505.15818": "|**2025-05-21**|**InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition**|Xue Yang Team|[2505.15818](http://arxiv.org/abs/2505.15818)|null|\n", "2505.15685": "|**2025-05-21**|**From Grounding to Manipulation: Case Studies of Foundation Model Integration in Embodied Robotic Systems**|Soujanya Poria Team|[2505.15685](http://arxiv.org/abs/2505.15685)|null|\n", "2505.15644": "|**2025-05-21**|**FragFake: A Dataset for Fine-Grained Detection of Edited Images with Vision Language Models**|Qian Wang Team|[2505.15644](http://arxiv.org/abs/2505.15644)|null|\n", "2505.15576": "|**2025-05-21**|**Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models**|Ya Wang Team|[2505.15576](http://arxiv.org/abs/2505.15576)|**[link](https://github.com/nynu-bdai/ahnpl)**|\n", "2505.15564": "|**2025-05-21**|**TinyDrive: Multiscale Visual Question Answering with Selective Token Routing for Autonomous Driving**|Abdallah Shami Team|[2505.15564](http://arxiv.org/abs/2505.15564)|null|\n", "2505.15529": "|**2025-05-21**|**Clapper: Compact Learning and Video Representation in VLMs**|Fuzheng Zhang Team|[2505.15529](http://arxiv.org/abs/2505.15529)|null|\n", "2505.15517": "|**2025-05-21**|**Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets**|Ken Goldberg Team|[2505.15517](http://arxiv.org/abs/2505.15517)|null|\n", "2505.15510": "|**2025-05-21**|**Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought**|Libo Qin Team|[2505.15510](http://arxiv.org/abs/2505.15510)|null|\n", "2505.15506": "|**2025-05-21**|**Prompt Tuning Vision Language Models with Margin Regularizer for Few-Shot Learning under Distribution Shifts**|Soma Biswas Team|[2505.15506](http://arxiv.org/abs/2505.15506)|**[link](https://github.com/debarshigit/promptmargin)**|\n", "2505.15504": "|**2025-05-21**|**Beyond Linearity: Squeeze-and-Recalibrate Blocks for Few-Shot Whole Slide Image Classification**|Irwin King Team|[2505.15504](http://arxiv.org/abs/2505.15504)|null|\n", "2505.15489": "|**2025-05-21**|**Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models**|Bryan Hooi Team|[2505.15489](http://arxiv.org/abs/2505.15489)|null|\n", "2505.15436": "|**2025-05-21**|**Chain-of-Focus: Adaptive Visual Search and Zooming for Multimodal Reasoning via RL**|Qing Li Team|[2505.15436](http://arxiv.org/abs/2505.15436)|null|\n", "2505.15435": "|**2025-05-21**|**TimeCausality: Evaluating the Causal Ability in Time Dimension for Vision Language Models**|Keze Wang Team|[2505.15435](http://arxiv.org/abs/2505.15435)|null|\n", "2505.15425": "|**2025-05-21**|**On the Robustness of Medical Vision-Language Models: Are they Truly Generalizable?**|Mohammad Yaqub Team|[2505.15425](http://arxiv.org/abs/2505.15425)|null|\n", "2505.15389": "|**2025-05-21**|**Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study**|Hwanjo Yu Team|[2505.15389](http://arxiv.org/abs/2505.15389)|null|\n", "2505.15373": "|**2025-05-21**|**RAZER: Robust Accelerated Zero-Shot 3D Open-Vocabulary Panoptic Reconstruction with Spatio-Temporal Aggregation**|Farshad Khorrami Team|[2505.15373](http://arxiv.org/abs/2505.15373)|null|\n", "2505.15367": "|**2025-05-21**|**Better Safe Than Sorry? Overreaction Problem of Vision Language Models in Visual Emergency Recognition**|Youngsook Song Team|[2505.15367](http://arxiv.org/abs/2505.15367)|null|\n", "2505.15298": "|**2025-05-21**|**AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving**|Diange Yang Team|[2505.15298](http://arxiv.org/abs/2505.15298)|null|\n", "2505.15265": "|**2025-05-21**|**Blind Spot Navigation: Evolutionary Discovery of Sensitive Semantic Concepts for LVLMs**|Zibin Zheng Team|[2505.15265](http://arxiv.org/abs/2505.15265)|null|\n", "2505.15249": "|**2025-05-21**|**Fooling the LVLM Judges: Visual Biases in LVLM-Based Evaluation**|Kyomin Jung Team|[2505.15249](http://arxiv.org/abs/2505.15249)|null|\n", "2505.16854": "|**2025-05-22**|**Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models**|Mike Zheng Shou Team|[2505.16854](http://arxiv.org/abs/2505.16854)|**[link](https://github.com/kokolerk/ton)**|\n", "2505.16839": "|**2025-05-23**|**LaViDa: A Large Diffusion Language Model for Multimodal Understanding**|Aditya Grover Team|[2505.16839](http://arxiv.org/abs/2505.16839)|**[link](https://github.com/jacklishufan/lavida)**|\n", "2505.16832": "|**2025-05-22**|**From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization**|Huaxiu Yao Team|[2505.16832](http://arxiv.org/abs/2505.16832)|**[link](https://github.com/aiming-lab/eduvisbench)**|\n", "2505.16815": "|**2025-05-22**|**Perceptual Quality Assessment for Embodied AI**|Guangtao Zhai Team|[2505.16815](http://arxiv.org/abs/2505.16815)|**[link](https://github.com/lcysyzxdxc/embodiediqa)**|\n", "2505.16805": "|**2025-05-22**|**SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**|Hongsheng Li Team|[2505.16805](http://arxiv.org/abs/2505.16805)|null|\n", "2505.16793": "|**2025-05-22**|**REOBench: Benchmarking Robustness of Earth Observation Foundation Models**|Tianjin Huang Team|[2505.16793](http://arxiv.org/abs/2505.16793)|**[link](https://github.com/lx709/reobench)**|\n", "2505.16778": "|**2025-05-22**|**Single Domain Generalization for Few-Shot Counting via Universal Representation Matching**|Xinghao Chen Team|[2505.16778](http://arxiv.org/abs/2505.16778)|**[link](https://github.com/jbr97/urm)**|\n", "2505.16774": "|**2025-05-22**|**IFEval-Audio: Benchmarking Instruction-Following Capability in Audio-based Large Language Models**|AiTi Aw Team|[2505.16774](http://arxiv.org/abs/2505.16774)|**[link](https://github.com/audiollms/audiobench)**|\n", "2505.16763": "|**2025-05-22**|**Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation**|Jianbing Shen Team|[2505.16763](http://arxiv.org/abs/2505.16763)|null|\n", "2505.16659": "|**2025-05-22**|**SD-MAD: Sign-Driven Few-shot Multi-Anomaly Detection in Medical Images**|Mahsa Baktashmotlagh Team|[2505.16659](http://arxiv.org/abs/2505.16659)|null|\n", "2505.16647": "|**2025-05-22**|**Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models**|P\u00e5l Halvorsen Team|[2505.16647](http://arxiv.org/abs/2505.16647)|null|\n", "2505.16602": "|**2025-05-22**|**MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation**|Zongqing Lu Team|[2505.16602](http://arxiv.org/abs/2505.16602)|null|\n", "2505.16517": "|**2025-05-22**|**ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models**|Xiuying Chen Team|[2505.16517](http://arxiv.org/abs/2505.16517)|null|\n", "2505.16446": "|**2025-05-22**|**Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models**|Yaochu Jin Team|[2505.16446](http://arxiv.org/abs/2505.16446)|null|\n", "2505.16416": "|**2025-05-22**|**Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models**|Kai Han Team|[2505.16416](http://arxiv.org/abs/2505.16416)|**[link](https://github.com/lose4578/circlerope)**|\n", "2505.16411": "|**2025-05-22**|**Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression**|Souvik Kundu Team|[2505.16411](http://arxiv.org/abs/2505.16411)|**[link](https://github.com/yueche77/spin)**|\n", "2505.16377": "|**2025-05-22**|**VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving**|Samuel Labi Team|[2505.16377](http://arxiv.org/abs/2505.16377)|null|\n", "2505.16279": "|**2025-05-22**|**MM-MovieDubber: Towards Multi-Modal Learning for Multi-Modal Movie Dubbing**|Xinhan Di Team|[2505.16279](http://arxiv.org/abs/2505.16279)|null|\n", "2505.16149": "|**2025-05-22**|**When VLMs Meet Image Classification: Test Sets Renovation via Missing Label Identification**|Jiaheng Wei Team|[2505.16149](http://arxiv.org/abs/2505.16149)|null|\n", "2505.16146": "|**2025-05-22**|**Steering LVLMs via Sparse Autoencoder for Hallucination Mitigation**|Junfeng Fang Team|[2505.16146](http://arxiv.org/abs/2505.16146)|null|\n", "2505.18134": "|**2025-05-23**|**VideoGameBench: Can Vision-Language Models complete popular video games?**|Ofir Press Team|[2505.18134](http://arxiv.org/abs/2505.18134)|null|\n", "2505.18129": "|**2025-05-23**|**One RL to See Them All: Visual Triple Unified Reinforcement Learning**|Junjie Yan Team|[2505.18129](http://arxiv.org/abs/2505.18129)|null|\n", "2505.18087": "|**2025-05-23**|**CXReasonBench: A Benchmark for Evaluating Structured Diagnostic Reasoning in Chest X-rays**|Edward Choi Team|[2505.18087](http://arxiv.org/abs/2505.18087)|null|\n", "2505.18053": "|**2025-05-23**|**FDBPL: Faster Distillation-Based Prompt Learning for Region-Aware Vision-Language Models Adaptation**|Shibiao Xu Team|[2505.18053](http://arxiv.org/abs/2505.18053)|null|\n", "2505.18039": "|**2025-05-23**|**Clip4Retrofit: Enabling Real-Time Image Labeling on Edge Devices via Cross-Architecture CLIP Distillation**|Bogdan Sorin Coseriu Team|[2505.18039](http://arxiv.org/abs/2505.18039)|null|\n", "2505.17982": "|**2025-05-23**|**Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language Alignment and Modeling**|Mun Yong Yi Team|[2505.17982](http://arxiv.org/abs/2505.17982)|null|\n", "2505.17835": "|**2025-05-23**|**VLM Models and Automated Grading of Atopic Dermatitis**|Hamed Ghodrati Team|[2505.17835](http://arxiv.org/abs/2505.17835)|null|\n", "2505.17812": "|**2025-05-23**|**Seeing It or Not? Interpretable Vision-aware Latent Steering to Mitigate Object Hallucinations**|Chao Shen Team|[2505.17812](http://arxiv.org/abs/2505.17812)|null|\n", "2505.17779": "|**2025-05-23**|**U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding**|Hongcheng Guo Team|[2505.17779](http://arxiv.org/abs/2505.17779)|null|\n", "2505.17727": "|**2025-05-23**|**SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the Real World Domain**|Yu Li Team|[2505.17727](http://arxiv.org/abs/2505.17727)|null|\n", "2505.17702": "|**2025-05-23**|**Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek**|Xiangdong Zhou Team|[2505.17702](http://arxiv.org/abs/2505.17702)|null|\n", "2505.17670": "|**2025-05-23**|**Towards General Continuous Memory for Vision-Language Models**|Biwei Huang Team|[2505.17670](http://arxiv.org/abs/2505.17670)|null|\n", "2505.17654": "|**2025-05-23**|**EVADE: Multimodal Benchmark for Evasive Content Detection in E-Commerce Applications**|Min Yang Team|[2505.17654](http://arxiv.org/abs/2505.17654)|null|\n", "2505.17645": "|**2025-05-23**|**HoloLLM: Multisensory Foundation Model for Language-Grounded Human Sensing and Reasoning**|Jianfei Yang Team|[2505.17645](http://arxiv.org/abs/2505.17645)|null|\n", "2505.17625": "|**2025-05-23**|**Enhancing Large Vision-Language Models with Layout Modality for Table Question Answering on Japanese Annual Securities Reports**|Takahiro Omi Team|[2505.17625](http://arxiv.org/abs/2505.17625)|null|\n", "2505.17619": "|**2025-05-23**|**CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography Quality Assessment**|Zeng-Guang Hou Team|[2505.17619](http://arxiv.org/abs/2505.17619)|null|\n", "2505.17609": "|**2025-05-23**|**Decoupled Visual Interpretation and Linguistic Reasoning for Math Problem Solving**|Wangmeng Zuo Team|[2505.17609](http://arxiv.org/abs/2505.17609)|null|\n", "2505.17602": "|**2025-05-23**|**A Unified Multi-Scale Attention-Based Network for Automatic 3D Segmentation of Lung Parenchyma & Nodules In Thoracic CT Images**|Furqan Shaukat Team|[2505.17602](http://arxiv.org/abs/2505.17602)|null|\n", "2505.17536": "|**2025-05-23**|**Multimodal Conversation Structure Understanding**|David Bamman Team|[2505.17536](http://arxiv.org/abs/2505.17536)|null|\n", "2505.17529": "|**2025-05-23**|**Do You Keep an Eye on What I Ask? Mitigating Multimodal Hallucination via Attention-Guided Ensemble Decoding**|Sungzoon Cho Team|[2505.17529](http://arxiv.org/abs/2505.17529)|null|\n", "2505.20129": "|**2025-05-26**|**Agentic 3D Scene Generation with Spatially Contextualized VLMs**|Chi-Keung Tang Team|[2505.20129](http://arxiv.org/abs/2505.20129)|null|\n", "2505.20122": "|**2025-05-26**|**MEBench: A Novel Benchmark for Understanding Mutual Exclusivity Bias in Vision-Language Models**|James M. Rehg Team|[2505.20122](http://arxiv.org/abs/2505.20122)|null|\n", "2505.20033": "|**2025-05-27**|**EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition**|S\u00f6ren Auer Team|[2505.20033](http://arxiv.org/abs/2505.20033)|null|\n", "2505.20032": "|**2025-05-26**|**ViTaPEs: Visuotactile Position Encodings for Cross-Modal Alignment in Multimodal Transformers**|Elmar R\u00fcckert Team|[2505.20032](http://arxiv.org/abs/2505.20032)|null|\n", "2505.20021": "|**2025-05-26**|**Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models**|Ernest K. Ryu Team|[2505.20021](http://arxiv.org/abs/2505.20021)|null|\n", "2505.19944": "|**2025-05-26**|**Can Visual Encoder Learn to See Arrows?**|Hiroaki Ozaki Team|[2505.19944](http://arxiv.org/abs/2505.19944)|null|\n", "2505.19911": "|**2025-05-26**|**Attention! You Vision Language Model Could Be Maliciously Manipulated**|Shudong Zhang Team|[2505.19911](http://arxiv.org/abs/2505.19911)|null|\n", "2505.19895": "|**2025-05-26**|**Underwater Diffusion Attention Network with Contrastive Language-Image Joint Learning for Underwater Image Enhancement**|Muzammil Behzad Team|[2505.19895](http://arxiv.org/abs/2505.19895)|null|\n", "2505.19840": "|**2025-05-26**|**One Surrogate to Fool Them All: Universal, Transferable, and Targeted Adversarial Attacks with CLIP**|Kehuan Zhang Team|[2505.19840](http://arxiv.org/abs/2505.19840)|null|\n", "2505.19769": "|**2025-05-26**|**TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning**|Dongbin Zhao Team|[2505.19769](http://arxiv.org/abs/2505.19769)|null|\n", "2505.19696": "|**2025-05-26**|**Modeling Beyond MOS: Quality Assessment Models Must Integrate Context, Reasoning, and Multimodality**|Alessandro Bruno Team|[2505.19696](http://arxiv.org/abs/2505.19696)|null|\n", "2505.19678": "|**2025-05-26**|**Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs**|Shu-Tao Xia Team|[2505.19678](http://arxiv.org/abs/2505.19678)|null|\n", "2505.19610": "|**2025-05-26**|**JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language Models**|Yingchun Wang Team|[2505.19610](http://arxiv.org/abs/2505.19610)|null|\n", "2505.19569": "|**2025-05-26**|**What You Perceive Is What You Conceive: A Cognition-Inspired Framework for Open Vocabulary Image Segmentation**|Rongrong Ji Team|[2505.19569](http://arxiv.org/abs/2505.19569)|null|\n", "2505.19536": "|**2025-05-26**|**FlowCut: Rethinking Redundancy via Information Flow for Efficient Vision-Language Models**|Ruixuan Li Team|[2505.19536](http://arxiv.org/abs/2505.19536)|null|\n", "2505.19503": "|**2025-05-26**|**Locality-Aware Zero-Shot Human-Object Interaction Detection**|Minsu Cho Team|[2505.19503](http://arxiv.org/abs/2505.19503)|null|\n", "2505.19498": "|**2025-05-26**|**Enhancing Visual Reliance in Text Generation: A Bayesian Perspective on Mitigating Hallucination in Large Vision-Language Models**|Guoliang Kang Team|[2505.19498](http://arxiv.org/abs/2505.19498)|null|\n", "2505.19406": "|**2025-05-26**|**Unveiling the Compositional Ability Gap in Vision-Language Reasoning Model**|Yu Cheng Team|[2505.19406](http://arxiv.org/abs/2505.19406)|null|\n", "2505.19381": "|**2025-05-27**|**DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving**|Hao Zhao Team|[2505.19381](http://arxiv.org/abs/2505.19381)|null|\n", "2505.19373": "|**2025-05-26**|**DiSa: Directional Saliency-Aware Prompt Learning for Generalizable Vision-Language Models**|Fatemeh Afghah Team|[2505.19373](http://arxiv.org/abs/2505.19373)|null|\n", "2505.20236": "|**2025-05-26**|**Seeing is Believing, but How Much? A Comprehensive Analysis of Verbalized Calibration in Vision-Language Models**|Naoto Yokoya Team|[2505.20236](http://arxiv.org/abs/2505.20236)|null|\n", "2505.21500": "|**2025-05-27**|**ViewSpatial-Bench: Evaluating Multi-perspective Spatial Localization in Vision-Language Models**|Yueting Zhuang Team|[2505.21500](http://arxiv.org/abs/2505.21500)|null|\n", "2505.21499": "|**2025-05-27**|**AdInject: Real-World Black-Box Attacks on Web Agents via Advertising Delivery**|Qing Wang Team|[2505.21499](http://arxiv.org/abs/2505.21499)|null|\n", "2505.21472": "|**2025-05-27**|**Mitigating Hallucination in Large Vision-Language Models via Adaptive Attention Calibration**|Ziwei Zhu Team|[2505.21472](http://arxiv.org/abs/2505.21472)|null|\n", "2505.21465": "|**2025-05-27**|**ID-Align: RoPE-Conscious Position Remapping for Dynamic High-Resolution Adaptation in Vision-Language Models**|Wentao Zhang Team|[2505.21465](http://arxiv.org/abs/2505.21465)|null|\n", "2505.21459": "|**2025-05-27**|**LazyVLM: Neuro-Symbolic Approach to Video Analytics**|M. Tamer \u00d6zsu Team|[2505.21459](http://arxiv.org/abs/2505.21459)|null|\n", "2505.21382": "|**2025-05-27**|**DeCAF: Decentralized Consensus-And-Factorization for Low-Rank Adaptation of Foundation Models**|Soumik Sarkar Team|[2505.21382](http://arxiv.org/abs/2505.21382)|null|\n", "2505.21279": "|**2025-05-27**|**XBOUND: Exploring the Capability Boundaries of Device-Control Agents through Trajectory Tree Exploration**|Min Zhang Team|[2505.21279](http://arxiv.org/abs/2505.21279)|null|\n", "2505.21106": "|**2025-05-27**|**Interpreting Social Bias in LVLMs via Information Flow Analysis and Multi-Round Dialogue Evaluation**|Yutao Yue Team|[2505.21106](http://arxiv.org/abs/2505.21106)|null|\n", "2505.21089": "|**2025-05-27**|**DisasterM3: A Remote Sensing Vision-Language Dataset for Disaster Damage Assessment and Response**|Naoto Yokoya Team|[2505.21089](http://arxiv.org/abs/2505.21089)|null|\n", "2505.21061": "|**2025-05-27**|**LPOI: Listwise Preference Optimization for Vision Language Models**|Gunhee Kim Team|[2505.21061](http://arxiv.org/abs/2505.21061)|null|\n", "2505.20981": "|**2025-05-27**|**RefAV: Towards Planning-Centric Scenario Mining**|Neehar Peri Team|[2505.20981](http://arxiv.org/abs/2505.20981)|null|\n", "2505.20937": "|**2025-05-27**|**On VLMs for Diverse Tasks in Multimodal Meme Classification**|Jasabanta Patro Team|[2505.20937](http://arxiv.org/abs/2505.20937)|null|\n", "2505.20901": "|**2025-05-27**|**A Stereotype Content Analysis on Color-related Social Bias in Large Vision Language Models**|Bugeun Kim Team|[2505.20901](http://arxiv.org/abs/2505.20901)|null|\n", "2505.20862": "|**2025-05-27**|**AVCD: Mitigating Hallucinations in Audio-Visual Large Language Models through Contrastive Decoding**|Joon Son Chung Team|[2505.20862](http://arxiv.org/abs/2505.20862)|null|\n", "2505.20793": "|**2025-05-27**|**Rendering-Aware Reinforcement Learning for Vector Graphics Generation**|Marco Pedersoli Team|[2505.20793](http://arxiv.org/abs/2505.20793)|null|\n", "2505.20783": "|**2025-05-27**|**FM-Planner: Foundation Model Guided Path Planning for Autonomous Drone Navigation**|Mir Feroskhan Team|[2505.20783](http://arxiv.org/abs/2505.20783)|null|\n", "2505.20728": "|**2025-05-27**|**Jigsaw-Puzzles: From Seeing to Understanding to Reasoning in Vision-Language Models**|Yao Yang Team|[2505.20728](http://arxiv.org/abs/2505.20728)|null|\n", "2505.20726": "|**2025-05-27**|**ManiTaskGen: A Comprehensive Task Generator for Benchmarking and Improving Vision-Language Agents on Embodied Decision-Making**|Hao Su Team|[2505.20726](http://arxiv.org/abs/2505.20726)|null|\n", "2505.20711": "|**2025-05-27**|**Automating eHMI Action Design with LLMs for Automated Vehicle Communication**|Takeo Igarashi Team|[2505.20711](http://arxiv.org/abs/2505.20711)|null|\n", "2505.20672": "|**2025-05-27**|**GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning**|Sundong Kim Team|[2505.20672](http://arxiv.org/abs/2505.20672)|null|\n", "2505.22664": "|**2025-05-28**|**Zero-Shot Vision Encoder Grafting via LLM Surrogates**|Tom Goldstein Team|[2505.22664](http://arxiv.org/abs/2505.22664)|**[link](https://github.com/facebookresearch/zero)**|\n", "2505.22663": "|**2025-05-28**|**Training Free Stylized Abstraction**|Vishal M. Patel Team|[2505.22663](http://arxiv.org/abs/2505.22663)|null|\n", "2505.22654": "|**2025-05-28**|**VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models**|Dong Yu Team|[2505.22654](http://arxiv.org/abs/2505.22654)|null|\n", "2505.22651": "|**2025-05-28**|**Sherlock: Self-Correcting Reasoning in Vision-Language Models**|Ruqi Zhang Team|[2505.22651](http://arxiv.org/abs/2505.22651)|null|\n", "2505.22481": "|**2025-05-28**|**Hypothesis Testing in Imaging Inverse Problems**|Marcelo Pereyra Team|[2505.22481](http://arxiv.org/abs/2505.22481)|null|\n", "2505.22429": "|**2025-05-28**|**Zero-Shot 3D Visual Grounding from Vision-Language Models**|Junwei Liang Team|[2505.22429](http://arxiv.org/abs/2505.22429)|null|\n", "2505.22305": "|**2025-05-28**|**IKIWISI: An Interactive Visual Pattern Generator for Evaluating the Reliability of Vision-Language Models Without Ground Truth**|Syed Masum Billah Team|[2505.22305](http://arxiv.org/abs/2505.22305)|null|\n", "2505.22200": "|**2025-05-28**|**Investigating Mechanisms for In-Context Vision Language Binding**|Vineet Gandhi Team|[2505.22200](http://arxiv.org/abs/2505.22200)|null|\n", "2505.22150": "|**2025-05-29**|**Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging**|Piji Li Team|[2505.22150](http://arxiv.org/abs/2505.22150)|null|\n", "2505.22143": "|**2025-05-28**|**3D Question Answering via only 2D Vision-Language Models**|Qianru Sun Team|[2505.22143](http://arxiv.org/abs/2505.22143)|null|\n", "2505.22050": "|**2025-05-28**|**Reinforced Reasoning for Embodied Planning**|Bo Jin Team|[2505.22050](http://arxiv.org/abs/2505.22050)|null|\n", "2505.22038": "|**2025-05-28**|**Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization**|Xinlei Chen Team|[2505.22038](http://arxiv.org/abs/2505.22038)|null|\n", "2505.21979": "|**2025-05-28**|**Pearl: A Multimodal Culturally-Aware Arabic Instruction Dataset**|Muhammad Abdul-Mageed Team|[2505.21979](http://arxiv.org/abs/2505.21979)|null|\n", "2505.21969": "|**2025-05-29**|**DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation**|Xin Tan Team|[2505.21969](http://arxiv.org/abs/2505.21969)|null|\n", "2505.21967": "|**2025-05-28**|**Seeing the Threat: Vulnerabilities in Vision-Language Models to Adversarial Attack**|Usman Naseem Team|[2505.21967](http://arxiv.org/abs/2505.21967)|null|\n", "2505.21955": "|**2025-05-28**|**Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs**|Byonghyo Shim Team|[2505.21955](http://arxiv.org/abs/2505.21955)|null|\n", "2505.21906": "|**2025-05-28**|**Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge**|Yi Xu Team|[2505.21906](http://arxiv.org/abs/2505.21906)|null|\n", "2505.21844": "|**2025-05-28**|**Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation**|Christian Desrosiers Team|[2505.21844](http://arxiv.org/abs/2505.21844)|null|\n", "2505.21771": "|**2025-05-27**|**MMTBENCH: A Unified Benchmark for Complex Multimodal Table Reasoning**|Vivek Gupta Team|[2505.21771](http://arxiv.org/abs/2505.21771)|null|\n", "2505.21698": "|**2025-05-27**|**MedBridge: Bridging Foundation Vision-Language Models to Medical Image Diagnosis**|Christian Wachinger Team|[2505.21698](http://arxiv.org/abs/2505.21698)|null|\n", "2505.23762": "|**2025-05-29**|**ZeroGUI: Automating Online GUI Learning at Zero Human Cost**|Jifeng Dai Team|[2505.23762](http://arxiv.org/abs/2505.23762)|**[link](https://github.com/opengvlab/zerogui)**|\n", "2505.23759": "|**2025-05-29**|**Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint**|David M. Chan Team|[2505.23759](http://arxiv.org/abs/2505.23759)|**[link](https://github.com/kyunnilee/visual_puzzles)**|\n", "2505.23745": "|**2025-05-29**|**To Trust Or Not To Trust Your Vision-Language Model's Prediction**|Olga Fink Team|[2505.23745](http://arxiv.org/abs/2505.23745)|**[link](https://github.com/epfl-imos/trustvlm)**|\n", "2505.23740": "|**2025-05-29**|**LayerPeeler: Autoregressive Peeling for Layer-wise Image Vectorization**|Jing Liao Team|[2505.23740](http://arxiv.org/abs/2505.23740)|null|\n", "2505.23705": "|**2025-05-29**|**Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better**|Sergey Levine Team|[2505.23705](http://arxiv.org/abs/2505.23705)|null|\n", "2505.23678": "|**2025-05-29**|**Grounded Reinforcement Learning for Visual Reasoning**|Katerina Fragkiadaki Team|[2505.23678](http://arxiv.org/abs/2505.23678)|null|\n", "2505.23566": "|**2025-05-29**|**Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition**|Liangcai Gao Team|[2505.23566](http://arxiv.org/abs/2505.23566)|null|\n", "2505.23558": "|**2025-05-30**|**Qwen Look Again: Guiding Vision-Language Reasoning Models to Re-attention Visual Information**|Weiping Li Team|[2505.23558](http://arxiv.org/abs/2505.23558)|**[link](https://github.com/liar406/look_again)**|\n", "2505.23518": "|**2025-05-29**|**TRAP: Targeted Redirecting of Agentic Preferences**|Gagandeep Singh Team|[2505.23518](http://arxiv.org/abs/2505.23518)|null|\n", "2505.23484": "|**2025-05-29**|**VCapsBench: A Large-scale Fine-grained Benchmark for Video Caption Quality Evaluation**|Xu-Cheng Yin Team|[2505.23484](http://arxiv.org/abs/2505.23484)|**[link](https://github.com/gxym/vcapsbench)**|\n", "2505.23358": "|**2025-05-29**|**Beam-Guided Knowledge Replay for Knowledge-Rich Image Captioning using Vision-Language Model**|Muzammil Behzad Team|[2505.23358](http://arxiv.org/abs/2505.23358)|null|\n", "2505.23271": "|**2025-05-29**|**LADA: Scalable Label-Specific CLIP Adapter for Continual Learning**|Min-Ling Zhang Team|[2505.23271](http://arxiv.org/abs/2505.23271)|**[link](https://github.com/maolinluo/lada)**|\n", "2505.23267": "|**2025-05-29**|**VLM-RRT: Vision Language Model Guided RRT Search for Autonomous UAV Navigation**|Panayiotis Kolios Team|[2505.23267](http://arxiv.org/abs/2505.23267)|null|\n", "2505.23266": "|**2025-05-29**|**Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion**|Tao Xiang Team|[2505.23266](http://arxiv.org/abs/2505.23266)|null|\n", "2505.23242": "|**2025-05-29**|**ChartMind: A Comprehensive Benchmark for Complex Real-world Multimodal Chart Question Answering**|Lei Wang Team|[2505.23242](http://arxiv.org/abs/2505.23242)|null|\n", "2505.23130": "|**2025-05-29**|**PhotoArtAgent: Intelligent Photo Retouching with Language Model-Based Artist Agents**|Jinjin Gu Team|[2505.23130](http://arxiv.org/abs/2505.23130)|null|\n", "2505.23043": "|**2025-05-29**|**Are Unified Vision-Language Models Necessary: Generalization Across Understanding and Generation**|Yu Cheng Team|[2505.23043](http://arxiv.org/abs/2505.23043)|**[link](https://github.com/majordavidzhang/generalization_unified_vlm)**|\n", "2505.23024": "|**2025-05-29**|**An Empirical Study of Federated Prompt Learning for Vision Language Model**|Mang Ye Team|[2505.23024](http://arxiv.org/abs/2505.23024)|null|\n", "2505.23010": "|**2025-05-29**|**SeG-SR: Integrating Semantic Knowledge into Remote Sensing Image Super-Resolution via Vision-Language Model**|Zhenwei Shi Team|[2505.23010](http://arxiv.org/abs/2505.23010)|null|\n", "2505.23004": "|**2025-05-29**|**QLIP: A Dynamic Quadtree Vision Prior Enhances MLLM Performance Without Retraining**|Muhao Chen Team|[2505.23004](http://arxiv.org/abs/2505.23004)|**[link](https://github.com/kyrochi/qlip)**|\n", "2505.24875": "|**2025-05-30**|**ReasonGen-R1: CoT for Autoregressive Image generation models through SFT and RL**|Lili Qiu Team|[2505.24875](http://arxiv.org/abs/2505.24875)|null|\n", "2505.24872": "|**2025-05-30**|**ProxyThinker: Test-Time Guidance through Small Visual Reasoners**|Vicente Ordonez Team|[2505.24872](http://arxiv.org/abs/2505.24872)|null|\n", "2505.24870": "|**2025-05-30**|**GenSpace: Benchmarking Spatially-Aware Image Generation**|Zhou Zhao Team|[2505.24870](http://arxiv.org/abs/2505.24870)|null|\n", "2505.24867": "|**2025-05-30**|**Time Blindness: Why Video-Language Models Can't See What Humans Can?**|Mohamed Elhoseiny Team|[2505.24867](http://arxiv.org/abs/2505.24867)|null|\n", "2505.24693": "|**2025-05-30**|**Conformal Prediction for Zero-Shot Models**|Jose Dolz Team|[2505.24693](http://arxiv.org/abs/2505.24693)|null|\n", "2505.24649": "|**2025-05-30**|**BIMA: Bijective Maximum Likelihood Learning Approach to Hallucination Prediction and Mitigation in Large Vision-Language Models**|Khoa Luu Team|[2505.24649](http://arxiv.org/abs/2505.24649)|null|\n", "2505.24600": "|**2025-05-30**|**SARD: A Large-Scale Synthetic Arabic OCR Dataset for Book-Style Text Recognition**|Wadii Boulila Team|[2505.24600](http://arxiv.org/abs/2505.24600)|null|\n", "2505.24519": "|**2025-05-30**|**AMIA: Automatic Masking and Joint Intention Analysis Makes LVLMs Robust Jailbreak Defenders**|Liang Ding Team|[2505.24519](http://arxiv.org/abs/2505.24519)|null|\n", "2505.24456": "|**2025-05-30**|**CaMMT: Benchmarking Culturally Aware Multimodal Machine Translation**|Thamar Solorio Team|[2505.24456](http://arxiv.org/abs/2505.24456)|null|\n", "2505.24424": "|**2025-05-30**|**Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning**|Matthias Hein Team|[2505.24424](http://arxiv.org/abs/2505.24424)|null|\n", "2505.24423": "|**2025-05-30**|**MMAFFBen: A Multilingual and Multimodal Affective Analysis Benchmark for Evaluating LLMs and VLMs**|Sophia Ananiadou Team|[2505.24423](http://arxiv.org/abs/2505.24423)|null|\n", "2505.24371": "|**2025-05-30**|**Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering**|Fadoua Ghourabi Team|[2505.24371](http://arxiv.org/abs/2505.24371)|null|\n", "2505.24342": "|**2025-05-30**|**KEVER^2: Knowledge-Enhanced Visual Emotion Reasoning and Retrieval**|Yong Li Team|[2505.24342](http://arxiv.org/abs/2505.24342)|null|\n", "2505.24317": "|**2025-05-30**|**ROAD: Responsibility-Oriented Reward Design for Reinforcement Learning in Autonomous Driving**|Songan Zhang Team|[2505.24317](http://arxiv.org/abs/2505.24317)|null|\n", "2505.24214": "|**2025-05-30**|**Benchmarking Foundation Models for Zero-Shot Biometric Tasks**|Arun Ross Team|[2505.24214](http://arxiv.org/abs/2505.24214)|null|\n", "2505.24208": "|**2025-05-30**|**Bootstrapping LLM Robustness for VLM Safety via Reducing the Pretraining Modality Gap**|Baharan Mirzasoleiman Team|[2505.24208](http://arxiv.org/abs/2505.24208)|null|\n", "2505.24173": "|**2025-05-30**|**DrVD-Bench: Do Vision-Language Models Reason Like Human Doctors in Medical Image Diagnosis?**|Xuegong Zhang Team|[2505.24173](http://arxiv.org/abs/2505.24173)|null|\n", "2505.24120": "|**2025-05-30**|**CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs**|Xuchen Song Team|[2505.24120](http://arxiv.org/abs/2505.24120)|null|\n", "2505.24073": "|**2025-05-29**|**mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation**|Zhengzhong Tu Team|[2505.24073](http://arxiv.org/abs/2505.24073)|null|\n", "2505.23990": "|**2025-05-29**|**Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding**|Tinoosh Mohsenin Team|[2505.23990](http://arxiv.org/abs/2505.23990)|null|\n", "2506.03135": "|**2025-06-03**|**OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models**|Li Yi Team|[2506.03135](http://arxiv.org/abs/2506.03135)|null|\n", "2506.03097": "|**2025-06-03**|**EgoVLM: Policy Optimization for Egocentric Video Understanding**|Linshen Liu Team|[2506.03097](http://arxiv.org/abs/2506.03097)|null|\n", "2506.03095": "|**2025-06-03**|**DPO Learning with LLMs-Judge Signal for Computer Use Agents**|Phillip Howard Team|[2506.03095](http://arxiv.org/abs/2506.03095)|null|\n", "2506.03093": "|**2025-06-03**|**From Flat to Hierarchical: Extracting Sparse Representations with Matching Pursuit**|Demba Ba Team|[2506.03093](http://arxiv.org/abs/2506.03093)|null|\n", "2506.02917": "|**2025-06-03**|**Text-guided Generation of Efficient Personalized Inspection Plans**|Aniket Bera Team|[2506.02917](http://arxiv.org/abs/2506.02917)|null|\n", "2506.02896": "|**2025-06-04**|**FlySearch: Exploring how vision-language models explore**|Maciej Wo\u0142czyk Team|[2506.02896](http://arxiv.org/abs/2506.02896)|null|\n", "2506.02865": "|**2025-06-03**|**Surfer-H Meets Holo1: Cost-Efficient Web Agent Powered by Open Weights**|Tony Wu Team|[2506.02865](http://arxiv.org/abs/2506.02865)|null|\n", "2506.02803": "|**2025-06-03**|**SemVink: Advancing VLMs' Semantic Understanding of Optical Illusions via Visual Global Thinking**|Yiwei Wang Team|[2506.02803](http://arxiv.org/abs/2506.02803)|null|\n", "2506.02738": "|**2025-06-04**|**Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning**|Arash Afkanpour Team|[2506.02738](http://arxiv.org/abs/2506.02738)|null|\n", "2506.02708": "|**2025-06-03**|**Iterative Self-Improvement of Vision Language Models for Image Scoring and Self-Explanation**|Toshihiko Yamasaki Team|[2506.02708](http://arxiv.org/abs/2506.02708)|null|\n", "2506.02671": "|**2025-06-03**|**Small Aid, Big Leap: Efficient Test-Time Adaptation for Vision-Language Models with AdaptNet**|Zhi Wang Team|[2506.02671](http://arxiv.org/abs/2506.02671)|null|\n", "2506.02615": "|**2025-06-03**|**Hierarchical Question-Answering for Driving Scene Understanding Using Vision-Language Models**|Dong Seog Han Team|[2506.02615](http://arxiv.org/abs/2506.02615)|null|\n", "2506.02557": "|**2025-06-03**|**Kernel-based Unsupervised Embedding Alignment for Enhanced Visual Representation in Vision-language Models**|Farzan Farnia Team|[2506.02557](http://arxiv.org/abs/2506.02557)|null|\n", "2506.02556": "|**2025-06-03**|**Sign Language: Towards Sign Understanding for Robot Autonomy**|David Hsu Team|[2506.02556](http://arxiv.org/abs/2506.02556)|null|\n", "2506.02555": "|**2025-06-03**|**SurgVLM: A Large Vision-Language Model and Systematic Evaluation Benchmark for Surgical Intelligence**|Yueming Jin Team|[2506.02555](http://arxiv.org/abs/2506.02555)|null|\n", "2506.02541": "|**2025-06-03**|**Rethinking Post-Unlearning Behavior of Large Vision-Language Models**|Kyomin Jung Team|[2506.02541](http://arxiv.org/abs/2506.02541)|null|\n", "2506.02535": "|**2025-06-04**|**MemoryOut: Learning Principal Features via Multimodal Sparse Filtering Network for Semi-supervised Video Anomaly Detection**|Qingyao Wu Team|[2506.02535](http://arxiv.org/abs/2506.02535)|null|\n", "2506.02387": "|**2025-06-03**|**VS-Bench: Evaluating VLMs for Strategic Reasoning and Decision-Making in Multi-Agent Environments**|Yu Wang Team|[2506.02387](http://arxiv.org/abs/2506.02387)|null|\n", "2506.02359": "|**2025-06-03**|**Auto-Labeling Data for Object Detection**|Jason J. Corso Team|[2506.02359](http://arxiv.org/abs/2506.02359)|null|\n", "2506.02354": "|**2025-06-03**|**RATE-Nav: Region-Aware Termination Enhancement for Zero-shot Object Navigation with Vision-Language Models**|Jianzong Wang Team|[2506.02354](http://arxiv.org/abs/2506.02354)|null|\n", "2506.04158": "|**2025-06-04**|**Image Editing As Programs with Diffusion Models**|Xinchao Wang Team|[2506.04158](http://arxiv.org/abs/2506.04158)|null|\n", "2506.04129": "|**2025-06-04**|**Recent Advances in Medical Image Classification**|Ngoc Quoc Ly Team|[2506.04129](http://arxiv.org/abs/2506.04129)|null|\n", "2506.04070": "|**2025-06-04**|**LaF-GRPO: In-Situ Navigation Instruction Generation for the Visually Impaired via GRPO with LLM-as-Follower Reward**|Jing Li Team|[2506.04070](http://arxiv.org/abs/2506.04070)|null|\n", "2506.04039": "|**2025-06-04**|**Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization**|Min Zhang Team|[2506.04039](http://arxiv.org/abs/2506.04039)|null|\n", "2506.04005": "|**2025-06-04**|**Vocabulary-free few-shot learning for Vision-Language Models**|Christophe De Vleeschouwer Team|[2506.04005](http://arxiv.org/abs/2506.04005)|null|\n", "2506.03933": "|**2025-06-04**|**DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models**|Anders Holst Team|[2506.03933](http://arxiv.org/abs/2506.03933)|null|\n", "2506.03662": "|**2025-06-04**|**Zero-Shot Temporal Interaction Localization for Egocentric Videos**|Hesheng Wang Team|[2506.03662](http://arxiv.org/abs/2506.03662)|null|\n", "2506.03642": "|**2025-06-04**|**Spatial Understanding from Videos: Structured Prompts Meet Simulation Data**|Liqiang Nie Team|[2506.03642](http://arxiv.org/abs/2506.03642)|null|\n", "2506.03614": "|**2025-06-04**|**VLMs Can Aggregate Scattered Training Patches**|Chaochao Lu Team|[2506.03614](http://arxiv.org/abs/2506.03614)|null|\n", "2506.03589": "|**2025-06-04**|**BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance**|Ngan Le Team|[2506.03589](http://arxiv.org/abs/2506.03589)|null|\n", "2506.03569": "|**2025-06-04**|**MiMo-VL Technical Report**|Bingquan Xia Team|[2506.03569](http://arxiv.org/abs/2506.03569)|null|\n", "2506.03521": "|**2025-06-04**|**Target Semantics Clustering via Text Representations for Robust Universal Domain Adaptation**|Yixin Zhang Team|[2506.03521](http://arxiv.org/abs/2506.03521)|null|\n", "2506.03517": "|**2025-06-04**|**DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models**|Aliaksandr Siarohin Team|[2506.03517](http://arxiv.org/abs/2506.03517)|null|\n", "2506.03511": "|**2025-06-04**|**POLARIS: A High-contrast Polarimetric Imaging Benchmark Dataset for Exoplanetary Disk Representation Learning**|Weixin Yao Team|[2506.03511](http://arxiv.org/abs/2506.03511)|**[link](https://github.com/astraeus999/POLARIS_img_analysis)**|\n", "2506.03371": "|**2025-06-03**|**Toward Reliable VLM: A Fine-Grained Benchmark and Framework for Exposure, Bias, and Inference in Korean Street Views**|Hansaem Kim Team|[2506.03371](http://arxiv.org/abs/2506.03371)|null|\n", "2506.03355": "|**2025-06-03**|**Robustness in Both Domains: CLIP Needs a Robust Text Encoder**|Volkan Cevher Team|[2506.03355](http://arxiv.org/abs/2506.03355)|null|\n", "2506.03270": "|**2025-06-03**|**Grounded Vision-Language Interpreter for Integrated Task and Motion Planning**|Atsushi Hashimoto Team|[2506.03270](http://arxiv.org/abs/2506.03270)|null|\n", "2506.05318": "|**2025-06-06**|**Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs**|Xiaodan Liang Team|[2506.05318](http://arxiv.org/abs/2506.05318)|null|\n", "2506.05218": "|**2025-06-05**|**MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm**|Xiang Bai Team|[2506.05218](http://arxiv.org/abs/2506.05218)|null|\n", "2506.05198": "|**2025-06-05**|**Quantifying Cross-Modality Memorization in Vision-Language Models**|Chiyuan Zhang Team|[2506.05198](http://arxiv.org/abs/2506.05198)|null|\n", "2506.05146": "|**2025-06-05**|**CIVET: Systematic Evaluation of Understanding in VLMs**|Giuseppe Riccardi Team|[2506.05146](http://arxiv.org/abs/2506.05146)|null|\n", "2506.05127": "|**2025-06-05**|**PixCell: A generative foundation model for digital histopathology images**|Dimitris Samaras Team|[2506.05127](http://arxiv.org/abs/2506.05127)|null|\n", "2506.05061": "|**2025-06-05**|**A Survey on Vietnamese Document Analysis and Recognition: Challenges and Future Directions**|Dung Nguyen Team|[2506.05061](http://arxiv.org/abs/2506.05061)|null|\n", "2506.05020": "|**2025-06-05**|**Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System**|Moju Zhao Team|[2506.05020](http://arxiv.org/abs/2506.05020)|null|\n", "2506.04929": "|**2025-06-05**|**ConECT Dataset: Overcoming Data Scarcity in Context-Aware E-Commerce MT**|Miko\u0142aj Koszowski Team|[2506.04929](http://arxiv.org/abs/2506.04929)|null|\n", "2506.04743": "|**2025-06-05**|**SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs**|Dacheng Tao Team|[2506.04743](http://arxiv.org/abs/2506.04743)|null|\n", "2506.04713": "|**2025-06-05**|**Robust Few-Shot Vision-Language Model Adaptation**|Shu Kong Team|[2506.04713](http://arxiv.org/abs/2506.04713)|null|\n", "2506.04704": "|**2025-06-05**|**HoliSafe: Holistic Safety Benchmarking and Modeling with Safety Meta Token for Vision-Language Model**|Sung Ju Hwang Team|[2506.04704](http://arxiv.org/abs/2506.04704)|null|\n", "2506.04606": "|**2025-06-05**|**SmartAvatar: Text- and Image-Guided Human Avatar Generation with VLM AI Agents**|Yu-Wing Tai Team|[2506.04606](http://arxiv.org/abs/2506.04606)|null|\n", "2506.04585": "|**2025-06-05**|**MuSciClaims: Multimodal Scientific Claim Verification**|Niranjan Balasubramanian Team|[2506.04585](http://arxiv.org/abs/2506.04585)|null|\n", "2506.04562": "|**2025-06-05**|**Handle-based Mesh Deformation Guided By Vision Language Model**|Aniket Bera Team|[2506.04562](http://arxiv.org/abs/2506.04562)|null|\n", "2506.04308": "|**2025-06-04**|**RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics**|Shanghang Zhang Team|[2506.04308](http://arxiv.org/abs/2506.04308)|null|\n", "2506.06279": "|**2025-06-06**|**CoMemo: LVLMs Need Image Context with Image Memory**|Jifeng Dai Team|[2506.06279](http://arxiv.org/abs/2506.06279)|null|\n", "2506.06275": "|**2025-06-06**|**Movie Facts and Fibs (MF$^2$): A Benchmark for Long Movie Understanding**|Andr\u00e9 F. T. Martins Team|[2506.06275](http://arxiv.org/abs/2506.06275)|null|\n", "2506.06232": "|**2025-06-06**|**Challenging Vision-Language Models with Surgical Data: A New Dataset and Broad Benchmarking Study**|Lena Maier-Hein Team|[2506.06232](http://arxiv.org/abs/2506.06232)|null|\n", "2506.06220": "|**2025-06-06**|**GenIR: Generative Visual Feedback for Mental Image Retrieval**|James Davis Team|[2506.06220](http://arxiv.org/abs/2506.06220)|null|\n", "2506.06218": "|**2025-06-06**|**STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving**|Horst Possegger Team|[2506.06218](http://arxiv.org/abs/2506.06218)|null|\n", "2506.06084": "|**2025-06-06**|**WisWheat: A Three-Tiered Vision-Language Dataset for Wheat Management**|Zijian Wang Team|[2506.06084](http://arxiv.org/abs/2506.06084)|null|\n", "2506.06076": "|**2025-06-06**|**Full Conformal Adaptation of Medical Vision-Language Models**|Jose Dolz Team|[2506.06076](http://arxiv.org/abs/2506.06076)|null|\n", "2506.06072": "|**2025-06-06**|**BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning**|Rudolf Lioutikov Team|[2506.06072](http://arxiv.org/abs/2506.06072)|null|\n", "2506.05982": "|**2025-06-06**|**MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness Against VLM-based Attacks**|Yiren Song Team|[2506.05982](http://arxiv.org/abs/2506.05982)|null|\n", "2506.05883": "|**2025-06-06**|**HMVLM: Multistage Reasoning-Enhanced Vision-Language Model for Long-Tailed Driving Scenarios**|Weihao Gu Team|[2506.05883](http://arxiv.org/abs/2506.05883)|null|\n", "2506.05765": "|**2025-06-06**|**Do Large Vision-Language Models Distinguish between the Actual and Apparent Features of Illusions?**|Hitomi Yanaka Team|[2506.05765](http://arxiv.org/abs/2506.05765)|null|\n", "2506.05696": "|**2025-06-06**|**MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory**|Jo\u00e3o Magalh\u00e3es Team|[2506.05696](http://arxiv.org/abs/2506.05696)|null|\n", "2506.05667": "|**2025-06-06**|**DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models**|Xianpeng Lang Team|[2506.05667](http://arxiv.org/abs/2506.05667)|null|\n", "2506.05523": "|**2025-06-05**|**MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning**|Furong Huang Team|[2506.05523](http://arxiv.org/abs/2506.05523)|null|\n", "2506.05450": "|**2025-06-05**|**Degradation-Aware Image Enhancement via Vision-Language Classification**|Zibo Meng Team|[2506.05450](http://arxiv.org/abs/2506.05450)|null|\n", "2506.08010": "|**2025-06-10**|**Vision Transformers Don't Need Trained Registers**|Yossi Gandelsman Team|[2506.08010](http://arxiv.org/abs/2506.08010)|null|\n", "2506.08008": "|**2025-06-09**|**Hidden in plain sight: VLMs overlook their visual representations**|Trevor Darrell Team|[2506.08008](http://arxiv.org/abs/2506.08008)|null|\n", "2506.07961": "|**2025-06-09**|**BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models**|Tieniu Tan Team|[2506.07961](http://arxiv.org/abs/2506.07961)|null|\n", "2506.07943": "|**2025-06-09**|**Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations**|Yiqing Shen Team|[2506.07943](http://arxiv.org/abs/2506.07943)|null|\n", "2506.07936": "|**2025-06-09**|**Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models**|Zsolt Kira Team|[2506.07936](http://arxiv.org/abs/2506.07936)|null|\n", "2506.07850": "|**2025-06-09**|**SAM2Auto: Auto Annotation Using FLASH**|Q. M. Jonathan Wu Team|[2506.07850](http://arxiv.org/abs/2506.07850)|null|\n", "2506.07803": "|**2025-06-09**|**Image Reconstruction as a Tool for Feature Analysis**|Andrey Kuznetsov Team|[2506.07803](http://arxiv.org/abs/2506.07803)|null|\n", "2506.07785": "|**2025-06-09**|**Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger**|Shiming Xiang Team|[2506.07785](http://arxiv.org/abs/2506.07785)|null|\n", "2506.07778": "|**2025-06-09**|**Language-Vision Planner and Executor for Text-to-Visual Reasoning**|Ling Liu Team|[2506.07778](http://arxiv.org/abs/2506.07778)|null|\n", "2506.07739": "|**2025-06-10**|**ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models**|Shuai Lu Team|[2506.07739](http://arxiv.org/abs/2506.07739)|null|\n", "2506.07697": "|**2025-06-09**|**OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting**|Bastian Leibe Team|[2506.07697](http://arxiv.org/abs/2506.07697)|null|\n", "2506.07631": "|**2025-06-09**|**Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline**|Idan Szpektor Team|[2506.07631](http://arxiv.org/abs/2506.07631)|null|\n", "2506.07627": "|**2025-06-09**|**Event-Priori-Based Vision-Language Model for Efficient Visual Understanding**|Michele Magno Team|[2506.07627](http://arxiv.org/abs/2506.07627)|null|\n", "2506.07564": "|**2025-06-10**|**SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems**|Zhengzhong Tu Team|[2506.07564](http://arxiv.org/abs/2506.07564)|null|\n", "2506.07553": "|**2025-06-10**|**GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition**|Conghui He Team|[2506.07553](http://arxiv.org/abs/2506.07553)|null|\n", "2506.07509": "|**2025-06-09**|**Taking Flight with Dialogue: Enabling Natural Language Control for PX4-based Drone Agent**|Ting Yang Ling Team|[2506.07509](http://arxiv.org/abs/2506.07509)|null|\n", "2506.07497": "|**2025-06-09**|**Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency**|Xinggang Wang Team|[2506.07497](http://arxiv.org/abs/2506.07497)|null|\n", "2506.07484": "|**2025-06-09**|**CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization**|Hyun Myung Team|[2506.07484](http://arxiv.org/abs/2506.07484)|null|\n", "2506.07416": "|**2025-06-09**|**LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments**|Josh Park Team|[2506.07416](http://arxiv.org/abs/2506.07416)|null|\n", "2506.07399": "|**2025-06-09**|**MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems**|Tao Qi Team|[2506.07399](http://arxiv.org/abs/2506.07399)|null|\n", "2506.09049": "|**2025-06-10**|**VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning**|Zhenfei Yin Team|[2506.09049](http://arxiv.org/abs/2506.09049)|null|\n", "2506.09047": "|**2025-06-11**|**Same Task, Different Circuits: Disentangling Modality-Specific Mechanisms in VLMs**|Yonatan Belinkov Team|[2506.09047](http://arxiv.org/abs/2506.09047)|null|\n", "2506.09040": "|**2025-06-10**|**Autoregressive Semantic Visual Reconstruction Helps VLMs Understand Better**|Jiaqi Wang Team|[2506.09040](http://arxiv.org/abs/2506.09040)|null|\n", "2506.08990": "|**2025-06-10**|**Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models**|Liansheng Wang Team|[2506.08990](http://arxiv.org/abs/2506.08990)|null|\n", "2506.08927": "|**2025-06-10**|**Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions**|Yejin Choi Team|[2506.08927](http://arxiv.org/abs/2506.08927)|null|\n", "2506.08817": "|**2025-06-12**|**Video-CoT: A Comprehensive Dataset for Spatiotemporal Understanding of Videos Based on Chain-of-Thought**|Shanghang Zhang Team|[2506.08817](http://arxiv.org/abs/2506.08817)|null|\n", "2506.08774": "|**2025-06-10**|**Multimodal Representation Alignment for Cross-modal Information Retrieval**|Luis A. Leiva Team|[2506.08774](http://arxiv.org/abs/2506.08774)|null|\n", "2506.08708": "|**2025-06-10**|**PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly**|Xiaodan Liang Team|[2506.08708](http://arxiv.org/abs/2506.08708)|null|\n", "2506.08691": "|**2025-06-10**|**VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism**|Weijiang Yu Team|[2506.08691](http://arxiv.org/abs/2506.08691)|null|\n", "2506.08678": "|**2025-06-10**|**ATAS: Any-to-Any Self-Distillation for Enhanced Open-Vocabulary Dense Prediction**|Taesup Kim Team|[2506.08678](http://arxiv.org/abs/2506.08678)|null|\n", "2506.08543": "|**2025-06-10**|**Convergence of Spectral Principal Paths: How Deep Networks Distill Linear Representations from Noisy Inputs**|Ang Li Team|[2506.08543](http://arxiv.org/abs/2506.08543)|null|\n", "2506.08429": "|**2025-06-10**|**Better Reasoning with Less Data: Enhancing VLMs Through Unified Modality Scoring**|Jiaheng Wei Team|[2506.08429](http://arxiv.org/abs/2506.08429)|null|\n", "2506.08399": "|**2025-06-11**|**SafeCoT: Improving VLM Safety with Minimal Reasoning**|Chaochao Lu Team|[2506.08399](http://arxiv.org/abs/2506.08399)|null|\n", "2506.08391": "|**2025-06-10**|**SECOND: Mitigating Perceptual Hallucination in Vision-Language Models via Selective and Contrastive Decoding**|Jaeyoung Do Team|[2506.08391](http://arxiv.org/abs/2506.08391)|null|\n", "2506.08227": "|**2025-06-09**|**A Good CREPE needs more than just Sugar: Investigating Biases in Compositional Vision-Language Benchmarks**|Matthias Bethge Team|[2506.08227](http://arxiv.org/abs/2506.08227)|null|\n", "2506.08194": "|**2025-06-11**|**GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra**|Guha Balakrishnan Team|[2506.08194](http://arxiv.org/abs/2506.08194)|null|\n", "2506.08189": "|**2025-06-09**|**Open World Scene Graph Generation using Vision Language Models**|Anuj Karpatne Team|[2506.08189](http://arxiv.org/abs/2506.08189)|null|\n", "2506.08071": "|**2025-06-09**|**CuRe: Cultural Gaps in the Long Tail of Text-to-Image Systems**|Ramya Korlakai Vinayak Team|[2506.08071](http://arxiv.org/abs/2506.08071)|null|\n", "2506.09965": "|**2025-06-11**|**Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing**|Tieniu Tan Team|[2506.09965](http://arxiv.org/abs/2506.09965)|**[link](https://github.com/antresearchnlp/vilasr)**|\n", "2506.09930": "|**2025-06-11**|**From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models**|Chen Feng Team|[2506.09930](http://arxiv.org/abs/2506.09930)|null|\n", "2506.09883": "|**2025-06-11**|**3D-Aware Vision-Language Models Fine-Tuning with Geometric Distillation**|Hyunjung Shim Team|[2506.09883](http://arxiv.org/abs/2506.09883)|**[link](https://github.com/kaist-cvml/3d-vlm-gd)**|\n", "2506.09691": "|**2025-06-11**|**Adding simple structure at inference improves Vision-Language Compositionality**|Gorka Azkune Team|[2506.09691](http://arxiv.org/abs/2506.09691)|**[link](https://github.com/imirandam/structure-inference-compositionality)**|\n", "2506.09638": "|**2025-06-11**|**FedVLMBench: Benchmarking Federated Fine-Tuning of Vision-Language Models**|Liangqiong Qu Team|[2506.09638](http://arxiv.org/abs/2506.09638)|null|\n", "2506.09522": "|**2025-06-11**|**Revisit What You See: Disclose Language Prior in Vision Tokens for Efficient Guided Decoding of LVLMs**|Jaehyung Kim Team|[2506.09522](http://arxiv.org/abs/2506.09522)|**[link](https://github.com/bscho333/ReVisiT)**|\n", "2506.09473": "|**2025-06-11**|**Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning**|Jia Li Team|[2506.09473](http://arxiv.org/abs/2506.09473)|null|\n", "2506.09445": "|**2025-06-11**|**TOGA: Temporally Grounded Open-Ended Video QA with Weak Supervision**|Susmit Jha Team|[2506.09445](http://arxiv.org/abs/2506.09445)|null|\n", "2506.09353": "|**2025-06-11**|**DAVSP: Safety Alignment for Large Vision-Language Models via Deep Aligned Visual Safety Prompt**|Ge Li Team|[2506.09353](http://arxiv.org/abs/2506.09353)|null|\n", "2506.09284": "|**2025-06-10**|**UAD: Unsupervised Affordance Distillation for Generalization in Robotic Manipulation**|Li Fei-Fei Team|[2506.09284](http://arxiv.org/abs/2506.09284)|null|\n", "2506.09172": "|**2025-06-10**|**MultiNet: An Open-Source Software Toolkit \\& Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models**|Harshvardhan Sikka Team|[2506.09172](http://arxiv.org/abs/2506.09172)|null|\n", "2506.10895": "|**2025-06-12**|**AIR: Zero-shot Generative Model Adaptation with Iterative Refinement**|Ngai-Man Cheung Team|[2506.10895](http://arxiv.org/abs/2506.10895)|**[link](https://github.com/guimeng-leo-liu/air)**|\n", "2506.10826": "|**2025-06-13**|**RationalVLA: A Rational Vision-Language-Action Model with Dual System**|Haoang Li Team|[2506.10826](http://arxiv.org/abs/2506.10826)|null|\n", "2506.10756": "|**2025-06-12**|**Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding**|Mir Feroskhan Team|[2506.10756](http://arxiv.org/abs/2506.10756)|null|\n", "2506.10730": "|**2025-06-13**|**IQE-CLIP: Instance-aware Query Embedding for Zero-/Few-shot Anomaly Detection in Medical Domain**|Yefeng Zheng Team|[2506.10730](http://arxiv.org/abs/2506.10730)|**[link](https://github.com/hongh0/iqe-clip)**|\n", "2506.10639": "|**2025-06-12**|**GigaVideo-1: Advancing Video Generation via Automatic Feedback with 4 GPU-Hours Fine-Tuning**|Guan Huang Team|[2506.10639](http://arxiv.org/abs/2506.10639)|null|\n", "2506.10575": "|**2025-06-12**|**Text to Image for Multi-Label Image Recognition with Joint Prompt-Adapter Learning**|Yong Liu Team|[2506.10575](http://arxiv.org/abs/2506.10575)|null|\n", "2506.10474": "|**2025-06-12**|**LLMs Are Not Yet Ready for Deepfake Image Detection**|Kristen Moore Team|[2506.10474](http://arxiv.org/abs/2506.10474)|null|\n", "2506.10342": "|**2025-06-12**|**UrbanSense:AFramework for Quantitative Analysis of Urban Streetscapes leveraging Vision Large Language Models**|Shuai Lu Team|[2506.10342](http://arxiv.org/abs/2506.10342)|null|\n", "2506.10334": "|**2025-06-12**|**Using Vision Language Models to Detect Students' Academic Emotion through Facial Expressions**|Gaowei Chen Team|[2506.10334](http://arxiv.org/abs/2506.10334)|null|\n", "2506.10286": "|**2025-06-12**|**HalLoc: Token-level Localization of Hallucinations for Vision Language Models**|Gunhee Kim Team|[2506.10286](http://arxiv.org/abs/2506.10286)|null|\n", "2506.10202": "|**2025-06-11**|**Q2E: Query-to-Event Decomposition for Zero-Shot Multilingual Text-to-Video Retrieval**|Francis Ferraro Team|[2506.10202](http://arxiv.org/abs/2506.10202)|null|\n", "2506.10182": "|**2025-06-11**|**Improving Personalized Search with Regularized Low-Rank Parameter Updates**|Bryan Russell Team|[2506.10182](http://arxiv.org/abs/2506.10182)|null|\n", "2506.10172": "|**2025-06-11**|**A Navigation Framework Utilizing Vision-Language Models**|Kaiyu tang Team|[2506.10172](http://arxiv.org/abs/2506.10172)|null|\n", "2506.10157": "|**2025-06-11**|**One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence**|Marinka Zitnik Team|[2506.10157](http://arxiv.org/abs/2506.10157)|null|\n", "2506.10128": "|**2025-06-11**|**ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs**|Lijuan Wang Team|[2506.10128](http://arxiv.org/abs/2506.10128)|null|\n", "2506.10085": "|**2025-06-11**|**Test-Time Adaptation for Generalizable Task Progress Estimation**|Alessandra Russo Team|[2506.10085](http://arxiv.org/abs/2506.10085)|null|\n", "2506.12009": "|**2025-06-13**|**Affogato: Learning Open-Vocabulary Affordance Grounding with Automated Data Generation at Scale**|Minsu Cho Team|[2506.12009](http://arxiv.org/abs/2506.12009)|null|\n", "2506.11976": "|**2025-06-13**|**How Visual Representations Map to Language Feature Space in Multimodal LLMs**|Neel Nanda Team|[2506.11976](http://arxiv.org/abs/2506.11976)|null|\n", "2506.11820": "|**2025-06-13**|**Rethinking Multilingual Vision-Language Translation: Dataset, Evaluation, and Adaptation**|Kaifu Zhang Team|[2506.11820](http://arxiv.org/abs/2506.11820)|null|\n", "2506.11684": "|**2025-06-13**|**MTabVQA: Evaluating Multi-Tabular Reasoning of Language Models in Visual Space**|Jan Strich Team|[2506.11684](http://arxiv.org/abs/2506.11684)|null|\n", "2506.11604": "|**2025-06-13**|**VLM@school -- Evaluation of AI image understanding on German middle school knowledge**|Vincent Tischler Team|[2506.11604](http://arxiv.org/abs/2506.11604)|null|\n", "2506.11595": "|**2025-06-13**|**EasyARC: Evaluating Vision Language Models on True Visual Reasoning**|Aylin Akkus Team|[2506.11595](http://arxiv.org/abs/2506.11595)|null|\n", "2506.11526": "|**2025-06-13**|**Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis**|Johannes Betz Team|[2506.11526](http://arxiv.org/abs/2506.11526)|null|\n", "2506.11515": "|**2025-06-13**|**Manager: Aggregating Insights from Unimodal Experts in Two-Tower VLMs and MLLMs**|Min-Yen Kan Team|[2506.11515](http://arxiv.org/abs/2506.11515)|null|\n", "2506.11496": "|**2025-06-13**|**Taming Stable Diffusion for Computed Tomography Blind Super-Resolution**|Lichao Mou Team|[2506.11496](http://arxiv.org/abs/2506.11496)|null|\n", "2506.11472": "|**2025-06-13**|**On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving**|Mert D. Pes\u00e9 Team|[2506.11472](http://arxiv.org/abs/2506.11472)|null|\n", "2506.11234": "|**2025-06-12**|**Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving**|Liam Paull Team|[2506.11234](http://arxiv.org/abs/2506.11234)|null|\n", "2506.13762": "|**2025-06-16**|**Touch begins where vision ends: Generalizable policies for contact-rich manipulation**|Raunaq Bhirangi Team|[2506.13762](http://arxiv.org/abs/2506.13762)|null|\n", "2506.13761": "|**2025-06-16**|**Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins**|Wei-Chiu Ma Team|[2506.13761](http://arxiv.org/abs/2506.13761)|null|\n", "2506.13723": "|**2025-06-16**|**OTFusion: Bridging Vision-only and Vision-Language Models via Optimal Transport for Transductive Zero-Shot Learning**|Yonghang Tai Team|[2506.13723](http://arxiv.org/abs/2506.13723)|null|\n", "2506.13679": "|**2025-06-16**|**ROSA: Harnessing Robot States for Vision-Language and Action Alignment**|Xiaoyan Sun Team|[2506.13679](http://arxiv.org/abs/2506.13679)|null|\n", "2506.13638": "|**2025-06-16**|**DualEdit: Dual Editing for Knowledge Updating in Vision-Language Models**|Hanspeter Pfister Team|[2506.13638](http://arxiv.org/abs/2506.13638)|null|\n", "2506.13428": "|**2025-06-16**|**VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation**|Wei Pan Team|[2506.13428](http://arxiv.org/abs/2506.13428)|null|\n", "2506.13367": "|**2025-06-16**|**Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation**|Marija Popovi\u0107 Team|[2506.13367](http://arxiv.org/abs/2506.13367)|null|\n", "2506.13282": "|**2025-06-16**|**Anomaly Object Segmentation with Vision-Language Models for Steel Scrap Recycling**|Rei Kawakami Team|[2506.13282](http://arxiv.org/abs/2506.13282)|null|\n", "2506.13205": "|**2025-06-16**|**Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments**|Ee-Chien Chang Team|[2506.13205](http://arxiv.org/abs/2506.13205)|null|\n", "2506.13187": "|**2025-06-16**|**Dynamic Context-oriented Decomposition for Task-aware Low-rank Adaptation with Less Forgetting and Faster Convergence**|Bernard Ghanem Team|[2506.13187](http://arxiv.org/abs/2506.13187)|null|\n", "2506.13166": "|**2025-06-16**|**GreedyPrune: Retenting Critical Visual Token Set for Large Vision Language Models**|Jun Wang Team|[2506.13166](http://arxiv.org/abs/2506.13166)|null|\n", "2506.13102": "|**2025-06-16**|**Rethinking Test-Time Scaling for Medical AI: Model and Task-Aware Strategies for LLMs and VLMs**|Byung-Hoon Kim Team|[2506.13102](http://arxiv.org/abs/2506.13102)|null|\n", "2506.13063": "|**2025-06-16**|**PRISM2: Unlocking Multi-Modal General Pathology AI with Clinical Dialogue**|Siqi Liu Team|[2506.13063](http://arxiv.org/abs/2506.13063)|null|\n", "2506.13038": "|**2025-06-17**|**HKD4VLM: A Progressive Hybrid Knowledge Distillation Framework for Robust Multimodal Hallucination and Factuality Detection in VLMs**|Xuezhi Cao Team|[2506.13038](http://arxiv.org/abs/2506.13038)|null|\n", "2506.12849": "|**2025-06-15**|**CAPO: Reinforcing Consistent Reasoning in Medical Decision-Making**|Zuozhu Liu Team|[2506.12849](http://arxiv.org/abs/2506.12849)|null|\n", "2506.12822": "|**2025-06-15**|**Enhancing Rating-Based Reinforcement Learning to Effectively Leverage Feedback from Large Vision-Language Models**|Chang D. Yoo Team|[2506.12822](http://arxiv.org/abs/2506.12822)|null|\n", "2506.12776": "|**2025-06-15**|**Native Visual Understanding: Resolving Resolution Dilemmas in Vision-Language Models**|Wentao Zhang Team|[2506.12776](http://arxiv.org/abs/2506.12776)|null|\n", "2506.12706": "|**2025-06-15**|**NAP-Tuning: Neural Augmented Prompt Tuning for Adversarially Robust Vision-Language Models**|Jitao Sang Team|[2506.12706](http://arxiv.org/abs/2506.12706)|null|\n", "2506.12683": "|**2025-06-15**|**Evaluating Cell Type Inference in Vision Language Models Under Varying Visual Context**|Sandeep Singhal Team|[2506.12683](http://arxiv.org/abs/2506.12683)|null|\n", "2506.12609": "|**2025-06-14**|**Not All Tokens and Heads Are Equally Important: Dual-Level Attention Intervention for Hallucination Mitigation**|Yuexian Zou Team|[2506.12609](http://arxiv.org/abs/2506.12609)|null|\n", "2506.14763": "|**2025-06-17**|**RobotSmith: Generative Robotic Tool Design for Acquisition of Complex Manipulation Skills**|Chuang Gan Team|[2506.14763](http://arxiv.org/abs/2506.14763)|null|\n", "2506.14727": "|**2025-06-17**|**Casper: Inferring Diverse Intents for Assistive Teleoperation with Vision Language Models**|Yuke Zhu Team|[2506.14727](http://arxiv.org/abs/2506.14727)|null|\n", "2506.14697": "|**2025-06-17**|**AGENTSAFE: Benchmarking the Safety of Embodied Agents on Hazardous Instructions**|Dacheng Tao Team|[2506.14697](http://arxiv.org/abs/2506.14697)|null|\n", "2506.14674": "|**2025-06-17**|**Recognition through Reasoning: Reinforcing Image Geo-localization with Large Vision-Language Models**|Jiaheng Wei Team|[2506.14674](http://arxiv.org/abs/2506.14674)|null|\n", "2506.14670": "|**2025-06-17**|**StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery**|Michelle Pasco Team|[2506.14670](http://arxiv.org/abs/2506.14670)|null|\n", "2506.14512": "|**2025-06-17**|**SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks**|Liang Lin Team|[2506.14512](http://arxiv.org/abs/2506.14512)|null|\n", "2506.14507": "|**2025-06-17**|**Can Pretrained Vision-Language Embeddings Alone Guide Robot Navigation?**|Soumik Sarkar Team|[2506.14507](http://arxiv.org/abs/2506.14507)|**[link](https://github.com/oadamharoon/text2nav)**|\n", "2506.14451": "|**2025-06-17**|**Adapting Lightweight Vision Language Models for Radiological Visual Question Answering**|Chang Sun Team|[2506.14451](http://arxiv.org/abs/2506.14451)|null|\n", "2506.14404": "|**2025-06-17**|**Causally Steered Diffusion for Automated Video Counterfactual Generation**|Sotirios A. Tsaftaris Team|[2506.14404](http://arxiv.org/abs/2506.14404)|null|\n", "2506.14233": "|**2025-06-17**|**Narrate2Nav: Real-Time Visual Navigation with Implicit Language Reasoning in Human-Centric Environments**|Xuesu Xiao Team|[2506.14233](http://arxiv.org/abs/2506.14233)|null|\n", "2506.14136": "|**2025-06-17**|**Interpreting Biomedical VLMs on High-Imbalance Out-of-Distributions: An Insight into BiomedCLIP on Radiology**|Benjamin Kwan Team|[2506.14136](http://arxiv.org/abs/2506.14136)|null|\n", "2506.14100": "|**2025-06-17**|**A Hierarchical Test Platform for Vision Language Model (VLM)-Integrated Real-World Autonomous Driving**|Ziran Wang Team|[2506.14100](http://arxiv.org/abs/2506.14100)|null|\n", "2506.14015": "|**2025-06-16**|**Disentangling 3D from Large Vision-Language Models for Controlled Portrait Generation**|Hyeongwoo Kim Team|[2506.14015](http://arxiv.org/abs/2506.14015)|null|\n", "2506.14009": "|**2025-06-16**|**GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics**|Mac Schwager Team|[2506.14009](http://arxiv.org/abs/2506.14009)|null|\n", "2506.13964": "|**2025-06-16**|**Comparison of ConvNeXt and Vision-Language Models for Breast Density Assessment in Screening Mammography**|Alejandro Santos-D\u00edaz Team|[2506.13964](http://arxiv.org/abs/2506.13964)|null|\n", "2506.13925": "|**2025-06-16**|**HierVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment**|Abdul Bais Team|[2506.13925](http://arxiv.org/abs/2506.13925)|null|\n", "2506.15681": "|**2025-06-18**|**GenRecal: Generation after Recalibration from Large to Small Vision-Language Models**|Yueh-Hua Wu Team|[2506.15681](http://arxiv.org/abs/2506.15681)|null|\n", "2506.15649": "|**2025-06-18**|**Dual-Stage Value-Guided Inference with Margin-Based Reward Adjustment for Fast and Faithful VLM Captioning**|Imran Razzak Team|[2506.15649](http://arxiv.org/abs/2506.15649)|null|\n", "2506.15635": "|**2025-06-18**|**FindingDory: A Benchmark to Evaluate Memory in Embodied Agents**|Zsolt Kira Team|[2506.15635](http://arxiv.org/abs/2506.15635)|null|\n", "2506.15594": "|**2025-06-18**|**WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts**|R\u00e9mi Lebret Team|[2506.15594](http://arxiv.org/abs/2506.15594)|**[link](https://github.com/negar-foroutan/wikimixqa)**|\n", "2506.15583": "|**2025-06-18**|**DiscoSG: Towards Discourse-Level Text Scene Graph Parsing through Iterative Graph Refinement**|Zhuang Li Team|[2506.15583](http://arxiv.org/abs/2506.15583)|**[link](https://github.com/shaoqlin/discosg)**|\n", "2506.15480": "|**2025-06-18**|**Context-Informed Grounding Supervision**|Minjoon Seo Team|[2506.15480](http://arxiv.org/abs/2506.15480)|**[link](https://github.com/kaistai/cings)**|\n", "2506.15318": "|**2025-06-19**|**OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models**|Guotai Wang Team|[2506.15318](http://arxiv.org/abs/2506.15318)|null|\n", "2506.15298": "|**2025-06-18**|**MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering**|Adrian K. Davision Team|[2506.15298](http://arxiv.org/abs/2506.15298)|null|\n", "2506.15180": "|**2025-06-18**|**ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections**|Shin'ichi Satoh Team|[2506.15180](http://arxiv.org/abs/2506.15180)|null|\n", "2506.15096": "|**2025-06-18**|**DyNaVLM: Zero-Shot Vision-Language Navigation System with Dynamic Viewpoints and Self-Refining Graph Memory**|Yue Gao Team|[2506.15096](http://arxiv.org/abs/2506.15096)|null|\n", "2506.15084": "|**2025-06-18**|**An Empirical Study of Bugs in Data Visualization Libraries**|Chengnian Sun Team|[2506.15084](http://arxiv.org/abs/2506.15084)|**[link](https://github.com/williamlus/dataviz-lib-bugs)**|\n", "2506.14907": "|**2025-06-17**|**PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning**|Yeyun Gong Team|[2506.14907](http://arxiv.org/abs/2506.14907)|**[link](https://github.com/alchemistyzz/perl)**|\n", "2506.17221": "|**2025-06-20**|**VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning**|Hengshuang Zhao Team|[2506.17221](http://arxiv.org/abs/2506.17221)|null|\n", "2506.17218": "|**2025-06-20**|**Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens**|Chuang Gan Team|[2506.17218](http://arxiv.org/abs/2506.17218)|null|\n", "2506.17144": "|**2025-06-20**|**Do We Need Large VLMs for Spotting Soccer Actions?**|Sandeep Chaurasia Team|[2506.17144](http://arxiv.org/abs/2506.17144)|null|\n", "2506.16994": "|**2025-06-20**|**Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments**|Nathaniel D. Bastian Team|[2506.16994](http://arxiv.org/abs/2506.16994)|null|\n", "2506.16806": "|**2025-06-20**|**FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation**|Jinqiao Wang Team|[2506.16806](http://arxiv.org/abs/2506.16806)|null|\n", "2506.16805": "|**2025-06-20**|**Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes**|Chen Feng Team|[2506.16805](http://arxiv.org/abs/2506.16805)|null|\n", "2506.16760": "|**2025-06-20**|**Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models**|Xiaohua Xu Team|[2506.16760](http://arxiv.org/abs/2506.16760)|null|\n", "2506.16730": "|**2025-06-20**|**TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion**|Xinbo Gao Team|[2506.16730](http://arxiv.org/abs/2506.16730)|null|\n", "2506.16716": "|**2025-06-20**|**V-CASS: Vision-context-aware Expressive Speech Synthesis for Enhancing User Understanding of Videos**|Xiaoyu Qin Team|[2506.16716](http://arxiv.org/abs/2506.16716)|null|\n", "2506.16703": "|**2025-06-20**|**VLM-Empowered Multi-Mode System for Efficient and Safe Planetary Navigation**|Liang Ding Team|[2506.16703](http://arxiv.org/abs/2506.16703)|null|\n", "2506.16691": "|**2025-06-20**|**LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation**|Jing Liu Team|[2506.16691](http://arxiv.org/abs/2506.16691)|null|\n", "2506.16652": "|**2025-06-19**|**CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity**|Yunzhu Li Team|[2506.16652](http://arxiv.org/abs/2506.16652)|null|\n", "2506.16623": "|**2025-06-19**|**History-Augmented Vision-Language Models for Frontier-Based Zero-Shot Object Navigation**|Fatemeh Afghah Team|[2506.16623](http://arxiv.org/abs/2506.16623)|null|\n", "2506.16396": "|**2025-06-19**|**GoalLadder: Incremental Goal Discovery with Vision-Language Models**|Shimon Whiteson Team|[2506.16396](http://arxiv.org/abs/2506.16396)|null|\n", "2506.16385": "|**2025-06-19**|**CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset**|Amith Adiraju Team|[2506.16385](http://arxiv.org/abs/2506.16385)|null|\n", "2506.16218": "|**2025-06-19**|**FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models**|Tat-Seng Chua Team|[2506.16218](http://arxiv.org/abs/2506.16218)|null|\n", "2506.16112": "|**2025-06-19**|**AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models**|Shanghang Zhang Team|[2506.16112](http://arxiv.org/abs/2506.16112)|null|\n", "2506.16058": "|**2025-06-19**|**Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation**|Yansong Tang Team|[2506.16058](http://arxiv.org/abs/2506.16058)|null|\n", "2506.16012": "|**2025-06-19**|**DualTHOR: A Dual-Arm Humanoid Simulation Platform for Contingency-Aware Planning**|Zongqing Lu Team|[2506.16012](http://arxiv.org/abs/2506.16012)|null|\n", "2506.15903": "|**2025-06-18**|**VectorEdits: A Dataset and Benchmark for Instruction-Based Editing of Vector Graphics**|Michal \u0160tef\u00e1nik Team|[2506.15903](http://arxiv.org/abs/2506.15903)|null|\n", "2506.18564": "|**2025-06-23**|**VQ-Insight: Teaching VLMs for AI-Generated Video Quality Understanding via Progressive Visual Reinforcement Learning**|Jian Zhang Team|[2506.18564](http://arxiv.org/abs/2506.18564)|null|\n", "2506.18504": "|**2025-06-23**|**Generalizing Vision-Language Models to Novel Domains: A Comprehensive Survey**|Heng Tao Shen Team|[2506.18504](http://arxiv.org/abs/2506.18504)|null|\n", "2506.18385": "|**2025-06-23**|**InternSpatial: A Comprehensive Dataset for Spatial Reasoning in Vision-Language Models**|Wenhai Wang Team|[2506.18385](http://arxiv.org/abs/2506.18385)|null|\n", "2506.18378": "|**2025-06-23**|**Taming Vision-Language Models for Medical Image Analysis: A Comprehensive Review**|Jing Qin Team|[2506.18378](http://arxiv.org/abs/2506.18378)|null|\n", "2506.18322": "|**2025-06-23**|**Escaping the SpuriVerse: Can Large Vision-Language Models Generalize Beyond Seen Spurious Correlations?**|Bill Howe Team|[2506.18322](http://arxiv.org/abs/2506.18322)|null|\n", "2506.18246": "|**2025-06-24**|**Referring Expression Instance Retrieval and A Strong End-to-End Baseline**|JinQiao Wang Team|[2506.18246](http://arxiv.org/abs/2506.18246)|null|\n", "2506.18234": "|**2025-06-23**|**Drive-R1: Bridging Reasoning and Planning in VLMs for Autonomous Driving with Reinforcement Learning**|Xinhai Zhao Team|[2506.18234](http://arxiv.org/abs/2506.18234)|null|\n", "2506.18140": "|**2025-06-22**|**See-in-Pairs: Reference Image-Guided Comparative Vision-Language Models for Medical Diagnosis**|Xiaoxiao Li Team|[2506.18140](http://arxiv.org/abs/2506.18140)|null|\n", "2506.18048": "|**2025-06-22**|**CLGRPO: Reasoning Ability Enhancement for Small VLMs**|Zhiwang Zhang Team|[2506.18048](http://arxiv.org/abs/2506.18048)|null|\n", "2506.17967": "|**2025-06-22**|**Adapting Vision-Language Models for Evaluating World Models**|Sarah Parisot Team|[2506.17967](http://arxiv.org/abs/2506.17967)|null|\n", "2506.17811": "|**2025-06-21**|**RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models**|Marco Pavone Team|[2506.17811](http://arxiv.org/abs/2506.17811)|null|\n", "2506.17664": "|**2025-06-21**|**MDSAM:Memory-Driven Sparse Attention Matrix for LVLMs Hallucination Mitigation**|Xiaochuan Shi Team|[2506.17664](http://arxiv.org/abs/2506.17664)|null|\n", "2506.17645": "|**2025-06-21**|**Histopathology Image Report Generation by Vision Language Model with Multimodal In-Context Learning**|Yu-Chiang Frank Wang Team|[2506.17645](http://arxiv.org/abs/2506.17645)|null|\n", "2506.17629": "|**2025-06-21**|**CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning**|Xiaoling Wang Team|[2506.17629](http://arxiv.org/abs/2506.17629)|null|\n", "2506.17590": "|**2025-06-21**|**DRAMA-X: A Fine-grained Intent Prediction and Risk Reasoning Benchmark For Driving**|Zhengzhong Tu Team|[2506.17590](http://arxiv.org/abs/2506.17590)|null|\n", "2506.17587": "|**2025-06-21**|**HalluRNN: Mitigating Hallucinations via Recurrent Cross-Layer Reasoning in Large Vision-Language Models**|Tao He Team|[2506.17587](http://arxiv.org/abs/2506.17587)|null|\n", "2506.17503": "|**2025-06-20**|**Trustworthy Few-Shot Transfer of Medical VLMs through Split Conformal Prediction**|Jose Dolz Team|[2506.17503](http://arxiv.org/abs/2506.17503)|null|\n", "2506.17500": "|**2025-06-20**|**Few-Shot, Now for Real: Medical VLMs Adaptation without Balanced Sets or Validation**|Ismail Ben Ayed Team|[2506.17500](http://arxiv.org/abs/2506.17500)|null|\n", "2506.17462": "|**2025-06-20**|**General-Purpose Robotic Navigation via LVLM-Orchestrated Perception, Reasoning, and Acting**|Georgios Georgakis Team|[2506.17462](http://arxiv.org/abs/2506.17462)|null|\n", "2506.17417": "|**2025-06-20**|**Aha Moment Revisited: Are VLMs Truly Capable of Self Verification in Inference-time Scaling?**|Klara Nahrstedt Team|[2506.17417](http://arxiv.org/abs/2506.17417)|null|\n", "2506.19850": "|**2025-06-24**|**Unified Vision-Language-Action Model**|Zhaoxiang Zhang Team|[2506.19850](http://arxiv.org/abs/2506.19850)|null|\n", "2506.19825": "|**2025-06-24**|**Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models**|Christoph M. Friedrich Team|[2506.19825](http://arxiv.org/abs/2506.19825)|null|\n", "2506.19816": "|**2025-06-24**|**CronusVLA: Transferring Latent Motion Across Time for Multi-Frame Prediction in Manipulation**|Jiangmiao Pang Team|[2506.19816](http://arxiv.org/abs/2506.19816)|null|\n", "2506.19694": "|**2025-06-24**|**UltraAD: Fine-Grained Ultrasound Anomaly Classification via Few-Shot CLIP Adaptation**|Zhongliang Jiang Team|[2506.19694](http://arxiv.org/abs/2506.19694)|null|\n", "2506.19651": "|**2025-06-24**|**PEVLM: Parallel Encoding for Vision-Language Models**|Yong Wu Team|[2506.19651](http://arxiv.org/abs/2506.19651)|null|\n", "2506.19610": "|**2025-06-24**|**V2T-CoT: From Vision to Text Chain-of-Thought for Medical Reasoning and Diagnosis**|Zuozhu Liu Team|[2506.19610](http://arxiv.org/abs/2506.19610)|null|\n", "2506.19608": "|**2025-06-24**|**ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP**|Bokui Chen Team|[2506.19608](http://arxiv.org/abs/2506.19608)|null|\n", "2506.19579": "|**2025-06-24**|**Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects**|Angelo Cangelosi Team|[2506.19579](http://arxiv.org/abs/2506.19579)|null|\n", "2506.19513": "|**2025-06-24**|**Visual hallucination detection in large vision-language models via evidential conflict**|Liping Jing Team|[2506.19513](http://arxiv.org/abs/2506.19513)|null|\n", "2506.19498": "|**2025-06-24**|**T-Rex: Task-Adaptive Spatial Representation Extraction for Robotic Manipulation with Vision-Language Models**|Qingyao Wu Team|[2506.19498](http://arxiv.org/abs/2506.19498)|null|\n", "2506.19389": "|**2025-06-24**|**Emergence of Text Readability in Vision Language Models**|Bohyung Han Team|[2506.19389](http://arxiv.org/abs/2506.19389)|null|\n", "2506.19303": "|**2025-06-24**|**Robotic Perception with a Large Tactile-Vision-Language Model for Physical Property Inference**|Nutan Chen Team|[2506.19303](http://arxiv.org/abs/2506.19303)|null|\n", "2506.19300": "|**2025-06-24**|**Open-Vocabulary Camouflaged Object Segmentation with Cascaded Vision Language Models**|Dan Zeng Team|[2506.19300](http://arxiv.org/abs/2506.19300)|null|\n", "2506.19288": "|**2025-06-24**|**Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding**|Hui Xiong Team|[2506.19288](http://arxiv.org/abs/2506.19288)|null|\n", "2506.19257": "|**2025-06-24**|**MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models**|Bo Zheng Team|[2506.19257](http://arxiv.org/abs/2506.19257)|null|\n", "2506.19212": "|**2025-06-24**|**Scaffolding Dexterous Manipulation with Vision-Language Models**|Dorsa Sadigh Team|[2506.19212](http://arxiv.org/abs/2506.19212)|null|\n", "2506.19079": "|**2025-06-23**|**Reading Smiles: Proxy Bias in Foundation Models for Facial Emotion Recognition**|Bjoern W. Schuller Team|[2506.19079](http://arxiv.org/abs/2506.19079)|null|\n", "2506.19072": "|**2025-06-23**|**HAWAII: Hierarchical Visual Knowledge Transfer for Efficient Vision-Language Models**|Krzysztof Czarnecki Team|[2506.19072](http://arxiv.org/abs/2506.19072)|null|\n", "2506.18985": "|**2025-06-23**|**GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs**|Guanxi Shen Team|[2506.18985](http://arxiv.org/abs/2506.18985)|null|\n", "2506.20616": "|**2025-06-27**|**Shape2Animal: Creative Animal Generation from Natural Silhouettes**|Trung-Nghia Le Team|[2506.20616](http://arxiv.org/abs/2506.20616)|null|\n", "2506.20566": "|**2025-06-25**|**HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction**|Maja Matari\u0107 Team|[2506.20566](http://arxiv.org/abs/2506.20566)|null|\n", "2506.20449": "|**2025-06-25**|**Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation**|Morten Rieger Hannemose Team|[2506.20449](http://arxiv.org/abs/2506.20449)|null|\n", "2506.20373": "|**2025-06-25**|**CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition**|Michael Gienger Team|[2506.20373](http://arxiv.org/abs/2506.20373)|null|\n", "2506.20332": "|**2025-06-25**|**Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards**|Bo Zheng Team|[2506.20332](http://arxiv.org/abs/2506.20332)|null|\n", "2506.20100": "|**2025-06-25**|**MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations**|Vikram S. Adve Team|[2506.20100](http://arxiv.org/abs/2506.20100)|null|\n", "2506.21509": "|**2025-06-26**|**Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration**|Jian Wu Team|[2506.21509](http://arxiv.org/abs/2506.21509)|null|\n", "2506.21476": "|**2025-06-26**|**Global and Local Entailment Learning for Natural World Imagery**|Nathan Jacobs Team|[2506.21476](http://arxiv.org/abs/2506.21476)|null|\n", "2506.21458": "|**2025-06-26**|**Spatial Mental Modeling from Limited Views**|Li Fei-Fei Team|[2506.21458](http://arxiv.org/abs/2506.21458)|null|\n", "2506.21356": "|**2025-06-27**|**ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models**|Ziwei Liu Team|[2506.21356](http://arxiv.org/abs/2506.21356)|null|\n", "2506.21317": "|**2025-06-26**|**LLaVA-Pose: Enhancing Human Pose and Action Understanding via Keypoint-Integrated Instruction Tuning**|Hayaru Shouno Team|[2506.21317](http://arxiv.org/abs/2506.21317)|null|\n", "2506.21316": "|**2025-06-26**|**DrishtiKon: Multi-Granular Visual Grounding for Text-Rich Document Images**|Ganesh Ramakrishnan Team|[2506.21316](http://arxiv.org/abs/2506.21316)|null|\n", "2506.21230": "|**2025-06-26**|**World-aware Planning Narratives Enhance Large Vision-Language Model Planner**|Xipeng QIu Team|[2506.21230](http://arxiv.org/abs/2506.21230)|null|\n", "2506.21144": "|**2025-06-26**|**Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion**|Jian Liang Team|[2506.21144](http://arxiv.org/abs/2506.21144)|null|\n", "2506.21041": "|**2025-06-26**|**V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling**|Bin Ran Team|[2506.21041](http://arxiv.org/abs/2506.21041)|null|\n", "2506.21017": "|**2025-06-26**|**Multimodal Prompt Alignment for Facial Expression Recognition**|Shutao Li Team|[2506.21017](http://arxiv.org/abs/2506.21017)|null|\n", "2506.21001": "|**2025-06-26**|**Style-Aligned Image Composition for Robust Detection of Abnormal Cells in Cytopathology**|S Kevin Zhou Team|[2506.21001](http://arxiv.org/abs/2506.21001)|null|\n", "2506.20991": "|**2025-06-26**|**TSDASeg: A Two-Stage Model with Direct Alignment for Interactive Point Cloud Segmentation**|Yihong Wu Team|[2506.20991](http://arxiv.org/abs/2506.20991)|null|\n", "2506.20990": "|**2025-06-26**|**SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes**|Zheng Zhang Team|[2506.20990](http://arxiv.org/abs/2506.20990)|null|\n", "2506.20966": "|**2025-06-26**|**Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends**|Zeng-Guang Hou Team|[2506.20966](http://arxiv.org/abs/2506.20966)|null|\n", "2506.20944": "|**2025-06-26**|**E-FreeM2: Efficient Training-Free Multi-Scale and Cross-Modal News Verification via MLLMs**|Minh-Son Dao Team|[2506.20944](http://arxiv.org/abs/2506.20944)|null|\n", "2506.20832": "|**2025-06-25**|**Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models**|Zafer Dogan Team|[2506.20832](http://arxiv.org/abs/2506.20832)|null|\n", "2506.20795": "|**2025-06-25**|**How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?**|Bastian Leibe Team|[2506.20795](http://arxiv.org/abs/2506.20795)|null|\n", "2506.22434": "|**2025-06-27**|**MiCo: Multi-image Contrast for Reinforcement Visual Reasoning**|Hengshuang Zhao Team|[2506.22434](http://arxiv.org/abs/2506.22434)|null|\n", "2506.22395": "|**2025-06-27**|**Test-Time Consistency in Vision Language Models**|Leonid Sigal Team|[2506.22395](http://arxiv.org/abs/2506.22395)|null|\n", "2506.22375": "|**2025-06-27**|**Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation**|Xun Xu Team|[2506.22375](http://arxiv.org/abs/2506.22375)|null|\n", "2506.22283": "|**2025-06-27**|**Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment**|Bo Du Team|[2506.22283](http://arxiv.org/abs/2506.22283)|null|\n", "2506.22274": "|**2025-06-27**|**COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication**|Albert Gatt Team|[2506.22274](http://arxiv.org/abs/2506.22274)|null|\n", "2506.22146": "|**2025-06-27**|**Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs**|Mahdieh Soleymani Baghshah Team|[2506.22146](http://arxiv.org/abs/2506.22146)|null|\n", "2506.22056": "|**2025-06-27**|**Universal Retrieval for Multimodal Trajectory Modeling**|Dehan Kong Team|[2506.22056](http://arxiv.org/abs/2506.22056)|null|\n", "2506.22032": "|**2025-06-27**|**Partial CLIP is Enough: Chimera-Seg for Zero-shot Semantic Segmentation**|Daisuke Deguchi Team|[2506.22032](http://arxiv.org/abs/2506.22032)|null|\n", "2506.21892": "|**2025-06-27**|**SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation**|Xulei Yang Team|[2506.21892](http://arxiv.org/abs/2506.21892)|null|\n", "2506.21885": "|**2025-06-27**|**Integrating Multi-Modal Sensors: A Review of Fusion Techniques for Intelligent Vehicles**|Matthew J. Barth Team|[2506.21885](http://arxiv.org/abs/2506.21885)|null|\n", "2506.21876": "|**2025-06-27**|**Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation**|Zhiting Hu Team|[2506.21876](http://arxiv.org/abs/2506.21876)|null|\n", "2506.21874": "|**2025-06-27**|**On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling**|Ben Y. Zhao Team|[2506.21874](http://arxiv.org/abs/2506.21874)|null|\n", "2506.21863": "|**2025-06-27**|**Remote Sensing Large Vision-Language Model: Semantic-augmented Multi-level Alignment and Semantic-aware Expert Modeling**|Yong Man Ro Team|[2506.21863](http://arxiv.org/abs/2506.21863)|null|\n", "2506.21860": "|**2025-06-27**|**Embodied Domain Adaptation for Object Detection**|Feras Dayoub Team|[2506.21860](http://arxiv.org/abs/2506.21860)|null|\n", "2506.21833": "|**2025-06-27**|**The Cost of Avoiding Backpropagation**|Hui Guan Team|[2506.21833](http://arxiv.org/abs/2506.21833)|null|\n", "2506.21762": "|**2025-06-26**|**ViStruct: Simulating Expert-Like Reasoning Through Task Decomposition and Visual Attention Cues**|Carolina Nobre Team|[2506.21762](http://arxiv.org/abs/2506.21762)|null|\n", "2506.21656": "|**2025-06-26**|**Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs**|Ismini Lourentzou Team|[2506.21656](http://arxiv.org/abs/2506.21656)|null|\n", "2506.24016": "|**2025-06-30**|**EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations**|Sungzoon Cho Team|[2506.24016](http://arxiv.org/abs/2506.24016)|null|\n", "2506.24000": "|**2025-06-30**|**The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models**|Tieniu Tan Team|[2506.24000](http://arxiv.org/abs/2506.24000)|null|\n", "2506.23903": "|**2025-06-30**|**GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models**|Hassan Rivaz Team|[2506.23903](http://arxiv.org/abs/2506.23903)|null|\n", "2506.23856": "|**2025-06-30**|**A Closer Look at Conditional Prompt Tuning for Vision-Language Models**|Heng Tao Shen Team|[2506.23856](http://arxiv.org/abs/2506.23856)|null|\n", "2506.23822": "|**2025-06-30**|**Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model**|Fahad Shahbaz Khan Team|[2506.23822](http://arxiv.org/abs/2506.23822)|null|\n", "2506.23785": "|**2025-06-30**|**Visual Textualization for Image Prompted Object Detection**|Yan Xu Team|[2506.23785](http://arxiv.org/abs/2506.23785)|null|\n", "2506.23725": "|**2025-06-30**|**PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?**|Ransalu Senanayake Team|[2506.23725](http://arxiv.org/abs/2506.23725)|null|\n", "2506.23663": "|**2025-06-30**|**On the Domain Robustness of Contrastive Vision-Language Models**|Erik Rodner Team|[2506.23663](http://arxiv.org/abs/2506.23663)|null|\n", "2506.23590": "|**2025-06-30**|**CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models**|Bing Qin Team|[2506.23590](http://arxiv.org/abs/2506.23590)|null|\n", "2506.23584": "|**2025-06-30**|**A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation**|Jie Xu Team|[2506.23584](http://arxiv.org/abs/2506.23584)|null|\n", "2506.23491": "|**2025-07-01**|**ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding**|ShengJing Yang Team|[2506.23491](http://arxiv.org/abs/2506.23491)|null|\n", "2506.23465": "|**2025-06-30**|**Sanitizing Manufacturing Dataset Labels Using Vision-Language Models**|Vinh Nguyen Team|[2506.23465](http://arxiv.org/abs/2506.23465)|null|\n", "2506.23352": "|**2025-06-29**|**GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields**|Yutaka Matsuo Team|[2506.23352](http://arxiv.org/abs/2506.23352)|null|\n", "2506.23329": "|**2025-06-29**|**IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering**|Brandon Y. Feng Team|[2506.23329](http://arxiv.org/abs/2506.23329)|null|\n", "2506.23309": "|**2025-07-01**|**SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting**|Hongliang Ren Team|[2506.23309](http://arxiv.org/abs/2506.23309)|null|\n", "2506.23122": "|**2025-06-29**|**Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models**|Tanmoy Chakraborty Team|[2506.23122](http://arxiv.org/abs/2506.23122)|null|\n", "2506.23115": "|**2025-06-29**|**MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings**|Zhicheng Dou Team|[2506.23115](http://arxiv.org/abs/2506.23115)|null|\n", "2506.23061": "|**2025-06-29**|**Empowering Small VLMs to Think with Dynamic Memorization and Exploration**|Long Chen Team|[2506.23061](http://arxiv.org/abs/2506.23061)|null|\n", "2506.23046": "|**2025-06-29**|**SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions**|Maarten Sap Team|[2506.23046](http://arxiv.org/abs/2506.23046)|null|\n", "2506.22982": "|**2025-06-28**|**Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models**|Swadesh Swain Team|[2506.22982](http://arxiv.org/abs/2506.22982)|null|\n", "2507.01790": "|**2025-07-02**|**How Do Vision-Language Models Process Conflicting Information Across Modalities?**|Ellie Pavlick Team|[2507.01790](http://arxiv.org/abs/2507.01790)|null|\n", "2507.01673": "|**2025-07-02**|**Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition**|Muzammil Behzad Team|[2507.01673](http://arxiv.org/abs/2507.01673)|null|\n", "2507.01544": "|**2025-07-02**|**MARVIS: Modality Adaptive Reasoning over VISualizations**|Chinmay Hegde Team|[2507.01544](http://arxiv.org/abs/2507.01544)|null|\n", "2507.01504": "|**2025-07-02**|**Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence**|Martin Schramm Team|[2507.01504](http://arxiv.org/abs/2507.01504)|null|\n", "2507.01485": "|**2025-07-02**|**BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments**|Mingzhai Sun Team|[2507.01485](http://arxiv.org/abs/2507.01485)|null|\n", "2507.01424": "|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Yanwei Fu Team|[2507.01424](http://arxiv.org/abs/2507.01424)|null|\n", "2507.01409": "|**2025-07-02**|**CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning**|Yoshitaka Ushiku Team|[2507.01409](http://arxiv.org/abs/2507.01409)|null|\n", "2507.01351": "|**2025-07-02**|**Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model**|Xi Li Team|[2507.01351](http://arxiv.org/abs/2507.01351)|null|\n", "2507.01255": "|**2025-07-02**|**AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation**|Jiawei Zhang Team|[2507.01255](http://arxiv.org/abs/2507.01255)|null|\n", "2507.01006": "|**2025-07-02**|**GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning**|Jie Tang Team|[2507.01006](http://arxiv.org/abs/2507.01006)|null|\n", "2507.00990": "|**2025-07-04**|**Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations**|Yunzhu Li Team|[2507.00990](http://arxiv.org/abs/2507.00990)|null|\n", "2507.00951": "|**2025-07-01**|**Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact**|Seyedali Mirjalili Team|[2507.00951](http://arxiv.org/abs/2507.00951)|null|\n", "2507.00907": "|**2025-07-01**|**The Age of Sensorial Zero Trust: Why We Can No Longer Trust Our Senses**|Fabio Correa Xavier Team|[2507.00907](http://arxiv.org/abs/2507.00907)|null|\n", "2507.00898": "|**2025-07-01**|**ONLY: One-Layer Intervention Sufficiently Mitigates Hallucinations in Large Vision-Language Models**|Yaqi Xie Team|[2507.00898](http://arxiv.org/abs/2507.00898)|null|\n", "2507.00886": "|**2025-07-01**|**GaussianVLM: Scene-centric 3D Vision-Language Models using Language-aligned Gaussian Splats for Embodied Reasoning and Beyond**|Luc Van Gool Team|[2507.00886](http://arxiv.org/abs/2507.00886)|null|\n", "2507.00721": "|**2025-07-01**|**UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement**|Xiangxiang Chu Team|[2507.00721](http://arxiv.org/abs/2507.00721)|null|\n", "2507.00700": "|**2025-07-01**|**Contrasting Cognitive Styles in Vision-Language Models: Holistic Attention in Japanese Versus Analytical Focus in English**|Rajesh Sharma Team|[2507.00700](http://arxiv.org/abs/2507.00700)|null|\n", "2507.00586": "|**2025-07-01**|**Context-Aware Academic Emotion Dataset and Benchmark**|Wenwu Yang Team|[2507.00586](http://arxiv.org/abs/2507.00586)|null|\n", "2507.00537": "|**2025-07-01**|**Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation**|Rong Xiao Team|[2507.00537](http://arxiv.org/abs/2507.00537)|null|\n", "2507.00525": "|**2025-07-01**|**Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving**|Yadan Luo Team|[2507.00525](http://arxiv.org/abs/2507.00525)|null|\n", "2507.02600": "|**2025-07-03**|**ArtGS:3D Gaussian Splatting for Interactive Visual-Physical Modeling and Manipulation of Articulated Objects**|Cewu Lu Team|[2507.02600](http://arxiv.org/abs/2507.02600)|null|\n", "2507.02190": "|**2025-07-02**|**cVLA: Towards Efficient Camera-Space VLAs**|Thomas Brox Team|[2507.02190](http://arxiv.org/abs/2507.02190)|null|\n", "2507.02074": "|**2025-07-02**|**Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges**|Anuj Sharma Team|[2507.02074](http://arxiv.org/abs/2507.02074)|null|\n", "2507.02001": "|**2025-07-01**|**Temporal Chain of Thought: Long-Video Understanding by Thinking in Frames**|Cordelia Schmid Team|[2507.02001](http://arxiv.org/abs/2507.02001)|null|\n", "2507.05227": "|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Cheng Lu Team|[2507.05227](http://arxiv.org/abs/2507.05227)|null|\n", "2507.05211": "|**2025-07-07**|**All in One: Visual-Description-Guided Unified Point Cloud Segmentation**|Rao Muhammad Anwer Team|[2507.05211](http://arxiv.org/abs/2507.05211)|null|\n", "2507.05165": "|**2025-07-07**|**Differential Attention for Multimodal Crisis Event Analysis**|Abdullah-Al-Zubaer Imran Team|[2507.05165](http://arxiv.org/abs/2507.05165)|null|\n", "2507.05056": "|**2025-07-07**|**INTER: Mitigating Hallucination in Large Vision-Language Models by Interaction Guidance Sampling**|Bo Zheng Team|[2507.05056](http://arxiv.org/abs/2507.05056)|null|\n", "2507.05020": "|**2025-07-07**|**Adaptation of Multi-modal Representation Models for Multi-task Surgical Computer Vision**|Nicolas Padoy Team|[2507.05020](http://arxiv.org/abs/2507.05020)|null|\n", "2507.04789": "|**2025-07-07**|**Training-free Generation of Temporally Consistent Rewards from VLMs**|Jian Tang Team|[2507.04789](http://arxiv.org/abs/2507.04789)|null|\n", "2507.04741": "|**2025-07-07**|**Vision-Language Models Can't See the Obvious**|Sanath Narayan Team|[2507.04741](http://arxiv.org/abs/2507.04741)|null|\n", "2507.04735": "|**2025-07-07**|**An analysis of vision-language models for fabric retrieval**|Fabio Poiesi Team|[2507.04735](http://arxiv.org/abs/2507.04735)|null|\n", "2507.04699": "|**2025-07-07**|**A Visual Leap in CLIP Compositionality Reasoning through Generation of Counterfactual Sets**|Jie Zhou Team|[2507.04699](http://arxiv.org/abs/2507.04699)|null|\n", "2507.04686": "|**2025-07-07**|**MOSU: Autonomous Long-range Robot Navigation with Multi-modal Scene Understanding**|Dinesh Manocha Team|[2507.04686](http://arxiv.org/abs/2507.04686)|null|\n", "2507.04680": "|**2025-07-07**|**Identify, Isolate, and Purge: Mitigating Hallucinations in LVLMs via Self-Evolving Distillation**|Chang Xu Team|[2507.04680](http://arxiv.org/abs/2507.04680)|null|\n", "2507.04524": "|**2025-07-06**|**VLM-TDP: VLM-guided Trajectory-conditioned Diffusion Policy for Robust Long-Horizon Manipulation**|Lei Han Team|[2507.04524](http://arxiv.org/abs/2507.04524)|null|\n", "2507.04511": "|**2025-07-08**|**FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection**|Ruixuan Wang Team|[2507.04511](http://arxiv.org/abs/2507.04511)|null|\n", "2507.04509": "|**2025-07-06**|**MVL-Loc: Leveraging Vision-Language Model for Generalizable Multi-Scene Camera Relocalization**|Changhao Chen Team|[2507.04509](http://arxiv.org/abs/2507.04509)|null|\n", "2507.04458": "|**2025-07-06**|**Think Twice Before You Judge: Mixture of Dual Reasoning Experts for Multimodal Sarcasm Detection**|Sanasam Ranbir Singh Team|[2507.04458](http://arxiv.org/abs/2507.04458)|null|\n", "2507.04377": "|**2025-07-06**|**Multi-Modal Semantic Parsing for the Interpretation of Tombstone Inscriptions**|Johan Bos Team|[2507.04377](http://arxiv.org/abs/2507.04377)|null|\n", "2507.04152": "|**2025-07-05**|**LVLM-Composer's Explicit Planning for Image Generation**|Amina Grant Team|[2507.04152](http://arxiv.org/abs/2507.04152)|null|\n", "2507.04151": "|**2025-07-05**|**Unlocking Compositional Control: Self-Supervision for LVLM-Based Image Generation**|Hunter Young Team|[2507.04151](http://arxiv.org/abs/2507.04151)|null|\n", "2507.04036": "|**2025-07-05**|**PresentAgent: Multimodal Agent for Presentation Video Generation**|Yang Zhao Team|[2507.04036](http://arxiv.org/abs/2507.04036)|null|\n", "2507.03958": "|**2025-07-05**|**A Comparative Study of Specialized LLMs as Dense Retrievers**|Jiafeng Guo Team|[2507.03958](http://arxiv.org/abs/2507.03958)|null|\n", "2507.06210": "|**2025-07-08**|**CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions**|Yi R. Fung Team|[2507.06210](http://arxiv.org/abs/2507.06210)|null|\n", "2507.06183": "|**2025-07-08**|**Enhancing Scientific Visual Question Answering through Multimodal Reasoning and Ensemble Modeling**|Naga Harshita Marupaka Team|[2507.06183](http://arxiv.org/abs/2507.06183)|null|\n", "2507.06167": "|**2025-07-10**|**Skywork-R1V3 Technical Report**|Yahui Zhou Team|[2507.06167](http://arxiv.org/abs/2507.06167)|null|\n", "2507.06140": "|**2025-07-08**|**LangMamba: A Language-driven Mamba Framework for Low-dose CT Denoising with Vision-language Models**|Hongming Shan Team|[2507.06140](http://arxiv.org/abs/2507.06140)|null|\n", "2507.05887": "|**2025-07-08**|**GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing**|Hao Liu Team|[2507.05887](http://arxiv.org/abs/2507.05887)|null|\n", "2507.05799": "|**2025-07-08**|**Bridging Perception and Language: A Systematic Benchmark for LVLMs' Understanding of Amodal Completion Reports**|Hitomi Yanaka Team|[2507.05799](http://arxiv.org/abs/2507.05799)|null|\n", "2507.05798": "|**2025-07-08**|**SPADE: Spatial-Aware Denoising Network for Open-vocabulary Panoptic Scene Graph Generation with Long- and Local-range Context Reasoning**|Tao He Team|[2507.05798](http://arxiv.org/abs/2507.05798)|null|\n", "2507.05731": "|**2025-07-08**|**A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation**|Yue Gao Team|[2507.05731](http://arxiv.org/abs/2507.05731)|null|\n", "2507.05677": "|**2025-07-09**|**Integrated Structural Prompt Learning for Vision-Language Models**|Bin Luo Team|[2507.05677](http://arxiv.org/abs/2507.05677)|null|\n", "2507.05673": "|**2025-07-08**|**R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding**|Shabnam Ghadar Team|[2507.05673](http://arxiv.org/abs/2507.05673)|null|\n", "2507.05668": "|**2025-07-08**|**Dynamic Rank Adaptation for Vision-Language Models**|Bin Luo Team|[2507.05668](http://arxiv.org/abs/2507.05668)|null|\n", "2507.05607": "|**2025-07-08**|**Structured Task Solving via Modular Embodied Intelligence: A Case Study on Rubik's Cube**|Shenghai Yuan Team|[2507.05607](http://arxiv.org/abs/2507.05607)|null|\n", "2507.05601": "|**2025-07-08**|**Rethinking Layered Graphic Design Generation with a Top-Down Approach**|Qifeng Chen Team|[2507.05601](http://arxiv.org/abs/2507.05601)|null|\n", "2507.05595": "|**2025-07-08**|**PaddleOCR 3.0 Technical Report**|Yanjun Ma Team|[2507.05595](http://arxiv.org/abs/2507.05595)|null|\n", "2507.05515": "|**2025-07-07**|**Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality**|Junxiao Wang Team|[2507.05515](http://arxiv.org/abs/2507.05515)|null|\n", "2507.05513": "|**2025-07-07**|**Llama Nemoretriever Colembed: Top-Performing Text-Image Retrieval Model**|Even Oldridge Team|[2507.05513](http://arxiv.org/abs/2507.05513)|null|\n", "2507.05427": "|**2025-07-07**|**OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts**|Priyadarshini Panda Team|[2507.05427](http://arxiv.org/abs/2507.05427)|null|\n", "2507.05394": "|**2025-07-07**|**pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models**|Ramtin Pedarsani Team|[2507.05394](http://arxiv.org/abs/2507.05394)|null|\n", "2507.07105": "|**2025-07-09**|**4KAgent: Agentic Any Image to 4K Super-Resolution**|Zhengzhong Tu Team|[2507.07105](http://arxiv.org/abs/2507.07105)|null|\n", "2507.07104": "|**2025-07-11**|**Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models**|Junfei Xiao Team|[2507.07104](http://arxiv.org/abs/2507.07104)|null|\n", "2507.07079": "|**2025-07-09**|**Evaluating Attribute Confusion in Fashion Text-to-Image Generation**|Davide Talon Team|[2507.07079](http://arxiv.org/abs/2507.07079)|null|\n", "2507.06973": "|**2025-07-09**|**Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM**|Sibei Yang Team|[2507.06973](http://arxiv.org/abs/2507.06973)|null|\n", "2507.06959": "|**2025-07-09**|**CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale**|Quan Wang Team|[2507.06959](http://arxiv.org/abs/2507.06959)|null|\n", "2507.06899": "|**2025-07-09**|**VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation**|Tat-Seng Chua Team|[2507.06899](http://arxiv.org/abs/2507.06899)|null|\n", "2507.06814": "|**2025-07-09**|**HVI-CIDNet+: Beyond Extreme Darkness for Low-Light Image Enhancement**|Yanning Zhang Team|[2507.06814](http://arxiv.org/abs/2507.06814)|null|\n", "2507.06761": "|**2025-07-09**|**Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu**|Donghyeok Choi Team|[2507.06761](http://arxiv.org/abs/2507.06761)|null|\n", "2507.06679": "|**2025-07-09**|**Text-promptable Object Counting via Quantity Awareness Enhancement**|Li Li Team|[2507.06679](http://arxiv.org/abs/2507.06679)|null|\n", "2507.06603": "|**2025-07-09**|**Cross-Modal Dual-Causal Learning for Long-Term Action Recognition**|Fan Chao Team|[2507.06603](http://arxiv.org/abs/2507.06603)|null|\n", "2507.06510": "|**2025-07-09**|**Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection**|Xiangmin Xu Team|[2507.06510](http://arxiv.org/abs/2507.06510)|null|\n", "2507.06484": "|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Nick Haber Team|[2507.06484](http://arxiv.org/abs/2507.06484)|null|\n", "2507.06441": "|**2025-07-08**|**VisioPath: Vision-Language Enhanced Model Predictive Control for Safe Autonomous Navigation in Mixed Traffic**|Andreas A. Malikopoulos Team|[2507.06441](http://arxiv.org/abs/2507.06441)|null|\n", "2507.07985": "|**2025-07-10**|**CLIP Won't Learn Object-Attribute Binding from Natural Data and Here is Why**|Thomas Brox Team|[2507.07985](http://arxiv.org/abs/2507.07985)|null|\n", "2507.07966": "|**2025-07-10**|**Scaling RL to Long Videos**|Song Han Team|[2507.07966](http://arxiv.org/abs/2507.07966)|null|\n", "2507.07939": "|**2025-07-10**|**SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement and Entropy-aware Alignment**|Lei Fan Team|[2507.07939](http://arxiv.org/abs/2507.07939)|null|\n", "2507.07818": "|**2025-07-10**|**MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving**|Chao Zhang Team|[2507.07818](http://arxiv.org/abs/2507.07818)|null|\n", "2507.07731": "|**2025-07-10**|**Energy-Guided Decoding for Object Hallucination Mitigation**|Christopher Zach Team|[2507.07731](http://arxiv.org/abs/2507.07731)|null|\n", "2507.07709": "|**2025-07-10**|**One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack on Unified Vision-Language Models**|Cairong Zhao Team|[2507.07709](http://arxiv.org/abs/2507.07709)|null|\n", "2507.07685": "|**2025-07-10**|**Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought**|Daiki Chijiwa Team|[2507.07685](http://arxiv.org/abs/2507.07685)|null|\n", "2507.07620": "|**2025-07-11**|**ViLU: Learning Vision-Language Uncertainties for Failure Prediction**|Nicolas Thome Team|[2507.07620](http://arxiv.org/abs/2507.07620)|null|\n", "2507.07605": "|**2025-07-10**|**LOSC: LiDAR Open-voc Segmentation Consolidator**|Renaud Marlet Team|[2507.07605](http://arxiv.org/abs/2507.07605)|null|\n", "2507.07562": "|**2025-07-10**|**The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs**|Qun Liu Team|[2507.07562](http://arxiv.org/abs/2507.07562)|null|\n", "2507.07551": "|**2025-07-10**|**ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing**|Markus Huff Team|[2507.07551](http://arxiv.org/abs/2507.07551)|null|\n", "2507.07340": "|**2025-07-11**|**Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning**|David Martins de Matos Team|[2507.07340](http://arxiv.org/abs/2507.07340)|null|\n", "2507.07317": "|**2025-07-09**|**ADIEE: Automatic Dataset Creation and Scorer for Instruction-Guided Image Editing Evaluation**|Suren Kumar Team|[2507.07317](http://arxiv.org/abs/2507.07317)|null|\n", "2507.07299": "|**2025-07-09**|**LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation**|Angel X. Chang Team|[2507.07299](http://arxiv.org/abs/2507.07299)|null|\n", "2507.07297": "|**2025-07-09**|**MagiC: Evaluating Multimodal Cognition Toward Grounded Visual Reasoning**|Dan Goldwasser Team|[2507.07297](http://arxiv.org/abs/2507.07297)|null|\n", "2507.08679": "|**2025-07-11**|**ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way**|Subarna Tripathi Team|[2507.08679](http://arxiv.org/abs/2507.08679)|null|\n", "2507.08624": "|**2025-07-11**|**Adaptive Framework for Ambient Intelligence in Rehabilitation Assistance**|Andr\u00e1s L\u0151rincz Team|[2507.08624](http://arxiv.org/abs/2507.08624)|null|\n", "2507.08610": "|**2025-07-11**|**Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data**|Ambedkar Dukkipati Team|[2507.08610](http://arxiv.org/abs/2507.08610)|null|\n", "2507.08607": "|**2025-07-11**|**BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis**|Hui Xiong Team|[2507.08607](http://arxiv.org/abs/2507.08607)|null|\n", "2507.08505": "|**2025-07-11**|**Efficient Deployment of Vision-Language Models on Mobile Devices: A Case Study on OnePlus 13R**|Sanidhya Kashyap Team|[2507.08505](http://arxiv.org/abs/2507.08505)|null|\n", "2507.08496": "|**2025-07-11**|**LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning**|Lei Fan Team|[2507.08496](http://arxiv.org/abs/2507.08496)|null|\n", "2507.08410": "|**2025-07-11**|**Multi-modal Mutual-Guidance Conditional Prompt Learning for Vision-Language Models**|Jianping Fan Team|[2507.08410](http://arxiv.org/abs/2507.08410)|null|\n", "2507.08224": "|**2025-07-11**|**Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning**|Yejin Choi Team|[2507.08224](http://arxiv.org/abs/2507.08224)|null|\n", "2507.10548": "|**2025-07-14**|**EmbRACE-3K: Embodied Reasoning and Action in Complex Environments**|Xiaojuan Qi Team|[2507.10548](http://arxiv.org/abs/2507.10548)|null|\n", "2507.10449": "|**2025-07-14**|**CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding**|Yi Wang Team|[2507.10449](http://arxiv.org/abs/2507.10449)|null|\n", "2507.10355": "|**2025-07-14**|**Beyond Graph Model: Reliable VLM Fine-Tuning via Random Graph Adapter**|Bin Luo Team|[2507.10355](http://arxiv.org/abs/2507.10355)|null|\n", "2507.10225": "|**2025-07-14**|**Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection**|Wenqiang Zhang Team|[2507.10225](http://arxiv.org/abs/2507.10225)|null|\n", "2507.10106": "|**2025-07-14**|**BlueGlass: A Framework for Composite AI Safety**|Kay-Ulrich Scholl Team|[2507.10106](http://arxiv.org/abs/2507.10106)|null|\n", "2507.10087": "|**2025-07-14**|**Foundation Model Driven Robotics: A Comprehensive Review**|Ammar Waheed Team|[2507.10087](http://arxiv.org/abs/2507.10087)|null|\n", "2507.10066": "|**2025-07-14**|**LayLens: Improving Deepfake Understanding through Simplified Explanations**|Abhinav Dhall Team|[2507.10066](http://arxiv.org/abs/2507.10066)|null|\n", "2507.10053": "|**2025-07-14**|**CoSMo: A Multimodal Transformer for Page Stream Segmentation in Comic Books**|Dimosthenis Karatzas Team|[2507.10053](http://arxiv.org/abs/2507.10053)|null|\n", "2507.09961": "|**2025-07-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Zhen Lei Team|[2507.09961](http://arxiv.org/abs/2507.09961)|null|\n", "2507.09795": "|**2025-07-13**|**NegRefine: Refining Negative Label-Based Zero-Shot OOD Detection**|Pulei Xiong Team|[2507.09795](http://arxiv.org/abs/2507.09795)|null|\n", "2507.09615": "|**2025-07-13**|**Towards Fine-Grained Adaptation of CLIP via a Self-Trained Alignment Score**|Muhammad Haris Khan Team|[2507.09615](http://arxiv.org/abs/2507.09615)|null|\n", "2507.09500": "|**2025-07-13**|**Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations**|Guiguang Ding Team|[2507.09500](http://arxiv.org/abs/2507.09500)|null|\n", "2507.09491": "|**2025-07-13**|**GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?**|Huaxiu Yao Team|[2507.09491](http://arxiv.org/abs/2507.09491)|null|\n", "2507.09209": "|**2025-07-12**|**Uncertainty-Driven Expert Control: Enhancing the Reliability of Medical Vision-Language Models**|Tat-Seng Chua Team|[2507.09209](http://arxiv.org/abs/2507.09209)|null|\n", "2507.09184": "|**2025-07-12**|**MCA-LLaVA: Manhattan Causal Attention for Reducing Hallucination in Large Vision-Language Models**|Dahan Wang Team|[2507.09184](http://arxiv.org/abs/2507.09184)|null|\n", "2507.09155": "|**2025-07-12**|**OPENXRD: A Comprehensive Benchmark and Enhancement Framework for LLM/MLLM XRD Question Answering**|Niaz Abdolrahim Team|[2507.09155](http://arxiv.org/abs/2507.09155)|null|\n", "2507.09097": "|**2025-07-12**|**RadEyeVideo: Enhancing general-domain Large Vision Language Model for chest X-ray analysis with video representations of eye gaze**|Honghan Wu Team|[2507.09097](http://arxiv.org/abs/2507.09097)|null|\n", "2507.09071": "|**2025-07-11**|**BlindSight: Harnessing Sparsity for Efficient VLMs**|Steven K. Reinhardt Team|[2507.09071](http://arxiv.org/abs/2507.09071)|null|\n", "2507.09011": "|**2025-07-11**|**Beyond vividness: Content analysis of induced hallucinations reveals the hidden structure of individual differences in visual imagery**|Seana Coulson Team|[2507.09011](http://arxiv.org/abs/2507.09011)|null|\n", "2507.08982": "|**2025-07-11**|**VIP: Visual Information Protection through Adversarial Attacks on Vision-Language Models**|Olivier D\u00e9forges Team|[2507.08982](http://arxiv.org/abs/2507.08982)|null|\n", "2507.11200": "|**2025-07-18**|**How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study**|Rossella Arcucci Team|[2507.11200](http://arxiv.org/abs/2507.11200)|null|\n", "2507.11155": "|**2025-07-15**|**Bridging the Gap in Vision Language Models in Identifying Unsafe Concepts Across Modalities**|Yang Zhang Team|[2507.11155](http://arxiv.org/abs/2507.11155)|null|\n", "2507.11153": "|**2025-07-15**|**Assessing Color Vision Test in Large Vision-language Models**|Hongyang Chen Team|[2507.11153](http://arxiv.org/abs/2507.11153)|null|\n", "2507.11114": "|**2025-07-15**|**MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models**|Hamza Moustafa Team|[2507.11114](http://arxiv.org/abs/2507.11114)|null|\n", "2507.11079": "|**2025-07-15**|**Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander**|Lei Chen Team|[2507.11079](http://arxiv.org/abs/2507.11079)|null|\n", "2507.11003": "|**2025-07-15**|**Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection**|Guanzhong Tian Team|[2507.11003](http://arxiv.org/abs/2507.11003)|null|\n", "2507.12465": "|**2025-07-20**|**PhysX-3D: Physical-Grounded 3D Asset Generation**|Ziwei Liu Team|[2507.12465](http://arxiv.org/abs/2507.12465)|null|\n", "2507.12441": "|**2025-07-16**|**Describe Anything Model for Visual Question Answering on Text-rich Images**|Min Xu Team|[2507.12441](http://arxiv.org/abs/2507.12441)|null|\n", "2507.12414": "|**2025-07-16**|**AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models**|Sihao Ding Team|[2507.12414](http://arxiv.org/abs/2507.12414)|null|\n", "2507.12236": "|**2025-07-16**|**Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models**|Bernhard Kainz Team|[2507.12236](http://arxiv.org/abs/2507.12236)|null|\n", "2507.12060": "|**2025-07-16**|**InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing**|Wen-Huang Cheng Team|[2507.12060](http://arxiv.org/abs/2507.12060)|null|\n", "2507.11969": "|**2025-07-16**|**GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models**|Rongrong Ji Team|[2507.11969](http://arxiv.org/abs/2507.11969)|null|\n", "2507.11939": "|**2025-07-16**|**POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering**|Qin Jin Team|[2507.11939](http://arxiv.org/abs/2507.11939)|null|\n", "2507.11730": "|**2025-07-15**|**Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis**|Lihang Ying Team|[2507.11730](http://arxiv.org/abs/2507.11730)|null|\n", "2507.13348": "|**2025-07-17**|**VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning**|Jiaya Jia Team|[2507.13348](http://arxiv.org/abs/2507.13348)|null|\n", "2507.13113": "|**2025-07-17**|**Leveraging Language Prior for Infrared Small Target Detection**|Pravendra Singh Team|[2507.13113](http://arxiv.org/abs/2507.13113)|null|\n", "2507.13089": "|**2025-07-17**|**GLAD: Generalizable Tuning for Vision-Language Models**|Shifeng Chen Team|[2507.13089](http://arxiv.org/abs/2507.13089)|null|\n", "2507.13061": "|**2025-07-17**|**Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection**|Changwen Zheng Team|[2507.13061](http://arxiv.org/abs/2507.13061)|null|\n", "2507.12911": "|**2025-07-21**|**LaViPlan : Language-Guided Visual Path Planning with RLVR**|Hayeon Oh Team|[2507.12911](http://arxiv.org/abs/2507.12911)|null|\n", "2507.12795": "|**2025-07-17**|**City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning**|Xiaowen Chu Team|[2507.12795](http://arxiv.org/abs/2507.12795)|null|\n", "2507.12644": "|**2025-07-16**|**VLMgineer: Vision Language Models as Robotic Toolsmiths**|Dinesh Jayaraman Team|[2507.12644](http://arxiv.org/abs/2507.12644)|null|\n", "2507.12621": "|**2025-07-16**|**NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting**|Chaoli Wang Team|[2507.12621](http://arxiv.org/abs/2507.12621)|null|\n", "2507.12508": "|**2025-07-16**|**MindJourney: Test-Time Scaling with World Models for Spatial Reasoning**|Chuang Gan Team|[2507.12508](http://arxiv.org/abs/2507.12508)|null|\n", "2507.12499": "|**2025-07-16**|**ReAL-AD: Towards Human-Like Reasoning in End-to-End Autonomous Driving**|Xinge Zhu Team|[2507.12499](http://arxiv.org/abs/2507.12499)|null|\n", "2507.12490": "|**2025-07-15**|**Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering**|Dimosthenis Karatzas Team|[2507.12490](http://arxiv.org/abs/2507.12490)|null|\n", "2507.14067": "|**2025-07-18**|**VLA-Mark: A cross modal watermark for large vision-language alignment model**|Xuming Hu Team|[2507.14067](http://arxiv.org/abs/2507.14067)|null|\n", "2507.14049": "|**2025-07-18**|**EdgeVLA: Efficient Vision-Language-Action Models**|Benjamin Bolte Team|[2507.14049](http://arxiv.org/abs/2507.14049)|null|\n", "2507.14024": "|**2025-07-18**|**Moodifier: MLLM-Enhanced Emotion-Driven Image Editing**|Sharon X. Huang Team|[2507.14024](http://arxiv.org/abs/2507.14024)|null|\n", "2507.13868": "|**2025-07-18**|**When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models**|Alberto Cazzaniga Team|[2507.13868](http://arxiv.org/abs/2507.13868)|null|\n", "2507.13773": "|**2025-07-18**|**Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions**|Jiajun Zhang Team|[2507.13773](http://arxiv.org/abs/2507.13773)|null|\n", "2507.13568": "|**2025-07-17**|**LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning**|Margrit Betke Team|[2507.13568](http://arxiv.org/abs/2507.13568)|null|\n", "2507.13405": "|**2025-07-17**|**COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark**|Vasu Sharma Team|[2507.13405](http://arxiv.org/abs/2507.13405)|null|\n", "2507.15852": "|**2025-07-22**|**SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction**|Jiaqi Wang Team|[2507.15852](http://arxiv.org/abs/2507.15852)|null|\n", "2507.15824": "|**2025-07-21**|**Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models**|Erkut Erdem Team|[2507.15824](http://arxiv.org/abs/2507.15824)|null|\n", "2507.15680": "|**2025-07-23**|**Visual-Language Model Knowledge Distillation Method for Image Quality Assessment**|Jiarun Song Team|[2507.15680](http://arxiv.org/abs/2507.15680)|null|\n", "2507.15576": "|**2025-07-21**|**Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging**|Margret Keuper Team|[2507.15576](http://arxiv.org/abs/2507.15576)|null|\n", "2507.15542": "|**2025-07-21**|**HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation**|Robby T. Tan Team|[2507.15542](http://arxiv.org/abs/2507.15542)|null|\n", "2507.15509": "|**2025-07-21**|**Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner**|Lin Ma Team|[2507.15509](http://arxiv.org/abs/2507.15509)|null|\n", "2507.15480": "|**2025-07-21**|**One Last Attention for Your Vision-Language Model**|Zhiqiang Shen Team|[2507.15480](http://arxiv.org/abs/2507.15480)|null|\n", "2507.15428": "|**2025-07-21**|**EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent**|Xinlei Chen Team|[2507.15428](http://arxiv.org/abs/2507.15428)|null|\n", "2507.15285": "|**2025-07-21**|**In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems**|Christoph Busch Team|[2507.15285](http://arxiv.org/abs/2507.15285)|null|\n", "2507.15266": "|**2025-07-21**|**VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving**|Tong Heng Lee Team|[2507.15266](http://arxiv.org/abs/2507.15266)|null|\n", "2507.15025": "|**2025-07-20**|**Survey of GenAI for Automotive Software Development: From Requirements to Executable Code**|Alois Knoll Team|[2507.15025](http://arxiv.org/abs/2507.15025)|null|\n", "2507.14976": "|**2025-07-20**|**Hierarchical Cross-modal Prompt Learning for Vision-Language Models**|Zhenhua Huang Team|[2507.14976](http://arxiv.org/abs/2507.14976)|null|\n", "2507.14823": "|**2025-07-20**|**FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models**|Mengnan Du Team|[2507.14823](http://arxiv.org/abs/2507.14823)|null|\n", "2507.14449": "|**2025-07-19**|**IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark**|Ruiheng Zhang Team|[2507.14449](http://arxiv.org/abs/2507.14449)|null|\n", "2507.14312": "|**2025-07-18**|**CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation**|Nicolas Thome Team|[2507.14312](http://arxiv.org/abs/2507.14312)|null|\n", "2507.14298": "|**2025-07-18**|**In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding**|Leonid Sigal Team|[2507.14298](http://arxiv.org/abs/2507.14298)|null|\n", "2507.16814": "|**2025-07-22**|**Semi-off-Policy Reinforcement Learning for Vision-Language Slow-thinking Reasoning**|Kai Chen Team|[2507.16814](http://arxiv.org/abs/2507.16814)|null|\n", "2507.16781": "|**2025-07-22**|**Cooling Matters: Benchmarking Large Language Models and Vision-Language Models on Liquid-Cooled Versus Air-Cooled H100 GPU Systems**|Arslan Munir Team|[2507.16781](http://arxiv.org/abs/2507.16781)|null|\n", "2507.16716": "|**2025-07-22**|**Enhancing Remote Sensing Vision-Language Models Through MLLM and LLM-Based High-Quality Image-Text Dataset Generation**|Ke Yang Team|[2507.16716](http://arxiv.org/abs/2507.16716)|null|\n", "2507.16713": "|**2025-07-22**|**Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory**|Marco Hutter Team|[2507.16713](http://arxiv.org/abs/2507.16713)|null|\n", "2507.16524": "|**2025-07-22**|**Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models**|Chao Zhang Team|[2507.16524](http://arxiv.org/abs/2507.16524)|null|\n", "2507.16466": "|**2025-07-22**|**SceneLoom: Communicating Data with Scene Context**|Siming Chen Team|[2507.16466](http://arxiv.org/abs/2507.16466)|null|\n", "2507.16257": "|**2025-07-22**|**Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models**|Isao Echizen Team|[2507.16257](http://arxiv.org/abs/2507.16257)|null|\n", "2507.17722": "|**2025-07-23**|**BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems**|Christian Berger Team|[2507.17722](http://arxiv.org/abs/2507.17722)|null|\n", "2507.17520": "|**2025-07-23**|**InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation**|Jiangmiao Pang Team|[2507.17520](http://arxiv.org/abs/2507.17520)|null|\n", "2507.17456": "|**2025-07-23**|**Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection**|Elisa Ricci Team|[2507.17456](http://arxiv.org/abs/2507.17456)|null|\n", "2507.17455": "|**2025-07-23**|**VLM-Guided Visual Place Recognition for Planet-Scale Geo-Localization**|Shoaib Ehsan Team|[2507.17455](http://arxiv.org/abs/2507.17455)|null|\n", "2507.17436": "|**2025-07-23**|**Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection**|Xi Li Team|[2507.17436](http://arxiv.org/abs/2507.17436)|null|\n", "2507.17379": "|**2025-07-23**|**Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models**|Guanghui Sun Team|[2507.17379](http://arxiv.org/abs/2507.17379)|null|\n", "2507.17353": "|**2025-07-23**|**RoadBench: A Vision-Language Foundation Model and Benchmark for Road Damage Understanding**|Tianyang Wang Team|[2507.17353](http://arxiv.org/abs/2507.17353)|null|\n", "2507.17118": "|**2025-07-23**|**HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study**|Maria Spence Team|[2507.17118](http://arxiv.org/abs/2507.17118)|null|\n", "2507.17088": "|**2025-07-23**|**FedVLM: Scalable Personalized Vision-Language Models through Federated Learning**|Habeeb Olufowobi Team|[2507.17088](http://arxiv.org/abs/2507.17088)|null|\n", "2507.17080": "|**2025-07-22**|**VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings**|Kannan Achan Team|[2507.17080](http://arxiv.org/abs/2507.17080)|null|\n", "2507.17047": "|**2025-07-22**|**Controllable Hybrid Captioner for Improved Long-form Video Understanding**|Arun Reddy Team|[2507.17047](http://arxiv.org/abs/2507.17047)|null|\n", "2508.00579": "|**2025-08-01**|**MMRAG-DocQA: A Multi-Modal Retrieval-Augmented Generation Method for Document Question-Answering with Hierarchical Index and Multi-Granularity Retrieval**|Chengcheng Mai Team|[2508.00579](http://arxiv.org/abs/2508.00579)|null|\n", "2508.00557": "|**2025-08-01**|**Training-Free Class Purification for Open-Vocabulary Semantic Segmentation**|Xiaohua Xie Team|[2508.00557](http://arxiv.org/abs/2508.00557)|null|\n", "2508.00553": "|**2025-08-01**|**HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models**|Bin Chen Team|[2508.00553](http://arxiv.org/abs/2508.00553)|null|\n", "2508.00549": "|**2025-08-01**|**Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images**|Timo Ropinski Team|[2508.00549](http://arxiv.org/abs/2508.00549)|null|\n", "2508.00522": "|**2025-08-01**|**EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in Fine-Tuning Large Language Models and Beyond**|Baochang Zhang Team|[2508.00522](http://arxiv.org/abs/2508.00522)|null|\n", "2508.00456": "|**2025-08-01**|**When Vision-Language Model (VLM) Meets Beam Prediction: A Multimodal Contrastive Learning Framework**|Tony Q. S. Quek Team|[2508.00456](http://arxiv.org/abs/2508.00456)|null|\n", "2508.00447": "|**2025-08-01**|**CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text**|Petar Durdevic Team|[2508.00447](http://arxiv.org/abs/2508.00447)|null|\n", "2508.00445": "|**2025-08-01**|**AutoDebias: Automated Framework for Debiasing Text-to-Image Models**|Yang Liu Team|[2508.00445](http://arxiv.org/abs/2508.00445)|null|\n", "2508.00400": "|**2025-08-01**|**Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents**|Rowel O. Atienza Team|[2508.00400](http://arxiv.org/abs/2508.00400)|null|\n", "2508.00399": "|**2025-08-01**|**iSafetyBench: A video-language benchmark for safety in industrial environment**|Shruti Vyas Team|[2508.00399](http://arxiv.org/abs/2508.00399)|null|\n", "2508.00395": "|**2025-08-01**|**Decouple before Align: Visual Disentanglement Enhances Prompt Tuning**|Yanfeng Wang Team|[2508.00395](http://arxiv.org/abs/2508.00395)|null|\n", "2508.00390": "|**2025-08-01**|**SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation**|Renxin Zhong Team|[2508.00390](http://arxiv.org/abs/2508.00390)|null|\n", "2508.00378": "|**2025-08-01**|**CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding**|Lin Shang Team|[2508.00378](http://arxiv.org/abs/2508.00378)|null|\n", "2508.00356": "|**2025-08-01**|**Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning**|Athanasios Voulodimos Team|[2508.00356](http://arxiv.org/abs/2508.00356)|null|\n", "2508.00321": "|**2025-08-01**|**Evaluating the Efficacy of Large Language Models for Generating Fine-Grained Visual Privacy Policies in Homes**|Hewu Li Team|[2508.00321](http://arxiv.org/abs/2508.00321)|null|\n", "2508.00311": "|**2025-08-01**|**DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios**|Lin Ma Team|[2508.00311](http://arxiv.org/abs/2508.00311)|null|\n", "2508.00260": "|**2025-08-01**|**Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models**|Eunwoo Kim Team|[2508.00260](http://arxiv.org/abs/2508.00260)|null|\n", "2508.00230": "|**2025-08-01**|**Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product**|Ehsan Abbasnejad Team|[2508.00230](http://arxiv.org/abs/2508.00230)|null|\n", "2508.00171": "|**2025-07-31**|**On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI**|Enzo Ferrante Team|[2508.00171](http://arxiv.org/abs/2508.00171)|null|\n", "2507.23543": "|**2025-07-31**|**ART: Adaptive Relation Tuning for Generalized Relation Prediction**|Stefan Roth Team|[2507.23543](http://arxiv.org/abs/2507.23543)|null|\n", "2508.05580": "|**2025-08-07**|**Follow-Your-Instruction: A Comprehensive MLLM Agent for World Data Synthesis**|Zeyu Wang Team|[2508.05580](http://arxiv.org/abs/2508.05580)|null|\n", "2508.05547": "|**2025-08-07**|**Adapting Vision-Language Models Without Labels: A Comprehensive Survey**|Olga Fink Team|[2508.05547](http://arxiv.org/abs/2508.05547)|**[link](https://github.com/tim-learn/Awesome-LabelFree-VLMs})**|\n", "2508.05430": "|**2025-08-07**|**Explaining Similarity in Vision-Language Encoders with Weighted Banzhaf Interactions**|Przemyslaw Biecek Team|[2508.05430](http://arxiv.org/abs/2508.05430)|null|\n", "2508.05409": "|**2025-08-07**|**From Detection to Correction: Backdoor-Resilient Face Recognition via Vision-Language Trigger Detection and Noise-Based Neutralization**|Ibrahim Khalil Team|[2508.05409](http://arxiv.org/abs/2508.05409)|null|\n", "2508.05405": "|**2025-08-07**|**DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning**|Bo Zheng Team|[2508.05405](http://arxiv.org/abs/2508.05405)|null|\n", "2508.05383": "|**2025-08-07**|**StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models**|Youqiang Zhou Team|[2508.05383](http://arxiv.org/abs/2508.05383)|null|\n", "2508.05323": "|**2025-08-07**|**Textual Inversion for Efficient Adaptation of Open-Vocabulary Object Detectors Without Forgetting**|Hugo Kuijf Team|[2508.05323](http://arxiv.org/abs/2508.05323)|null|\n", "2508.05294": "|**2025-08-07**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Jorge Pe\u00f1a Queralta Team|[2508.05294](http://arxiv.org/abs/2508.05294)|null|\n", "2508.05244": "|**2025-08-07**|**RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding**|Guiru Liu Team|[2508.05244](http://arxiv.org/abs/2508.05244)|null|\n", "2508.05237": "|**2025-08-07**|**Navigating the Trade-off: A Synthesis of Defensive Strategies for Zero-Shot Adversarial Robustness in Vision-Language Models**|Jason Sun Team|[2508.05237](http://arxiv.org/abs/2508.05237)|null|\n", "2508.05221": "|**2025-08-07**|**ReasoningTrack: Chain-of-Thought Reasoning for Long-term Vision-Language Tracking**|Zhipeng Zhang Team|[2508.05221](http://arxiv.org/abs/2508.05221)|null|\n", "2508.05202": "|**2025-08-07**|**SPEX: A Vision-Language Model for Land Cover Extraction on Spectral Remote Sensing Images**|Liangpei Zhang Team|[2508.05202](http://arxiv.org/abs/2508.05202)|null|\n", "2508.05148": "|**2025-08-07**|**Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories**|Andrew I. Cooper Team|[2508.05148](http://arxiv.org/abs/2508.05148)|null|\n", "2508.05008": "|**2025-08-07**|**Multimodal Causal-Driven Representation Learning for Generalizable Medical Image Segmentation**|Zhen Lei Team|[2508.05008](http://arxiv.org/abs/2508.05008)|null|\n", "2508.04998": "|**2025-08-07**|**Attribute Guidance With Inherent Pseudo-label For Occluded Person Re-identification**|Haiyang Zhang Team|[2508.04998](http://arxiv.org/abs/2508.04998)|null|\n", "2508.04987": "|**2025-08-07**|**Unified modality separation: A vision-language framework for unsupervised domain adaptation**|Heng Tao Shen Team|[2508.04987](http://arxiv.org/abs/2508.04987)|null|\n", "2508.04942": "|**2025-08-07**|**Accelerating Conditional Prompt Learning via Masked Image Modeling for Vision-Language Models**|Hyunseung Choo Team|[2508.04942](http://arxiv.org/abs/2508.04942)|null|\n", "2508.04931": "|**2025-08-06**|**INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM**|Nikos Tsagarakis Team|[2508.04931](http://arxiv.org/abs/2508.04931)|**[link](https://robo-intention.github.io)**|\n", "2508.04895": "|**2025-08-06**|**Automated Bug Frame Retrieval from Gameplay Videos Using Vision-Language Models**|Cor-Paul Bezemer Team|[2508.04895](http://arxiv.org/abs/2508.04895)|null|\n", "2508.04868": "|**2025-08-06**|**Dual-Stream Attention with Multi-Modal Queries for Object Detection in Transportation Applications**|Wassim Bouachir Team|[2508.04868](http://arxiv.org/abs/2508.04868)|null|\n", "2508.06317": "|**2025-08-08**|**Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding**|Kun Shao Team|[2508.06317](http://arxiv.org/abs/2508.06317)|null|\n", "2508.06291": "|**2025-08-08**|**Real-Time 3D Vision-Language Embedding Mapping**|Elmar Rueckert Team|[2508.06291](http://arxiv.org/abs/2508.06291)|null|\n", "2508.06220": "|**2025-08-08**|**InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?**|Youngjae Yu Team|[2508.06220](http://arxiv.org/abs/2508.06220)|null|\n", "2508.06152": "|**2025-08-08**|**VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation**|ChengSheng Deng Team|[2508.06152](http://arxiv.org/abs/2508.06152)|null|\n", "2508.06092": "|**2025-08-08**|**Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation**|Shaohui Liu Team|[2508.06092](http://arxiv.org/abs/2508.06092)|null|\n", "2508.06084": "|**2025-08-08**|**AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance**|Yunhao Liu Team|[2508.06084](http://arxiv.org/abs/2508.06084)|null|\n", "2508.06038": "|**2025-08-08**|**Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models**|Zhouhan Lin Team|[2508.06038](http://arxiv.org/abs/2508.06038)|null|\n", "2508.06036": "|**2025-08-08**|**More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment**|Zhepeng Wang Team|[2508.06036](http://arxiv.org/abs/2508.06036)|null|\n", "2508.05996": "|**2025-08-08**|**Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making**|Xiaosong Wang Team|[2508.05996](http://arxiv.org/abs/2508.05996)|null|\n", "2508.05976": "|**2025-08-08**|**PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation**|Yao Mu Team|[2508.05976](http://arxiv.org/abs/2508.05976)|null|\n", "2508.05899": "|**2025-08-07**|**HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing**|Chris Callison-Burch Team|[2508.05899](http://arxiv.org/abs/2508.05899)|null|\n", "2508.05898": "|**2025-08-07**|**ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates**|Ali cheraghian Team|[2508.05898](http://arxiv.org/abs/2508.05898)|null|\n", "2508.08240": "|**2025-08-11**|**ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks**|Chunhua Shen Team|[2508.08240](http://arxiv.org/abs/2508.08240)|null|\n", "2508.08199": "|**2025-08-11**|**Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model**|Shaoliang Peng Team|[2508.08199](http://arxiv.org/abs/2508.08199)|null|\n", "2508.08040": "|**2025-08-11**|**BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models**|Bo Wang Team|[2508.08040](http://arxiv.org/abs/2508.08040)|null|\n", "2508.08038": "|**2025-08-11**|**TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation**|Robert Wille Team|[2508.08038](http://arxiv.org/abs/2508.08038)|null|\n", "2508.07925": "|**2025-08-11**|**TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding**|Jee-Hyong Lee Team|[2508.07925](http://arxiv.org/abs/2508.07925)|null|\n", "2508.07918": "|**2025-08-11**|**RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering**|Mukesh Prasad Team|[2508.07918](http://arxiv.org/abs/2508.07918)|null|\n", "2508.07871": "|**2025-08-11**|**CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning**|Ruixiang Tang Team|[2508.07871](http://arxiv.org/abs/2508.07871)|null|\n", "2508.07835": "|**2025-08-11**|**Effortless Vision-Language Model Specialization in Histopathology without Annotation**|Katharina Breininger Team|[2508.07835](http://arxiv.org/abs/2508.07835)|null|\n", "2508.07833": "|**2025-08-11**|**MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization**|Alexandros Stergiou Team|[2508.07833](http://arxiv.org/abs/2508.07833)|**[link](https://anaekin.github.io/MIMIC)**|\n", "2508.07819": "|**2025-08-11**|**Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP**|Yueyi Luo Team|[2508.07819](http://arxiv.org/abs/2508.07819)|null|\n", "2508.07814": "|**2025-08-11**|**SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing**|Dzmitry Tsetserukou Team|[2508.07814](http://arxiv.org/abs/2508.07814)|null|\n", "2508.07648": "|**2025-08-11**|**Grasp-HGN: Grasping the Unexpected**|Gunar Schirner Team|[2508.07648](http://arxiv.org/abs/2508.07648)|null|\n", "2508.07642": "|**2025-08-11**|**Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents**|Parisa Kordjamshidi Team|[2508.07642](http://arxiv.org/abs/2508.07642)|null|\n", "2508.07630": "|**2025-08-11**|**InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information**|Vivek Gupta Team|[2508.07630](http://arxiv.org/abs/2508.07630)|null|\n", "2508.07626": "|**2025-08-11**|**AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning**|Yang Liu Team|[2508.07626](http://arxiv.org/abs/2508.07626)|null|\n", "2508.07570": "|**2025-08-11**|**Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models**|Duc Thanh Nguyen Team|[2508.07570](http://arxiv.org/abs/2508.07570)|null|\n", "2508.07501": "|**2025-08-10**|**FormCoach: Lift Smarter, Not Harder**|Lingjie Liu Team|[2508.07501](http://arxiv.org/abs/2508.07501)|null|\n", "2508.07432": "|**2025-08-10**|**Freeze and Reveal: Exposing Modality Bias in Vision-Language Models**|Ponnurangam Kumaraguru Team|[2508.07432](http://arxiv.org/abs/2508.07432)|null|\n", "2508.07406": "|**2025-08-10**|**AgriVLN: Vision-and-Language Navigation for Agricultural Robots**|Xiang Li Team|[2508.07406](http://arxiv.org/abs/2508.07406)|null|\n", "2508.07260": "|**2025-08-10**|**Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM**|Wentao Zhang Team|[2508.07260](http://arxiv.org/abs/2508.07260)|null|\n", "2508.09123": "|**2025-08-12**|**OpenCUA: Open Foundations for Computer-Use Agents**|Tao Yu Team|[2508.09123](http://arxiv.org/abs/2508.09123)|null|\n", "2508.09099": "|**2025-08-12**|**Bridging Formal Language with Chain-of-Thought Reasoning to Geometry Problem Solving**|Tian Ding Team|[2508.09099](http://arxiv.org/abs/2508.09099)|null|\n", "2508.09087": "|**2025-08-12**|**Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision**|Prashnna Gyawali Team|[2508.09087](http://arxiv.org/abs/2508.09087)|null|\n", "2508.09071": "|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Jiale Cao Team|[2508.09071](http://arxiv.org/abs/2508.09071)|**[link](https://linsun449.github.io/GeoVLA/)**|\n", "2508.09061": "|**2025-08-12**|**VLM-3D:End-to-End Vision-Language Models for Open-World 3D Perception**|Lei He Team|[2508.09061](http://arxiv.org/abs/2508.09061)|null|\n", "2508.09057": "|**2025-08-12**|**MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by Multi-App, Vague, Interactive, Single-App and Unethical Instructions**|Jin Xu Team|[2508.09057](http://arxiv.org/abs/2508.09057)|null|\n", "2508.08983": "|**2025-08-12**|**Rational Inverse Reasoning**|Leslie Pack Kaelbling Team|[2508.08983](http://arxiv.org/abs/2508.08983)|null|\n", "2508.08930": "|**2025-08-12**|**How Does a Virtual Agent Decide Where to Look? -- Symbolic Cognitive Reasoning for Embodied Head Rotation**|Hyeongyeop Kang Team|[2508.08930](http://arxiv.org/abs/2508.08930)|null|\n", "2508.08926": "|**2025-08-12**|**Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models**|Xuelong Li Team|[2508.08926](http://arxiv.org/abs/2508.08926)|null|\n", "2508.08821": "|**2025-08-12**|**3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs**|Eddy Ilg Team|[2508.08821](http://arxiv.org/abs/2508.08821)|null|\n", "2508.08701": "|**2025-08-12**|**SafeFix: Targeted Model Repair via Controlled Image Generation**|Yunhui Guo Team|[2508.08701](http://arxiv.org/abs/2508.08701)|null|\n", "2508.08688": "|**2025-08-12**|**STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision**|Marios Savvides Team|[2508.08688](http://arxiv.org/abs/2508.08688)|null|\n", "2508.08644": "|**2025-08-12**|**AME: Aligned Manifold Entropy for Robust Vision-Language Distillation**|Yuming Ou Team|[2508.08644](http://arxiv.org/abs/2508.08644)|null|\n", "2508.08604": "|**2025-08-13**|**Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization**|Hyunwoo J. Kim Team|[2508.08604](http://arxiv.org/abs/2508.08604)|null|\n", "2508.08570": "|**2025-08-12**|**Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation**|Qi Lei Team|[2508.08570](http://arxiv.org/abs/2508.08570)|null|\n", "2508.08521": "|**2025-08-11**|**VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models**|Ravikumar Balakrishnan Team|[2508.08521](http://arxiv.org/abs/2508.08521)|null|\n", "2508.08508": "|**2025-08-11**|**Re:Verse -- Can Your VLM Read a Manga?**|Shruti Vyas Team|[2508.08508](http://arxiv.org/abs/2508.08508)|null|\n", "2508.10771": "|**2025-08-14**|**AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences**|Joey Tianyi Zhou Team|[2508.10771](http://arxiv.org/abs/2508.10771)|null|\n", "2508.10770": "|**2025-08-14**|**From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models**|Wenqi Shao Team|[2508.10770](http://arxiv.org/abs/2508.10770)|null|\n", "2508.10681": "|**2025-08-14**|**IADGPT: Unified LVLM for Few-Shot Industrial Anomaly Detection, Localization, and Reasoning via In-Context Learning**|Bin Li Team|[2508.10681](http://arxiv.org/abs/2508.10681)|null|\n", "2508.10667": "|**2025-08-14**|**AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models**|Jieping Ye Team|[2508.10667](http://arxiv.org/abs/2508.10667)|null|\n", "2508.10645": "|**2025-08-14**|**SemPT: Semantic Prompt Tuning for Vision-Language Models**|Zhenzhong Chen Team|[2508.10645](http://arxiv.org/abs/2508.10645)|null|\n", "2508.10635": "|**2025-08-14**|**ChatENV: An Interactive Vision-Language Model for Sensor-Guided Environmental Monitoring and Scenario Simulation**|Mohsen Guizani Team|[2508.10635](http://arxiv.org/abs/2508.10635)|null|\n", "2508.10556": "|**2025-08-14**|**Retrieval-Augmented Prompt for OOD Detection**|Changqing Zhang Team|[2508.10556](http://arxiv.org/abs/2508.10556)|null|\n", "2508.10444": "|**2025-08-14**|**DiFaR: Enhancing Multimodal Misinformation Detection with Diverse, Factual, and Relevant Rationales**|Zhi Zeng Team|[2508.10444](http://arxiv.org/abs/2508.10444)|null|\n", "2508.10429": "|**2025-08-14**|**MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance**|Yi Zhang Team|[2508.10429](http://arxiv.org/abs/2508.10429)|**[link](https://huggingface.co/datasets/Codatta/MM-Food-100K)**|\n", "2508.10427": "|**2025-08-14**|**STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes**|Yu Yamaguchi Team|[2508.10427](http://arxiv.org/abs/2508.10427)|**[link](https://turingmotors.github.io/stride-qa/)**|\n", "2508.10397": "|**2025-08-14**|**PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection**|Xinghui Song Team|[2508.10397](http://arxiv.org/abs/2508.10397)|null|\n", "2508.10367": "|**2025-08-14**|**Contrast Sensitivity Function of Multimodal Vision-Language Models**|Valero Laparra Team|[2508.10367](http://arxiv.org/abs/2508.10367)|null|\n", "2508.10287": "|**2025-08-14**|**JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics**|Hamid Rezatofighi Team|[2508.10287](http://arxiv.org/abs/2508.10287)|null|\n", "2508.10264": "|**2025-08-14**|**MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs**|Yujun Cai Team|[2508.10264](http://arxiv.org/abs/2508.10264)|null|\n", "2508.10180": "|**2025-08-13**|**Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs**|Xiaoxiao Li Team|[2508.10180](http://arxiv.org/abs/2508.10180)|null|\n", "2508.10171": "|**2025-08-13**|**SynSpill: Improved Industrial Spill Detection With Synthetic Data**|Shruti Vyas Team|[2508.10171](http://arxiv.org/abs/2508.10171)|null|\n", "2508.10113": "|**2025-08-13**|**Interpretable Oracle Bone Script Decipherment through Radical and Pictographic Analysis with LVLMs**|Bin Li Team|[2508.10113](http://arxiv.org/abs/2508.10113)|null|\n", "2508.09981": "|**2025-08-13**|**LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit**|Wenya Wang Team|[2508.09981](http://arxiv.org/abs/2508.09981)|null|\n", "2508.09966": "|**2025-08-13**|**January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis**|Mark Woodward Team|[2508.09966](http://arxiv.org/abs/2508.09966)|null|\n", "2508.09922": "|**2025-08-14**|**Prototype-Guided Diffusion: Visual Conditioning without External Memory**|Mustapha Lebbah Team|[2508.09922](http://arxiv.org/abs/2508.09922)|null|\n", "2508.11538": "|**2025-08-15**|**Reinforcing Video Reasoning Segmentation to Think Before It Segments**|Huchuan Lu Team|[2508.11538](http://arxiv.org/abs/2508.11538)|null|\n", "2508.11479": "|**2025-08-15**|**OVSegDT: Segmenting Transformer for Open-Vocabulary Object Goal Navigation**|Aleksandr Panov Team|[2508.11479](http://arxiv.org/abs/2508.11479)|null|\n", "2508.11428": "|**2025-08-15**|**ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving**|Li Zhang Team|[2508.11428](http://arxiv.org/abs/2508.11428)|null|\n", "2508.11341": "|**2025-08-15**|**Semantically Guided Adversarial Testing of Vision Models Using Language Models**|Jorge M. Cruz-Duarte Team|[2508.11341](http://arxiv.org/abs/2508.11341)|null|\n", "2508.11330": "|**2025-08-15**|**Noise Matters: Optimizing Matching Noise for Diffusion Classifiers**|Long Chen Team|[2508.11330](http://arxiv.org/abs/2508.11330)|null|\n", "2508.11317": "|**2025-08-15**|**Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models**|Tat-Seng Chua Team|[2508.11317](http://arxiv.org/abs/2508.11317)|null|\n", "2508.11262": "|**2025-08-15**|**Vision-Language Models display a strong gender bias**|Sreedath Panat Team|[2508.11262](http://arxiv.org/abs/2508.11262)|null|\n", "2508.11256": "|**2025-08-15**|**Generalized Decoupled Learning for Enhancing Open-Vocabulary Dense Perception**|Zhuotao Tian Team|[2508.11256](http://arxiv.org/abs/2508.11256)|null|\n", "2508.11196": "|**2025-08-15**|**UAV-VL-R1: Generalizing Vision-Language Models via Supervised Fine-Tuning and Multi-Stage GRPO for UAV Visual Reasoning**|Yue Zhang Team|[2508.11196](http://arxiv.org/abs/2508.11196)|null|\n", "2508.11176": "|**2025-08-15**|**Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning**|Bin Luo Team|[2508.11176](http://arxiv.org/abs/2508.11176)|null|\n", "2508.11170": "|**2025-08-15**|**Better Supervised Fine-tuning for VQA: Integer-Only Loss**|Junhui Cui Team|[2508.11170](http://arxiv.org/abs/2508.11170)|null|\n", "2508.11093": "|**2025-08-14**|**Utilizing Vision-Language Models as Action Models for Intent Recognition and Assistance**|Rustam Stolkin Team|[2508.11093](http://arxiv.org/abs/2508.11093)|null|\n", "2508.11011": "|**2025-08-14**|**Are Large Pre-trained Vision Language Models Effective Construction Safety Inspectors?**|Zhengbo Zou Team|[2508.11011](http://arxiv.org/abs/2508.11011)|null|\n", "2508.10972": "|**2025-08-14**|**Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision**|Anhong Guo Team|[2508.10972](http://arxiv.org/abs/2508.10972)|null|\n", "2508.13073": "|**2025-08-18**|**Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey**|Liqiang Nie Team|[2508.13073](http://arxiv.org/abs/2508.13073)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|\n", "2508.13043": "|**2025-08-18**|**IntelliCap: Intelligent Guidance for Consistent View Sampling**|Shohei Mori Team|[2508.13043](http://arxiv.org/abs/2508.13043)|**[link](https://mediated-reality.github.io/projects/yasunaga_ismar25/)**|\n", "2508.12957": "|**2025-08-18**|**Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination**|Lihua Zhang Team|[2508.12957](http://arxiv.org/abs/2508.12957)|null|\n", "2508.12916": "|**2025-08-18**|**RoboRetriever: Single-Camera Robot Object Retrieval via Active and Interactive Perception with Dynamic Scene Graph**|Yunquan Sun Team|[2508.12916](http://arxiv.org/abs/2508.12916)|null|\n", "2508.12877": "|**2025-08-18**|**Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning**|Ruixuan Wang Team|[2508.12877](http://arxiv.org/abs/2508.12877)|null|\n", "2508.12861": "|**2025-08-18**|**Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models**|Ruixuan Wang Team|[2508.12861](http://arxiv.org/abs/2508.12861)|null|\n", "2508.12778": "|**2025-08-18**|**HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks**|Yu Wang Team|[2508.12778](http://arxiv.org/abs/2508.12778)|null|\n", "2508.12711": "|**2025-08-18**|**Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection**|Wei Zhou Team|[2508.12711](http://arxiv.org/abs/2508.12711)|null|\n", "2508.12668": "|**2025-08-18**|**WP-CLIP: Leveraging CLIP to Predict W\u00f6lfflin's Principles in Visual Art**|Feng Liu Team|[2508.12668](http://arxiv.org/abs/2508.12668)|**[link](https://github.com/abhijay9/wpclip)**|\n", "2508.12638": "|**2025-08-18**|**SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer**|Zheng Yang Team|[2508.12638](http://arxiv.org/abs/2508.12638)|null|\n", "2508.12603": "|**2025-08-18**|**ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving**|Ziran Wang Team|[2508.12603](http://arxiv.org/abs/2508.12603)|null|\n", "2508.12587": "|**2025-08-18**|**Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models**|Chris Ngo Team|[2508.12587](http://arxiv.org/abs/2508.12587)|null|\n", "2508.12543": "|**2025-08-18**|**REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language**|Yash Butala Team|[2508.12543](http://arxiv.org/abs/2508.12543)|null|\n", "2508.12512": "|**2025-08-17**|**LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models**|Venkatram Vishwanath Team|[2508.12512](http://arxiv.org/abs/2508.12512)|null|\n", "2508.12473": "|**2025-08-17**|**Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System**|Kasun De Zoysa Team|[2508.12473](http://arxiv.org/abs/2508.12473)|null|\n", "2508.12458": "|**2025-08-17**|**M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following**|Yanfei Qian Team|[2508.12458](http://arxiv.org/abs/2508.12458)|null|\n", "2508.12455": "|**2025-08-17**|**X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning**|Shaoqing Tang Team|[2508.12455](http://arxiv.org/abs/2508.12455)|null|\n", "2508.12404": "|**2025-08-17**|**LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving**|Li Zhang Team|[2508.12404](http://arxiv.org/abs/2508.12404)|null|\n", "2508.12400": "|**2025-08-17**|**MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models**|Xueying Huang Team|[2508.12400](http://arxiv.org/abs/2508.12400)|null|\n", "2508.12399": "|**2025-08-17**|**Federated Cross-Modal Style-Aware Prompt Generation**|Amit Sethi Team|[2508.12399](http://arxiv.org/abs/2508.12399)|null|\n", "2508.13998": "|**2025-08-19**|**Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation**|Jianye Hao Team|[2508.13998](http://arxiv.org/abs/2508.13998)|null|\n", "2508.13744": "|**2025-08-19**|**Mitigating Cross-Image Information Leakage in LVLMs for Multi-Image Tasks**|Junsuk Choe Team|[2508.13744](http://arxiv.org/abs/2508.13744)|**[link](https://github.com/yejipark-m/FOCUS)**|\n", "2508.13739": "|**2025-08-19**|**Enhancing Targeted Adversarial Attacks on Large Vision-Language Models through Intermediate Projector Guidance**|Bin Xiao Team|[2508.13739](http://arxiv.org/abs/2508.13739)|null|\n", "2508.13713": "|**2025-08-19**|**Hierarchical Vision-Language Retrieval of Educational Metaverse Content in Agriculture**|Giuseppe Serra Team|[2508.13713](http://arxiv.org/abs/2508.13713)|null|\n", "2508.13680": "|**2025-08-19**|**ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?**|Daeyoung Kim Team|[2508.13680](http://arxiv.org/abs/2508.13680)|null|\n", "2508.13587": "|**2025-08-19**|**Breaking the SFT Plateau: Multimodal Structured Reinforcement Learning for Chart-to-Code Generation**|Lin Ma Team|[2508.13587](http://arxiv.org/abs/2508.13587)|null|\n", "2508.13560": "|**2025-08-21**|**DictAS: A Framework for Class-Generalizable Few-Shot Anomaly Segmentation via Dictionary Lookup**|Guiguang Ding Team|[2508.13560](http://arxiv.org/abs/2508.13560)|**[link](https://github.com/xiaozhen228/DictAS)**|\n", "2508.13524": "|**2025-08-19**|**Evaluating Open-Source Vision Language Models for Facial Emotion Recognition against Traditional Deep Learning Models**|Sridevi Bonthu Team|[2508.13524](http://arxiv.org/abs/2508.13524)|null|\n", "2508.13470": "|**2025-08-19**|**STER-VLM: Spatio-Temporal With Enhanced Reference Vision-Language Models**|Tien-Huy Nguyen Team|[2508.13470](http://arxiv.org/abs/2508.13470)|null|\n", "2508.13446": "|**2025-08-19**|**CAST: Counterfactual Labels Improve Instruction Following in Vision-Language-Action Models**|Sergey Levine Team|[2508.13446](http://arxiv.org/abs/2508.13446)|null|\n", "2508.13439": "|**2025-08-19**|**Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference**|Jidong J. Yang Team|[2508.13439](http://arxiv.org/abs/2508.13439)|null|\n", "2508.13428": "|**2025-08-19**|**Mitigating Easy Option Bias in Multiple-Choice Question Answering**|Basura Fernando Team|[2508.13428](http://arxiv.org/abs/2508.13428)|null|\n", "2508.13305": "|**2025-08-18**|**Prune2Drive: A Plug-and-Play Framework for Accelerating Vision-Language Models in Autonomous Driving**|Linfeng Zhang Team|[2508.13305](http://arxiv.org/abs/2508.13305)|null|\n", "2508.13256": "|**2025-08-18**|**CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support**|Jinming Duan Team|[2508.13256](http://arxiv.org/abs/2508.13256)|null|\n", "2508.14537": "|**2025-08-20**|**WISE-FUSE: Efficient Whole Slide Image Encoding via Coarse-to-Fine Patch Selection with VLM and LLM Knowledge Fusion**|Won-Ki Jeong Team|[2508.14537](http://arxiv.org/abs/2508.14537)|null|\n", "2508.14280": "|**2025-08-19**|**Multi-Rationale Explainable Object Recognition via Contrastive Conditional Inference**|Simon Gottschalk Team|[2508.14280](http://arxiv.org/abs/2508.14280)|null|\n", "2508.14197": "|**2025-08-19**|**CLIPSym: Delving into Symmetry Detection with CLIP**|Raymond A. Yeh Team|[2508.14197](http://arxiv.org/abs/2508.14197)|null|\n", "2508.14153": "|**2025-08-19**|**LENS: Learning to Segment Anything with Unified Reinforced Reasoning**|Xinggang Wang Team|[2508.14153](http://arxiv.org/abs/2508.14153)|**[link](https://github.com/hustvl/LENS)**|\n", "2508.15688": "|**2025-08-21**|**LLM-empowered Dynamic Prompt Routing for Vision-Language Models Tuning under Long-Tailed Distributions**|Yulong Bian Team|[2508.15688](http://arxiv.org/abs/2508.15688)|null|\n", "2508.15663": "|**2025-08-21**|**Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation**|Alexey K. Kovalev Team|[2508.15663](http://arxiv.org/abs/2508.15663)|null|\n", "2508.15297": "|**2025-08-21**|**DesignCLIP: Multimodal Learning with CLIP for Design Patent Understanding**|Sourav Medya Team|[2508.15297](http://arxiv.org/abs/2508.15297)|null|\n", "2508.15256": "|**2025-08-21**|**Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images**|Jin Tae Kwak Team|[2508.15256](http://arxiv.org/abs/2508.15256)|null|\n", "2508.15236": "|**2025-08-21**|**Pathology-Informed Latent Diffusion Model for Anomaly Detection in Lymph Node Metastasis**|Jin Tae Kwak Team|[2508.15236](http://arxiv.org/abs/2508.15236)|null|\n", "2508.15222": "|**2025-08-21**|**See it. Say it. Sorted: Agentic System for Compositional Diagram Generation**|Ed Li Team|[2508.15222](http://arxiv.org/abs/2508.15222)|null|\n", "2508.15164": "|**2025-08-21**|**ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following**|Taeyang Yoon Team|[2508.15164](http://arxiv.org/abs/2508.15164)|null|\n", "2508.15036": "|**2025-08-20**|**MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs**|Yunsi Fei Team|[2508.15036](http://arxiv.org/abs/2508.15036)|null|\n", "2508.16463": "|**2025-08-22**|**Modular Embedding Recomposition for Incremental Learning**|Simone Calderara Team|[2508.16463](http://arxiv.org/abs/2508.16463)|null|\n", "2508.16271": "|**2025-08-22**|**Structuring GUI Elements through Vision Language Models: Towards Action Space Generation**|Jingdong Chen Team|[2508.16271](http://arxiv.org/abs/2508.16271)|null|\n", "2508.16158": "|**2025-08-22**|**RAGSR: Regional Attention Guided Diffusion for Image Super-Resolution**|Gui-Song Xia Team|[2508.16158](http://arxiv.org/abs/2508.16158)|null|\n", "2508.16157": "|**2025-08-22**|**Beyond Human-prompting: Adaptive Prompt Tuning with Semantic Alignment for Anomaly Detection**|Chao-Chun Chen Team|[2508.16157](http://arxiv.org/abs/2508.16157)|null|\n", "2508.16076": "|**2025-08-22**|**Prompting with Sign Parameters for Low-resource Sign Language Instruction Generation**|Hasan Mahmud Team|[2508.16076](http://arxiv.org/abs/2508.16076)|null|\n", "2508.16070": "|**2025-08-22**|**Less Redundancy: Boosting Practicality of Vision Language Model in Walking Assistants**|Jinchao Zhang Team|[2508.16070](http://arxiv.org/abs/2508.16070)|null|\n", "2508.15960": "|**2025-08-21**|**Glo-VLMs: Leveraging Vision-Language Models for Fine-Grained Diseased Glomerulus Classification**|Ruining Deng Team|[2508.15960](http://arxiv.org/abs/2508.15960)|null|\n", "2508.15930": "|**2025-08-21**|**Semantic-Aware Ship Detection with Vision-Language Integration**|Xiaomeng Huang Team|[2508.15930](http://arxiv.org/abs/2508.15930)|null|\n", "2508.15903": "|**2025-08-21**|**VT-LVLM-AR: A Video-Temporal Large Vision-Language Model Adapter for Fine-Grained Action Recognition in Long-Term Videos**|Zihan Xu Team|[2508.15903](http://arxiv.org/abs/2508.15903)|null|\n", "2508.18268": "|**2025-08-25**|**SafeBimanual: Diffusion-based Trajectory Optimization for Safe Bimanual Manipulation**|Ziwei Wang Team|[2508.18268](http://arxiv.org/abs/2508.18268)|**[link](https://denghaoyuan123.github.io/SafeBimanip/)**|\n", "2508.18264": "|**2025-08-25**|**MMTok: Multimodal Coverage Maximization for Efficient Inference of VLMs**|Qi Qian Team|[2508.18264](http://arxiv.org/abs/2508.18264)|**[link](https://project.ironieser.cc/mmtok)**|\n", "2508.18179": "|**2025-08-25**|**SEAM: Semantically Equivalent Across Modalities Benchmark for Vision-Language Models**|Ashton Anderson Team|[2508.18179](http://arxiv.org/abs/2508.18179)|null|\n", "2508.18177": "|**2025-08-25**|**Scene-Aware Vectorized Memory Multi-Agent Framework with Cross-Modal Differentiated Quantization VLMs for Visually Impaired Assistance**|Liyong Ren Team|[2508.18177](http://arxiv.org/abs/2508.18177)|null|\n", "2508.18050": "|**2025-08-25**|**ArgusCogito: Chain-of-Thought for Cross-Modal Synergy and Omnidirectional Reasoning in Camouflaged Object Segmentation**|Ye Li Team|[2508.18050](http://arxiv.org/abs/2508.18050)|null|\n", "2508.18040": "|**2025-08-25**|**PerPilot: Personalizing VLM-based Mobile Agents via Memory and Exploration**|Zhen Wang Team|[2508.18040](http://arxiv.org/abs/2508.18040)|null|\n", "2508.17846": "|**2025-08-25**|**Alternating Training-based Label Smoothing Enhances Prompt Generalization**|Yu Zhang Team|[2508.17846](http://arxiv.org/abs/2508.17846)|null|\n", "2508.17807": "|**2025-08-25**|**PoRe: Position-Reweighted Visual Token Pruning for Vision Language Models**|Dan Zeng Team|[2508.17807](http://arxiv.org/abs/2508.17807)|null|\n", "2508.17714": "|**2025-08-25**|**F2RVLM: Boosting Fine-grained Fragment Retrieval for Multi-Modal Long-form Dialogue with Vision Language Model**|Jinchao Zhang Team|[2508.17714](http://arxiv.org/abs/2508.17714)|null|\n", "2508.17686": "|**2025-08-25**|**Language-Guided Temporal Token Pruning for Efficient VideoLLM Processing**|Yogesh Kumar Team|[2508.17686](http://arxiv.org/abs/2508.17686)|null|\n", "2508.17667": "|**2025-08-25**|**Hierarchical Vision-Language Learning for Medical Out-of-Distribution Detection**|Ruixuan Wang Team|[2508.17667](http://arxiv.org/abs/2508.17667)|null|\n", "2508.17638": "|**2025-08-25**|**Dynamic Embedding of Hierarchical Visual Features for Efficient Vision-Language Fine-Tuning**|Chunping Qiu Team|[2508.17638](http://arxiv.org/abs/2508.17638)|null|\n", "2508.17595": "|**2025-08-25**|**TinyGiantVLM: A Lightweight Vision-Language Architecture for Spatial Reasoning under Resource Constraints**|Xuan-Huong Nguyen Team|[2508.17595](http://arxiv.org/abs/2508.17595)|null|\n", "2508.17568": "|**2025-08-25**|**MetaGen: A DSL, Database, and Benchmark for VLM-Assisted Metamaterial Generation**|Wojciech Matusik Team|[2508.17568](http://arxiv.org/abs/2508.17568)|null|\n", "2508.17467": "|**2025-08-24**|**MoE-Inference-Bench: Performance Evaluation of Mixture of Expert Large Language and Vision Models**|Venkatram Vishwanath Team|[2508.17467](http://arxiv.org/abs/2508.17467)|null|\n", "2508.17442": "|**2025-08-24**|**Multi-Level LVLM Guidance for Untrimmed Video Action Recognition**|Yunjie Guo Team|[2508.17442](http://arxiv.org/abs/2508.17442)|null|\n", "2508.17417": "|**2025-08-24**|**Constrained Prompt Enhancement for Improving Zero-Shot Generalization of Vision-Language Models**|Qinghua Hu Team|[2508.17417](http://arxiv.org/abs/2508.17417)|null|\n", "2508.17394": "|**2025-08-24**|**Lightweight Joint Optimization of General-Purpose Vision-Language Models and Retrievers for Medical Diagnosis**|Tom Hope Team|[2508.17394](http://arxiv.org/abs/2508.17394)|null|\n", "2508.17334": "|**2025-08-26**|**Mind the (Language) Gap: Towards Probing Numerical and Cross-Lingual Limits of LVLMs**|Gaurav Harit Team|[2508.17334](http://arxiv.org/abs/2508.17334)|null|\n", "2508.17298": "|**2025-08-24**|**Explain Before You Answer: A Survey on Compositional Visual Reasoning**|Hamid Rezatofighi Team|[2508.17298](http://arxiv.org/abs/2508.17298)|null|\n", "2508.19111": "|**2025-08-26**|**Do LVLMs Know What They Know? A Systematic Study of Knowledge Boundary Perception in LVLMs**|Keping Bi Team|[2508.19111](http://arxiv.org/abs/2508.19111)|null|\n", "2508.19024": "|**2025-08-26**|**ProPy: Building Interactive Prompt Pyramids upon CLIP for Partially Relevant Video Retrieval**|Xiaoguang Zhao Team|[2508.19024](http://arxiv.org/abs/2508.19024)|null|\n", "2508.18989": "|**2025-08-26**|**Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone**|Amit Sheth Team|[2508.18989](http://arxiv.org/abs/2508.18989)|null|\n", "2508.18984": "|**2025-08-28**|**Enhancing Document VQA Models via Retrieval-Augmented Generation**|Ernest Valveny Team|[2508.18984](http://arxiv.org/abs/2508.18984)|null|\n", "2508.18886": "|**2025-08-26**|**Toward Robust Medical Fairness: Debiased Dual-Modal Alignment via Text-Guided Attribute-Disentangled Prompt Learning for Vision-Language Models**|Yong Xia Team|[2508.18886](http://arxiv.org/abs/2508.18886)|null|\n", "2508.18805": "|**2025-08-26**|**Hidden Tail: Adversarial Image Causing Stealthy Resource Consumption in Vision-Language Models**|Guowen Xu Team|[2508.18805](http://arxiv.org/abs/2508.18805)|null|\n", "2508.18753": "|**2025-08-26**|**Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods**|Robby T. Tan Team|[2508.18753](http://arxiv.org/abs/2508.18753)|null|\n", "2508.18687": "|**2025-08-26**|**Knowing or Guessing? Robust Medical Visual Question Answering via Joint Consistency and Contrastive Learning**|Zuozhu Liu Team|[2508.18687](http://arxiv.org/abs/2508.18687)|null|\n", "2508.18649": "|**2025-08-26**|**PRISM: Robust VLM Alignment with Principled Reasoning for Integrated Safety in Multimodality**|Chaowei Xiao Team|[2508.18649](http://arxiv.org/abs/2508.18649)|null|\n", "2508.18430": "|**2025-08-25**|**CLARIFY: A Specialist-Generalist Framework for Accurate and Lightweight Dermatological Visual Question Answering**|Mohammad Ariful Haque Team|[2508.18430](http://arxiv.org/abs/2508.18430)|null|\n", "2508.18381": "|**2025-08-25**|**Language-Specific Layer Matters: Efficient Multilingual Enhancement for Large Vision-Language Models**|Jingbo Zhu Team|[2508.18381](http://arxiv.org/abs/2508.18381)|null|\n", "2508.20029": "|**2025-08-27**|**Segmentation Assisted Incremental Test Time Adaptation in an Open World**|Soma Biswas Team|[2508.20029](http://arxiv.org/abs/2508.20029)|null|\n", "2508.20018": "|**2025-08-27**|**SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control**|Ping Luo Team|[2508.20018](http://arxiv.org/abs/2508.20018)|null|\n", "2508.19972": "|**2025-08-27**|**GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity**|Yixuan Li Team|[2508.19972](http://arxiv.org/abs/2508.19972)|null|\n", "2508.19967": "|**2025-08-27**|**Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models**|Shoaib Ehsan Team|[2508.19967](http://arxiv.org/abs/2508.19967)|null|\n", "2508.19944": "|**2025-08-27**|**KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts**|Hyunjun Eun Team|[2508.19944](http://arxiv.org/abs/2508.19944)|null|\n", "2508.19724": "|**2025-08-28**|**NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks**|Somak Aditya Team|[2508.19724](http://arxiv.org/abs/2508.19724)|null|\n", "2508.19679": "|**2025-08-27**|**InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning**|Bo Zheng Team|[2508.19679](http://arxiv.org/abs/2508.19679)|null|\n", "2508.19652": "|**2025-08-27**|**Self-Rewarding Vision-Language Model via Reasoning Decomposition**|Dong Yu Team|[2508.19652](http://arxiv.org/abs/2508.19652)|null|\n", "2508.19639": "|**2025-08-27**|**FakeSV-VLM: Taming VLM for Detecting Fake Short-Video News via Progressive Mixture-Of-Experts Adapter**|Zhun Zhong Team|[2508.19639](http://arxiv.org/abs/2508.19639)|null|\n", "2508.19391": "|**2025-08-26**|**LaVA-Man: Learning Visual Action Representations for Robot Manipulation**|Changjae Oh Team|[2508.19391](http://arxiv.org/abs/2508.19391)|null|\n", "2508.19376": "|**2025-08-26**|**Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments**|Pierre Baldi Team|[2508.19376](http://arxiv.org/abs/2508.19376)|null|\n", "2508.19322": "|**2025-08-26**|**AT-CXR: Uncertainty-Aware Agentic Triage for Chest X-rays**|Yiyu Shi Team|[2508.19322](http://arxiv.org/abs/2508.19322)|null|\n", "2508.21066": "|**2025-08-28**|**OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning**|Xinglong Wu Team|[2508.21066](http://arxiv.org/abs/2508.21066)|**[link](https://one-reward.github.io)**|\n", "2508.21046": "|**2025-08-28**|**CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification**|Liqiang Nie Team|[2508.21046](http://arxiv.org/abs/2508.21046)|**[link](https://jiutian-vl.github.io/CogVLA-page)**|\n", "2508.20840": "|**2025-08-28**|**Learning Primitive Embodied World Models: Towards Scalable Robotic Learning**|Qinying Gu Team|[2508.20840](http://arxiv.org/abs/2508.20840)|null|\n", "2508.20830": "|**2025-08-28**|**Estimating 2D Keypoints of Surgical Tools Using Vision-Language Models with Low-Rank Adaptation**|Binod Bhattarai Team|[2508.20830](http://arxiv.org/abs/2508.20830)|null|\n", "2508.20783": "|**2025-08-28**|**Evaluating Compositional Generalisation in VLMs and Diffusion Models**|Martha Lewis Team|[2508.20783](http://arxiv.org/abs/2508.20783)|null|\n", "2508.20760": "|**2025-09-02**|**Occlusion Robustness of CLIP for Military Vehicle Classification**|Hugo J. Kuijf Team|[2508.20760](http://arxiv.org/abs/2508.20760)|null|\n", "2508.20670": "|**2025-08-28**|**\"Humor, Art, or Misinformation?\": A Multimodal Dataset for Intent-Aware Synthetic Image Detection**|Panagiotis C. Petrantonakis Team|[2508.20670](http://arxiv.org/abs/2508.20670)|null|\n", "2508.20570": "|**2025-08-28**|**Towards Mechanistic Defenses Against Typographic Attacks in CLIP**|Wojciech Samek Team|[2508.20570](http://arxiv.org/abs/2508.20570)|null|\n", "2508.20549": "|**2025-08-28**|**MedGR$^2$: Breaking the Data Barrier for Medical Reasoning via Generative Reward Learning**|Shangyang Li Team|[2508.20549](http://arxiv.org/abs/2508.20549)|null|\n", "2508.20345": "|**2025-08-28**|**MedFoundationHub: A Lightweight and Secure Toolkit for Deploying Medical Vision Language Foundation Models**|Yuankai Huo Team|[2508.20345](http://arxiv.org/abs/2508.20345)|null|\n", "2508.20325": "|**2025-08-28**|**GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs**|Haohan Wang Team|[2508.20325](http://arxiv.org/abs/2508.20325)|null|\n", "2508.20227": "|**2025-08-27**|**A Novel Framework for Automated Explain Vision Model Using Vision-Language Models**|Truong Son Hy Team|[2508.20227](http://arxiv.org/abs/2508.20227)|null|\n", "2508.21809": "|**2025-08-29**|**VoCap: Video Object Captioning and Segmentation from Any Prompt**|Cordelia Schmid Team|[2508.21809](http://arxiv.org/abs/2508.21809)|null|\n", "2508.21732": "|**2025-08-29**|**CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models**|Rodrigo Ventura Team|[2508.21732](http://arxiv.org/abs/2508.21732)|null|\n", "2508.21565": "|**2025-08-29**|**How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images**|Yoonjin Yoon Team|[2508.21565](http://arxiv.org/abs/2508.21565)|null|\n", "2508.21539": "|**2025-08-29**|**HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones**|Shaozi Li Team|[2508.21539](http://arxiv.org/abs/2508.21539)|null|\n", "2509.03025": "|**2025-09-05**|**Unveiling the Response of Large Vision-Language Models to Visually Absent Tokens**|Eunho Yang Team|[2509.03025](http://arxiv.org/abs/2509.03025)|null|\n", "2509.02966": "|**2025-09-03**|**KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models**|Hong Chen Team|[2509.02966](http://arxiv.org/abs/2509.02966)|null|\n", "2509.02864": "|**2025-09-02**|**A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation**|Pedro J. Moreno Team|[2509.02864](http://arxiv.org/abs/2509.02864)|null|\n", "2509.02805": "|**2025-09-02**|**Challenges in Understanding Modality Conflict in Vision-Language Models**|David Jensen Team|[2509.02805](http://arxiv.org/abs/2509.02805)|null|\n", "2509.02659": "|**2025-09-02**|**2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model**|Yi Yang Team|[2509.02659](http://arxiv.org/abs/2509.02659)|null|\n", "2509.02324": "|**2025-09-02**|**Language-Guided Long Horizon Manipulation with LLM-based Planning and Visual Perception**|Bin He Team|[2509.02324](http://arxiv.org/abs/2509.02324)|null|\n", "2509.02273": "|**2025-09-02**|**RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing**|Yao Zhu Team|[2509.02273](http://arxiv.org/abs/2509.02273)|null|\n", "2509.02100": "|**2025-09-02**|**E-THER: A PCT-Grounded Dataset for Benchmarking Empathic AI**|Syed Afaq Ali Shah Team|[2509.02100](http://arxiv.org/abs/2509.02100)|null|\n", "2509.01959": "|**2025-09-02**|**Structure-aware Contrastive Learning for Diagram Understanding of Multimodal Models**|Hiroshi Sasaki Team|[2509.01959](http://arxiv.org/abs/2509.01959)|null|\n", "2509.01907": "|**2025-09-02**|**RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events**|Feng Zhang Team|[2509.01907](http://arxiv.org/abs/2509.01907)|null|\n", "2509.01895": "|**2025-09-02**|**Automated Wildfire Damage Assessment from Multi view Ground level Imagery Via Vision Language Models**|Yiming Xiao Team|[2509.01895](http://arxiv.org/abs/2509.01895)|null|\n", "2509.01658": "|**2025-09-01**|**MoTo: A Zero-shot Plug-in Interaction-aware Navigation for General Mobile Manipulation**|Haibin Yan Team|[2509.01658](http://arxiv.org/abs/2509.01658)|**[link](https://gary3410.github.io/MoTo/)**|\n", "2509.01554": "|**2025-09-01**|**Unified Supervision For Vision-Language Modeling in 3D Computed Tomography**|Xueyan Mei Team|[2509.01554](http://arxiv.org/abs/2509.01554)|null|\n", "2509.01552": "|**2025-09-01**|**Variation-aware Vision Token Dropping for Faster Large Vision-Language Models**|Honggang Chen Team|[2509.01552](http://arxiv.org/abs/2509.01552)|**[link](https://github.com/xuyang-liu16/V2Drop})**|\n", "2509.01350": "|**2025-09-01**|**Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models**|Zhiming Tan Team|[2509.01350](http://arxiv.org/abs/2509.01350)|null|\n", "2509.01275": "|**2025-09-03**|**Novel Category Discovery with X-Agent Attention for Open-Vocabulary Semantic Segmentation**|Yanyun Qu Team|[2509.01275](http://arxiv.org/abs/2509.01275)|null|\n", "2509.01259": "|**2025-09-01**|**ReCap: Event-Aware Image Captioning with Article Retrieval and Semantic Gaussian Normalization**|Trung-Nghia Le Team|[2509.01259](http://arxiv.org/abs/2509.01259)|null|\n", "2509.01215": "|**2025-09-01**|**POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion**|Jie Zhou Team|[2509.01215](http://arxiv.org/abs/2509.01215)|null|\n", "2509.01209": "|**2025-09-01**|**Measuring Image-Relation Alignment: Reference-Free Evaluation of VLMs and Synthetic Pre-training for Open-Vocabulary Scene Graph Generation**|Akihiro Sugimoto Team|[2509.01209](http://arxiv.org/abs/2509.01209)|null|\n", "2509.02615": "|**2025-08-31**|**Radio Astronomy in the Era of Vision-Language Models: Prompt Sensitivity and Adaptation**|Slava Voloshynovskiy Team|[2509.02615](http://arxiv.org/abs/2509.02615)|null|\n", "2509.04448": "|**2025-09-04**|**TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection**|Mong Li Lee Team|[2509.04448](http://arxiv.org/abs/2509.04448)|**[link](https://yanzehong.github.io/trust-vl/)**|\n", "2509.04334": "|**2025-09-05**|**GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization**|Yixuan Li Team|[2509.04334](http://arxiv.org/abs/2509.04334)|null|\n", "2509.04243": "|**2025-09-04**|**Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding**|Juntao Li Team|[2509.04243](http://arxiv.org/abs/2509.04243)|null|\n", "2509.04214": "|**2025-09-04**|**An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline**|Nathaniel D. Bastian Team|[2509.04214](http://arxiv.org/abs/2509.04214)|null|\n", "2509.04162": "|**2025-09-04**|**Real Time FPGA Based Transformers & VLMs for Vision Tasks: SOTA Designs and Optimizations**|Ashiyana Abdul Majeed Team|[2509.04162](http://arxiv.org/abs/2509.04162)|null|\n", "2509.03961": "|**2025-09-04**|**Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection**|C. L. Philip Chen Team|[2509.03961](http://arxiv.org/abs/2509.03961)|null|\n", "2509.03895": "|**2025-09-04**|**Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of Vision-Language Model**|Hyunseung Choo Team|[2509.03895](http://arxiv.org/abs/2509.03895)|null|\n", "2509.03893": "|**2025-09-04**|**Weakly-Supervised Learning of Dense Functional Correspondences**|Jiajun Wu Team|[2509.03893](http://arxiv.org/abs/2509.03893)|**[link](https://dense-functional-correspondence.github.io/)**|\n", "2509.03863": "|**2025-09-04**|**Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata**|C\u00e9dric Colas Team|[2509.03863](http://arxiv.org/abs/2509.03863)|null|\n", "2509.03805": "|**2025-09-04**|**Measuring How (Not Just Whether) VLMs Build Common Ground**|Malihe Alikhani Team|[2509.03805](http://arxiv.org/abs/2509.03805)|null|\n", "2509.03803": "|**2025-09-04**|**Causality-guided Prompt Learning for Vision-language Models via Visual Granulation**|Qiulei Dong Team|[2509.03803](http://arxiv.org/abs/2509.03803)|null|\n", "2509.03800": "|**2025-09-04**|**MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting**|Xiaofeng Yang Team|[2509.03800](http://arxiv.org/abs/2509.03800)|null|\n", "2509.03740": "|**2025-09-03**|**Singular Value Few-shot Adaptation of Vision-Language Models**|Yiming Xiao Team|[2509.03740](http://arxiv.org/abs/2509.03740)|null|\n", "2509.03615": "|**2025-09-03**|**E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition**|Anupam Purwar Team|[2509.03615](http://arxiv.org/abs/2509.03615)|null|\n", "2509.05154": "|**2025-09-05**|**VLSM-Ensemble: Ensembling CLIP-based Vision-Language Models for Enhanced Medical Image Segmentation**|Noel E. O'Connor Team|[2509.05154](http://arxiv.org/abs/2509.05154)|null|\n", "2509.05112": "|**2025-09-05**|**GenAI-based test case generation and execution in SDV platform**|Alois Knoll Team|[2509.05112](http://arxiv.org/abs/2509.05112)|null|\n", "2509.05080": "|**2025-09-05**|**MM-DREX: Multimodal-Driven Dynamic Routing of LLM Experts for Financial Trading**|Fei Wu Team|[2509.05080](http://arxiv.org/abs/2509.05080)|null|\n", "2509.05000": "|**2025-09-05**|**Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework**|Guangmang Cui Team|[2509.05000](http://arxiv.org/abs/2509.05000)|null|\n", "2509.04894": "|**2025-09-05**|**SynGen-Vision: Synthetic Data Generation for training industrial vision models**|Nitish Bhardwaj Team|[2509.04894](http://arxiv.org/abs/2509.04894)|null|\n", "2509.04834": "|**2025-09-05**|**TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting Scramjet Combustion Evolution**|Guihua Shan Team|[2509.04834](http://arxiv.org/abs/2509.04834)|null|\n", "2509.04772": "|**2025-09-05**|**FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph**|John E. Taylor Team|[2509.04772](http://arxiv.org/abs/2509.04772)|null|\n", "2509.04758": "|**2025-09-05**|**Dynamic Group Detection using VLM-augmented Temporal Groupness Graph**|Norimichi Ukita Team|[2509.04758](http://arxiv.org/abs/2509.04758)|null|\n", "2509.04687": "|**2025-09-04**|**Guideline-Consistent Segmentation via Multi-Agent Refinement**|James Davis Team|[2509.04687](http://arxiv.org/abs/2509.04687)|null|\n", "2509.06932": "|**2025-09-10**|**LLaDA-VLA: Vision Language Diffusion Action Models**|Xiaoyan Sun Team|[2509.06932](http://arxiv.org/abs/2509.06932)|null|\n", "2509.06771": "|**2025-09-08**|**D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning**|Nagendra Kumar Team|[2509.06771](http://arxiv.org/abs/2509.06771)|null|\n", "2509.06768": "|**2025-09-08**|**Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots**|Aliasghar Arab Team|[2509.06768](http://arxiv.org/abs/2509.06768)|null|\n", "2509.06759": "|**2025-09-08**|**Aligning Large Vision-Language Models by Deep Reinforcement Learning and Direct Preference Optimization**|Janis Dalins Team|[2509.06759](http://arxiv.org/abs/2509.06759)|null|\n", "2509.06461": "|**2025-09-08**|**Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning**|Xueqi Cheng Team|[2509.06461](http://arxiv.org/abs/2509.06461)|null|\n", "2509.06427": "|**2025-09-08**|**When Language Model Guides Vision: Grounding DINO for Cattle Muzzle Detection**|Muhammad Ashad Kabir Team|[2509.06427](http://arxiv.org/abs/2509.06427)|null|\n", "2509.06415": "|**2025-09-08**|**Index-Preserving Lightweight Token Pruning for Efficient Document Understanding in Vision-Language Models**|Inyong Yun Team|[2509.06415](http://arxiv.org/abs/2509.06415)|null|\n", "2509.06409": "|**2025-09-08**|**Teaching AI Stepwise Diagnostic Reasoning with Report-Guided Chain-of-Thought Learning**|Dong Liang Team|[2509.06409](http://arxiv.org/abs/2509.06409)|null|\n", "2509.06336": "|**2025-09-08**|**Multi View Slot Attention Using Paraphrased Texts For Face Anti-Spoofing**|Ha Young Kim Team|[2509.06336](http://arxiv.org/abs/2509.06336)|null|\n", "2509.06266": "|**2025-09-08**|**Spatial Reasoning with Vision-Language Models in Ego-Centric Multi-View Scenes**|Mohammad Akbari Team|[2509.06266](http://arxiv.org/abs/2509.06266)|null|\n", "2509.06105": "|**2025-09-07**|**PathoHR: Hierarchical Reasoning for Vision-Language Models in Pathology**|Hujun Yin Team|[2509.06105](http://arxiv.org/abs/2509.06105)|null|\n", "2509.06033": "|**2025-09-07**|**Analysis of Blood Report Images Using General Purpose Vision-Language Models**|Hamid Beigy Team|[2509.06033](http://arxiv.org/abs/2509.06033)|null|\n", "2509.06031": "|**2025-09-07**|**ZLATTE: A Geometry-Aware, Learning-Free Framework for Language-Driven Trajectory Reshaping in Human-Robot Interaction**|Luis Figueredo Team|[2509.06031](http://arxiv.org/abs/2509.06031)|null|\n", "2509.05978": "|**2025-09-07**|**Imagining Alternatives: Towards High-Resolution 3D Counterfactual Medical Image Generation via Language Guidance**|Tal Arbel Team|[2509.05978](http://arxiv.org/abs/2509.05978)|null|\n", "2509.05838": "|**2025-09-06**|**Towards an Automated Framework to Audit Youth Safety on TikTok**|Francesco Pierri Team|[2509.05838](http://arxiv.org/abs/2509.05838)|null|\n", "2509.05718": "|**2025-09-06**|**Do Vision-Language Models See Visualizations Like Humans? Alignment in Chart Categorization**|Torsten M\u00f6ller Team|[2509.05718](http://arxiv.org/abs/2509.05718)|null|\n", "2509.05703": "|**2025-09-06**|**Knowledge-Augmented Vision Language Models for Underwater Bioacoustic Spectrogram Analysis**|Kazuhiro Nakadai Team|[2509.05703](http://arxiv.org/abs/2509.05703)|null|\n", "2509.07966": "|**2025-09-09**|**Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images**|Marc Haraoui Team|[2509.07966](http://arxiv.org/abs/2509.07966)|null|\n", "2509.07613": "|**2025-09-09**|**Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease**|Xiaochen Yang Team|[2509.07613](http://arxiv.org/abs/2509.07613)|null|\n", "2509.07488": "|**2025-09-09**|**Fine-Tuning Vision-Language Models for Visual Navigation Assistance**|Xi Wang Team|[2509.07488](http://arxiv.org/abs/2509.07488)|null|\n", "2509.07463": "|**2025-09-09**|**DepthVision: Robust Vision-Language Understanding through GAN-Based LiDAR-to-RGB Synthesis**|Alois C. Knoll Team|[2509.07463](http://arxiv.org/abs/2509.07463)|null|\n", "2509.07334": "|**2025-09-09**|**SpecifyUI: Supporting Iterative UI Design Intent Expression through Structured Specifications and Generative AI**|Liuqing Chen Team|[2509.07334](http://arxiv.org/abs/2509.07334)|null|\n", "2509.08826": "|**2025-09-10**|**RewardDance: Reward Scaling in Visual Generation**|Weilin Huang Team|[2509.08826](http://arxiv.org/abs/2509.08826)|null|\n", "2509.08820": "|**2025-09-10**|**RoboChemist: Long-Horizon and Safety-Compliant Robotic Chemical Experimentation**|Hao Zhao Team|[2509.08820](http://arxiv.org/abs/2509.08820)|**[link](https://zzongzheng0918.github.io/RoboChemist.github.io/)**|\n", "2509.08757": "|**2025-09-10**|**SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation**|Peter Stone Team|[2509.08757](http://arxiv.org/abs/2509.08757)|**[link](https://larg.github.io/socialnav-sub)**|\n", "2509.08500": "|**2025-09-10**|**TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making**|Xiu Li Team|[2509.08500](http://arxiv.org/abs/2509.08500)|null|\n", "2509.08490": "|**2025-09-10**|**A Structured Review of Underwater Object Detection Challenges and Solutions: From Traditional to Large Vision Language Models**|Zhou Ni Team|[2509.08490](http://arxiv.org/abs/2509.08490)|null|\n", "2509.08461": "|**2025-09-11**|**Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics**|Pierre Baldi Team|[2509.08461](http://arxiv.org/abs/2509.08461)|null|\n", "2509.08338": "|**2025-09-10**|**Retrieval-Augmented VLMs for Multimodal Melanoma Diagnosis**|Charmgil Hong Team|[2509.08338](http://arxiv.org/abs/2509.08338)|null|\n", "2509.08270": "|**2025-09-10**|**Interpretable Physics Reasoning and Performance Taxonomy in Vision-Language Models**|Monali Deshmukh Team|[2509.08270](http://arxiv.org/abs/2509.08270)|null|\n", "2509.08266": "|**2025-09-10**|**Examining Vision Language Models through Multi-dimensional Experiments with Vision and Text Features**|Donald E. Brown Team|[2509.08266](http://arxiv.org/abs/2509.08266)|null|\n", "2509.08216": "|**2025-09-10**|**Vector embedding of multi-modal texts: a tool for discovery?**|Sachith Withana Team|[2509.08216](http://arxiv.org/abs/2509.08216)|null|\n", "2509.08142": "|**2025-09-09**|**Privacy Preserving Semantic Communications Using Vision Language Models: A Segmentation and Generation Approach**|Qianqian Zhang Team|[2509.08142](http://arxiv.org/abs/2509.08142)|null|\n", "2509.09680": "|**2025-09-11**|**FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark**|Hongsheng Li Team|[2509.09680](http://arxiv.org/abs/2509.09680)|**[link](https://flux-reason-6m.github.io/)**|\n", "2509.09541": "|**2025-09-11**|**Compositional Concept Generalization with Variational Quantum Circuits**|Mehrnoosh sadrzadeh Team|[2509.09541](http://arxiv.org/abs/2509.09541)|null|\n", "2509.09397": "|**2025-09-11**|**Decoupling Clinical and Class-Agnostic Features for Reliable Few-Shot Adaptation under Shift**|Dwarikanath Mahapatra Team|[2509.09397](http://arxiv.org/abs/2509.09397)|null|\n", "2509.09372": "|**2025-09-11**|**VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model**|Donglin Wang Team|[2509.09372](http://arxiv.org/abs/2509.09372)|null|\n", "2509.09356": "|**2025-09-11**|**Curriculum-Based Multi-Tier Semantic Exploration via Deep Reinforcement Learning**|Abderrezzak Debilou Team|[2509.09356](http://arxiv.org/abs/2509.09356)|null|\n", "2509.09311": "|**2025-09-11**|**Image Recognition with Vision and Language Embeddings of VLMs**|Jiri Matas Team|[2509.09311](http://arxiv.org/abs/2509.09311)|null|\n", "2509.09286": "|**2025-09-11**|**Visual Programmability: A Guide for Code-as-Thought in Chart Understanding**|Ya Zhang Team|[2509.09286](http://arxiv.org/abs/2509.09286)|null|\n", "2509.09254": "|**2025-09-11**|**Towards Better Dental AI: A Multimodal Benchmark and Instruction Dataset for Panoramic X-ray Analysis**|Kuo Feng Hung Team|[2509.09254](http://arxiv.org/abs/2509.09254)|null|\n", "2509.09172": "|**2025-09-11**|**Bridging the Gap Between Ideal and Real-world Evaluation: Benchmarking AI-Generated Image Detection in Challenging Scenarios**|Yao Zhu Team|[2509.09172](http://arxiv.org/abs/2509.09172)|null|\n", "2509.09116": "|**2025-09-11**|**Zero-shot Hierarchical Plant Segmentation via Foundation Segmentation Models and Text-to-image Attention**|Fumio Okura Team|[2509.09116](http://arxiv.org/abs/2509.09116)|null|\n", "2509.09014": "|**2025-09-10**|**COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation**|Umair Hassan Team|[2509.09014](http://arxiv.org/abs/2509.09014)|**[link](https://huggingface.co/datasets/umairhassan02/urdu-translated-coco-captions-subset.)**|\n", "2509.09013": "|**2025-09-10**|**Can Vision-Language Models Solve Visual Math Equations?**|Mrinmaya Sachan Team|[2509.09013](http://arxiv.org/abs/2509.09013)|null|\n", "2509.08913": "|**2025-09-10**|**Generalized User-Oriented Image Semantic Coding Empowered by Large Vision-Language Model**|Vincent W. S. Wong Team|[2509.08913](http://arxiv.org/abs/2509.08913)|null|\n", "2509.08897": "|**2025-09-10**|**Recurrence Meets Transformers for Universal Multimodal Retrieval**|Rita Cucchiara Team|[2509.08897](http://arxiv.org/abs/2509.08897)|null|\n", "2509.10416": "|**2025-09-12**|**TASC: Task-Aware Shared Control for Teleoperated Manipulation**|Renaud Detry Team|[2509.10416](http://arxiv.org/abs/2509.10416)|null|\n", "2509.10345": "|**2025-09-12**|**Towards Understanding Visual Grounding in Visual Language Models**|Eda B. \u00d6zyi\u011fit Team|[2509.10345](http://arxiv.org/abs/2509.10345)|null|\n", "2509.10278": "|**2025-09-12**|**Detecting Text Manipulation in Images using Vision Language Models**|S\u00e9bastien Marcel Team|[2509.10278](http://arxiv.org/abs/2509.10278)|**[link](https://www.idiap.ch/paper/textvlmdet/)**|\n", "2509.10260": "|**2025-09-12**|**MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation**|Xiaoming Wei Team|[2509.10260](http://arxiv.org/abs/2509.10260)|null|\n", "2509.10129": "|**2025-09-12**|**Towards Reliable and Interpretable Document Question Answering via VLMs**|Simone Marinai Team|[2509.10129](http://arxiv.org/abs/2509.10129)|null|\n", "2509.10105": "|**2025-09-12**|**VARCO-VISION-2.0 Technical Report**|Youngjune Kim Team|[2509.10105](http://arxiv.org/abs/2509.10105)|null|\n", "2509.10059": "|**2025-09-12**|**Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration**|Wayne Zhang Team|[2509.10059](http://arxiv.org/abs/2509.10059)|null|\n", "2509.10026": "|**2025-09-12**|**LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA**|Jianshu Li Team|[2509.10026](http://arxiv.org/abs/2509.10026)|null|\n", "2509.09790": "|**2025-09-11**|**How well can LLMs provide planning feedback in grounded environments?**|Victor Zhong Team|[2509.09790](http://arxiv.org/abs/2509.09790)|null|\n", "2509.12145": "|**2025-09-15**|**Open-ended Hierarchical Streaming Video Understanding with Vision Language Models**|Seon Joo Kim Team|[2509.12145](http://arxiv.org/abs/2509.12145)|null|\n", "2509.12132": "|**2025-09-15**|**Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models**|Jiajun Zhang Team|[2509.12132](http://arxiv.org/abs/2509.12132)|null|\n", "2509.12129": "|**2025-09-16**|**Embodied Navigation Foundation Model**|He Wang Team|[2509.12129](http://arxiv.org/abs/2509.12129)|**[link](https://pku-epic.github.io/NavFoM-Web/)**|\n", "2509.11986": "|**2025-09-15**|**Lost in Embeddings: Information Loss in Vision-Language Models**|Anders S\u00f8gaard Team|[2509.11986](http://arxiv.org/abs/2509.11986)|null|\n", "2509.11961": "|**2025-09-15**|**Spec-LLaVA: Accelerating Vision-Language Models with Dynamic Tree-Based Speculative Decoding**|Yijun Chen Team|[2509.11961](http://arxiv.org/abs/2509.11961)|null|\n", "2509.11862": "|**2025-09-15**|**Bridging Vision Language Models and Symbolic Grounding for Video Question Answering**|Daisy Zhe Wang Team|[2509.11862](http://arxiv.org/abs/2509.11862)|null|\n", "2509.11840": "|**2025-09-15**|**Synthetic Captions for Open-Vocabulary Zero-Shot Segmentation**|Michael Louis Iuzzolino Team|[2509.11840](http://arxiv.org/abs/2509.11840)|null|\n", "2509.11815": "|**2025-09-15**|**SpecVLM: Fast Speculative Decoding in Vision-Language Models**|Emad Barsoum Team|[2509.11815](http://arxiv.org/abs/2509.11815)|null|\n", "2509.11766": "|**2025-09-15**|**Igniting VLMs toward the Embodied Space**|Zach Xu Team|[2509.11766](http://arxiv.org/abs/2509.11766)|null|\n", "2509.11714": "|**2025-09-15**|**EMeRALDS: Electronic Medical Record Driven Automated Lung Nodule Detection and Classification in Thoracic CT Images**|Syed Muhammad Anwar Team|[2509.11714](http://arxiv.org/abs/2509.11714)|null|\n", "2509.11548": "|**2025-09-15**|**How Auxiliary Reasoning Unleashes GUI Grounding in VLMs**|Manni Duan Team|[2509.11548](http://arxiv.org/abs/2509.11548)|null|\n", "2509.11514": "|**2025-09-15**|**LVLMs are Bad at Overhearing Human Referential Communication**|Susan E. Brennan Team|[2509.11514](http://arxiv.org/abs/2509.11514)|null|\n", "2509.11465": "|**2025-09-14**|**CEMTM: Contextual Embedding-based Multimodal Topic Modeling**|Giuseppe Carenini Team|[2509.11465](http://arxiv.org/abs/2509.11465)|null|\n", "2509.11417": "|**2025-09-14**|**Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations**|Xuanlin Li Team|[2509.11417](http://arxiv.org/abs/2509.11417)|**[link](https://gen-vla.github.io/)**|\n", "2509.11364": "|**2025-09-14**|**ActivePose: Active 6D Object Pose Estimation and Tracking for Robotic Manipulation**|Yizhao Wang Team|[2509.11364](http://arxiv.org/abs/2509.11364)|null|\n", "2509.11287": "|**2025-09-14**|**Mitigating Hallucinations in Large Vision-Language Models by Self-Injecting Hallucinations**|Weiming Hu Team|[2509.11287](http://arxiv.org/abs/2509.11287)|null|\n", "2509.11071": "|**2025-09-14**|**The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge**|Dehui Du Team|[2509.11071](http://arxiv.org/abs/2509.11071)|null|\n", "2509.11065": "|**2025-09-14**|**ViScratch: Using Large Language Models and Gameplay Videos for Automated Feedback in Scratch**|Jialu Zhang Team|[2509.11065](http://arxiv.org/abs/2509.11065)|null|\n", "2509.10765": "|**2025-09-13**|**Language-based Color ISP Tuning**|Jiro Takatori Team|[2509.10765](http://arxiv.org/abs/2509.10765)|null|\n", "2509.13317": "|**2025-09-16**|**3D Aware Region Prompted Vision Language Model**|Sifei Liu Team|[2509.13317](http://arxiv.org/abs/2509.13317)|**[link](https://www.anjiecheng.me/sr3d)**|\n", "2509.13289": "|**2025-09-16**|**Image Realness Assessment and Localization with Multimodal Features**|Somdyuti Paul Team|[2509.13289](http://arxiv.org/abs/2509.13289)|null|\n", "2509.13282": "|**2025-09-16**|**ChartGaze: Enhancing Chart Understanding in LVLMs with Eye-Tracking Guided Attention Refinement**|Giuseppe Carenini Team|[2509.13282](http://arxiv.org/abs/2509.13282)|null|\n", "2509.13270": "|**2025-09-16**|**RadGame: An AI-Powered Platform for Radiology Education**|Pranav Rajpurkar Team|[2509.13270](http://arxiv.org/abs/2509.13270)|null|\n", "2509.13067": "|**2025-09-16**|**HERO: Rethinking Visual Token Early Dropping in High-Resolution Large Vision-Language Models**|Xiangyang Xue Team|[2509.13067](http://arxiv.org/abs/2509.13067)|null|\n", "2509.13031": "|**2025-09-16**|**Perception Before Reasoning: Two-Stage Reinforcement Learning for Visual Reasoning in Vision-Language Models**|Jingdong Wang Team|[2509.13031](http://arxiv.org/abs/2509.13031)|null|\n", "2509.12897": "|**2025-09-16**|**Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models**|Chong Feng Team|[2509.12897](http://arxiv.org/abs/2509.12897)|null|\n", "2509.12876": "|**2025-09-16**|**Benchmarking and Improving LVLMs on Event Extraction from Multimedia Documents**|Haiyang Zhang Team|[2509.12876](http://arxiv.org/abs/2509.12876)|null|\n", "2509.12724": "|**2025-09-16**|**Defense-to-Attack: Bypassing Weak Defenses Enables Stronger Jailbreaks in Vision-Language Models**|Xingjun Ma Team|[2509.12724](http://arxiv.org/abs/2509.12724)|null|\n", "2509.12715": "|**2025-09-16**|**AsyMoE: Leveraging Modal Asymmetry for Enhanced Expert Specialization in Large Vision-Language Models**|Jin Huang Team|[2509.12715](http://arxiv.org/abs/2509.12715)|null|\n", "2509.12492": "|**2025-09-15**|**Evaluating Robustness of Vision-Language Models Under Noisy Conditions**|Alireza Team|[2509.12492](http://arxiv.org/abs/2509.12492)|null|\n", "2509.12367": "|**2025-09-15**|**An integrated process for design and control of lunar robotics using AI and simulation**|Martin Servin Team|[2509.12367](http://arxiv.org/abs/2509.12367)|null|\n", "2509.14227": "|**2025-09-17**|**Cin\u00e9aste: A Fine-grained Contextual Movie Question Answering Benchmark**|Vishal M. Patel Team|[2509.14227](http://arxiv.org/abs/2509.14227)|null|\n", "2509.14172": "|**2025-09-19**|**TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning**|Guitao Cao Team|[2509.14172](http://arxiv.org/abs/2509.14172)|null|\n", "2509.14060": "|**2025-09-17**|**VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement**|Fei Richard Yu Team|[2509.14060](http://arxiv.org/abs/2509.14060)|null|\n", "2509.13939": "|**2025-09-17**|**Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation**|Minh Hoai Team|[2509.13939](http://arxiv.org/abs/2509.13939)|null|\n", "2509.13919": "|**2025-09-17**|**Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration**|Xiaoqiang Li Team|[2509.13919](http://arxiv.org/abs/2509.13919)|null|\n", "2509.13858": "|**2025-09-17**|**EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics**|Jielei Wang Team|[2509.13858](http://arxiv.org/abs/2509.13858)|null|\n", "2509.13836": "|**2025-09-17**|**Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models**|Longwen Gao Team|[2509.13836](http://arxiv.org/abs/2509.13836)|null|\n", "2509.13760": "|**2025-09-17**|**Iterative Prompt Refinement for Safer Text-to-Image Generation**|Byung-Jun Lee Team|[2509.13760](http://arxiv.org/abs/2509.13760)|null|\n", "2509.13731": "|**2025-09-17**|**Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings**|Changjoo Nam Team|[2509.13731](http://arxiv.org/abs/2509.13731)|null|\n", "2509.13666": "|**2025-09-17**|**DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring**|Xiaomin Lin Team|[2509.13666](http://arxiv.org/abs/2509.13666)|null|\n", "2509.13590": "|**2025-09-16**|**Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation**|Samer Al-Hamadani Team|[2509.13590](http://arxiv.org/abs/2509.13590)|null|\n", "2509.13572": "|**2025-09-16**|**Using Visual Language Models to Control Bionic Hands: Assessment of Object Perception and Grasp Inference**|Cedomir Stefanovic Team|[2509.13572](http://arxiv.org/abs/2509.13572)|null|\n", "2509.13399": "|**2025-09-16**|**EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing**|Mingyuan Zhou Team|[2509.13399](http://arxiv.org/abs/2509.13399)|null|\n", "2509.15226": "|**2025-09-18**|**Calibration-Aware Prompt Learning for Medical Vision-Language Models**|Muhammad Haris Khan Team|[2509.15226](http://arxiv.org/abs/2509.15226)|null|\n", "2509.15221": "|**2025-09-19**|**ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data**|Wenhai Wang Team|[2509.15221](http://arxiv.org/abs/2509.15221)|null|\n", "2509.15211": "|**2025-09-18**|**What's the Best Way to Retrieve Slides? A Comparative Study of Multimodal, Caption-Based, and Hybrid Retrieval Techniques**|Grigorios Tsoumakas Team|[2509.15211](http://arxiv.org/abs/2509.15211)|null|\n", "2509.15154": "|**2025-09-18**|**MedFact-R1: Towards Factual Medical Reasoning via Pseudo-Label Augmentation**|Guodong Ding Team|[2509.15154](http://arxiv.org/abs/2509.15154)|null|\n", "2509.15076": "|**2025-09-18**|**Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models**|Yanqing Zhang Team|[2509.15076](http://arxiv.org/abs/2509.15076)|null|\n", "2509.15059": "|**2025-09-18**|**QuizRank: Picking Images by Quizzing VLMs**|Eytan Adar Team|[2509.15059](http://arxiv.org/abs/2509.15059)|null|\n", "2509.14985": "|**2025-09-18**|**PRISM: Product Retrieval In Shopping Carts using Hybrid Matching**|Jiajing Chen Team|[2509.14985](http://arxiv.org/abs/2509.14985)|null|\n", "2509.14977": "|**2025-09-18**|**EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence**|Qinghua Huang Team|[2509.14977](http://arxiv.org/abs/2509.14977)|null|\n", "2509.14967": "|**2025-09-19**|**Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery**|Yasuhisa Hasegawa Team|[2509.14967](http://arxiv.org/abs/2509.14967)|null|\n", "2509.14860": "|**2025-09-18**|**MARIC: Multi-Agent Reasoning for Image Classification**|Seunghyun Lee Team|[2509.14860](http://arxiv.org/abs/2509.14860)|null|\n", "2509.14837": "|**2025-09-18**|**V-SEAM: Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models**|Ming Jiang Team|[2509.14837](http://arxiv.org/abs/2509.14837)|null|\n", "2509.14769": "|**2025-09-18**|**Frame Sampling Strategies Matter: A Benchmark for small vision language models**|Mounim A. El Yacoubi Team|[2509.14769](http://arxiv.org/abs/2509.14769)|null|\n", "2509.14574": "|**2025-09-18**|**Do Vision-Language Models See Urban Scenes as People Do? An Urban Perception Benchmark**|Rashid Mushkani Team|[2509.14574](http://arxiv.org/abs/2509.14574)|null|\n", "2509.14571": "|**2025-09-18**|**VisMoDAl: Visual Analytics for Evaluating and Improving Corruption Robustness of Vision-Language Models**|Yuxin Ma Team|[2509.14571](http://arxiv.org/abs/2509.14571)|null|\n", "2509.14380": "|**2025-09-17**|**CRAFT: Coaching Reinforcement Learning Autonomously using Foundation Models for Multi-Robot Coordination Tasks**|Negar Mehr Team|[2509.14380](http://arxiv.org/abs/2509.14380)|null|\n", "2509.16163": "|**2025-09-19**|**Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks**|Evangelos E. Papalexakis Team|[2509.16163](http://arxiv.org/abs/2509.16163)|null|\n", "2509.16088": "|**2025-09-19**|**Randomized Smoothing Meets Vision-Language Models**|Chih-Hong Cheng Team|[2509.16088](http://arxiv.org/abs/2509.16088)|null|\n", "2509.16072": "|**2025-09-19**|**I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models**|Mohamed Chetouani Team|[2509.16072](http://arxiv.org/abs/2509.16072)|null|\n", "2509.16053": "|**2025-09-19**|**Compose by Focus: Scene Graph-based Atomic Skills**|Heng Yang Team|[2509.16053](http://arxiv.org/abs/2509.16053)|null|\n", "2509.15803": "|**2025-09-19**|**CIDER: A Causal Cure for Brand-Obsessed Text-to-Image Models**|Wushao Wen Team|[2509.15803](http://arxiv.org/abs/2509.15803)|null|\n", "2509.15772": "|**2025-09-19**|**Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation**|He Sun Team|[2509.15772](http://arxiv.org/abs/2509.15772)|null|\n", "2509.15738": "|**2025-09-19**|**GUI-ReWalk: Massive Data Generation for GUI Agent via Stochastic Exploration and Intent-Aware Reasoning**|Zhaojian Li Team|[2509.15738](http://arxiv.org/abs/2509.15738)|null|\n", "2509.15704": "|**2025-09-19**|**Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance**|Xiangyang Xue Team|[2509.15704](http://arxiv.org/abs/2509.15704)|null|\n", "2509.15695": "|**2025-09-19**|**ORIC: Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models**|Hao Su Team|[2509.15695](http://arxiv.org/abs/2509.15695)|null|\n", "2509.15661": "|**2025-09-19**|**SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models**|Nima Mesgarani Team|[2509.15661](http://arxiv.org/abs/2509.15661)|null|\n", "2509.15607": "|**2025-09-19**|**PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models**|Byung-Cheol Min Team|[2509.15607](http://arxiv.org/abs/2509.15607)|null|\n", "2509.15490": "|**2025-09-18**|**SmolRGPT: Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters**|Andy Couturier Team|[2509.15490](http://arxiv.org/abs/2509.15490)|null|\n", "2509.15482": "|**2025-09-18**|**Comparing Computational Pathology Foundation Models using Representational Similarity Analysis**|William Lotter Team|[2509.15482](http://arxiv.org/abs/2509.15482)|null|\n", "2509.15435": "|**2025-09-18**|**ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models**|Nathaniel D. Bastian Team|[2509.15435](http://arxiv.org/abs/2509.15435)|null|\n", "2509.15432": "|**2025-09-18**|**SERVAL: Surprisingly Effective Zero-Shot Visual Document Retrieval Powered by Large Vision and Language Models**|Andrew Yates Team|[2509.15432](http://arxiv.org/abs/2509.15432)|null|\n", "2509.15330": "|**2025-09-18**|**CoDoL: Conditional Domain Prompt Learning for Out-of-Distribution Generalization**|Xin Lin Team|[2509.15330](http://arxiv.org/abs/2509.15330)|null|\n", "2509.18041": "|**2025-09-22**|**NeuS-QA: Grounding Long-Form Video Understanding in Temporal Logic and Neuro-Symbolic Reasoning**|Sandeep Chinchali Team|[2509.18041](http://arxiv.org/abs/2509.18041)|null|\n", "2509.17666": "|**2025-09-22**|**Robust and Resilient Soft Robotic Object Insertion with Compliance-Enabled Contact Formation and Failure Recovery**|Yoshitaka Ushiku Team|[2509.17666](http://arxiv.org/abs/2509.17666)|null|\n", "2509.17664": "|**2025-09-22**|**SD-VLM: Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models**|Jieping Ye Team|[2509.17664](http://arxiv.org/abs/2509.17664)|null|\n", "2509.17615": "|**2025-09-22**|**From Benchmarks to Reality: Advancing Visual Anomaly Detection by the VAND 3.0 Challenge**|Paula Ramos Team|[2509.17615](http://arxiv.org/abs/2509.17615)|null|\n", "2509.17598": "|**2025-09-22**|**COLA: Context-aware Language-driven Test-time Adaptation**|Zhihe Lu Team|[2509.17598](http://arxiv.org/abs/2509.17598)|null|\n", "2509.17588": "|**2025-09-22**|**Interpreting Attention Heads for Image-to-Text Information Flow in Large Vision-Language Models**|Seong Jae Hwang Team|[2509.17588](http://arxiv.org/abs/2509.17588)|null|\n", "2509.17562": "|**2025-09-23**|**Visual Instruction Pretraining for Domain-Specific Foundation Models**|Jian Yang Team|[2509.17562](http://arxiv.org/abs/2509.17562)|null|\n", "2509.17481": "|**2025-09-22**|**ChartHal: A Fine-grained Framework Evaluating Hallucination of Large Vision Language Models in Chart Understanding**|Xiaoyu Qin Team|[2509.17481](http://arxiv.org/abs/2509.17481)|null|\n", "2509.17452": "|**2025-09-22**|**Training-Free Label Space Alignment for Universal Domain Adaptation**|Donghyun Kim Team|[2509.17452](http://arxiv.org/abs/2509.17452)|null|\n", "2509.17429": "|**2025-09-23**|**Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration**|Yueming Jin Team|[2509.17429](http://arxiv.org/abs/2509.17429)|null|\n", "2509.17418": "|**2025-09-22**|**Vision Language Models Are Not (Yet) Spelling Correctors**|Bojun Zhang Team|[2509.17418](http://arxiv.org/abs/2509.17418)|null|\n", "2509.17336": "|**2025-09-22**|**Mano Report**|Shuo Wang Team|[2509.17336](http://arxiv.org/abs/2509.17336)|null|\n", "2509.17328": "|**2025-09-22**|**UIPro: Unleashing Superior Interaction Capability For GUI Agents**|Zhaoxiang Zhang Team|[2509.17328](http://arxiv.org/abs/2509.17328)|null|\n", "2509.17321": "|**2025-09-22**|**OpenGVL - Benchmarking Visual Temporal Progress for Data Curation**|Krzysztof Walas Team|[2509.17321](http://arxiv.org/abs/2509.17321)|null|\n", "2509.17177": "|**2025-09-21**|**FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions**|Zhongyuan Wang Team|[2509.17177](http://arxiv.org/abs/2509.17177)|null|\n", "2509.17084": "|**2025-09-21**|**MoCLIP-Lite: Efficient Video Recognition by Fusing CLIP with Motion Vectors**|Soumyabrata Dev Team|[2509.17084](http://arxiv.org/abs/2509.17084)|null|\n", "2509.17065": "|**2025-09-21**|**CardiacCLIP: Video-based CLIP Adaptation for LVEF Prediction in a Few-shot Manner**|Xiaomeng Li Team|[2509.17065](http://arxiv.org/abs/2509.17065)|null|\n", "2509.17044": "|**2025-09-21**|**AgriDoctor: A Multimodal Intelligent Assistant for Agriculture**|Liang Wang Team|[2509.17044](http://arxiv.org/abs/2509.17044)|null|\n", "2509.17042": "|**2025-09-21**|**Orchestrate, Generate, Reflect: A VLM-Based Multi-Agent Collaboration Framework for Automated Driving Policy Learning**|Jun Ma Team|[2509.17042](http://arxiv.org/abs/2509.17042)|null|\n", "2509.17024": "|**2025-09-21**|**When Color-Space Decoupling Meets Diffusion for Adverse-Weather Image Restoration**|Jun Li Team|[2509.17024](http://arxiv.org/abs/2509.17024)|null|\n", "2509.19274": "|**2025-09-23**|**DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture**|Sriparna Saha Team|[2509.19274](http://arxiv.org/abs/2509.19274)|null|\n", "2509.19207": "|**2025-09-23**|**Long Story Short: Disentangling Compositionality and Long-Caption Understanding in VLMs**|Yova Kementchedjhieva Team|[2509.19207](http://arxiv.org/abs/2509.19207)|null|\n", "2509.19203": "|**2025-09-23**|**Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions**|Georgios Tzimiropoulos Team|[2509.19203](http://arxiv.org/abs/2509.19203)|null|\n", "2509.19191": "|**2025-09-23**|**Reading Images Like Texts: Sequential Image Understanding in Vision-Language Models**|Xiaojie Wang Team|[2509.19191](http://arxiv.org/abs/2509.19191)|null|\n", "2509.19102": "|**2025-09-23**|**FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation**|Jianwei Zhang Team|[2509.19102](http://arxiv.org/abs/2509.19102)|**[link](https://sites.google.com/view/funcanon)**|\n", "2509.19070": "|**2025-09-23**|**ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?**|Jiahao Cui Team|[2509.19070](http://arxiv.org/abs/2509.19070)|null|\n", "2509.19012": "|**2025-09-23**|**Pure Vision Language Action (VLA) Models: A Comprehensive Survey**|Qingguo Zhou Team|[2509.19012](http://arxiv.org/abs/2509.19012)|null|\n", "2509.19003": "|**2025-09-23**|**Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards**|Xinlong Wang Team|[2509.19003](http://arxiv.org/abs/2509.19003)|null|\n", "2509.18938": "|**2025-09-23**|**No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning**|Joel Lu\u00eds Carbonera Team|[2509.18938](http://arxiv.org/abs/2509.18938)|null|\n", "2509.18905": "|**2025-09-23**|**How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective**|Huchuan Lu Team|[2509.18905](http://arxiv.org/abs/2509.18905)|null|\n", "2509.18839": "|**2025-09-23**|**Benchmarking Vision-Language and Multimodal Large Language Models in Zero-shot and Few-shot Scenarios: A study on Christian Iconography**|Giovanni Colavizza Team|[2509.18839](http://arxiv.org/abs/2509.18839)|null|\n", "2509.18763": "|**2025-09-23**|**Bi-VLM: Pushing Ultra-Low Precision Post-Training Quantization Boundaries in Vision-Language Models**|Dinesh Manocha Team|[2509.18763](http://arxiv.org/abs/2509.18763)|null|\n", "2509.18733": "|**2025-09-23**|**Knowledge Transfer from Interaction Learning**|Shugong Xu Team|[2509.18733](http://arxiv.org/abs/2509.18733)|null|\n", "2509.18715": "|**2025-09-23**|**What Makes You Unique? Attribute Prompt Composition for Object Re-Identification**|Huchuan Lu Team|[2509.18715](http://arxiv.org/abs/2509.18715)|null|\n", "2509.18711": "|**2025-09-23**|**RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images**|Quan Wang Team|[2509.18711](http://arxiv.org/abs/2509.18711)|null|\n", "2509.18672": "|**2025-09-23**|**NaviSense: A Multimodal Assistive Mobile application for Object Retrieval by Persons with Visual Impairment**|Vijaykrishnan Narayanan Team|[2509.18672](http://arxiv.org/abs/2509.18672)|null|\n", "2509.18638": "|**2025-09-23**|**Learning neuroimaging models from health system-scale data**|Todd Hollon Team|[2509.18638](http://arxiv.org/abs/2509.18638)|null|\n", "2509.18610": "|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Mac Schwager Team|[2509.18610](http://arxiv.org/abs/2509.18610)|null|\n", "2509.18592": "|**2025-09-23**|**VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation**|Ufuk Topcu Team|[2509.18592](http://arxiv.org/abs/2509.18592)|**[link](https://vln-zero.github.io/)**|\n", "2509.18425": "|**2025-09-22**|**Losing the Plot: How VLM responses degrade on imperfect charts**|Mahantesh Halappanavar Team|[2509.18425](http://arxiv.org/abs/2509.18425)|null|\n", "2509.20279": "|**2025-09-24**|**A co-evolving agentic AI system for medical imaging analysis**|Zhi Huang Team|[2509.20279](http://arxiv.org/abs/2509.20279)|null|\n", "2509.20196": "|**2025-09-24**|**Universal Camouflage Attack on Vision-Language Models for Autonomous Driving**|Wenqi Ren Team|[2509.20196](http://arxiv.org/abs/2509.20196)|null|\n", "2509.20146": "|**2025-09-24**|**EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language Models**|Dacheng Tao Team|[2509.20146](http://arxiv.org/abs/2509.20146)|null|\n", "2509.20119": "|**2025-09-24**|**A Simple Data Augmentation Strategy for Text-in-Image Scientific VQA**|Yova Kementchedjhieva Team|[2509.20119](http://arxiv.org/abs/2509.20119)|null|\n", "2509.20109": "|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Xianpeng Lang Team|[2509.20109](http://arxiv.org/abs/2509.20109)|null|\n", "2509.20077": "|**2025-09-24**|**Queryable 3D Scene Representation: A Multi-Modal Framework for Semantic Reasoning and Robotic Task Planning**|Jiajun Liu Team|[2509.20077](http://arxiv.org/abs/2509.20077)|null|\n", "2509.19973": "|**2025-09-25**|**OmniScene: Attention-Augmented Multimodal 4D Scene Understanding for Autonomous Driving**|Jun Ma Team|[2509.19973](http://arxiv.org/abs/2509.19973)|null|\n", "2509.19958": "|**2025-09-24**|**Generalist Robot Manipulation beyond Action Labeled Data**|Danda Pani Paudel Team|[2509.19958](http://arxiv.org/abs/2509.19958)|null|\n", "2509.19858": "|**2025-09-24**|**Benchmarking Gaslighting Attacks Against Speech Large Language Models**|Pan Zhou Team|[2509.19858](http://arxiv.org/abs/2509.19858)|null|\n", "2509.19768": "|**2025-09-24**|**CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition**|Monica S. Lam Team|[2509.19768](http://arxiv.org/abs/2509.19768)|null|\n", "2509.19760": "|**2025-09-24**|**Logics-Parsing Technical Report**|Minggang Wu Team|[2509.19760](http://arxiv.org/abs/2509.19760)|null|\n", "2509.19688": "|**2025-09-24**|**Formal Safety Verification and Refinement for Generative Motion Planners via Certified Local Stabilization**|Glen Chou Team|[2509.19688](http://arxiv.org/abs/2509.19688)|null|\n", "2509.19659": "|**2025-09-24**|**Bias in the Picture: Benchmarking VLMs with Social-Cue News Images and LLM-as-Judge Assessment**|Shaina Raza Team|[2509.19659](http://arxiv.org/abs/2509.19659)|null|\n", "2509.19595": "|**2025-09-23**|**Anatomy of a Feeling: Narrating Embodied Emotions via Large Vision-Language Models**|Tianyu Jiang Team|[2509.19595](http://arxiv.org/abs/2509.19595)|null|\n", "2509.19552": "|**2025-09-23**|**iFinder: Structured Zero-Shot Vision-Based LLM Grounding for Dash-Cam Video Reasoning**|Abhishek Aich Team|[2509.19552](http://arxiv.org/abs/2509.19552)|null|\n", "2509.19524": "|**2025-09-23**|**Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation**|Chi-Guhn Lee Team|[2509.19524](http://arxiv.org/abs/2509.19524)|null|\n", "2509.21301": "|**2025-09-25**|**Nova: Real-Time Agentic Vision-Language Model Serving with Adaptive Cross-Stage Parallelization**|Guihai Chen Team|[2509.21301](http://arxiv.org/abs/2509.21301)|null|\n", "2509.21287": "|**2025-09-25**|**DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding**|Mehrnoosh Sadrzadeh Team|[2509.21287](http://arxiv.org/abs/2509.21287)|null|\n", "2509.21262": "|**2025-09-25**|**Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication**|Alexander Nagaev Team|[2509.21262](http://arxiv.org/abs/2509.21262)|null|\n", "2509.21257": "|**2025-09-25**|**Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation**|Mohammad Hossein Rohban Team|[2509.21257](http://arxiv.org/abs/2509.21257)|null|\n", "2509.21247": "|**2025-09-25**|**Learning to Look: Cognitive Attention Alignment with Vision-Language Models**|Nidhi Rastogi Team|[2509.21247](http://arxiv.org/abs/2509.21247)|null|\n", "2509.21205": "|**2025-09-25**|**TABLET: A Large-Scale Dataset for Robust Visual Table Understanding**|Mirella Lapata Team|[2509.21205](http://arxiv.org/abs/2509.21205)|null|\n", "2509.21189": "|**2025-09-25**|**Human-like Navigation in a World Built for Humans**|Shenlong Wang Team|[2509.21189](http://arxiv.org/abs/2509.21189)|**[link](https://reasonnav.github.io/)**|\n", "2509.21173": "|**2025-09-25**|**Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy**|Chokri Mraidha Team|[2509.21173](http://arxiv.org/abs/2509.21173)|null|\n", "2509.21126": "|**2025-09-25**|**Teaching RL Agents to Act Better: VLM as Action Advisor for Online Reinforcement Learning**|Mingyu Hu Team|[2509.21126](http://arxiv.org/abs/2509.21126)|null|\n", "2509.21107": "|**2025-09-25**|**Cross-Modal Instructions for Robot Motion Generation**|Weiming Zhi Team|[2509.21107](http://arxiv.org/abs/2509.21107)|null|\n", "2509.21102": "|**2025-09-25**|**Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models**|Robert Jenssen Team|[2509.21102](http://arxiv.org/abs/2509.21102)|null|\n", "2509.21079": "|**2025-09-25**|**SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials**|Lu Cheng Team|[2509.21079](http://arxiv.org/abs/2509.21079)|null|\n", "2509.20961": "|**2025-09-25**|**Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos**|Alka Maurya Team|[2509.20961](http://arxiv.org/abs/2509.20961)|null|\n", "2509.20941": "|**2025-09-25**|**Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery**|M. Ali Nasseri Team|[2509.20941](http://arxiv.org/abs/2509.20941)|null|\n", "2509.20843": "|**2025-09-25**|**MTRDrive: Memory-Tool Synergistic Reasoning for Robust Autonomous Driving in Corner Cases**|Diange Yang Team|[2509.20843](http://arxiv.org/abs/2509.20843)|null|\n", "2509.20792": "|**2025-09-25**|**DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation**|Ved Umrajkar Team|[2509.20792](http://arxiv.org/abs/2509.20792)|null|\n", "2509.20769": "|**2025-09-25**|**Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems**|Ruiliang Liu Team|[2509.20769](http://arxiv.org/abs/2509.20769)|null|\n", "2509.20751": "|**2025-09-25**|**Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models**|Meenakshi Khosla Team|[2509.20751](http://arxiv.org/abs/2509.20751)|null|\n", "2509.20628": "|**2025-09-25**|**Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery**|Ali Mostafavi Team|[2509.20628](http://arxiv.org/abs/2509.20628)|null|\n", "2509.20524": "|**2025-09-24**|**InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On**|Karim Bouyarmane Team|[2509.20524](http://arxiv.org/abs/2509.20524)|null|\n", "2509.22653": "|**2025-09-26**|**See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation**|Yu-Lun Liu Team|[2509.22653](http://arxiv.org/abs/2509.22653)|**[link](https://spf-web.pages.dev)**|\n", "2509.22647": "|**2025-09-26**|**CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning**|Dahua Lin Team|[2509.22647](http://arxiv.org/abs/2509.22647)|**[link](https://github.com/InternLM/CapRL)**|\n", "2509.22645": "|**2025-09-26**|**Hierarchical Representation Matching for CLIP-based Class-Incremental Learning**|Da-Wei Zhou Team|[2509.22645](http://arxiv.org/abs/2509.22645)|null|\n", "2509.22642": "|**2025-09-26**|**WoW: Towards a World omniscient World model Through Embodied Interaction**|Jian Tang Team|[2509.22642](http://arxiv.org/abs/2509.22642)|null|\n", "2509.22624": "|**2025-09-26**|**SPARK: Synergistic Policy And Reward Co-Evolving Framework**|Jiaqi Wang Team|[2509.22624](http://arxiv.org/abs/2509.22624)|**[link](https://github.com/InternLM/Spark)**|\n", "2509.22524": "|**2025-09-26**|**Color Names in Vision-Language Models**|Javier Vazquez-Corral Team|[2509.22524](http://arxiv.org/abs/2509.22524)|null|\n", "2509.22447": "|**2025-09-26**|**Guiding Evolution of Artificial Life Using Vision-Language Models**|Frederico Wieser Team|[2509.22447](http://arxiv.org/abs/2509.22447)|null|\n", "2509.22437": "|**2025-09-26**|**Chimera: Diagnosing Shortcut Learning in Visual-Language Understanding**|Mrinmaya Sachan Team|[2509.22437](http://arxiv.org/abs/2509.22437)|**[link](https://github.com/CHIzhP/Chimera))**|\n", "2509.22404": "|**2025-09-26**|**RAU: Reference-based Anatomical Understanding with Vision Language Models**|Shanhui Sun Team|[2509.22404](http://arxiv.org/abs/2509.22404)|null|\n", "2509.22378": "|**2025-09-26**|**Zero-Effort Image-to-Music Generation: An Interpretable RAG-based VLM Approach**|Zijing Zhou Team|[2509.22378](http://arxiv.org/abs/2509.22378)|null|\n", "2509.22283": "|**2025-09-26**|**Rule-Based Reinforcement Learning for Document Image Classification with Vision Language Models**|Andreas Fischer Team|[2509.22283](http://arxiv.org/abs/2509.22283)|**[link](https://github.com/jungomi/vision-finetune)**|\n", "2509.22258": "|**2025-09-26**|**Beyond Classification Accuracy: Neural-MedBench and the Need for Deeper Reasoning Benchmarks**|Shangyang Li Team|[2509.22258](http://arxiv.org/abs/2509.22258)|null|\n", "2509.22229": "|**2025-09-26**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Cheng Deng Team|[2509.22229](http://arxiv.org/abs/2509.22229)|null|\n", "2509.22225": "|**2025-09-26**|**Polysemous Language Gaussian Splatting via Matching-based Mask Lifting**|Ge Li Team|[2509.22225](http://arxiv.org/abs/2509.22225)|null|\n", "2509.22221": "|**2025-09-26**|**Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models**|Bo Yang Team|[2509.22221](http://arxiv.org/abs/2509.22221)|null|\n", "2509.22195": "|**2025-09-26**|**Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting**|Anirudha Majumdar Team|[2509.22195](http://arxiv.org/abs/2509.22195)|null|\n", "2509.22186": "|**2025-09-26**|**MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing**|Conghui He Team|[2509.22186](http://arxiv.org/abs/2509.22186)|**[link](https://github.com/opendatalab/MinerU)**|\n", "2509.22123": "|**2025-09-26**|**Multilingual Vision-Language Models, A Survey**|Jind\u0159ich Libovick\u00fd Team|[2509.22123](http://arxiv.org/abs/2509.22123)|null|\n", "2509.22014": "|**2025-09-26**|**Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics**|Stefan K. Ehrlich Team|[2509.22014](http://arxiv.org/abs/2509.22014)|null|\n", "2509.22010": "|**2025-09-26**|**CoFFT: Chain of Foresight-Focus Thought for Visual Language Models**|Mike Zheng Shou Team|[2509.22010](http://arxiv.org/abs/2509.22010)|null|\n", "2509.25143": "|**2025-09-29**|**TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models**|Nanyun Peng Team|[2509.25143](http://arxiv.org/abs/2509.25143)|null|\n", "2509.25142": "|**2025-09-29**|**Visual serial processing deficits explain divergences in human and VLM reasoning**|Thomas L. Griffiths Team|[2509.25142](http://arxiv.org/abs/2509.25142)|null|\n", "2509.25026": "|**2025-09-29**|**GeoVLM-R1: Reinforcement Fine-Tuning for Improved Remote Sensing Reasoning**|Salman Khan Team|[2509.25026](http://arxiv.org/abs/2509.25026)|**[link](https://mustansarfiaz.github.io/GeoVLM-R1/)**|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Qing Zhang Team|[2509.24948](http://arxiv.org/abs/2509.24948)|null|\n", "2509.24917": "|**2025-09-29**|**From Code to Action: Hierarchical Learning of Diffusion-VLM Policies**|Daniel Dijkman Team|[2509.24917](http://arxiv.org/abs/2509.24917)|null|\n", "2509.24837": "|**2025-09-29**|**Training-Free Token Pruning via Zeroth-Order Gradient Estimation in Vision-Language Models**|Sungeun Hong Team|[2509.24837](http://arxiv.org/abs/2509.24837)|null|\n", "2509.24768": "|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Ville Kyrki Team|[2509.24768](http://arxiv.org/abs/2509.24768)|null|\n", "2509.24709": "|**2025-09-29**|**IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?**|Botian Shi Team|[2509.24709](http://arxiv.org/abs/2509.24709)|null|\n", "2509.24640": "|**2025-09-29**|**Can you SPLICE it together? A Human Curated Benchmark for Probing Visual Reasoning in VLMs**|Elia Bruni Team|[2509.24640](http://arxiv.org/abs/2509.24640)|null|\n", "2509.24597": "|**2025-09-30**|**Inducing Dyslexia in Vision Language Models**|Martin Schrimpf Team|[2509.24597](http://arxiv.org/abs/2509.24597)|null|\n", "2509.24566": "|**2025-09-29**|**TokenSwap: Backdoor Attack on the Compositional Understanding of Large Vision-Language Models**|Joey Tianyi Zhou Team|[2509.24566](http://arxiv.org/abs/2509.24566)|null|\n", "2509.24528": "|**2025-09-29**|**CORE-3D: Context-aware Open-vocabulary Retrieval by Embeddings in 3D**|Matin Mirzababaei Team|[2509.24528](http://arxiv.org/abs/2509.24528)|null|\n", "2509.24524": "|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Xianyuan Zhan Team|[2509.24524](http://arxiv.org/abs/2509.24524)|null|\n", "2509.24494": "|**2025-09-29**|**GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient Chain-of-Thought Training**|Hao Dong Team|[2509.24494](http://arxiv.org/abs/2509.24494)|null|\n", "2509.24473": "|**2025-09-29**|**Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks**|Kai Chen Team|[2509.24473](http://arxiv.org/abs/2509.24473)|null|\n", "2509.24378": "|**2025-09-29**|**AXIS: Explainable Time Series Anomaly Detection with Large Language Models**|Chen Zhang Team|[2509.24378](http://arxiv.org/abs/2509.24378)|null|\n", "2509.24321": "|**2025-09-29**|**SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm**|Jiankun Wang Team|[2509.24321](http://arxiv.org/abs/2509.24321)|null|\n", "2509.24304": "|**2025-09-30**|**FrameThinker: Learning to Think with Long Videos via Multi-Turn Frame Spotlighting**|Yu Cheng Team|[2509.24304](http://arxiv.org/abs/2509.24304)|null|\n", "2509.24219": "|**2025-09-29**|**ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning**|Yang You Team|[2509.24219](http://arxiv.org/abs/2509.24219)|null|\n", "2509.24192": "|**2025-09-29**|**Talk in Pieces, See in Whole: Disentangling and Hierarchical Aggregating Representations for Language-based Object Detection**|Donghyun Kim Team|[2509.24192](http://arxiv.org/abs/2509.24192)|null|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Shanghang Zhang Team|[2509.26642](http://arxiv.org/abs/2509.26642)|null|\n", "2509.26641": "|**2025-09-30**|**Query-Kontext: An Unified Multimodal Model for Image Generation and Editing**|Jingdong Wang Team|[2509.26641](http://arxiv.org/abs/2509.26641)|null|\n", "2509.26594": "|**2025-09-30**|**Clarification as Supervision: Reinforcement Learning for Vision-Language Interfaces**|Ivan Titov Team|[2509.26594](http://arxiv.org/abs/2509.26594)|null|\n", "2509.26557": "|**2025-09-30**|**The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows**|Emerson Murphy-Hill Team|[2509.26557](http://arxiv.org/abs/2509.26557)|null|\n", "2509.26555": "|**2025-09-30**|**Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation**|Varun Jampani Team|[2509.26555](http://arxiv.org/abs/2509.26555)|**[link](https://stable-cinemetrics.github.io/)**|\n", "2509.26462": "|**2025-09-30**|**Zero-Shot Decentralized Federated Learning**|Giovanni Bellitto Team|[2509.26462](http://arxiv.org/abs/2509.26462)|**[link](https://github.com/perceivelab/ZeroDFL)**|\n", "2509.26330": "|**2025-09-30**|**SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval**|Huei-Fang Yang Team|[2509.26330](http://arxiv.org/abs/2509.26330)|null|\n", "2509.26278": "|**2025-09-30**|**ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation**|Antonio Liotta Team|[2509.26278](http://arxiv.org/abs/2509.26278)|null|\n", "2509.26235": "|**2025-09-30**|**Interpret, prune and distill Donut : towards lightweight VLMs for VQA on document**|David Naccache Team|[2509.26235](http://arxiv.org/abs/2509.26235)|null|\n", "2509.26208": "|**2025-09-30**|**TSalV360: A Method and Dataset for Text-driven Saliency Detection in 360-Degrees Videos**|Vasileios Mezaris Team|[2509.26208](http://arxiv.org/abs/2509.26208)|**[link](https://ieeexplore.ieee.org/)**|\n", "2509.26039": "|**2025-09-30**|**SGS: Segmentation-Guided Scoring for Global Scene Inconsistencies**|Xue Li Team|[2509.26039](http://arxiv.org/abs/2509.26039)|null|\n", "2509.26006": "|**2025-10-01**|**AgenticIQA: An Agentic Framework for Adaptive and Interpretable Image Quality Assessment**|Weisi Lin Team|[2509.26006](http://arxiv.org/abs/2509.26006)|null|\n", "2509.26004": "|**2025-09-30**|**Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations**|Antonino Furnari Team|[2509.26004](http://arxiv.org/abs/2509.26004)|null|\n", "2509.25991": "|**2025-09-30**|**Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline**|Zhun Zhong Team|[2509.25991](http://arxiv.org/abs/2509.25991)|null|\n", "2509.25944": "|**2025-09-30**|**NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving**|Johannes Betz Team|[2509.25944](http://arxiv.org/abs/2509.25944)|null|\n", "2509.25916": "|**2025-09-30**|**VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs**|Tiancheng Zhao Team|[2509.25916](http://arxiv.org/abs/2509.25916)|null|\n", "2509.25896": "|**2025-10-01**|**LLaVAShield: Safeguarding Multimodal Multi-Turn Dialogues in Vision-Language Models**|Yongjun Shen Team|[2509.25896](http://arxiv.org/abs/2509.25896)|null|\n", "2509.25866": "|**2025-09-30**|**DeepSketcher: Internalizing Visual Manipulation for Multimodal Reasoning**|Jing Zhang Team|[2509.25866](http://arxiv.org/abs/2509.25866)|null|\n", "2509.25863": "|**2025-09-30**|**MAPLE: Multi-scale Attribute-enhanced Prompt Learning for Few-shot Whole Slide Image Classification**|Daoqiang Zhang Team|[2509.25863](http://arxiv.org/abs/2509.25863)|null|\n", "2509.25852": "|**2025-09-30**|**Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation**|Hao Chen Team|[2509.25852](http://arxiv.org/abs/2509.25852)|null|\n", "2510.02292": "|**2025-10-02**|**From Behavioral Performance to Internal Competence: Interpreting Vision-Language Models with VLM-Lens**|Freda Shi Team|[2510.02292](http://arxiv.org/abs/2510.02292)|**[link](https://github.com/compling-wat/vlm-lens)**|\n", "2510.02270": "|**2025-10-02**|**microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for Fine-Grained Image Classification**|Muhammad Haris Khan Team|[2510.02270](http://arxiv.org/abs/2510.02270)|null|\n", "2510.02204": "|**2025-10-02**|**Say One Thing, Do Another? Diagnosing Reasoning-Execution Gaps in VLM-Powered Mobile-Use Agents**|Zhuosheng Zhang Team|[2510.02204](http://arxiv.org/abs/2510.02204)|null|\n", "2510.02186": "|**2025-10-02**|**GeoPurify: A Data-Efficient Geometric Distillation Framework for Open-Vocabulary 3D Segmentation**|Heng Tao Shen Team|[2510.02186](http://arxiv.org/abs/2510.02186)|null|\n", "2510.02155": "|**2025-10-02**|**Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting**|Jing Zhang Team|[2510.02155](http://arxiv.org/abs/2510.02155)|null|\n", "2510.01795": "|**2025-10-02**|**Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving**|Chun Jason Xue Team|[2510.01795](http://arxiv.org/abs/2510.01795)|null|\n", "2510.01718": "|**2025-10-02**|**Accelerating Attention with Basis Decomposition**|Jialin Zhao Team|[2510.01718](http://arxiv.org/abs/2510.01718)|null|\n", "2510.01711": "|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Jinwoo Shin Team|[2510.01711](http://arxiv.org/abs/2510.01711)|null|\n", "2510.01700": "|**2025-10-02**|**VaPR -- Vision-language Preference alignment for Reasoning**|Nanyun Peng Team|[2510.01700](http://arxiv.org/abs/2510.01700)|null|\n", "2510.01681": "|**2025-10-02**|**Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning**|Wentao Zhang Team|[2510.01681](http://arxiv.org/abs/2510.01681)|null|\n", "2510.01649": "|**2025-10-02**|**Source-Free Cross-Domain Continual Learning**|Kutluyil Dogancay Team|[2510.01649](http://arxiv.org/abs/2510.01649)|null|\n", "2510.01642": "|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Bihan Wen Team|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|\n", "2510.01582": "|**2025-10-02**|**ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models**|Murali Emani Team|[2510.01582](http://arxiv.org/abs/2510.01582)|null|\n", "2510.01494": "|**2025-10-03**|**Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed**|Sanmi Koyejo Team|[2510.01494](http://arxiv.org/abs/2510.01494)|null|\n", "2510.01483": "|**2025-10-01**|**VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs**|Gonzalo Ferrer Team|[2510.01483](http://arxiv.org/abs/2510.01483)|null|\n", "2510.01454": "|**2025-10-01**|**Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories**|Baharan Mirzasoleiman Team|[2510.01454](http://arxiv.org/abs/2510.01454)|**[link](https://bigml-cs-ucla.github.io/XMAS-project-page/)**|\n", "2510.01448": "|**2025-10-01**|**GeoSURGE: Geo-localization using Semantic Fusion with Hierarchy of Geographic Embeddings**|Rakesh Kumar Team|[2510.01448](http://arxiv.org/abs/2510.01448)|null|\n", "2510.01388": "|**2025-10-01**|**VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation**|Amirreza Shaban Team|[2510.01388](http://arxiv.org/abs/2510.01388)|null|\n", "2510.01185": "|**2025-10-01**|**Dirichlet-Prior Shaping: Guiding Expert Specialization in Upcycled MoEs**|Paul Whatmough Team|[2510.01185](http://arxiv.org/abs/2510.01185)|null|\n", "2510.01304": "|**2025-10-01**|**Agentic Jigsaw Interaction Learning for Enhancing Visual Perception and Reasoning in Vision-Language Models**|Feng Zhao Team|[2510.01304](http://arxiv.org/abs/2510.01304)|null|\n", "2510.03182": "|**2025-10-03**|**Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning**|Yang Zhang Team|[2510.03182](http://arxiv.org/abs/2510.03182)|null|\n", "2510.03160": "|**2025-10-03**|**SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus**|Caifeng Shan Team|[2510.03160](http://arxiv.org/abs/2510.03160)|null|\n", "2510.02922": "|**2025-10-03**|**Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights**|Konstantina Nikita Team|[2510.02922](http://arxiv.org/abs/2510.02922)|null|\n", "2510.02913": "|**2025-10-03**|**Zero-Shot Robustness of Vision Language Models Via Confidence-Aware Weighting**|Mostafa Tavassolipour Team|[2510.02913](http://arxiv.org/abs/2510.02913)|null|\n", "2510.02815": "|**2025-10-03**|**Med-K2N: Flexible K-to-N Modality Translation for Medical Image Synthesis**|Xin Gao Team|[2510.02815](http://arxiv.org/abs/2510.02815)|null|\n", "2510.02790": "|**2025-10-03**|**MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding**|Yujiu Yang Team|[2510.02790](http://arxiv.org/abs/2510.02790)|null|\n", "2510.02787": "|**2025-10-03**|**OTR: Synthesizing Overlay Text Dataset for Text Removal**|Kota Yamaguchi Team|[2510.02787](http://arxiv.org/abs/2510.02787)|**[link](https://doi.org/10.1145/3746027.3758297)**|\n", "2510.02780": "|**2025-10-03**|**Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models**|Prahitha Movva Team|[2510.02780](http://arxiv.org/abs/2510.02780)|null|\n", "2510.02778": "|**2025-10-03**|**AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding**|Mohammed Bennamoun Team|[2510.02778](http://arxiv.org/abs/2510.02778)|null|\n", "2510.02750": "|**2025-10-03**|**Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models**|Zhen Lei Team|[2510.02750](http://arxiv.org/abs/2510.02750)|null|\n", "2510.02728": "|**2025-10-03**|**Team Xiaomi EV-AD VLA: Caption-Guided Retrieval System for Cross-Modal Drone Navigation -- Technical Report for IROS 2025 RoboSense Challenge Track 4**|Xiaoshuai Hao Team|[2510.02728](http://arxiv.org/abs/2510.02728)|null|\n", "2510.02677": "|**2025-10-03**|**ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks**|Bo Li Team|[2510.02677](http://arxiv.org/abs/2510.02677)|null|\n", "2510.02543": "|**2025-10-02**|**Exploring OCR-augmented Generation for Bilingual VQA**|Sunho Park Team|[2510.02543](http://arxiv.org/abs/2510.02543)|null|\n", "2510.02528": "|**2025-10-02**|**Multimodal Function Vectors for Spatial Relations**|Hongjing Lu Team|[2510.02528](http://arxiv.org/abs/2510.02528)|null|\n", "2510.05038": "|**2025-10-06**|**Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization**|Ariel Gera Team|[2510.05038](http://arxiv.org/abs/2510.05038)|null|\n", "2510.04991": "|**2025-10-06**|**Efficient Navigation in Unknown Indoor Environments with Vision-Language Models**|J. P. How Team|[2510.04991](http://arxiv.org/abs/2510.04991)|null|\n", "2510.04710": "|**2025-10-06**|**ViTs: Teaching Machines to See Time Series Anomalies Like Human Experts**|Dan Pei Team|[2510.04710](http://arxiv.org/abs/2510.04710)|null|\n", "2510.04564": "|**2025-10-06**|**Conditional Representation Learning for Customized Tasks**|Xi Peng Team|[2510.04564](http://arxiv.org/abs/2510.04564)|null|\n", "2510.04532": "|**2025-10-06**|**More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models**|Jun Luo Team|[2510.04532](http://arxiv.org/abs/2510.04532)|null|\n", "2510.04479": "|**2025-10-06**|**VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery**|Hao Tang Team|[2510.04479](http://arxiv.org/abs/2510.04479)|null|\n", "2510.04477": "|**2025-10-06**|**MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models**|Gyeongyeon Hwang Team|[2510.04477](http://arxiv.org/abs/2510.04477)|null|\n", "2510.04428": "|**2025-10-06**|**A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame Selection For Video Question Answering**|Chen Chen Team|[2510.04428](http://arxiv.org/abs/2510.04428)|null|\n", "2510.04401": "|**2025-10-06**|**Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting**|Jiahao Zhang Team|[2510.04401](http://arxiv.org/abs/2510.04401)|null|\n", "2510.04257": "|**2025-10-05**|**AgentTypo: Adaptive Typographic Prompt Injection Attacks against Black-box Multimodal Agents**|Bin Xiao Team|[2510.04257](http://arxiv.org/abs/2510.04257)|null|\n", "2510.04246": "|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Jinwoo Shin Team|[2510.04246](http://arxiv.org/abs/2510.04246)|**[link](https://huiwon-jang.github.io/contextvla)**|\n", "2510.04225": "|**2025-10-05**|**Zoom-In to Sort AI-Generated Images Out**|Jianfu Zhang Team|[2510.04225](http://arxiv.org/abs/2510.04225)|null|\n", "2510.04145": "|**2025-10-05**|**Automating construction safety inspections using a multi-modal vision-language RAG framework**|Daniel Dias-da-Costa Team|[2510.04145](http://arxiv.org/abs/2510.04145)|null|\n", "2510.04002": "|**2025-10-07**|**AgriGPT-VL: Agricultural Vision-Language Understanding Suite**|Shijian Li Team|[2510.04002](http://arxiv.org/abs/2510.04002)|null|\n", "2510.03978": "|**2025-10-04**|**No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models**|Serena Yeung-Levy Team|[2510.03978](http://arxiv.org/abs/2510.03978)|null|\n", "2510.03903": "|**2025-10-04**|**Zero-Shot Fine-Grained Image Classification Using Large Vision-Language Models**|Chris Thomas Team|[2510.03903](http://arxiv.org/abs/2510.03903)|null|\n", "2510.03896": "|**2025-10-04**|**Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert**|Chunhua Shen Team|[2510.03896](http://arxiv.org/abs/2510.03896)|null|\n", "2510.03840": "|**2025-10-04**|**Mirage: Unveiling Hidden Artifacts in Synthetic Images with Large Vision-Language Models**|Durga Toshniwal Team|[2510.03840](http://arxiv.org/abs/2510.03840)|null|\n", "2510.03721": "|**2025-10-04**|**Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models**|Zeynep Akata Team|[2510.03721](http://arxiv.org/abs/2510.03721)|null|\n", "2510.03666": "|**2025-10-04**|**MonitorVLM:A Vision Language Framework for Safety Violation Detection in Mining Operations**|Jingliang Duan Team|[2510.03666](http://arxiv.org/abs/2510.03666)|null|\n", "2510.06067": "|**2025-10-07**|**Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA**|Junfeng Yang Team|[2510.06067](http://arxiv.org/abs/2510.06067)|null|\n", "2510.06064": "|**2025-10-07**|**Medical Vision Language Models as Policies for Robotic Surgery**|Martin Radfar Team|[2510.06064](http://arxiv.org/abs/2510.06064)|null|\n", "2510.05722": "|**2025-10-07**|**Data Factory with Minimal Human Effort Using VLMs**|Andrew Markham Team|[2510.05722](http://arxiv.org/abs/2510.05722)|null|\n", "2510.05544": "|**2025-10-07**|**Activation-Informed Pareto-Guided Low-Rank Compression for Efficient LLM/VLM**|Zheng Zhang Team|[2510.05544](http://arxiv.org/abs/2510.05544)|null|\n", "2510.07181": "|**2025-10-09**|**TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics**|Shanghang Zhang Team|[2510.07181](http://arxiv.org/abs/2510.07181)|null|\n", "2510.07135": "|**2025-10-08**|**Few-Shot Adaptation Benchmark for Remote Sensing Vision-Language Models**|Benoit Macq Team|[2510.07135](http://arxiv.org/abs/2510.07135)|null|\n", "2510.07098": "|**2025-10-08**|**TALENT: Table VQA via Augmented Language-Enhanced Natural-text Transcription**|Haoyu Wang Team|[2510.07098](http://arxiv.org/abs/2510.07098)|null|\n", "2510.07077": "|**2025-10-08**|**Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications**|Yuke Zhu Team|[2510.07077](http://arxiv.org/abs/2510.07077)|**[link](https://vla-survey.github.io)**|\n", "2510.07035": "|**2025-10-08**|**Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single and Paired Modality Integration**|Yuan Fang Team|[2510.07035](http://arxiv.org/abs/2510.07035)|null|\n", "2510.06790": "|**2025-10-08**|**Get RICH or Die Scaling: Profitably Trading Inference Compute for Robustness**|Brian Bartoldson Team|[2510.06790](http://arxiv.org/abs/2510.06790)|null|\n", "2510.06783": "|**2025-10-08**|**TTRV: Test-Time Reinforcement Learning for Vision Language Models**|M. Jehanzeb Mirza Team|[2510.06783](http://arxiv.org/abs/2510.06783)|null|\n", "2510.06664": "|**2025-10-08**|**ToolMem: Enhancing Multimodal Agents with Learnable Tool Capability Memory**|Zora Zhiruo Wang Team|[2510.06664](http://arxiv.org/abs/2510.06664)|null|\n", "2510.06529": "|**2025-10-08**|**VUGEN: Visual Understanding priors for GENeration**|Jakob Verbeek Team|[2510.06529](http://arxiv.org/abs/2510.06529)|null|\n", "2510.06292": "|**2025-10-07**|**ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations**|Yujun Cai Team|[2510.06292](http://arxiv.org/abs/2510.06292)|null|\n", "2510.06280": "|**2025-10-06**|**Surgeons Are Indian Males and Speech Therapists Are White Females: Auditing Biases in Vision-Language Models for Healthcare Professionals**|Beenish Moalla Chaudhry Team|[2510.06280](http://arxiv.org/abs/2510.06280)|null|\n", "2510.08567": "|**2025-10-09**|**MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning**|Salman Khan Team|[2510.08567](http://arxiv.org/abs/2510.08567)|null|\n", "2510.08531": "|**2025-10-09**|**SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models**|Yueting Zhuang Team|[2510.08531](http://arxiv.org/abs/2510.08531)|**[link](https://zju-real.github.io/SpatialLadder/)**|\n", "2510.08510": "|**2025-10-09**|**To Sink or Not to Sink: Visual Information Pathways in Large Vision-Language Models**|Leonid Sigal Team|[2510.08510](http://arxiv.org/abs/2510.08510)|**[link](https://davidhalladay.github.io/diysink_demo)**|\n", "2510.08508": "|**2025-10-09**|**MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration**|Guangtao Zhai Team|[2510.08508](http://arxiv.org/abs/2510.08508)|null|\n", "2510.08482": "|**2025-10-09**|**The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping**|Esam Ghaleb Team|[2510.08482](http://arxiv.org/abs/2510.08482)|null|\n", "2510.08470": "|**2025-10-09**|**Looking to Learn: Token-wise Dynamic Gating for Low-Resource Vision-Language Modelling**|Paula Buttery Team|[2510.08470](http://arxiv.org/abs/2510.08470)|null|\n", "2510.08398": "|**2025-10-09**|**VideoVerse: How Far is Your T2V Generator from a World Model?**|Lei Zhang Team|[2510.08398](http://arxiv.org/abs/2510.08398)|null|\n", "2510.08352": "|**2025-10-09**|**Evaluating Small Vision-Language Models on Distance-Dependent Traffic Perception**|Ciaran Eising Team|[2510.08352](http://arxiv.org/abs/2510.08352)|null|\n", "2510.08238": "|**2025-10-09**|**Chain-of-Trigger: An Agentic Backdoor that Paradoxically Enhances Agentic Robustness**|Hai Zhao Team|[2510.08238](http://arxiv.org/abs/2510.08238)|null|\n", "2510.08132": "|**2025-10-09**|**Approximate Domain Unlearning for Vision-Language Models**|Go Irie Team|[2510.08132](http://arxiv.org/abs/2510.08132)|null|\n", "2510.08003": "|**2025-10-09**|**CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning**|Rongrong Ji Team|[2510.08003](http://arxiv.org/abs/2510.08003)|null|\n", "2510.07975": "|**2025-10-09**|**Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation**|Jianhua Sun Team|[2510.07975](http://arxiv.org/abs/2510.07975)|null|\n", "2510.07809": "|**2025-10-09**|**Effective and Stealthy One-Shot Jailbreaks on Deployed Mobile Vision-Language Agents**|Jun Zhu Team|[2510.07809](http://arxiv.org/abs/2510.07809)|null|\n", "2510.07791": "|**2025-10-09**|**GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models**|Long Zeng Team|[2510.07791](http://arxiv.org/abs/2510.07791)|null|\n", "2510.07778": "|**2025-10-09**|**IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction**|Liqiang Nie Team|[2510.07778](http://arxiv.org/abs/2510.07778)|null|\n", "2510.07709": "|**2025-10-09**|**Multimodal Safety Evaluation in Generative Agent Social Simulations**|Bernard Ghanem Team|[2510.07709](http://arxiv.org/abs/2510.07709)|null|\n", "2510.07632": "|**2025-10-09**|**Test-Time Matching: Unlocking Compositional Reasoning in Multimodal Models**|Fuzhi Tang Team|[2510.07632](http://arxiv.org/abs/2510.07632)|null|\n", "2510.07567": "|**2025-10-08**|**Cross-Modal Attention Guided Unlearning in Vision-Language Models**|Xintao Wu Team|[2510.07567](http://arxiv.org/abs/2510.07567)|null|\n", "2510.07545": "|**2025-10-08**|**Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices**|Jimmy Huang Team|[2510.07545](http://arxiv.org/abs/2510.07545)|null|\n", "2510.09608": "|**2025-10-10**|**StreamingVLM: Real-Time Understanding for Infinite Video Streams**|Song Han Team|[2510.09608](http://arxiv.org/abs/2510.09608)|null|\n", "2510.09607": "|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Caifeng Shan Team|[2510.09607](http://arxiv.org/abs/2510.09607)|**[link](https://ltbai.github.io/VITA-VLA/)**|\n", "2510.09586": "|**2025-10-10**|**Vision Language Models: A Survey of 26K Papers**|Fengming Lin Team|[2510.09586](http://arxiv.org/abs/2510.09586)|null|\n", "2510.09473": "|**2025-10-10**|**D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models**|Wonjun Hwang Team|[2510.09473](http://arxiv.org/abs/2510.09473)|null|\n", "2510.09358": "|**2025-10-10**|**Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models**|Jiao Ran Team|[2510.09358](http://arxiv.org/abs/2510.09358)|**[link](https://github.com/bytedance/DynamicCoT)**|\n", "2510.09285": "|**2025-10-10**|**Spotlight on Token Perception for Multimodal Reinforcement Learning**|Yu Cheng Team|[2510.09285](http://arxiv.org/abs/2510.09285)|**[link](https://github.com/huaixuheqing/VPPO-RL)**|\n", "2510.09256": "|**2025-10-10**|**Hallucination Filtering in Radiology Vision-Language Models Using Discrete Semantic Entropy**|Daniel Truhn Team|[2510.09256](http://arxiv.org/abs/2510.09256)|**[link](https://github.com/TruhnLab/VisionSemanticEntropy)**|\n", "2510.09253": "|**2025-10-10**|**Zero-shot image privacy classification with Vision-Language Models**|Andrea Cavallaro Team|[2510.09253](http://arxiv.org/abs/2510.09253)|null|\n", "2510.09228": "|**2025-10-10**|**Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation**|Subrahmanyam Murala Team|[2510.09228](http://arxiv.org/abs/2510.09228)|null|\n", "2510.09078": "|**2025-10-10**|**MCMC: Bridging Rendering, Optimization and Generative AI**|Wenzel Jakob Team|[2510.09078](http://arxiv.org/abs/2510.09078)|null|\n", "2510.09008": "|**2025-10-10**|**On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models**|Se Young Chun Team|[2510.09008](http://arxiv.org/abs/2510.09008)|null|\n", "2510.08964": "|**2025-10-10**|**Unleashing Perception-Time Scaling to Multimodal Reasoning Models**|Minghui Qiu Team|[2510.08964](http://arxiv.org/abs/2510.08964)|null|\n", "2510.08919": "|**2025-10-10**|**PHyCLIP: $\\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning**|Takashi Matsubara Team|[2510.08919](http://arxiv.org/abs/2510.08919)|null|\n", "2510.08851": "|**2025-10-09**|**CDE: Concept-Driven Exploration for Reinforcement Learning**|Joseph Campbell Team|[2510.08851](http://arxiv.org/abs/2510.08851)|null|\n", "2510.08849": "|**2025-10-09**|**FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation**|Zhihua Wei Team|[2510.08849](http://arxiv.org/abs/2510.08849)|null|\n", "2510.08818": "|**2025-10-09**|**D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition**|Yun Fu Team|[2510.08818](http://arxiv.org/abs/2510.08818)|null|\n", "2510.08789": "|**2025-10-09**|**Q-Router: Agentic Video Quality Assessment with Expert Model Routing and Artifact Localization**|Zhengzhong Tu Team|[2510.08789](http://arxiv.org/abs/2510.08789)|null|\n", "2510.11718": "|**2025-10-13**|**CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images**|Xihui Liu Team|[2510.11718](http://arxiv.org/abs/2510.11718)|null|\n", "2510.11689": "|**2025-10-13**|**Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation**|Mac Schwager Team|[2510.11689](http://arxiv.org/abs/2510.11689)|null|\n", "2510.11631": "|**2025-10-13**|**EvoCAD: Evolutionary CAD Code Generation with Vision Language Models**|Niki van Stein Team|[2510.11631](http://arxiv.org/abs/2510.11631)|null|\n", "2510.11520": "|**2025-10-13**|**mmWalk: Towards Multi-modal Multi-view Walking Assistance**|Rainer Stiefelhagen Team|[2510.11520](http://arxiv.org/abs/2510.11520)|**[link](https://github.com/KediYing/mmWalk)**|\n", "2510.11456": "|**2025-10-13**|**Coupled Degradation Modeling and Fusion: A VLM-Guided Degradation-Coupled Network for Degradation-Aware Infrared and Visible Image Fusion**|Guangmang Cui Team|[2510.11456](http://arxiv.org/abs/2510.11456)|null|\n", "2510.11314": "|**2025-10-13**|**Template-Based Text-to-Image Alignment for Language Accessibility: A Study on Visualizing Text Simplifications**|Yingqiang Gao Team|[2510.11314](http://arxiv.org/abs/2510.11314)|null|\n", "2510.11302": "|**2025-10-13**|**When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models**|Samer Al-Hamadani Team|[2510.11302](http://arxiv.org/abs/2510.11302)|null|\n", "2510.11296": "|**2025-10-13**|**$\u0394\\mathrm{Energy}$: Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization**|Nanyang Ye Team|[2510.11296](http://arxiv.org/abs/2510.11296)|null|\n", "2510.11295": "|**2025-10-13**|**Human Uncertainty-Aware Data Selection and Automatic Labeling in Visual Question Answering**|Thomas Seidl Team|[2510.11295](http://arxiv.org/abs/2510.11295)|null|\n", "2510.11196": "|**2025-10-13**|**Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations**|Keno K. Bressem Team|[2510.11196](http://arxiv.org/abs/2510.11196)|null|\n", "2510.11178": "|**2025-10-13**|**BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models**|Roy Ka-Wei Lee Team|[2510.11178](http://arxiv.org/abs/2510.11178)|null|\n", "2510.11027": "|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Zhi Hou Team|[2510.11027](http://arxiv.org/abs/2510.11027)|null|\n", "2510.11020": "|**2025-10-13**|**GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation**|Jing Zhang Team|[2510.11020](http://arxiv.org/abs/2510.11020)|null|\n", "2510.11012": "|**2025-10-13**|**COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models**|Aidong Zhang Team|[2510.11012](http://arxiv.org/abs/2510.11012)|null|\n", "2510.10982": "|**2025-10-13**|**Catch-Only-One: Non-Transferable Examples for Model-Specific Authorization**|Guangdong Bai Team|[2510.10982](http://arxiv.org/abs/2510.10982)|null|\n", "2510.10973": "|**2025-10-13**|**Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning**|Aidong Zhang Team|[2510.10973](http://arxiv.org/abs/2510.10973)|null|\n", "2510.10969": "|**2025-10-13**|**IUT-Plug: A Plug-in tool for Interleaved Image-Text Generation**|Jing Tang Team|[2510.10969](http://arxiv.org/abs/2510.10969)|null|\n", "2510.10962": "|**2025-10-13**|**MC#: Mixture Compressor for Mixture-of-Experts Large Models**|Xiaojuan Qi Team|[2510.10962](http://arxiv.org/abs/2510.10962)|null|\n", "2510.10921": "|**2025-10-13**|**FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model**|Yuhui Yin Team|[2510.10921](http://arxiv.org/abs/2510.10921)|null|\n", "2510.10889": "|**2025-10-13**|**Topological Alignment of Shared Vision-Language Embedding Space**|Jae-Hun Jung Team|[2510.10889](http://arxiv.org/abs/2510.10889)|null|\n", "2510.12789": "|**2025-10-14**|**UniFusion: Vision-Language Model as Unified Encoder in Image Generation**|Ajinkya Kale Team|[2510.12789](http://arxiv.org/abs/2510.12789)|**[link](https://thekevinli.github.io/unifusion/)**|\n", "2510.12709": "|**2025-10-15**|**SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model**|Chao Feng Team|[2510.12709](http://arxiv.org/abs/2510.12709)|null|\n", "2510.12693": "|**2025-10-14**|**ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning**|Tong Zhang Team|[2510.12693](http://arxiv.org/abs/2510.12693)|null|\n", "2510.12548": "|**2025-10-14**|**VISaGE: Understanding Visual Generics and Exceptions**|Emily Allaway Team|[2510.12548](http://arxiv.org/abs/2510.12548)|null|\n", "2510.12444": "|**2025-10-14**|**A Review of Longitudinal Radiology Report Generation: Dataset Composition, Methods, and Performance Evaluation**|Luping Zhou Team|[2510.12444](http://arxiv.org/abs/2510.12444)|null|\n", "2510.12400": "|**2025-10-14**|**Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda**|Nuno F. Rodrigues Team|[2510.12400](http://arxiv.org/abs/2510.12400)|null|\n", "2510.12287": "|**2025-10-14**|**Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector**|Yiwei Wang Team|[2510.12287](http://arxiv.org/abs/2510.12287)|null|\n", "2510.12276": "|**2025-10-14**|**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**|Haoang Li Team|[2510.12276](http://arxiv.org/abs/2510.12276)|null|\n", "2510.12225": "|**2025-10-14**|**HoneyBee: Data Recipes for Vision-Language Reasoners**|Ramakanth Pasunuru Team|[2510.12225](http://arxiv.org/abs/2510.12225)|null|\n", "2510.12190": "|**2025-10-14**|**Hierarchical Reasoning with Vision-Language Models for Incident Reports from Dashcam Videos**|Yu Yamaguchi Team|[2510.12190](http://arxiv.org/abs/2510.12190)|null|\n", "2510.12119": "|**2025-10-14**|**ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval-Augmented Image Generation**|Renjie Wan Team|[2510.12119](http://arxiv.org/abs/2510.12119)|null|\n", "2510.12014": "|**2025-10-13**|**Embedding the Teacher: Distilling vLLM Preferences for Scalable Image Retrieval**|Vyas Raina Team|[2510.12014](http://arxiv.org/abs/2510.12014)|null|\n", "2510.11978": "|**2025-10-13**|**Learning Dynamics of VLM Finetuning**|Keze Wang Team|[2510.11978](http://arxiv.org/abs/2510.11978)|null|\n", "2510.11852": "|**2025-10-13**|**Evaluating Open-Source Vision-Language Models for Multimodal Sarcasm Detection**|Marcos Zampieri Team|[2510.11852](http://arxiv.org/abs/2510.11852)|**[link](https://icdmw25mmai.github.io/)**|\n", "2510.11835": "|**2025-10-13**|**Data or Language Supervision: What Makes CLIP Better than DINO?**|Serena Yeung-Levy Team|[2510.11835](http://arxiv.org/abs/2510.11835)|null|\n", "2510.13808": "|**2025-10-15**|**VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models**|Srijan Das Team|[2510.13808](http://arxiv.org/abs/2510.13808)|null|\n", "2510.13804": "|**2025-10-15**|**Generative Universal Verifier as Multimodal Meta-Reasoner**|Yujiu Yang Team|[2510.13804](http://arxiv.org/abs/2510.13804)|null|\n", "2510.13394": "|**2025-10-15**|**Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models**|Xiaowei Huang Team|[2510.13394](http://arxiv.org/abs/2510.13394)|null|\n", "2510.13375": "|**2025-10-15**|**DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning**|Hang Zhao Team|[2510.13375](http://arxiv.org/abs/2510.13375)|null|\n", "2510.13364": "|**2025-10-15**|**Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity**|Jubal Chandy Jacob Team|[2510.13364](http://arxiv.org/abs/2510.13364)|null|\n", "2510.13359": "|**2025-10-15**|**Improving Visual Recommendation on E-commerce Platforms Using Vision-Language Models**|Andre Rusli Team|[2510.13359](http://arxiv.org/abs/2510.13359)|null|\n", "2510.13315": "|**2025-10-15**|**Self-Augmented Visual Contrastive Decoding**|Vivek Gupta Team|[2510.13315](http://arxiv.org/abs/2510.13315)|null|\n", "2510.13276": "|**2025-10-15**|**MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models**|Min Zhang Team|[2510.13276](http://arxiv.org/abs/2510.13276)|null|\n", "2510.13251": "|**2025-10-15**|**Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs**|Bohyung Han Team|[2510.13251](http://arxiv.org/abs/2510.13251)|null|\n", "2510.13232": "|**2025-10-15**|**What \"Not\" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging**|Hyunjung Shim Team|[2510.13232](http://arxiv.org/abs/2510.13232)|null|\n", "2510.13190": "|**2025-10-15**|**SHIELD: Classifier-Guided Prompting for Robust and Safer LVLMs**|Usman Naseem Team|[2510.13190](http://arxiv.org/abs/2510.13190)|null|\n", "2510.13108": "|**2025-10-15**|**DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models**|Jose M. Alvarez Team|[2510.13108](http://arxiv.org/abs/2510.13108)|null|\n", "2510.13054": "|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Fabio Ramos Team|[2510.13054](http://arxiv.org/abs/2510.13054)|null|\n", "2510.13016": "|**2025-10-14**|**SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding**|Thomas Seidl Team|[2510.13016](http://arxiv.org/abs/2510.13016)|null|\n", "2510.12992": "|**2025-10-14**|**UNCAP: Uncertainty-Guided Planning Using Natural Language Communication for Cooperative Autonomous Vehicles**|Ufuk Topcu Team|[2510.12992](http://arxiv.org/abs/2510.12992)|null|\n", "2510.12974": "|**2025-10-14**|**Scope: Selective Cross-modal Orchestration of Visual Perception Experts**|Perouz Taslakian Team|[2510.12974](http://arxiv.org/abs/2510.12974)|null|\n", "2510.12953": "|**2025-10-14**|**Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation**|Bo Du Team|[2510.12953](http://arxiv.org/abs/2510.12953)|null|\n", "2510.12931": "|**2025-10-14**|**Unifying Vision-Language Latents for Zero-label Image Caption Enhancement**|Woo Seong Chung Team|[2510.12931](http://arxiv.org/abs/2510.12931)|null|\n", "2510.14979": "|**2025-10-16**|**From Pixels to Words -- Towards Native Vision-Language Primitives at Scale**|Ziwei Liu Team|[2510.14979](http://arxiv.org/abs/2510.14979)|null|\n", "2510.14978": "|**2025-10-16**|**Learning an Image Editing Model without Image Editing Pairs**|Xun Huang Team|[2510.14978](http://arxiv.org/abs/2510.14978)|**[link](https://nupurkmr9.github.io/npedit/)**|\n", "2510.14968": "|**2025-10-16**|**RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks**|Jiachen Li Team|[2510.14968](http://arxiv.org/abs/2510.14968)|null|\n", "2510.14828": "|**2025-10-16**|**RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning**|Haoran Li Team|[2510.14828](http://arxiv.org/abs/2510.14828)|null|\n", "2510.14792": "|**2025-10-16**|**CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection**|Hyunjung Shim Team|[2510.14792](http://arxiv.org/abs/2510.14792)|null|\n", "2510.14737": "|**2025-10-16**|**Free-Grained Hierarchical Recognition**|Stella X. Yu Team|[2510.14737](http://arxiv.org/abs/2510.14737)|null|\n", "2510.14624": "|**2025-10-16**|**Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference**|Andrew Tao Team|[2510.14624](http://arxiv.org/abs/2510.14624)|null|\n", "2510.14583": "|**2025-10-16**|**Talking Points: Describing and Localizing Pixels**|Shai Avidan Team|[2510.14583](http://arxiv.org/abs/2510.14583)|null|\n", "2510.14543": "|**2025-10-16**|**Exploring Cross-Modal Flows for Few-Shot Learning**|Long Chen Team|[2510.14543](http://arxiv.org/abs/2510.14543)|null|\n", "2510.14528": "|**2025-10-17**|**PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model**|Yanjun Ma Team|[2510.14528](http://arxiv.org/abs/2510.14528)|**[link](https://github.com/PaddlePaddle/PaddleOCR)**|\n", "2510.14526": "|**2025-10-16**|**Noise Projection: Closing the Prompt-Agnostic Gap Behind Text-to-Image Misalignment in Diffusion Models**|Ziyu Zhao Team|[2510.14526](http://arxiv.org/abs/2510.14526)|null|\n", "2510.14388": "|**2025-10-16**|**Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control**|Yuanchun Shi Team|[2510.14388](http://arxiv.org/abs/2510.14388)|null|\n", "2510.14304": "|**2025-10-16**|**Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding**|Jinkyu Kim Team|[2510.14304](http://arxiv.org/abs/2510.14304)|**[link](https://github.com/KR-0822/TCD)**|\n", "2510.13993": "|**2025-10-15**|**Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models**|Miguel Arana-Catania Team|[2510.13993](http://arxiv.org/abs/2510.13993)|null|\n", "2510.15866": "|**2025-10-17**|**BiomedXPro: Prompt Optimization for Explainable Diagnosis with Biomedical Vision Language Models**|Damayanthi Herath Team|[2510.15866](http://arxiv.org/abs/2510.15866)|null|\n", "2510.15841": "|**2025-10-17**|**Neuro-Symbolic Spatial Reasoning in Segmentation**|Shaogang Gong Team|[2510.15841](http://arxiv.org/abs/2510.15841)|null|\n", "2510.15430": "|**2025-10-17**|**Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models**|Xiting Wang Team|[2510.15430](http://arxiv.org/abs/2510.15430)|null|\n", "2510.15418": "|**2025-10-17**|**Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs**|Goh Man Fye Team|[2510.15418](http://arxiv.org/abs/2510.15418)|null|\n", "2510.15349": "|**2025-10-17**|**Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing**|Yuan Qi Team|[2510.15349](http://arxiv.org/abs/2510.15349)|null|\n", "2510.17800": "|**2025-10-21**|**Glyph: Scaling Context Windows via Visual-Text Compression**|Minlie Huang Team|[2510.17800](http://arxiv.org/abs/2510.17800)|null|\n", "2510.17777": "|**2025-10-20**|**SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference**|Zhijian Liu Team|[2510.17777](http://arxiv.org/abs/2510.17777)|null|\n", "2510.17771": "|**2025-10-20**|**Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs**|Hanghang Tong Team|[2510.17771](http://arxiv.org/abs/2510.17771)|null|\n", "2510.17759": "|**2025-10-20**|**VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models**|Ruqi Zhang Team|[2510.17759](http://arxiv.org/abs/2510.17759)|null|\n", "2510.17651": "|**2025-10-20**|**Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs**|Rachid Chelouah Team|[2510.17651](http://arxiv.org/abs/2510.17651)|null|\n", "2510.17633": "|**2025-10-20**|**SARSteer: Safeguarding Large Audio Language Models via Safe-Ablated Refusal Steering**|Li Liu Team|[2510.17633](http://arxiv.org/abs/2510.17633)|null|\n", "2510.17590": "|**2025-10-20**|**MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning**|Adiba Mahbub Proma Team|[2510.17590](http://arxiv.org/abs/2510.17590)|null|\n", "2510.17354": "|**2025-10-20**|**Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation**|Zhicheng Dou Team|[2510.17354](http://arxiv.org/abs/2510.17354)|null|\n", "2510.17313": "|**2025-10-20**|**Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations**|Omri Azencot Team|[2510.17313](http://arxiv.org/abs/2510.17313)|null|\n", "2510.17269": "|**2025-10-20**|**FineVision: Open Data Is All You Need**|Andr\u00e9s Marafioti Team|[2510.17269](http://arxiv.org/abs/2510.17269)|null|\n", "2510.17197": "|**2025-10-20**|**ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models**|Guoming Tang Team|[2510.17197](http://arxiv.org/abs/2510.17197)|null|\n", "2510.17191": "|**2025-10-20**|**SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving**|Shaohua Wu Team|[2510.17191](http://arxiv.org/abs/2510.17191)|null|\n", "2510.17150": "|**2025-10-20**|**OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation**|Arash Ajoudani Team|[2510.17150](http://arxiv.org/abs/2510.17150)|**[link](https://sites.google.com/view/omni-vic})**|\n", "2510.17111": "|**2025-10-20**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Jian Cheng Team|[2510.17111](http://arxiv.org/abs/2510.17111)|null|\n", "2510.17034": "|**2025-10-19**|**Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding**|Yutong Zhong Team|[2510.17034](http://arxiv.org/abs/2510.17034)|null|\n", "2510.16924": "|**2025-10-19**|**Does Visual Grounding Enhance the Understanding of Embodied Knowledge in Large Language Models?**|Renfen Hu Team|[2510.16924](http://arxiv.org/abs/2510.16924)|null|\n", "2510.16907": "|**2025-10-19**|**VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents**|Manling Li Team|[2510.16907](http://arxiv.org/abs/2510.16907)|null|\n", "2510.16870": "|**2025-10-19**|**Uncovering Brain-Like Hierarchical Patterns in Vision-Language Models through fMRI-Based Neural Encoding**|Xiaowei He Team|[2510.16870](http://arxiv.org/abs/2510.16870)|null|\n", "2510.16772": "|**2025-10-19**|**Region in Context: Text-condition Image editing with Human-like semantic reasoning**|Phan Xuan Tan Team|[2510.16772](http://arxiv.org/abs/2510.16772)|null|\n", "2510.16769": "|**2025-10-19**|**See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models**|Xike Xie Team|[2510.16769](http://arxiv.org/abs/2510.16769)|null|\n", "2510.18873": "|**2025-10-21**|**DSI-Bench: A Benchmark for Dynamic Spatial Intelligence**|Zhou Zhao Team|[2510.18873](http://arxiv.org/abs/2510.18873)|null|\n", "2510.18837": "|**2025-10-21**|**FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning**|Jagath C. Rajapakse Team|[2510.18837](http://arxiv.org/abs/2510.18837)|null|\n", "2510.18751": "|**2025-10-21**|**Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation**|Elvis Hsieh Team|[2510.18751](http://arxiv.org/abs/2510.18751)|null|\n", "2510.18703": "|**2025-10-21**|**Exploring a Unified Vision-Centric Contrastive Alternatives on Multi-Modal Web Documents**|Mike Zheng Shou Team|[2510.18703](http://arxiv.org/abs/2510.18703)|**[link](https://linyq17.github.io/VC2L/)**|\n", "2510.18632": "|**2025-10-21**|**Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views**|Ruqi Huang Team|[2510.18632](http://arxiv.org/abs/2510.18632)|null|\n", "2510.18596": "|**2025-10-21**|**CUARewardBench: A Benchmark for Evaluating Reward Models on Computer-using Agent**|Xing Sun Team|[2510.18596](http://arxiv.org/abs/2510.18596)|null|\n", "2510.18583": "|**2025-10-21**|**CovMatch: Cross-Covariance Guided Multimodal Dataset Distillation with Trainable Text Encoder**|Hye Won Chung Team|[2510.18583](http://arxiv.org/abs/2510.18583)|null|\n", "2510.18502": "|**2025-10-21**|**Zero-Shot Vehicle Model Recognition via Text-Based Retrieval-Augmented Generation**|Yan-Ann Chen Team|[2510.18502](http://arxiv.org/abs/2510.18502)|null|\n", "2510.18483": "|**2025-10-21**|**StarBench: A Turn-Based RPG Benchmark for Agentic Multimodal Decision-Making and Information Seeking**|Donglin Yu Team|[2510.18483](http://arxiv.org/abs/2510.18483)|null|\n", "2510.18439": "|**2025-10-21**|**Grounding or Guessing? Visual Signals for Detecting Hallucinations in Sign Language Translation**|Cristina Espa\u00f1a-Bonet Team|[2510.18439](http://arxiv.org/abs/2510.18439)|null|\n", "2510.18433": "|**2025-10-21**|**ImageGem: In-the-wild Generative Image Interaction Dataset for Generative Model Personalization**|Hongyi Wen Team|[2510.18433](http://arxiv.org/abs/2510.18433)|null|\n", "2510.18321": "|**2025-10-21**|**Beyond Single Models: Mitigating Multimodal Hallucinations via Adaptive Token Ensemble Decoding**|Xian Wu Team|[2510.18321](http://arxiv.org/abs/2510.18321)|null|\n", "2510.18269": "|**2025-10-21**|**StreamingTOM: Streaming Token Compression for Efficient Video Understanding**|Huan Wang Team|[2510.18269](http://arxiv.org/abs/2510.18269)|null|\n", "2510.18262": "|**2025-10-21**|**UWBench: A Comprehensive Vision-Language Benchmark for Underwater Understanding**|Xuelong Li Team|[2510.18262](http://arxiv.org/abs/2510.18262)|null|\n", "2510.18188": "|**2025-10-21**|**RadDiagSeg-M: A Vision Language Model for Joint Diagnosis and Multi-Target Segmentation in Radiology**|Bjoern Menze Team|[2510.18188](http://arxiv.org/abs/2510.18188)|null|\n", "2510.18117": "|**2025-10-20**|**Online In-Context Distillation for Low-Resource Vision Language Models**|Karteek Alahari Team|[2510.18117](http://arxiv.org/abs/2510.18117)|null|\n", "2510.18054": "|**2025-10-20**|**HouseTour: A Virtual Real Estate A(I)gent**|Iro Armeni Team|[2510.18054](http://arxiv.org/abs/2510.18054)|null|\n", "2510.18034": "|**2025-10-20**|**SAVANT: Semantic Analysis with Vision-Augmented Anomaly deTection**|Johannes Betz Team|[2510.18034](http://arxiv.org/abs/2510.18034)|null|\n", "2510.19818": "|**2025-10-22**|**Semantic World Models**|Abhishek Gupta Team|[2510.19818](http://arxiv.org/abs/2510.19818)|null|\n", "2510.19817": "|**2025-10-22**|**olmOCR 2: Unit Test Rewards for Document OCR**|Kyle Lo Team|[2510.19817](http://arxiv.org/abs/2510.19817)|**[link](https://olmocr.allen.ai/)**|\n", "2510.19802": "|**2025-10-22**|**Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models**|Xuelong Li Team|[2510.19802](http://arxiv.org/abs/2510.19802)|null|\n", "2510.19626": "|**2025-10-22**|**MedReason-R1: Learning to Reason for CT Diagnosis with Reinforcement Learning and Local Zoom**|Shaohua Kevin Zhou Team|[2510.19626](http://arxiv.org/abs/2510.19626)|**[link](https://github.com/Leevan001/MedReason-R1)**|\n", "2510.19599": "|**2025-10-22**|**XBench: A Comprehensive Benchmark for Visual-Language Explanations in Chest Radiography**|Mauricio Reyes Team|[2510.19599](http://arxiv.org/abs/2510.19599)|null|\n", "2510.19574": "|**2025-10-22**|**Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection**|Qiben Yan Team|[2510.19574](http://arxiv.org/abs/2510.19574)|null|\n", "2510.19559": "|**2025-10-22**|**A Matter of Time: Revealing the Structure of Time in Vision-Language Models**|Matthias Zeppelzauer Team|[2510.19559](http://arxiv.org/abs/2510.19559)|null|\n", "2510.19555": "|**2025-10-22**|**[De|Re]constructing VLMs' Reasoning in Counting**|Giuseppe Riccardi Team|[2510.19555](http://arxiv.org/abs/2510.19555)|null|\n", "2510.19496": "|**2025-10-22**|**CARES: Context-Aware Resolution Selector for VLMs**|Eli Schwartz Team|[2510.19496](http://arxiv.org/abs/2510.19496)|null|\n", "2510.19400": "|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Baining Guo Team|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|\n", "2510.19333": "|**2025-10-22**|**A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP**|Wei Yu Chen Team|[2510.19333](http://arxiv.org/abs/2510.19333)|null|\n", "2510.19307": "|**2025-10-22**|**Unified Reinforcement and Imitation Learning for Vision-Language Models**|Yueh-Hua Wu Team|[2510.19307](http://arxiv.org/abs/2510.19307)|**[link](https://byungkwanlee.github.io/RIL-page)**|\n", "2510.19268": "|**2025-10-22**|**Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models**|Changhyun Choi Team|[2510.19268](http://arxiv.org/abs/2510.19268)|null|\n", "2510.19160": "|**2025-10-22**|**Preliminary Use of Vision Language Model Driven Extraction of Mouse Behavior Towards Understanding Fear Expression**|Evangelos E. Papalexakis Team|[2510.19160](http://arxiv.org/abs/2510.19160)|null|\n", "2510.19060": "|**2025-10-21**|**PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions**|Kathleen McKeown Team|[2510.19060](http://arxiv.org/abs/2510.19060)|**[link](https://github.com/amith-ananthram/posh)**|\n", "2510.19001": "|**2025-10-21**|**Robust Driving QA through Metadata-Grounded Context and Task-Specific Prompts**|Hyunjung Shim Team|[2510.19001](http://arxiv.org/abs/2510.19001)|null|\n", "2510.20812": "|**2025-10-23**|**Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation**|Shengjie Wang Team|[2510.20812](http://arxiv.org/abs/2510.20812)|null|\n", "2510.20707": "|**2025-10-23**|**Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models**|Linfeng Zhang Team|[2510.20707](http://arxiv.org/abs/2510.20707)|**[link](https://github.com/xuyang-liu16/MixKV)**|\n", "2510.20696": "|**2025-10-23**|**Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward**|Chenliang Xu Team|[2510.20696](http://arxiv.org/abs/2510.20696)|null|\n", "2510.20639": "|**2025-10-23**|**Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging**|Bjoern Menze Team|[2510.20639](http://arxiv.org/abs/2510.20639)|null|\n", "2510.20477": "|**2025-10-23**|**Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models**|Lan-Zhe Guo Team|[2510.20477](http://arxiv.org/abs/2510.20477)|null|\n", "2510.20333": "|**2025-10-23**|**GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?**|Yingchun Wang Team|[2510.20333](http://arxiv.org/abs/2510.20333)|null|\n", "2510.20287": "|**2025-10-23**|**Breakdance Video classification in the age of Generative AI**|Michelle Munson Team|[2510.20287](http://arxiv.org/abs/2510.20287)|null|\n", "2510.20244": "|**2025-10-23**|**Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding**|Sangyoun Lee Team|[2510.20244](http://arxiv.org/abs/2510.20244)|null|\n", "2510.20229": "|**2025-10-23**|**Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context**|Sibei Yang Team|[2510.20229](http://arxiv.org/abs/2510.20229)|null|\n", "2510.19949": "|**2025-10-24**|**Surfer 2: The Next Generation of Cross-Platform Computer Use Agents**|Jevgenij Zubovskij Team|[2510.19949](http://arxiv.org/abs/2510.19949)|null|\n", "2510.21679": "|**2025-10-24**|**A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection**|Peter Henderson Team|[2510.21679](http://arxiv.org/abs/2510.21679)|null|\n", "2510.21606": "|**2025-10-24**|**Modest-Align: Data-Efficient Alignment for Vision-Language Models**|Zuozhu Liu Team|[2510.21606](http://arxiv.org/abs/2510.21606)|null|\n", "2510.21518": "|**2025-10-24**|**Head Pursuit: Probing Attention Specialization in Multimodal Transformers**|Alberto Cazzaniga Team|[2510.21518](http://arxiv.org/abs/2510.21518)|null|\n", "2510.21449": "|**2025-10-24**|**MoniTor: Exploiting Large Language Models with Instruction for Online Video Anomaly Detection**|Jie Qin Team|[2510.21449](http://arxiv.org/abs/2510.21449)|null|\n", "2510.21424": "|**2025-10-24**|**Vision Language Models for Dynamic Human Activity Recognition in Healthcare Settings**|Fakhri Karray Team|[2510.21424](http://arxiv.org/abs/2510.21424)|null|\n", "2510.21412": "|**2025-10-24**|**Bridging the gap to real-world language-grounded visual concept learning**|Seunghoon Hong Team|[2510.21412](http://arxiv.org/abs/2510.21412)|null|\n", "2510.21323": "|**2025-10-24**|**VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set**|Shuhui Wang Team|[2510.21323](http://arxiv.org/abs/2510.21323)|null|\n", "2510.21175": "|**2025-10-24**|**Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models**|Taesup Kim Team|[2510.21175](http://arxiv.org/abs/2510.21175)|null|\n", "2510.21121": "|**2025-10-24**|**Generalizable Hierarchical Skill Learning via Object-Centric Representation**|Robert Platt Team|[2510.21121](http://arxiv.org/abs/2510.21121)|null|\n", "2510.21120": "|**2025-10-24**|**SafetyPairs: Isolating Safety Critical Image Features with Counterfactual Image Generation**|Joseph Yitan Cheng Team|[2510.21120](http://arxiv.org/abs/2510.21120)|null|\n", "2510.21093": "|**2025-10-24**|**MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning**|Dong In Kim Team|[2510.21093](http://arxiv.org/abs/2510.21093)|null|\n", "2510.21083": "|**2025-10-24**|**Knowledge-Driven Vision-Language Model for Plexus Detection in Hirschsprung's Disease**|Adrian D. C. Chan Team|[2510.21083](http://arxiv.org/abs/2510.21083)|null|\n", "2510.21069": "|**2025-10-24**|**ZING-3D: Zero-shot Incremental 3D Scene Graphs via Vision-Language Models**|Jimmy Chiun Team|[2510.21069](http://arxiv.org/abs/2510.21069)|null|\n", "2510.20967": "|**2025-10-23**|**3DReasonKnee: Advancing Grounded Reasoning in Medical Vision Language Models**|Pranav Rajpurkar Team|[2510.20967](http://arxiv.org/abs/2510.20967)|null|\n", "2510.23571": "|**2025-10-27**|**RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation**|Katerina Fragkiadaki Team|[2510.23571](http://arxiv.org/abs/2510.23571)|**[link](https://robotarenainf.github.io)**|\n", "2510.23497": "|**2025-10-28**|**VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation**|Cordelia Schmid Team|[2510.23497](http://arxiv.org/abs/2510.23497)|null|\n", "2510.23482": "|**2025-10-27**|**On the Faithfulness of Visual Thinking: Measurement and Enhancement**|Guisong Xia Team|[2510.23482](http://arxiv.org/abs/2510.23482)|null|\n", "2510.23253": "|**2025-10-27**|**A Video Is Not Worth a Thousand Words**|Michael Wray Team|[2510.23253](http://arxiv.org/abs/2510.23253)|null|\n", "2510.23217": "|**2025-10-27**|**Process Reward Models for Sentence-Level Verification of LVLM Radiology Reports**|Curtis P. Langlotz Team|[2510.23217](http://arxiv.org/abs/2510.23217)|null|\n", "2510.23203": "|**2025-10-27**|**DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification**|Angelo Broere Team|[2510.23203](http://arxiv.org/abs/2510.23203)|null|\n", "2510.23190": "|**2025-10-27**|**Evaluation of Vision-LLMs in Surveillance Video**|Jelte P. Mense Team|[2510.23190](http://arxiv.org/abs/2510.23190)|null|\n", "2510.23184": "|**2025-10-27**|**Finding 3D Scene Analogies with Multimodal Foundation Models**|Young Min Kim Team|[2510.23184](http://arxiv.org/abs/2510.23184)|null|\n", "2510.23095": "|**2025-10-27**|**Revisiting Multimodal Positional Encoding in Vision-Language Models**|Shuai Bai Team|[2510.23095](http://arxiv.org/abs/2510.23095)|null|\n", "2510.23066": "|**2025-10-27**|**Multi-Stage Field Extraction of Financial Documents with OCR and Compact Vision-Language Models**|Donald MacDonald Team|[2510.23066](http://arxiv.org/abs/2510.23066)|null|\n", "2510.22975": "|**2025-10-27**|**VoMP: Predicting Volumetric Mechanical Property Fields**|Maria Shugrina Team|[2510.22975](http://arxiv.org/abs/2510.22975)|**[link](https://research.nvidia.com/labs/sil/projects/vomp)**|\n", "2510.22917": "|**2025-10-28**|**HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment**|Zhen Li Team|[2510.22917](http://arxiv.org/abs/2510.22917)|null|\n", "2510.22868": "|**2025-10-26**|**Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models**|Jiong Tang Team|[2510.22868](http://arxiv.org/abs/2510.22868)|null|\n", "2510.22838": "|**2025-10-26**|**Semantic-Preserving Cross-Style Visual Reasoning for Robust Multi-Modal Understanding in Large Vision-Language Models**|Kaito Tanaka Team|[2510.22838](http://arxiv.org/abs/2510.22838)|null|\n", "2510.22798": "|**2025-10-26**|**VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions**|Taehwan Kim Team|[2510.22798](http://arxiv.org/abs/2510.22798)|**[link](https://vehme.github.io/)**|\n", "2510.22785": "|**2025-10-26**|**Self-Calibrated Consistency can Fight Back for Adversarial Robustness in Vision-Language Models**|Mingkun Xu Team|[2510.22785](http://arxiv.org/abs/2510.22785)|null|\n", "2510.22768": "|**2025-10-26**|**MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion**|Chien-Sheng Wu Team|[2510.22768](http://arxiv.org/abs/2510.22768)|null|\n", "2510.22765": "|**2025-10-26**|**Jarvis: Towards Personalized AI Assistant via Personal KV-Cache Retrieval**|Wentao Zhang Team|[2510.22765](http://arxiv.org/abs/2510.22765)|null|\n", "2510.22728": "|**2025-10-26**|**S-Chain: Structured Visual Chain-of-Thought For Medicine**|Anh Totti Nguyen Team|[2510.22728](http://arxiv.org/abs/2510.22728)|null|\n", "2510.22702": "|**2025-10-26**|**Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally Calibrated Urban Development Monitoring**|Prathamesh Mayekar Team|[2510.22702](http://arxiv.org/abs/2510.22702)|null|\n", "2510.24650": "|**2025-10-28**|**Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning**|Arnold W. Schumann Team|[2510.24650](http://arxiv.org/abs/2510.24650)|null|\n", "2510.24411": "|**2025-10-28**|**OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows**|Lingpeng Kong Team|[2510.24411](http://arxiv.org/abs/2510.24411)|null|\n", "2510.24331": "|**2025-10-28**|**What do vision-language models see in the context? Investigating multimodal in-context learning**|Sandra Avila Team|[2510.24331](http://arxiv.org/abs/2510.24331)|null|\n", "2510.24321": "|**2025-10-28**|**Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning**|Ivan Kitanovski Team|[2510.24321](http://arxiv.org/abs/2510.24321)|null|\n", "2510.24285": "|**2025-10-28**|**ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model**|Rui Yan Team|[2510.24285](http://arxiv.org/abs/2510.24285)|null|\n", "2510.24242": "|**2025-10-28**|**Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models**|Yue Gao Team|[2510.24242](http://arxiv.org/abs/2510.24242)|null|\n", "2510.24180": "|**2025-10-28**|**V-SAT: Video Subtitle Annotation Tool**|Vishwanathan Raman Team|[2510.24180](http://arxiv.org/abs/2510.24180)|null|\n", "2510.24152": "|**2025-10-28**|**Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning**|Xubo Luo Team|[2510.24152](http://arxiv.org/abs/2510.24152)|null|\n", "2510.24133": "|**2025-10-28**|**Compositional Image Synthesis with Inference-Time Scaling**|Namhyuk Ahn Team|[2510.24133](http://arxiv.org/abs/2510.24133)|**[link](https://github.com/gcl-inha/ReFocus)**|\n", "2510.24115": "|**2025-10-28**|**HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology**|Vandita Singh Team|[2510.24115](http://arxiv.org/abs/2510.24115)|null|\n", "2510.24109": "|**2025-10-28**|**PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI**|Philip Dames Team|[2510.24109](http://arxiv.org/abs/2510.24109)|null|\n", "2510.24038": "|**2025-10-28**|**Enhancing CLIP Robustness via Cross-Modality Alignment**|Hanwang Zhang Team|[2510.24038](http://arxiv.org/abs/2510.24038)|null|\n", "2510.24010": "|**2025-10-28**|**Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks**|Hannah Kerner Team|[2510.24010](http://arxiv.org/abs/2510.24010)|null|\n", "2510.23968": "|**2025-10-28**|**Reasoning Visual Language Model for Chest X-Ray Analysis**|Daguang Xu Team|[2510.23968](http://arxiv.org/abs/2510.23968)|null|\n", "2510.23925": "|**2025-10-27**|**Latent Chain-of-Thought for Visual Reasoning**|Zhiqiang Tao Team|[2510.23925](http://arxiv.org/abs/2510.23925)|null|\n", "2510.23775": "|**2025-10-27**|**Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices**|Madesh Kuppusamy Team|[2510.23775](http://arxiv.org/abs/2510.23775)|null|\n", "2510.25682": "|**2025-10-30**|**PairUni: Pairwise Training for Unified Multimodal Language Models**|Zhuochen Wang Team|[2510.25682](http://arxiv.org/abs/2510.25682)|null|\n", "2510.25668": "|**2025-10-29**|**ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents**|Bela Gipp Team|[2510.25668](http://arxiv.org/abs/2510.25668)|null|\n", "2510.25616": "|**2025-10-29**|**Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization**|Aleksandr I. Panov Team|[2510.25616](http://arxiv.org/abs/2510.25616)|null|\n", "2510.25548": "|**2025-10-29**|**Using VLM Reasoning to Constrain Task and Motion Planning**|Zachary Kingston Team|[2510.25548](http://arxiv.org/abs/2510.25548)|null|\n", "2510.25413": "|**2025-10-29**|**Seeing, Signing, and Saying: A Vision-Language Model-Assisted Pipeline for Sign Language Data Acquisition and Curation from Social Media**|Josef van Genabith Team|[2510.25413](http://arxiv.org/abs/2510.25413)|null|\n", "2510.25191": "|**2025-10-29**|**SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning**|Wei Pan Team|[2510.25191](http://arxiv.org/abs/2510.25191)|null|\n", "2510.25179": "|**2025-10-29**|**Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models**|Usman Naseem Team|[2510.25179](http://arxiv.org/abs/2510.25179)|null|\n", "2510.25138": "|**2025-10-29**|**Learning Spatial-Aware Manipulation Ordering**|Jian Pu Team|[2510.25138](http://arxiv.org/abs/2510.25138)|null|\n", "2510.25122": "|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jinghui Lu Team|[2510.25122](http://arxiv.org/abs/2510.25122)|null|\n", "2510.25094": "|**2025-10-29**|**Visual Diversity and Region-aware Prompt Learning for Zero-shot HOI Detection**|Hyunwoo J. Kim Team|[2510.25094](http://arxiv.org/abs/2510.25094)|null|\n", "2510.25067": "|**2025-10-29**|**DRIP: Dynamic patch Reduction via Interpretable Pooling**|Sachin Kumar Team|[2510.25067](http://arxiv.org/abs/2510.25067)|null|\n", "2510.25032": "|**2025-10-28**|**Efficient License Plate Recognition via Pseudo-Labeled Supervision with Grounding DINO and YOLOv8**|Ching Yee Suen Team|[2510.25032](http://arxiv.org/abs/2510.25032)|null|\n", "2510.24949": "|**2025-10-28**|**SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving**|Mykel J. Kochenderfer Team|[2510.24949](http://arxiv.org/abs/2510.24949)|null|\n", "2510.24942": "|**2025-10-28**|**Finding Culture-Sensitive Neurons in Vision-Language Models**|Ivan Titov Team|[2510.24942](http://arxiv.org/abs/2510.24942)|null|\n", "2510.26781": "|**2025-11-03**|**ChartAB: A Benchmark for Chart Grounding & Dense Alignment**|Tianyi Zhou Team|[2510.26781](http://arxiv.org/abs/2510.26781)|null|\n", "2510.26769": "|**2025-10-30**|**SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models**|Chris Thomas Team|[2510.26769](http://arxiv.org/abs/2510.26769)|null|\n", "2510.26641": "|**2025-10-30**|**All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles**|Abolfazl Razi Team|[2510.26641](http://arxiv.org/abs/2510.26641)|null|\n", "2510.26474": "|**2025-10-30**|**Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing**|Xuanjing Huang Team|[2510.26474](http://arxiv.org/abs/2510.26474)|null|\n", "2510.26466": "|**2025-11-03**|**Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition**|ShengJun Huang Team|[2510.26466](http://arxiv.org/abs/2510.26466)|null|\n", "2510.26464": "|**2025-10-30**|**Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection**|Chengjie Wang Team|[2510.26464](http://arxiv.org/abs/2510.26464)|null|\n", "2510.26441": "|**2025-10-30**|**A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models**|Muhammad Haris Khan Team|[2510.26441](http://arxiv.org/abs/2510.26441)|null|\n", "2510.26411": "|**2025-10-30**|**MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders**|Marco Grangetto Team|[2510.26411](http://arxiv.org/abs/2510.26411)|null|\n", "2510.26271": "|**2025-10-30**|**Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual**|Peerat Limkonchotiwat Team|[2510.26271](http://arxiv.org/abs/2510.26271)|null|\n", "2510.26241": "|**2025-10-30**|**Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models**|Shigeru Kitazawa Team|[2510.26241](http://arxiv.org/abs/2510.26241)|null|\n", "2510.26151": "|**2025-10-30**|**MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction**|Ali Diba Team|[2510.26151](http://arxiv.org/abs/2510.26151)|null|\n", "2510.26098": "|**2025-10-30**|**GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks**|Qing Li Team|[2510.26098](http://arxiv.org/abs/2510.26098)|null|\n", "2510.26052": "|**2025-10-30**|**Dynamic VLM-Guided Negative Prompting for Diffusion Models**|Yoonseok Choi Team|[2510.26052](http://arxiv.org/abs/2510.26052)|null|\n", "2510.26006": "|**2025-10-29**|**CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments**|Antoine Bosselut Team|[2510.26006](http://arxiv.org/abs/2510.26006)|null|\n", "2510.27680": "|**2025-10-31**|**PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting**|Tyler J. Bradshaw Team|[2510.27680](http://arxiv.org/abs/2510.27680)|null|\n", "2510.27606": "|**2025-10-31**|**Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning**|Jiaqi Wang Team|[2510.27606](http://arxiv.org/abs/2510.27606)|null|\n", "2510.27452": "|**2025-10-31**|**From Pixels to Paths: A Multi-Agent Framework for Editable Scientific Illustration**|Kaipeng Zhang Team|[2510.27452](http://arxiv.org/abs/2510.27452)|null|\n", "2510.27391": "|**2025-10-31**|**Modality Alignment across Trees on Heterogeneous Hyperbolic Manifolds**|Mehrtash Harandi Team|[2510.27391](http://arxiv.org/abs/2510.27391)|null|\n", "2510.27280": "|**2025-10-31**|**FOCUS: Efficient Keyframe Selection for Long Video Understanding**|Yang You Team|[2510.27280](http://arxiv.org/abs/2510.27280)|null|\n", "2510.27265": "|**2025-10-31**|**T3: Test-Time Model Merging in VLMs for Zero-Shot Medical Imaging Analysis**|Mohammad Yaqub Team|[2510.27265](http://arxiv.org/abs/2510.27265)|null|\n", "2510.27256": "|**2025-10-31**|**ECVL-ROUTER: Scenario-Aware Routing for Vision-Language Models**|Tengxiang Zhang Team|[2510.27256](http://arxiv.org/abs/2510.27256)|null|\n", "2510.27255": "|**2025-11-03**|**Enhancing Spatio-Temporal Zero-shot Action Recognition with Language-driven Description Attributes**|Seong-Whan Lee Team|[2510.27255](http://arxiv.org/abs/2510.27255)|null|\n", "2510.27164": "|**2025-10-31**|**Generating Accurate and Detailed Captions for High-Resolution Images**|Jiyoung Jung Team|[2510.27164](http://arxiv.org/abs/2510.27164)|null|\n", "2510.26996": "|**2025-10-30**|**MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation**|Xiaohui Xie Team|[2510.26996](http://arxiv.org/abs/2510.26996)|null|\n", "2510.26937": "|**2025-10-30**|**MM-OPERA: Benchmarking Open-ended Association Reasoning for Large Vision-Language Models**|Ziliang Chen Team|[2510.26937](http://arxiv.org/abs/2510.26937)|null|\n", "2510.26909": "|**2025-10-30**|**NaviTrace: Evaluating Embodied Navigation of Vision-Language Models**|Jonas Frey Team|[2510.26909](http://arxiv.org/abs/2510.26909)|null|\n", "2510.26905": "|**2025-10-30**|**Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations**|Jane Cleland-Huang Team|[2510.26905](http://arxiv.org/abs/2510.26905)|null|\n", "2510.26865": "|**2025-10-30**|**Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench**|Xi Yang Team|[2510.26865](http://arxiv.org/abs/2510.26865)|**[link](https://flageval-baai.github.io/MeasureBenchPage/)**|\n", "2511.02776": "|**2025-11-04**|**XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations**|Jian Tang Team|[2511.02776](http://arxiv.org/abs/2511.02776)|null|\n", "2511.02503": "|**2025-11-04**|**Adapting General-Purpose Foundation Models for X-ray Ptychography in Low-Data Regimes**|Yi Jiang Team|[2511.02503](http://arxiv.org/abs/2511.02503)|null|\n", "2511.02384": "|**2025-11-04**|**RxnCaption: Reformulating Reaction Diagram Parsing as Visual Prompt Guided Captioning**|Conghui He Team|[2511.02384](http://arxiv.org/abs/2511.02384)|null|\n", "2511.02367": "|**2025-11-04**|**The Pervasive Blind Spot: Benchmarking VLM Inference Risks on Everyday Personal Videos**|Hewu Li Team|[2511.02367](http://arxiv.org/abs/2511.02367)|null|\n", "2511.02360": "|**2025-11-04**|**CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space Reasoning**|Han Yan Team|[2511.02360](http://arxiv.org/abs/2511.02360)|null|\n", "2511.02239": "|**2025-11-04**|**LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation**|Changhyun Choi Team|[2511.02239](http://arxiv.org/abs/2511.02239)|**[link](https://vla2026.github.io/LACY/)**|\n", "2511.02162": "|**2025-11-04**|**Text to Robotic Assembly of Multi Component Objects using 3D Generative AI and Vision Language Models**|Randall Davis Team|[2511.02162](http://arxiv.org/abs/2511.02162)|null|\n", "2511.02113": "|**2025-11-03**|**Enhancing Multimodal Recommendations with Vision-Language Models and Information-Aware Fusion**|Dung D. Le Team|[2511.02113](http://arxiv.org/abs/2511.02113)|null|\n", "2511.01999": "|**2025-11-03**|**TRACE: Textual Reasoning for Affordance Coordinate Extraction**|Matthew S. Brown Team|[2511.01999](http://arxiv.org/abs/2511.01999)|null|\n", "2511.01831": "|**2025-11-04**|**Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models**|Mingwei Shen Team|[2511.01831](http://arxiv.org/abs/2511.01831)|null|\n", "2511.01817": "|**2025-11-03**|**SciTextures: Collecting and Connecting Visual Patterns, Models, and Code Across Science and Art**|Alona Strugatski Team|[2511.01817](http://arxiv.org/abs/2511.01817)|null|\n", "2511.01791": "|**2025-11-03**|**GenDexHand: Generative Simulation for Dexterous Hands**|Yi Ma Team|[2511.01791](http://arxiv.org/abs/2511.01791)|null|\n", "2511.01755": "|**2025-11-03**|**3EED: Ground Everything Everywhere in 3D**|Ziwei Liu Team|[2511.01755](http://arxiv.org/abs/2511.01755)|**[link](https://project-3eed.github.io/)**|\n", "2511.01678": "|**2025-11-03**|**UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback**|Fan Wang Team|[2511.01678](http://arxiv.org/abs/2511.01678)|null|\n", "2511.01617": "|**2025-11-03**|**Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers**|Naeemullah Khan Team|[2511.01617](http://arxiv.org/abs/2511.01617)|null|\n", "2511.01952": "|**2025-11-03**|**Black-Box Membership Inference Attack for LVLMs via Prior Knowledge-Calibrated Memory Probing**|Tao Qi Team|[2511.01952](http://arxiv.org/abs/2511.01952)|null|\n", "2511.01550": "|**2025-11-03**|**Analyzing Sustainability Messaging in Large-Scale Corporate Social Media**|Marcel Worring Team|[2511.01550](http://arxiv.org/abs/2511.01550)|null|\n", "2511.01472": "|**2025-11-03**|**AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models**|Spandan Roy Team|[2511.01472](http://arxiv.org/abs/2511.01472)|null|\n", "2511.01463": "|**2025-11-03**|**HMVLM: Human Motion-Vision-Lanuage Model via MoE LoRA**|Shihong Xia Team|[2511.01463](http://arxiv.org/abs/2511.01463)|null|\n", "2511.01458": "|**2025-11-03**|**When to Trust the Answer: Question-Aligned Semantic Nearest Neighbor Entropy for Safer Surgical VQA**|Mobarak I. Hoque Team|[2511.01458](http://arxiv.org/abs/2511.01458)|null|\n", "2512.15713": "|**2025-12-17**|**DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models**|Xinggang Wang Team|[2512.15713](http://arxiv.org/abs/2512.15713)|null|\n", "2512.15701": "|**2025-12-17**|**VLIC: Vision-Language Models As Perceptual Judges for Human-Aligned Image Compression**|Jason Zhang Team|[2512.15701](http://arxiv.org/abs/2512.15701)|null|\n", "2512.15649": "|**2025-12-17**|**VTCBench: Can Vision-Language Models Understand Long Context with Vision-Text Compression?**|Zhaoxiang Zhang Team|[2512.15649](http://arxiv.org/abs/2512.15649)|null|\n", "2512.15372": "|**2025-12-17**|**Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models**|Georgina Cosma Team|[2512.15372](http://arxiv.org/abs/2512.15372)|null|\n", "2512.15310": "|**2025-12-17**|**SynthSeg-Agents: Multi-Agent Synthetic Data Generation for Zero-Shot Weakly Supervised Semantic Segmentation**|Jimin Xiao Team|[2512.15310](http://arxiv.org/abs/2512.15310)|null|\n", "2512.15254": "|**2025-12-17**|**Assessing the Visual Enumeration Abilities of Specialized Counting Architectures and Vision-Language Models**|Alberto Testolin Team|[2512.15254](http://arxiv.org/abs/2512.15254)|null|\n", "2512.15249": "|**2025-12-17**|**Intersectional Fairness in Vision-Language Models for Medical Image Disease Classification**|Jinman Kim Team|[2512.15249](http://arxiv.org/abs/2512.15249)|null|\n", "2512.15160": "|**2025-12-17**|**EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence**|Yifan Yang Team|[2512.15160](http://arxiv.org/abs/2512.15160)|null|\n", "2512.14944": "|**2025-12-16**|**Puzzle Curriculum GRPO for Vision-Centric Reasoning**|Radek Grzeszczuk Team|[2512.14944](http://arxiv.org/abs/2512.14944)|**[link](https://pcgrpo.github.io)**|\n", "2512.14926": "|**2025-12-16**|**Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models**|Dumitru-Clementin Cercel Team|[2512.14926](http://arxiv.org/abs/2512.14926)|null|\n", "2512.14661": "|**2025-12-16**|**Focus: A Streaming Concentration Architecture for Efficient Vision-Language Models**|Yiran Chen Team|[2512.14661](http://arxiv.org/abs/2512.14661)|null|\n", "2512.14442": "|**2025-12-16**|**A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning**|Ying-Cong Chen Team|[2512.14442](http://arxiv.org/abs/2512.14442)|null|\n", "2512.14420": "|**2025-12-16**|**DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning**|Yusuke Sekikawa Team|[2512.14420](http://arxiv.org/abs/2512.14420)|null|\n", "2512.14336": "|**2025-12-16**|**Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure**|Jaegul Choo Team|[2512.14336](http://arxiv.org/abs/2512.14336)|null|\n", "2512.14312": "|**2025-12-16**|**From YOLO to VLMs: Advancing Zero-Shot and Few-Shot Detection of Wastewater Treatment Plants Using Satellite Imagery in MENA Region**|Garcia Andarcia Mariangel Team|[2512.14312](http://arxiv.org/abs/2512.14312)|null|\n", "2512.14770": "|**2025-12-16**|**Improving VQA Reliability: A Dual-Assessment Approach with Self-Reflection and Cross-Model Verification**|Longwen Gao Team|[2512.14770](http://arxiv.org/abs/2512.14770)|null|\n", "2512.14177": "|**2025-12-16**|**Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes**|Gianni Franchi Team|[2512.14177](http://arxiv.org/abs/2512.14177)|null|\n", "2512.14130": "|**2025-12-16**|**UIXPOSE: Mobile Malware Detection via Intention-Behaviour Discrepancy Analysis**|Van-Thuan Pham Team|[2512.14130](http://arxiv.org/abs/2512.14130)|null|\n", "2512.14102": "|**2025-12-16**|**Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries**|Maarten Kruithof Team|[2512.14102](http://arxiv.org/abs/2512.14102)|null|\n", "2512.14068": "|**2025-12-16**|**SDAR-VL: Stable and Efficient Block-wise Diffusion for Vision-Language Understanding**|Bowen Zhou Team|[2512.14068](http://arxiv.org/abs/2512.14068)|null|\n", "2512.16793": "|**2025-12-18**|**PhysBrain: Human Egocentric Data as a Bridge from Vision Language Models to Physical Intelligence**|Kai Chen Team|[2512.16793](http://arxiv.org/abs/2512.16793)|null|\n", "2512.16755": "|**2025-12-18**|**CitySeeker: How Do VLMS Explore Embodied Urban Navigation With Implicit Human Needs?**|Haofen Wang Team|[2512.16755](http://arxiv.org/abs/2512.16755)|null|\n", "2512.16561": "|**2025-12-18**|**N3D-VLM: Native 3D Grounding Enables Accurate Spatial Reasoning in Vision-Language Models**|Dong Yu Team|[2512.16561](http://arxiv.org/abs/2512.16561)|**[link](https://n3d-vlm.github.io)**|\n", "2512.16531": "|**2025-12-18**|**Scaling Laws for Energy Efficiency of Local LLMs**|Rom\u00e1n Or\u00fas Team|[2512.16531](http://arxiv.org/abs/2512.16531)|null|\n", "2512.16523": "|**2025-12-18**|**TTP: Test-Time Padding for Adversarial Detection and Robust Adaptation on Vision-Language Models**|Qi Li Team|[2512.16523](http://arxiv.org/abs/2512.16523)|null|\n", "2512.16461": "|**2025-12-18**|**SNOW: Spatio-Temporal Scene Understanding with World Knowledge for Open-World Embodied Reasoning**|Eric Sax Team|[2512.16461](http://arxiv.org/abs/2512.16461)|null|\n", "2512.16446": "|**2025-12-18**|**E-SDS: Environment-aware See it, Do it, Sorted - Automated Environment-Aware Reinforcement Learning for Humanoid Locomotion**|Dimitrios Kanoulas Team|[2512.16446](http://arxiv.org/abs/2512.16446)|null|\n", "2512.16349": "|**2025-12-18**|**Collaborative Edge-to-Server Inference for Vision-Language Models**|Yongjune Kim Team|[2512.16349](http://arxiv.org/abs/2512.16349)|null|\n", "2512.16302": "|**2025-12-18**|**ManiLong-Shot: Interaction-Aware One-Shot Imitation Learning for Long-Horizon Manipulation**|Yang Gao Team|[2512.16302](http://arxiv.org/abs/2512.16302)|null|\n", "2512.16237": "|**2025-12-18**|**Scaling Spatial Reasoning in MLLMs through Programmatic Data Synthesis**|Yao Yuan Team|[2512.16237](http://arxiv.org/abs/2512.16237)|null|\n", "2512.16201": "|**2025-12-18**|**Visual Alignment of Medical Vision-Language Models for Grounded Radiology Report Generation**|Srimat Chakradhar Team|[2512.16201](http://arxiv.org/abs/2512.16201)|null|\n", "2512.16164": "|**2025-12-18**|**C-DGPA: Class-Centric Dual-Alignment Generative Prompt Adaptation**|Yuncheng Shen Team|[2512.16164](http://arxiv.org/abs/2512.16164)|null|\n", "2512.16145": "|**2025-12-18**|**MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation**|Jinman Kim Team|[2512.16145](http://arxiv.org/abs/2512.16145)|null|\n", "2512.16077": "|**2025-12-18**|**Auto-Vocabulary 3D Object Detection**|Raymond A. Yeh Team|[2512.16077](http://arxiv.org/abs/2512.16077)|null|\n", "2512.15977": "|**2025-12-17**|**Are vision-language models ready to zero-shot replace supervised classification models in agriculture?**|Mason J. Earles Team|[2512.15977](http://arxiv.org/abs/2512.15977)|null|\n", "2512.15971": "|**2025-12-17**|**From Words to Wavelengths: VLMs for Few-Shot Multispectral Object Detection**|S\u00e9bastien Lef\u00e8vre Team|[2512.15971](http://arxiv.org/abs/2512.15971)|null|\n", "2512.15957": "|**2025-12-17**|**Seeing is Believing (and Predicting): Context-Aware Multi-Human Behavior Prediction with Vision Language Models**|Marco Aiello Team|[2512.15957](http://arxiv.org/abs/2512.15957)|null|\n", "2512.15940": "|**2025-12-17**|**R4: Retrieval-Augmented Reasoning for Vision-Language Models in 4D Spatio-Temporal Space**|Eric Sax Team|[2512.15940](http://arxiv.org/abs/2512.15940)|null|\n", "2512.15926": "|**2025-12-17**|**DSO: Direct Steering Optimization for Bias Mitigation**|Nicholas Apostoloff Team|[2512.15926](http://arxiv.org/abs/2512.15926)|null|\n", "2512.16909": "|**2025-12-18**|**MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning**|Koushil Sreenath Team|[2512.16909](http://arxiv.org/abs/2512.16909)|**[link](https://hybridrobotics.github.io/MomaGraph/)**|\n", "2512.16924": "|**2025-12-18**|**The World is Your Canvas: Painting Promptable Events with Reference Images, Trajectories, and Text**|Qifeng Chen Team|[2512.16924](http://arxiv.org/abs/2512.16924)|**[link](https://worldcanvas.github.io/)**|\n", "2512.16921": "|**2025-12-18**|**Differences That Matter: Auditing Models for Capability Gap Discovery and Rectification**|Wen-Sheng Chu Team|[2512.16921](http://arxiv.org/abs/2512.16921)|**[link](https://auditdm.github.io/)**|\n", "2512.16906": "|**2025-12-18**|**VIVA: VLM-Guided Instruction-Based Video Editing with Reward Optimization**|Chongyang Ma Team|[2512.16906](http://arxiv.org/abs/2512.16906)|null|\n", "2512.16899": "|**2025-12-18**|**Multimodal RewardBench 2: Evaluating Omni Reward Models for Interleaved Text and Image**|Marjan Ghazvininejad Team|[2512.16899](http://arxiv.org/abs/2512.16899)|**[link](https://github.com/facebookresearch/MMRB2)**|\n", "2512.16776": "|**2025-12-18**|**Kling-Omni Technical Report**|Yongjie Zhu Team|[2512.16776](http://arxiv.org/abs/2512.16776)|null|\n", "2512.16760": "|**2025-12-18**|**Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future**|Junwei Liang Team|[2512.16760](http://arxiv.org/abs/2512.16760)|**[link](https://github.com/worldbench/awesome-vla-for-ad)**|\n", "2512.16245": "|**2025-12-18**|**AlignMerge - Alignment-Preserving Large Language Model Merging via Fisher-Guided Geometric Constraints**|Amitava Das Team|[2512.16245](http://arxiv.org/abs/2512.16245)|null|\n", "2512.15949": "|**2025-12-17**|**The Perceptual Observatory Characterizing Robustness and Grounding in MLLMs**|Vivek Gupta Team|[2512.15949](http://arxiv.org/abs/2512.15949)|null|\n", "2512.15938": "|**2025-12-17**|**SALVE: Sparse Autoencoder-Latent Vector Editing for Mechanistic Control of Neural Networks**|Vegard Flovik Team|[2512.15938](http://arxiv.org/abs/2512.15938)|null|\n", "2512.15840": "|**2025-12-17**|**Large Video Planner Enables Generalizable Robot Control**|Yilun Du Team|[2512.15840](http://arxiv.org/abs/2512.15840)|null|\n", "2512.15635": "|**2025-12-17**|**IC-Effect: Precise and Efficient Video Effects Editing via In-Context Learning**|Qi Mao Team|[2512.15635](http://arxiv.org/abs/2512.15635)|null|\n", "2512.14989": "|**2025-12-17**|**Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams**|Guoping Hu Team|[2512.14989](http://arxiv.org/abs/2512.14989)|null|\n", "2512.15804": "|**2025-12-16**|**XBIDetective: Leveraging Vision Language Models for Identifying Cross-Browser Visual Inconsistencies**|Cor-Paul Bezemer Team|[2512.15804](http://arxiv.org/abs/2512.15804)|null|\n", "2512.14698": "|**2025-12-16**|**TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs**|Limin Wang Team|[2512.14698](http://arxiv.org/abs/2512.14698)|**[link](https://timelens-arc-lab.github.io/)**|\n", "2512.14044": "|**2025-12-16**|**OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving**|Wuxiong Huang Team|[2512.14044](http://arxiv.org/abs/2512.14044)|null|\n", "2512.14014": "|**2025-12-16**|**MobileWorldBench: Towards Semantic World Modeling For Mobile Agents**|Aditya Grover Team|[2512.14014](http://arxiv.org/abs/2512.14014)|null|\n", "2512.13974": "|**2025-12-16**|**Autonomous Construction-Site Safety Inspection Using Mobile Robots: A Multilayer VLM-LLM Pipeline**|Abiola Akanmu Team|[2512.13974](http://arxiv.org/abs/2512.13974)|null|\n", "2512.13961": "|**2025-12-15**|**Olmo 3**|Hannaneh Hajishirzi Team|[2512.13961](http://arxiv.org/abs/2512.13961)|null|\n", "2512.13953": "|**2025-12-15**|**From Unlearning to UNBRANDING: A Benchmark for Trademark-Safe Text-to-Image Generation**|Przemys\u0142aw Spurek Team|[2512.13953](http://arxiv.org/abs/2512.13953)|null|\n", "2512.13855": "|**2025-12-15**|**Improvise, Adapt, Overcome -- Telescopic Adapters for Efficient Fine-tuning of Vision Language Models in Medical Imaging**|Amit Shukla Team|[2512.13855](http://arxiv.org/abs/2512.13855)|null|\n", "2512.13671": "|**2025-12-15**|**AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection**|Yan Wang Team|[2512.13671](http://arxiv.org/abs/2512.13671)|null|\n", "2512.13670": "|**2025-12-15**|**NL2SpaTiaL: Generating Geometric Spatio-Temporal Logic Specifications from Natural Language for Manipulation Tasks**|Mingyu Cai Team|[2512.13670](http://arxiv.org/abs/2512.13670)|null|\n", "2512.13660": "|**2025-12-15**|**RoboTracer: Mastering Spatial Trace with Reasoning in Vision-Language Models for Robotics**|Shanghang Zhang Team|[2512.13660](http://arxiv.org/abs/2512.13660)|**[link](https://zhoues.github.io/RoboTracer)**|\n", "2512.13609": "|**2025-12-15**|**Do-Undo: Generating and Reversing Physical Actions in Vision-Language Models**|Fatih Porikli Team|[2512.13609](http://arxiv.org/abs/2512.13609)|null|\n", "2512.13511": "|**2025-12-15**|**TARA: Simple and Efficient Time Aware Retrieval Adaptation of MLLMs for Video Understanding**|Andrew Zisserman Team|[2512.13511](http://arxiv.org/abs/2512.13511)|**[link](http://bpiyush.github.io/tara-website)**|\n", "2512.13380": "|**2025-12-15**|**Universal Dexterous Functional Grasping via Demonstration-Editing Reinforcement Learning**|Zongqing Lu Team|[2512.13380](http://arxiv.org/abs/2512.13380)|null|\n", "2512.14757": "|**2025-12-15**|**SocialNav-MoE: A Mixture-of-Experts Vision Language Model for Socially Compliant Navigation with Reinforcement Fine-Tuning**|Ling Xiao Team|[2512.14757](http://arxiv.org/abs/2512.14757)|null|\n", "2512.13313": "|**2025-12-15**|**KlingAvatar 2.0 Technical Report**|Yan Zhou Team|[2512.13313](http://arxiv.org/abs/2512.13313)|null|\n", "2512.13298": "|**2025-12-15**|**MiniLingua: A Small Open-Source LLM for European Languages**|Pekka Marttinen Team|[2512.13298](http://arxiv.org/abs/2512.13298)|**[link](https://github.com/MiniLingua-ai/training_artifacts)**|\n", "2512.13290": "|**2025-12-15**|**LINA: Learning INterventions Adaptively for Physical Alignment and Generalization in Diffusion Models**|Chaochao Lu Team|[2512.13290](http://arxiv.org/abs/2512.13290)|null|\n", "2512.13285": "|**2025-12-16**|**CausalCLIP: Causally-Informed Feature Disentanglement and Filtering for Generalizable Detection of Generated Images**|Qinghui He Team|[2512.13285](http://arxiv.org/abs/2512.13285)|null|\n", "2512.13276": "|**2025-12-15**|**CogniEdit: Dense Gradient Flow Optimization for Fine-Grained Image Editing**|Qi Tian Team|[2512.13276](http://arxiv.org/abs/2512.13276)|null|\n", "2512.13250": "|**2025-12-15**|**Toward Ambulatory Vision: Learning Visually-Grounded Active View Selection**|Minhyuk Sung Team|[2512.13250](http://arxiv.org/abs/2512.13250)|**[link](https://active-view-selection.github.io/)**|\n", "2512.13240": "|**2025-12-15**|**Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection**|Zechang Li Team|[2512.13240](http://arxiv.org/abs/2512.13240)|null|\n", "2512.13177": "|**2025-12-16**|**MMDrive: Interactive Scene Understanding Beyond Vision with Multi-representational Fusion**|Weiping Ding Team|[2512.13177](http://arxiv.org/abs/2512.13177)|null|\n", "2512.13080": "|**2025-12-15**|**Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos**|Zongqing Lu Team|[2512.13080](http://arxiv.org/abs/2512.13080)|null|\n", "2512.13072": "|**2025-12-15**|**Forging a Dynamic Memory: Retrieval-Guided Continual Learning for Generalist Medical Foundation Models**|Lihua Zhang Team|[2512.13072](http://arxiv.org/abs/2512.13072)|null|\n", "2512.13043": "|**2025-12-15**|**GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training**|Deheng Ye Team|[2512.13043](http://arxiv.org/abs/2512.13043)|null|\n", "2512.13008": "|**2025-12-15**|**TWLR: Text-Guided Weakly-Supervised Lesion Localization and Severity Regression for Explainable Diabetic Retinopathy Grading**|Huaxiong Huang Team|[2512.13008](http://arxiv.org/abs/2512.13008)|null|\n", "2512.14754": "|**2025-12-15**|**Revisiting the Reliability of Language Models in Instruction-Following**|Han Qiu Team|[2512.14754](http://arxiv.org/abs/2512.14754)|null|\n", "2512.12929": "|**2025-12-15**|**MADTempo: An Interactive System for Multi-Event Temporal Video Retrieval with Query Augmentation**|Thanh-Huong Le Team|[2512.12929](http://arxiv.org/abs/2512.12929)|null|\n", "2512.12885": "|**2025-12-14**|**SignRAG: A Retrieval-Augmented System for Scalable Zero-Shot Road Sign Recognition**|Keith Redmill Team|[2512.12885](http://arxiv.org/abs/2512.12885)|null|\n", "2512.12793": "|**2025-12-18**|**VLG-Loc: Vision-Language Global Localization from Labeled Footprint Maps**|Ryo Yonetani Team|[2512.12793](http://arxiv.org/abs/2512.12793)|null|\n", "2512.13741": "|**2025-12-14**|**The Laminar Flow Hypothesis: Detecting Jailbreaks via Semantic Turbulence in Large Language Models**|Md. Hasib Ur Rahman Team|[2512.13741](http://arxiv.org/abs/2512.13741)|null|\n", "2512.12775": "|**2025-12-14**|**Persistent Personas? Role-Playing, Instruction Following, and Safety in Extended Interactions**|Benjamin Roth Team|[2512.12775](http://arxiv.org/abs/2512.12775)|null|\n", "2512.12701": "|**2025-12-14**|**Efficient Vision-Language Reasoning via Adaptive Token Pruning**|Henry Hu Team|[2512.12701](http://arxiv.org/abs/2512.12701)|null|\n", "2512.12690": "|**2025-12-14**|**Reassessing the Role of Supervised Fine-Tuning: An Empirical Study in VLM Reasoning**|Jian Liang Team|[2512.12690](http://arxiv.org/abs/2512.12690)|null|\n", "2512.12596": "|**2025-12-14**|**Content-Aware Ad Banner Layout Generation with Two-Stage Chain-of-Thought in Vision Language Models**|Kazuhide Nakata Team|[2512.12596](http://arxiv.org/abs/2512.12596)|null|\n", "2512.12571": "|**2025-12-14**|**From Tokens to Photons: Test-Time Physical Prompting for Vison-Language Models**|Hyung-Sin Kim Team|[2512.12571](http://arxiv.org/abs/2512.12571)|null|\n", "2512.12492": "|**2025-12-16**|**Adaptive Detector-Verifier Framework for Zero-Shot Polyp Detection in Open-World Settings**|Yuqi Ouyang Team|[2512.12492](http://arxiv.org/abs/2512.12492)|null|\n", "2512.12487": "|**2025-12-13**|**More Than the Final Answer: Improving Visual Extraction and Logical Consistency in Vision-Language Models**|Jing Shi Team|[2512.12487](http://arxiv.org/abs/2512.12487)|null|\n", "2512.12424": "|**2025-12-13**|**ViInfographicVQA: A Benchmark for Single and Multi-image Visual Question Answering on Vietnamese Infographics**|Quoc-Thai Nguyen Team|[2512.12424](http://arxiv.org/abs/2512.12424)|null|\n", "2512.12309": "|**2025-12-13**|**WeDetect: Fast Open-Vocabulary Object Detection as Retrieval**|Wei-Shi Zheng Team|[2512.12309](http://arxiv.org/abs/2512.12309)|null|\n", "2512.12268": "|**2025-12-13**|**MetaTPT: Meta Test-time Prompt Tuning for Vision-Language Models**|Ling Shao Team|[2512.12268](http://arxiv.org/abs/2512.12268)|null|\n", "2512.12246": "|**2025-12-13**|**Moment and Highlight Detection via MLLM Frame Segmentation**|Ayu Purwarianti Team|[2512.12246](http://arxiv.org/abs/2512.12246)|null|\n", "2512.12218": "|**2025-12-13**|**Journey Before Destination: On the importance of Visual Faithfulness in Slow Thinking**|Zheng Qi Team|[2512.12218](http://arxiv.org/abs/2512.12218)|null|\n", "2512.12107": "|**2025-12-13**|**EchoVLM: Measurement-Grounded Multimodal Learning for Echocardiography**|Puneet Sharma Team|[2512.12107](http://arxiv.org/abs/2512.12107)|null|\n", "2512.12089": "|**2025-12-12**|**VEGAS: Mitigating Hallucinations in Large Vision-Language Models via Vision-Encoder Attention Guided Adaptive Steering**|Peng Li Team|[2512.12089](http://arxiv.org/abs/2512.12089)|null|\n", "2512.12069": "|**2025-12-12**|**Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring**|Ning Zhang Team|[2512.12069](http://arxiv.org/abs/2512.12069)|null|\n", "2512.11995": "|**2025-12-12**|**V-REX: Benchmarking Exploratory Visual Reasoning via Chain-of-Questions**|Tianyi Zhou Team|[2512.11995](http://arxiv.org/abs/2512.11995)|null|\n", "2512.11982": "|**2025-12-12**|**Semantic search for 100M+ galaxy images using AI-generated captions**|Shirley Ho Team|[2512.11982](http://arxiv.org/abs/2512.11982)|null|\n", "2512.11567": "|**2025-12-12**|**Extending a Parliamentary Corpus with MPs' Tweets: Automatic Annotation and Evaluation Using MultiParTweet**|Alexander Mehler Team|[2512.11567](http://arxiv.org/abs/2512.11567)|null|\n", "2512.11490": "|**2025-12-12**|**VLM2GeoVec: Toward Universal Multimodal Embeddings for Remote Sensing**|Michael Felsberg Team|[2512.11490](http://arxiv.org/abs/2512.11490)|null|\n", "2512.11464": "|**2025-12-12**|**Exploring MLLM-Diffusion Information Transfer with MetaCanvas**|Chu Wang Team|[2512.11464](http://arxiv.org/abs/2512.11464)|**[link](https://metacanvas.github.io)**|\n", "2512.11399": "|**2025-12-12**|**Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction**|Nancy F. Chen Team|[2512.11399](http://arxiv.org/abs/2512.11399)|null|\n", "2512.11393": "|**2025-12-12**|**The N-Body Problem: Parallel Execution from Single-Person Egocentric Video**|Dima Damen Team|[2512.11393](http://arxiv.org/abs/2512.11393)|**[link](https://zhifanzhu.github.io/ego-nbody)**|\n", "2512.11391": "|**2025-12-12**|**Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization**|Jia Li Team|[2512.11391](http://arxiv.org/abs/2512.11391)|null|\n", "2512.11350": "|**2025-12-12**|**Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture**|Long T. Truong Team|[2512.11350](http://arxiv.org/abs/2512.11350)|null|\n", "2512.11315": "|**2025-12-12**|**Benchmarking the Generality of Vision-Language-Action Models**|Yangyue Wang Team|[2512.11315](http://arxiv.org/abs/2512.11315)|null|\n", "2512.11275": "|**2025-12-12**|**Towards Logic-Aware Manipulation: A Knowledge Primitive for VLM-Based Assistants in Smart Manufacturing**|Daqiang Guo Team|[2512.11275](http://arxiv.org/abs/2512.11275)|null|\n", "2512.11218": "|**2025-12-12**|**Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy**|Yue Wang Team|[2512.11218](http://arxiv.org/abs/2512.11218)|null|\n", "2512.11167": "|**2025-12-11**|**Image Tiling for High-Resolution Reasoning: Balancing Local Detail with Global Context**|Irina Rish Team|[2512.11167](http://arxiv.org/abs/2512.11167)|null|\n", "2512.11109": "|**2025-12-11**|**Limits and Gains of Test-Time Scaling in Vision-Language Reasoning**|Mahdieh Soleymani Baghshah Team|[2512.11109](http://arxiv.org/abs/2512.11109)|null|\n", "2512.11099": "|**2025-12-11**|**VGent: Visual Grounding via Modular Design for Disentangling Reasoning and Prediction**|Kangning Liu Team|[2512.11099](http://arxiv.org/abs/2512.11099)|null|\n", "2512.11098": "|**2025-12-11**|**Vision-Language Models for Infrared Industrial Sensing in Additive Manufacturing Scene Description**|Vinh Nguyen Team|[2512.11098](http://arxiv.org/abs/2512.11098)|null|\n", "2512.11061": "|**2025-12-11**|**VDAWorld: World Modelling via VLM-Directed Abstraction and Simulation**|Ayush Tewari Team|[2512.11061](http://arxiv.org/abs/2512.11061)|**[link](https://felixomahony.github.io/vdaworld/)**|\n", "2512.11060": "|**2025-12-11**|**Synthetic Vasculature and Pathology Enhance Vision-Language Model Reasoning**|Johannes C. Paetzold Team|[2512.11060](http://arxiv.org/abs/2512.11060)|null|\n", "2512.10942": "|**2025-12-11**|**VL-JEPA: Joint Embedding Predictive Architecture for Vision-language**|Pascale Fung Team|[2512.10942](http://arxiv.org/abs/2512.10942)|null|\n", "2512.10932": "|**2025-12-11**|**BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models**|Boqing Gong Team|[2512.10932](http://arxiv.org/abs/2512.10932)|null|\n", "2512.10894": "|**2025-12-11**|**DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance**|Difan Liu Team|[2512.10894](http://arxiv.org/abs/2512.10894)|**[link](https://intchous.github.io/DuetSVG-site)**|\n", "2512.10888": "|**2025-12-11**|**PubTables-v2: A new large-scale dataset for full-page and multi-page table extraction**|Maury Courtland Team|[2512.10888](http://arxiv.org/abs/2512.10888)|null|\n", "2512.10882": "|**2025-12-11**|**Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity**|Hauke Licht Team|[2512.10882](http://arxiv.org/abs/2512.10882)|null|\n", "2512.10867": "|**2025-12-12**|**From Macro to Micro: Benchmarking Microscopic Spatial Intelligence on Molecules via Vision-Language Models**|Wenbing Huang Team|[2512.10867](http://arxiv.org/abs/2512.10867)|null|\n", "2512.10750": "|**2025-12-11**|**LDP: Parameter-Efficient Fine-Tuning of Multimodal LLM for Medical Report Generation**|Suncheng Xiang Team|[2512.10750](http://arxiv.org/abs/2512.10750)|null|\n", "2512.10719": "|**2025-12-11**|**SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving**|Andreas Zell Team|[2512.10719](http://arxiv.org/abs/2512.10719)|null|\n", "2512.10713": "|**2025-12-11**|**PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code**|Marcel Zalmanovici Team|[2512.10713](http://arxiv.org/abs/2512.10713)|null|\n", "2512.10691": "|**2025-12-11**|**Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning**|Michael Krauthammer Team|[2512.10691](http://arxiv.org/abs/2512.10691)|null|\n", "2512.10619": "|**2025-12-11**|**DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM**|Wentao Zhang Team|[2512.10619](http://arxiv.org/abs/2512.10619)|null|\n", "2512.10596": "|**2025-12-11**|**Beyond Pixels: A Training-Free, Text-to-Text Framework for Remote Sensing Image Retrieval**|M. Prasad Team|[2512.10596](http://arxiv.org/abs/2512.10596)|null|\n", "2512.10501": "|**2025-12-12**|**Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation**|Hao Zhang Team|[2512.10501](http://arxiv.org/abs/2512.10501)|null|\n", "2512.10493": "|**2025-12-12**|**Decoding Human-LLM Collaboration in Coding: An Empirical Study of Multi-Turn Conversations in the Wild**|Lin Shi Team|[2512.10493](http://arxiv.org/abs/2512.10493)|null|\n", "2512.10414": "|**2025-12-11**|**Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention**|Xiaomeng Li Team|[2512.10414](http://arxiv.org/abs/2512.10414)|null|\n", "2512.10384": "|**2025-12-11**|**Towards Fine-Grained Recognition with Large Visual Language Models: Benchmark and Optimization Strategies**|Xin Lou Team|[2512.10384](http://arxiv.org/abs/2512.10384)|null|\n", "2512.10342": "|**2025-12-11**|**CoSPlan: Corrective Sequential Planning via Scene Graph Incremental Updates**|Yogesh S Rawat Team|[2512.10342](http://arxiv.org/abs/2512.10342)|null|\n", "2512.10336": "|**2025-12-11**|**Multilingual VLM Training: Adapting an English-Trained VLM to French**|Alexis Roger Team|[2512.10336](http://arxiv.org/abs/2512.10336)|null|\n", "2512.10316": "|**2025-12-11**|**ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation**|Hien Van Nguyen Team|[2512.10316](http://arxiv.org/abs/2512.10316)|null|\n", "2512.14735": "|**2025-12-11**|**PyFi: Toward Pyramid-like Financial Image Understanding for VLMs via Adversarial Agents**|Sijia Chen Team|[2512.14735](http://arxiv.org/abs/2512.14735)|null|\n", "2512.10300": "|**2025-12-11**|**Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules**|Krista A. Ehinger Team|[2512.10300](http://arxiv.org/abs/2512.10300)|null|\n", "2512.10244": "|**2025-12-11**|**Solving Semi-Supervised Few-Shot Learning from an Auto-Annotation Perspective**|Shu Kong Team|[2512.10244](http://arxiv.org/abs/2512.10244)|**[link](https://tian1327.github.io/SWIFT)**|\n", "2512.10172": "|**2025-12-11**|**Offscript: Automated Auditing of Instruction Adherence in LLMs**|Tanu Mitra Team|[2512.10172](http://arxiv.org/abs/2512.10172)|null|\n", "2512.14732": "|**2025-12-10**|**INFORM-CT: INtegrating LLMs and VLMs FOR Incidental Findings Management in Abdominal CT**|Guy ben-Yosef Team|[2512.14732](http://arxiv.org/abs/2512.14732)|null|\n", "2512.11908": "|**2025-12-10**|**Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models**|Arash Ajoudani Team|[2512.11908](http://arxiv.org/abs/2512.11908)|null|\n", "2512.10067": "|**2025-12-10**|**Independent Density Estimation**|Jiahao Liu Team|[2512.10067](http://arxiv.org/abs/2512.10067)|null|\n", "2512.10046": "|**2025-12-10**|**SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration**|Tianmin Shu Team|[2512.10046](http://arxiv.org/abs/2512.10046)|null|\n", "2512.09924": "|**2025-12-11**|**ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning**|Yike Guo Team|[2512.09924](http://arxiv.org/abs/2512.09924)|**[link](https://github.com/Liuxinyv/ReViSE))**|\n", "2512.09920": "|**2025-12-10**|**LISN: Language-Instructed Social Navigation with VLM-based Controller Modulating**|Lin Shao Team|[2512.09920](http://arxiv.org/abs/2512.09920)|null|\n", "2512.09907": "|**2025-12-10**|**VisualActBench: Can VLMs See and Act like a Human?**|Jiebo Luo Team|[2512.09907](http://arxiv.org/abs/2512.09907)|null|\n", "2512.09874": "|**2025-12-10**|**Benchmarking Document Parsers on Mathematical Formula Extraction from PDFs**|Janis Keuper Team|[2512.09874](http://arxiv.org/abs/2512.09874)|null|\n", "2512.09872": "|**2025-12-10**|**FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning**|Khaza Anuarul Hoque Team|[2512.09872](http://arxiv.org/abs/2512.09872)|null|\n", "2512.09670": "|**2025-12-10**|**An Automated Tip-and-Cue Framework for Optimized Satellite Tasking and Visual Intelligence**|Israel Cohen Team|[2512.09670](http://arxiv.org/abs/2512.09670)|null|\n", "2512.09555": "|**2025-12-10**|**Building Reasonable Inference for Vision-Language Models in Blind Image Quality Assessment**|Shin'ya Nishida Team|[2512.09555](http://arxiv.org/abs/2512.09555)|null|\n", "2512.09446": "|**2025-12-10**|**Defect-aware Hybrid Prompt Optimization via Progressive Tuning for Zero-Shot Multi-type Anomaly Detection and Segmentation**|Steffen Staab Team|[2512.09446](http://arxiv.org/abs/2512.09446)|null|\n", "2512.09441": "|**2025-12-10**|**Representation Calibration and Uncertainty Guidance for Class-Incremental Learning based on Vision Language Model**|Ruixuan Wang Team|[2512.09441](http://arxiv.org/abs/2512.09441)|null|\n", "2512.11899": "|**2025-12-10**|**Read or Ignore? A Unified Benchmark for Typographic-Attack Robustness and Text Recognition in Vision-Language Models**|Tsubasa Takahashi Team|[2512.11899](http://arxiv.org/abs/2512.11899)|null|\n", "2512.09349": "|**2025-12-10**|**COVLM-RL: Critical Object-Oriented Reasoning for Autonomous Driving Using VLM-Guided Reinforcement Learning**|Chen Lv Team|[2512.09349](http://arxiv.org/abs/2512.09349)|null|\n", "2512.09215": "|**2025-12-10**|**View-on-Graph: Zero-shot 3D Visual Grounding via Vision-Language Reasoning on Scene Graphs**|Xin Yang Team|[2512.09215](http://arxiv.org/abs/2512.09215)|null|\n", "2512.09172": "|**2025-12-17**|**Prompt-Based Continual Compositional Zero-Shot Learning**|Mohsen Ali Team|[2512.09172](http://arxiv.org/abs/2512.09172)|null|\n", "2512.09056": "|**2025-12-09**|**ConceptPose: Training-Free Zero-Shot Object Pose Estimation using Concept Vectors**|Benjamin Busam Team|[2512.09056](http://arxiv.org/abs/2512.09056)|null|\n", "2512.08922": "|**2025-12-09**|**Unified Diffusion Transformer for High-fidelity Text-Aware Image Restoration**|Seungryong Kim Team|[2512.08922](http://arxiv.org/abs/2512.08922)|null|\n", "2512.08889": "|**2025-12-09**|**No Labels, No Problem: Training Visual Reasoners with Multimodal Verifiers**|Georgia Gkioxari Team|[2512.08889](http://arxiv.org/abs/2512.08889)|**[link](https://glab-caltech.github.io/valor/)**|\n", "2512.08881": "|**2025-12-09**|**SATGround: A Spatially-Aware Approach for Visual Grounding in Remote Sensing**|Jiankang Deng Team|[2512.08881](http://arxiv.org/abs/2512.08881)|null|\n", "2512.08860": "|**2025-12-09**|**Tri-Bench: Stress-Testing VLM Reliability on Spatial Reasoning under Camera Tilt and Object Interference**|Amit Bendkhale Team|[2512.08860](http://arxiv.org/abs/2512.08860)|**[link](https://github.com/Amiton7/Tri-Bench.)**|\n", "2512.08829": "|**2025-12-09**|**InfiniteVL: Synergizing Linear and Sparse Attention for Highly-Efficient, Unlimited-Input Vision-Language Models**|Xinggang Wang Team|[2512.08829](http://arxiv.org/abs/2512.08829)|null|\n", "2512.08820": "|**2025-12-09**|**Training-Free Dual Hyperbolic Adapters for Better Cross-Modal Reasoning**|Angelica I. Aviles-Rivero Team|[2512.08820](http://arxiv.org/abs/2512.08820)|null|\n", "2512.11891": "|**2025-12-09**|**VLSA: Vision-Language-Action Models with Plug-and-Play Safety Constraint Layer**|Xiao He Team|[2512.11891](http://arxiv.org/abs/2512.11891)|null|\n", "2512.08627": "|**2025-12-09**|**Trajectory Densification and Depth from Perspective-based Blur**|Yueting Chen Team|[2512.08627](http://arxiv.org/abs/2512.08627)|null|\n", "2512.08580": "|**2025-12-10**|**Mind to Hand: Purposeful Robotic Control via Embodied Reasoning**|Jianan Wang Team|[2512.08580](http://arxiv.org/abs/2512.08580)|null|\n", "2512.08524": "|**2025-12-09**|**Beyond Real Weights: Hypercomplex Representations for Stable Quantization**|Shafin Rahman Team|[2512.08524](http://arxiv.org/abs/2512.08524)|null|\n", "2512.08410": "|**2025-12-09**|**Towards Effective and Efficient Long Video Understanding of Multimodal Large Language Models via One-shot Clip Retrieval**|Rongrong Ji Team|[2512.08410](http://arxiv.org/abs/2512.08410)|null|\n", "2512.08294": "|**2025-12-10**|**OpenSubject: Leveraging Video-Derived Identity and Diversity Priors for Subject-driven Image Generation and Manipulation**|Harry Yang Team|[2512.08294](http://arxiv.org/abs/2512.08294)|null|\n", "2512.08282": "|**2025-12-09**|**PAVAS: Physics-Aware Video-to-Audio Synthesis**|Yuki Mitsufuji Team|[2512.08282](http://arxiv.org/abs/2512.08282)|null|\n", "2512.08240": "|**2025-12-09**|**HybridToken-VLM: Hybrid Token Compression for Vision-Language Models**|Keze Wang Team|[2512.08240](http://arxiv.org/abs/2512.08240)|null|\n", "2512.08233": "|**2025-12-09**|**Semantic-Metric Bayesian Risk Fields: Learning Robot Safety from Human Videos with a VLM Prior**|Mac Schwager Team|[2512.08233](http://arxiv.org/abs/2512.08233)|null|\n", "2512.08228": "|**2025-12-09**|**MM-CoT:A Benchmark for Probing Visual Chain-of-Thought Reasoning in Multimodal Models**|Keze Wang Team|[2512.08228](http://arxiv.org/abs/2512.08228)|null|\n", "2512.14715": "|**2025-12-09**|**How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection**|Prabuddha Chakraborty Team|[2512.14715](http://arxiv.org/abs/2512.14715)|null|\n", "2512.08186": "|**2025-12-09**|**Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation**|Xihui Liu Team|[2512.08186](http://arxiv.org/abs/2512.08186)|null|\n", "2512.08093": "|**2025-12-08**|**Training LLMs for Honesty via Confessions**|Amelia Glaese Team|[2512.08093](http://arxiv.org/abs/2512.08093)|null|\n", "2512.08016": "|**2025-12-08**|**FRIEDA: Benchmarking Multi-Step Cartographic Reasoning in Vision-Language Models**|Yao-Yi Chiang Team|[2512.08016](http://arxiv.org/abs/2512.08016)|null|\n", "2512.07833": "|**2025-12-08**|**Relational Visual Similarity**|Yuheng Li Team|[2512.07833](http://arxiv.org/abs/2512.07833)|**[link](https://thaoshibe.github.io/relsim)**|\n", "2512.07564": "|**2025-12-08**|**Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models**|Renzo Ardiccioni Team|[2512.07564](http://arxiv.org/abs/2512.07564)|**[link](https://github.com/kassoumsanogo1/self-correcting-vlm-re-Attention.git)**|\n", "2512.07452": "|**2025-12-08**|**From Show Programmes to Data: Designing a Workflow to Make Performing Arts Ephemera Accessible Through Language Models**|Jeanne Fras Team|[2512.07452](http://arxiv.org/abs/2512.07452)|null|\n", "2512.07360": "|**2025-12-08**|**Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation**|Jianbo Jiao Team|[2512.07360](http://arxiv.org/abs/2512.07360)|null|\n", "2512.07344": "|**2025-12-08**|**Venus: An Efficient Edge Memory-and-Retrieval System for VLM-based Online Video Understanding**|Xu Chen Team|[2512.07344](http://arxiv.org/abs/2512.07344)|null|\n", "2512.07338": "|**2025-12-08**|**Generalized Referring Expression Segmentation on Aerial Photos**|Bruno Martins Team|[2512.07338](http://arxiv.org/abs/2512.07338)|null|\n", "2512.07302": "|**2025-12-08**|**Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts**|Chao Tao Team|[2512.07302](http://arxiv.org/abs/2512.07302)|null|\n", "2512.07276": "|**2025-12-08**|**Geo3DVQA: Evaluating Vision-Language Models for 3D Geospatial Reasoning from Aerial Imagery**|Naoto Yokoya Team|[2512.07276](http://arxiv.org/abs/2512.07276)|null|\n", "2512.07273": "|**2025-12-08**|**RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation**|Jun Wan Team|[2512.07273](http://arxiv.org/abs/2512.07273)|null|\n", "2512.07245": "|**2025-12-08**|**Zero-Shot Textual Explanations via Translating Decision-Critical Features**|Kazuhiko Kawamoto Team|[2512.07245](http://arxiv.org/abs/2512.07245)|null|\n", "2512.07234": "|**2025-12-08**|**Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models**|Yuchen Wang Team|[2512.07234](http://arxiv.org/abs/2512.07234)|null|\n", "2512.07222": "|**2025-12-09**|**Pay Less Attention to Function Words for Free Robustness of Vision-Language Models**|Chao Shen Team|[2512.07222](http://arxiv.org/abs/2512.07222)|null|\n", "2512.07215": "|**2025-12-09**|**VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation**|Sungho Kim Team|[2512.07215](http://arxiv.org/abs/2512.07215)|null|\n", "2512.07203": "|**2025-12-08**|**MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning**|Yichao Wu Team|[2512.07203](http://arxiv.org/abs/2512.07203)|null|\n", "2512.07177": "|**2025-12-08**|**Using Vision-Language Models as Proxies for Social Intelligence in Human-Robot Interaction**|Wendy Ju Team|[2512.07177](http://arxiv.org/abs/2512.07177)|null|\n", "2512.07155": "|**2025-12-15**|**CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics**|Jihyong Oh Team|[2512.07155](http://arxiv.org/abs/2512.07155)|**[link](https://cmlab-korea.github.io/CHIMERA/)**|\n", "2512.07141": "|**2025-12-08**|**Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models**|Wenjie Wang Team|[2512.07141](http://arxiv.org/abs/2512.07141)|null|\n", "2512.07136": "|**2025-12-08**|**A Large-Scale Multimodal Dataset and Benchmarks for Human Activity Scene Understanding and Reasoning**|Guoliang Xing Team|[2512.07136](http://arxiv.org/abs/2512.07136)|null|\n", "2512.07132": "|**2025-12-08**|**DART: Leveraging Multi-Agent Disagreement for Tool Recruitment in Multimodal Reasoning**|Mohit Bansal Team|[2512.07132](http://arxiv.org/abs/2512.07132)|**[link](https://github.com/nsivaku/dart)**|\n", "2512.07128": "|**2025-12-08**|**MulCLIP: A Multi-level Alignment Framework for Enhancing Fine-grained Long-context CLIP**|Dung D. Le Team|[2512.07128](http://arxiv.org/abs/2512.07128)|null|\n", "2512.06963": "|**2025-12-07**|**VideoVLA: Video Generators Can Be Generalizable Robot Manipulators**|Baining Guo Team|[2512.06963](http://arxiv.org/abs/2512.06963)|**[link](https://videovla-nips2025.github.io)**|\n", "2512.06883": "|**2025-12-07**|**Structural and Disentangled Adaptation of Large Vision Language Models for Multimodal Recommendation**|Nan Tang Team|[2512.06883](http://arxiv.org/abs/2512.06883)|null|\n"}, "VLA": {"2504.00907": "|**2025-04-02**|**Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning**|Roozbeh Mottaghi Team|[2504.00907](http://arxiv.org/abs/2504.00907)|null|\n", "2503.23463": "|**2025-03-30**|**OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Model**|Alois C. Knoll Team|[2503.23463](http://arxiv.org/abs/2503.23463)|**[link](https://github.com/DriveVLA/OpenDriveVLA)**|\n", "2503.22020": "|**2025-03-27**|**CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models**|Tsung-Yi Lin Team|[2503.22020](http://arxiv.org/abs/2503.22020)|null|\n", "2503.20384": "|**2025-04-14**|**MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation**|Shanghang Zhang Team|[2503.20384](http://arxiv.org/abs/2503.20384)|null|\n", "2503.20020": "|**2025-03-25**|**Gemini Robotics: Bringing AI into the Physical World**|Yuxiang Zhou Team|[2503.20020](http://arxiv.org/abs/2503.20020)|null|\n", "2503.19757": "|**2025-03-25**|**Dita: Scaling Diffusion Transformer for Generalist Vision-Language-Action Policy**|Yuntao Chen Team|[2503.19757](http://arxiv.org/abs/2503.19757)|null|\n", "2503.19516": "|**2025-03-25**|**DataPlatter: Boosting Robotic Manipulation Generalization with Minimal Costly Data**|Lin Ma Team|[2503.19516](http://arxiv.org/abs/2503.19516)|null|\n", "2503.14734": "|**2025-03-27**|**GR00T N1: An Open Foundation Model for Generalist Humanoid Robots**|Yuke Zhu Team|[2503.14734](http://arxiv.org/abs/2503.14734)|null|\n", "2503.13446": "|**2025-03-17**|**MoManipVLA: Transferring Vision-language-action Models for General Mobile Manipulation**|Haibin Yan Team|[2503.13446](http://arxiv.org/abs/2503.13446)|null|\n", "2503.14526": "|**2025-03-15**|**ReBot: Scaling Robot Learning with Real-to-Sim-to-Real Robotic Video Synthesis**|Mingyu Ding Team|[2503.14526](http://arxiv.org/abs/2503.14526)|null|\n", "2503.10631": "|**2025-03-17**|**HybridVLA: Collaborative Diffusion and Autoregression in a Unified Vision-Language-Action Model**|Shanghang Zhang Team|[2503.10631](http://arxiv.org/abs/2503.10631)|null|\n", "2503.09527": "|**2025-03-12**|**CombatVLA: An Efficient Vision-Language-Action Model for Combat Tasks in 3D Action Role-Playing Games**|Bo Zheng Team|[2503.09527](http://arxiv.org/abs/2503.09527)|null|\n", "2503.08007": "|**2025-03-11**|**MoRE: Unlocking Scalability in Reinforcement Learning for Quadruped Vision-Language-Action Models**|Zongyuan Ge Team|[2503.08007](http://arxiv.org/abs/2503.08007)|null|\n", "2503.07511": "|**2025-03-10**|**PointVLA: Injecting the 3D World into Vision-Language-Action Models**|Yichen Zhu Team|[2503.07511](http://arxiv.org/abs/2503.07511)|null|\n", "2503.05833": "|**2025-03-06**|**Refined Policy Distillation: From VLA Generalists to RL Experts**|Florian Walter Team|[2503.05833](http://arxiv.org/abs/2503.05833)|null|\n", "2503.04163": "|**2025-03-06**|**VLA Model-Expert Collaboration for Bi-directional Manipulation Learning**|Zeng-Guang Hou Team|[2503.04163](http://arxiv.org/abs/2503.04163)|null|\n", "2503.03734": "|**2025-03-26**|**OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature Extraction**|Pieter Abbeel Team|[2503.03734](http://arxiv.org/abs/2503.03734)|null|\n", "2503.03480": "|**2025-03-05**|**SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Safe Reinforcement Learning**|Yaodong Yang Team|[2503.03480](http://arxiv.org/abs/2503.03480)|null|\n", "2503.02310": "|**2025-03-04**|**Accelerating Vision-Language-Action Model Integrated with Action Chunking via Parallel Decoding**|Haoang Li Team|[2503.02310](http://arxiv.org/abs/2503.02310)|null|\n", "2503.01378": "|**2025-03-03**|**CognitiveDrone: A VLA Model and Evaluation Benchmark for Real-Time Cognitive Task Solving and Reasoning in UAVs**|Dzmitry Tsetserukou Team|[2503.01378](http://arxiv.org/abs/2503.01378)|null|\n", "2504.06538": "|**2025-04-09**|**OPAL: Encoding Causal Understanding of Physical Systems for Robot Learning**|Tyler Fenstermaker Team|[2504.06538](http://arxiv.org/abs/2504.06538)|null|\n", "2504.10458": "|**2025-04-18**|**GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents**|Xiaobo Xia Team|[2504.10458](http://arxiv.org/abs/2504.10458)|null|\n", "2504.16054": "|**2025-04-22**|**$\u03c0_{0.5}$: a Vision-Language-Action Model with Open-World Generalization**|Ury Zhilinsky Team|[2504.16054](http://arxiv.org/abs/2504.16054)|null|\n", "2504.15517": "|**2025-04-22**|**Few-Shot Vision-Language Action-Incremental Policy Learning**|Weili Guan Team|[2504.15517](http://arxiv.org/abs/2504.15517)|null|\n", "2504.19854": "|**2025-04-28**|**NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks**|Soujanya Poria Team|[2504.19854](http://arxiv.org/abs/2504.19854)|null|\n", "2505.02166": "|**2025-05-04**|**CrayonRobo: Object-Centric Prompt-Driven Vision-Language-Action Model for Robotic Manipulation**|Hao Dong Team|[2505.02166](http://arxiv.org/abs/2505.02166)|null|\n", "2505.02152": "|**2025-05-04**|**Interleave-VLA: Enhancing Robot Manipulation with Interleaved Image-Text Instructions**|Mingyu Ding Team|[2505.02152](http://arxiv.org/abs/2505.02152)|null|\n", "2505.03500": "|**2025-05-16**|**Task Reconstruction and Extrapolation for $\u03c0_0$ using Text Latent**|Quanyi Li Team|[2505.03500](http://arxiv.org/abs/2505.03500)|null|\n", "2505.03233": "|**2025-05-06**|**GraspVLA: a Grasping Foundation Model Pre-trained on Billion-scale Synthetic Action Data**|He Wang Team|[2505.03233](http://arxiv.org/abs/2505.03233)|null|\n", "2505.03174": "|**2025-05-06**|**Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets**|Ross Greer Team|[2505.03174](http://arxiv.org/abs/2505.03174)|null|\n", "2505.03912": "|**2025-05-06**|**OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation**|Donglin Wang Team|[2505.03912](http://arxiv.org/abs/2505.03912)|**[link](https://github.com/OpenHelix-robot/OpenHelix)**|\n", "2505.04769": "|**2025-05-07**|**Vision-Language-Action Models: Concepts, Progress, Applications and Challenges**|Manoj Karkee Team|[2505.04769](http://arxiv.org/abs/2505.04769)|null|\n", "2505.06111": "|**2025-05-15**|**UniVLA: Learning to Act Anywhere with Task-centric Latent Actions**|Hongyang Li Team|[2505.06111](http://arxiv.org/abs/2505.06111)|**[link](https://github.com/opendrivelab/univla)**|\n", "2505.05800": "|**2025-05-09**|**3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks**|Farshad Khorrami Team|[2505.05800](http://arxiv.org/abs/2505.05800)|null|\n", "2505.05540": "|**2025-05-08**|**Benchmarking Vision, Language, & Action Models in Procedurally Generated, Open Ended Action Environments**|Harshvardhan Sikka Team|[2505.05540](http://arxiv.org/abs/2505.05540)|**[link](https://github.com/ManifoldRG/MultiNet)**|\n", "2505.07817": "|**2025-05-12**|**Pixel Motion as Universal Representation for Robot Control**|Michael S Ryoo Team|[2505.07817](http://arxiv.org/abs/2505.07817)|null|\n", "2505.07395": "|**2025-05-12**|**ReinboT: Amplifying Robot Visual-Language Manipulation with Reinforcement Learning**|Donglin Wang Team|[2505.07395](http://arxiv.org/abs/2505.07395)|null|\n", "2505.08548": "|**2025-05-13**|**From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation**|Jianye Hao Team|[2505.08548](http://arxiv.org/abs/2505.08548)|null|\n", "2505.08243": "|**2025-05-17**|**Training Strategies for Efficient Embodied Reasoning**|Sergey Levine Team|[2505.08243](http://arxiv.org/abs/2505.08243)|null|\n", "2505.09601": "|**2025-05-14**|**Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware**|Ken Goldberg Team|[2505.09601](http://arxiv.org/abs/2505.09601)|null|\n", "2505.09040": "|**2025-05-14**|**RT-cache: Efficient Robot Trajectory Retrieval System**|Amir Barati Farimani Team|[2505.09040](http://arxiv.org/abs/2505.09040)|null|\n", "2505.11214": "|**2025-05-16**|**Unveiling the Potential of Vision-Language-Action Models with Open-Ended Multimodal Instructions**|Donglin Wang Team|[2505.11214](http://arxiv.org/abs/2505.11214)|null|\n", "2505.11123": "|**2025-05-16**|**Conditioning Matters: Training Diffusion Policies is Faster Than You Think**|Jianye Hao Team|[2505.11123](http://arxiv.org/abs/2505.11123)|null|\n", "2505.12224": "|**2025-05-25**|**RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction**|Bo Zhao Team|[2505.12224](http://arxiv.org/abs/2505.12224)|null|\n", "2505.11917": "|**2025-05-17**|**OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning**|Yang Gao Team|[2505.11917](http://arxiv.org/abs/2505.11917)|null|\n", "2505.14030": "|**2025-05-20**|**AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory**|Ping Luo Team|[2505.14030](http://arxiv.org/abs/2505.14030)|null|\n", "2505.13888": "|**2025-05-22**|**InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning**|Jingkuan Song Team|[2505.13888](http://arxiv.org/abs/2505.13888)|**[link](https://github.com/inspirevla/inspire)**|\n", "2505.15685": "|**2025-05-21**|**From Grounding to Manipulation: Case Studies of Foundation Model Integration in Embodied Robotic Systems**|Soujanya Poria Team|[2505.15685](http://arxiv.org/abs/2505.15685)|**[link](https://github.com/hritdy/claw_machine)**|\n", "2505.15660": "|**2025-05-24**|**Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization**|Junwei Liang Team|[2505.15660](http://arxiv.org/abs/2505.15660)|**[link](https://github.com/jiaming-zhou/X-ICM)**|\n", "2505.15659": "|**2025-05-21**|**FLARE: Robot Learning with Implicit World Modeling**|Linxi Fan Team|[2505.15659](http://arxiv.org/abs/2505.15659)|null|\n", "2505.15304": "|**2025-05-21**|**Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control**|Jungwook Choi Team|[2505.15304](http://arxiv.org/abs/2505.15304)|null|\n", "2505.15206": "|**2025-05-21**|**EndoVLA: Dual-Phase Vision-Language-Action Model for Autonomous Tracking in Endoscopy**|Hongliang Ren Team|[2505.15206](http://arxiv.org/abs/2505.15206)|null|\n", "2505.15098": "|**2025-05-21**|**Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation**|Xiaodong He Team|[2505.15098](http://arxiv.org/abs/2505.15098)|null|\n", "2505.17016": "|**2025-05-22**|**Interactive Post-Training for Vision-Language-Action Models**|Philipp Kr\u00e4henb\u00fchl Team|[2505.17016](http://arxiv.org/abs/2505.17016)|null|\n", "2505.16815": "|**2025-05-22**|**Perceptual Quality Assessment for Embodied AI**|Guangtao Zhai Team|[2505.16815](http://arxiv.org/abs/2505.16815)|**[link](https://github.com/lcysyzxdxc/embodiediqa)**|\n", "2505.16640": "|**2025-05-22**|**BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization**|Lichao Sun Team|[2505.16640](http://arxiv.org/abs/2505.16640)|null|\n", "2505.16278": "|**2025-05-22**|**DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving**|Junchi Yan Team|[2505.16278](http://arxiv.org/abs/2505.16278)|null|\n", "2505.17295": "|**2025-05-22**|**ScanBot: Towards Intelligent Surface Scanning in Embodied Robotic Systems**|Farhad Imani Team|[2505.17295](http://arxiv.org/abs/2505.17295)|null|\n", "2505.19789": "|**2025-05-26**|**What Can RL Bring to VLA Generalization? An Empirical Study**|Yu Wang Team|[2505.19789](http://arxiv.org/abs/2505.19789)|null|\n", "2505.19767": "|**2025-05-26**|**RFTF: Reinforcement Fine-tuning for Embodied Agents with Temporal Feedback**|Yongtao Wang Team|[2505.19767](http://arxiv.org/abs/2505.19767)|null|\n", "2505.19080": "|**2025-05-25**|**ReFineVLA: Reasoning-Aware Teacher-Guided Transfer Fine-Tuning**|Minh Nhat Vu Team|[2505.19080](http://arxiv.org/abs/2505.19080)|null|\n", "2505.18793": "|**2025-05-24**|**Genie Centurion: Accelerating Scalable Real-World Robot Training with Human Rewind-and-Refine Guidance**|Maoqing Yao Team|[2505.18793](http://arxiv.org/abs/2505.18793)|null|\n", "2505.18719": "|**2025-05-24**|**VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning**|Ziwei Wang Team|[2505.18719](http://arxiv.org/abs/2505.18719)|**[link](https://github.com/guanxinglu/vlarl)**|\n", "2505.21432": "|**2025-06-02**|**Hume: Introducing System-2 Thinking in Visual-Language-Action Model**|Xuelong Li Team|[2505.21432](http://arxiv.org/abs/2505.21432)|null|\n", "2505.21200": "|**2025-05-27**|**Think Twice, Act Once: Token-Aware Compression and Action Reuse for Efficient Inference in Vision-Language-Action Models**|Tao Chen Team|[2505.21200](http://arxiv.org/abs/2505.21200)|null|\n", "2505.20503": "|**2025-05-26**|**Embodied AI with Foundation Models for Mobile Service Robots: A Systematic Review**|Goldie Nejat Team|[2505.20503](http://arxiv.org/abs/2505.20503)|null|\n", "2505.22159": "|**2025-05-28**|**ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation**|Wenqiang Zhang Team|[2505.22159](http://arxiv.org/abs/2505.22159)|null|\n", "2505.21906": "|**2025-05-29**|**ChatVLA-2: Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge**|Yi Xu Team|[2505.21906](http://arxiv.org/abs/2505.21906)|null|\n", "2505.21567": "|**2025-05-27**|**EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models**|Xiang Chen Team|[2505.21567](http://arxiv.org/abs/2505.21567)|null|\n", "2505.23757": "|**2025-05-29**|**Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models**|Hao Zhao Team|[2505.23757](http://arxiv.org/abs/2505.23757)|**[link](https://github.com/ahydchh/impromptu-vla)**|\n", "2505.23705": "|**2025-05-29**|**Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better**|Sergey Levine Team|[2505.23705](http://arxiv.org/abs/2505.23705)|null|\n", "2505.23450": "|**2025-05-29**|**Agentic Robot: A Brain-Inspired Framework for Vision-Language-Action Models in Embodied Agents**|Lichao Sun Team|[2505.23450](http://arxiv.org/abs/2505.23450)|null|\n", "2505.23189": "|**2025-05-29**|**TrackVLA: Embodied Visual Tracking in the Wild**|He Wang Team|[2505.23189](http://arxiv.org/abs/2505.23189)|null|\n", "2505.24156": "|**2025-05-30**|**Towards a Generalizable Bimanual Foundation Policy via Flow-based Video Prediction**|Xuelong Li Team|[2505.24156](http://arxiv.org/abs/2505.24156)|null|\n", "2506.01953": "|**2025-06-02**|**Fast-in-Slow: A Dual-System Foundation Model Unifying Fast Manipulation within Slow Reasoning**|Pheng-Ann Heng Team|[2506.01953](http://arxiv.org/abs/2506.01953)|null|\n", "2506.01844": "|**2025-06-02**|**SmolVLA: A Vision-Language-Action Model for Affordable and Efficient Robotics**|Remi Cadene Team|[2506.01844](http://arxiv.org/abs/2506.01844)|**[link](https://github.com/huggingface/lerobot)**|\n", "2506.01616": "|**2025-06-02**|**MLA-Trust: Benchmarking Trustworthiness of Multimodal LLM Agents in GUI Environments**|Jun Zhu Team|[2506.01616](http://arxiv.org/abs/2506.01616)|null|\n", "2506.01300": "|**2025-06-02**|**ReAgent-V: A Reward-Driven Multi-Agent Framework for Video Understanding**|Huaxiu Yao Team|[2506.01300](http://arxiv.org/abs/2506.01300)|null|\n", "2506.01196": "|**2025-06-01**|**OG-VLA: 3D-Aware Vision Language Action Model via Orthographic Image Generation**|Valts Blukis Team|[2506.01196](http://arxiv.org/abs/2506.01196)|null|\n", "2506.00411": "|**2025-05-31**|**LoHoVLA: A Unified Vision-Language-Action Model for Long-Horizon Embodied Tasks**|Zhijie Deng Team|[2506.00411](http://arxiv.org/abs/2506.00411)|null|\n", "2506.03574": "|**2025-06-04**|**SwitchVLA: Execution-Aware Task Switching for Vision-Language-Action Models**|Jian Tang Team|[2506.03574](http://arxiv.org/abs/2506.03574)|null|\n", "2506.03350": "|**2025-06-03**|**Adversarial Attacks on Robotic Vision Language Action Models**|J. Zico Kolter Team|[2506.03350](http://arxiv.org/abs/2506.03350)|**[link](https://github.com/eliotjones1/robogcg)**|\n", "2506.05667": "|**2025-06-06**|**DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models**|Xianpeng Lang Team|[2506.05667](http://arxiv.org/abs/2506.05667)|null|\n", "2506.07961": "|**2025-06-09**|**BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models**|Tieniu Tan Team|[2506.07961](http://arxiv.org/abs/2506.07961)|null|\n", "2506.07639": "|**2025-06-09**|**Fast ECoT: Efficient Embodied Chain-of-Thought via Thoughts Reuse**|Chris Xiaoxuan Lu Team|[2506.07639](http://arxiv.org/abs/2506.07639)|null|\n", "2506.07530": "|**2025-06-09**|**BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation**|Xilin Chen Team|[2506.07530](http://arxiv.org/abs/2506.07530)|**[link](https://github.com/ustcwhy/bitvla)**|\n", "2506.07339": "|**2025-06-09**|**Real-Time Execution of Action Chunking Flow Policies**|Sergey Levine Team|[2506.07339](http://arxiv.org/abs/2506.07339)|null|\n", "2506.07127": "|**2025-06-12**|**Robotic Policy Learning via Human-assisted Action Preference Optimization**|Di Hu Team|[2506.07127](http://arxiv.org/abs/2506.07127)|null|\n", "2506.06677": "|**2025-06-07**|**RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation**|Si Liu Team|[2506.06677](http://arxiv.org/abs/2506.06677)|null|\n", "2506.06535": "|**2025-06-06**|**MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping**|Farshad Khorrami Team|[2506.06535](http://arxiv.org/abs/2506.06535)|null|\n", "2506.08822": "|**2025-06-10**|**FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency**|Jian Tang Team|[2506.08822](http://arxiv.org/abs/2506.08822)|null|\n", "2506.08462": "|**2025-06-10**|**Hybrid Reasoning for Perception, Explanation, and Autonomous Action in Manufacturing**|Sebastian W. Pattinson Team|[2506.08462](http://arxiv.org/abs/2506.08462)|null|\n", "2506.08440": "|**2025-06-11**|**TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization**|Qi Wang Team|[2506.08440](http://arxiv.org/abs/2506.08440)|null|\n", "2506.08296": "|**2025-06-11**|**HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation**|Cong Wang Team|[2506.08296](http://arxiv.org/abs/2506.08296)|null|\n", "2506.08185": "|**2025-06-14**|**Agentic Surgical AI: Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion in a Vision-Language-Action Framework**|Jason H. Moore Team|[2506.08185](http://arxiv.org/abs/2506.08185)|**[link](https://github.com/huixin-zhan-ai/surgeon_style_fingerprinting)**|\n", "2506.09937": "|**2025-06-11**|**SAFE: Multitask Failure Detection for Vision-Language-Action Models**|Florian Shkurti Team|[2506.09937](http://arxiv.org/abs/2506.09937)|null|\n", "2506.09930": "|**2025-06-11**|**From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models**|Chen Feng Team|[2506.09930](http://arxiv.org/abs/2506.09930)|null|\n", "2506.09172": "|**2025-06-17**|**An Open-Source Software Toolkit & Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models**|Harshvardhan Sikka Team|[2506.09172](http://arxiv.org/abs/2506.09172)|null|\n", "2506.10826": "|**2025-06-13**|**RationalVLA: A Rational Vision-Language-Action Model with Dual System**|Haoang Li Team|[2506.10826](http://arxiv.org/abs/2506.10826)|null|\n", "2506.10100": "|**2025-06-11**|**EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models**|Linfeng Zhang Team|[2506.10100](http://arxiv.org/abs/2506.10100)|null|\n", "2506.13757": "|**2025-06-16**|**AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning**|Jiaqi Ma Team|[2506.13757](http://arxiv.org/abs/2506.13757)|**[link](https://github.com/ucla-mobility/AutoVLA)**|\n", "2506.13751": "|**2025-06-19**|**LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction**|Shankar Sastry Team|[2506.13751](http://arxiv.org/abs/2506.13751)|null|\n", "2506.13725": "|**2025-06-16**|**CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding**|Haoang Li Team|[2506.13725](http://arxiv.org/abs/2506.13725)|null|\n", "2506.13679": "|**2025-06-16**|**ROSA: Harnessing Robot States for Vision-Language and Action Alignment**|Xiaoyan Sun Team|[2506.13679](http://arxiv.org/abs/2506.13679)|null|\n", "2506.13456": "|**2025-06-16**|**Block-wise Adaptive Caching for Accelerating Diffusion Policy**|Zhi Wang Team|[2506.13456](http://arxiv.org/abs/2506.13456)|null|\n", "2506.13045": "|**2025-06-19**|**A Comprehensive Survey on Continual Learning in Generative Models**|Cheng-Lin Liu Team|[2506.13045](http://arxiv.org/abs/2506.13045)|**[link](https://github.com/ghy0501/awesome-continual-learning-in-generative-models)**|\n", "2506.12723": "|**2025-06-19**|**SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration**|Wenwu Zhu Team|[2506.12723](http://arxiv.org/abs/2506.12723)|null|\n", "2506.14317": "|**2025-06-19**|**ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes**|Hao Dong Team|[2506.14317](http://arxiv.org/abs/2506.14317)|null|\n", "2506.14009": "|**2025-06-16**|**GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics**|Mac Schwager Team|[2506.14009](http://arxiv.org/abs/2506.14009)|null|\n", "2506.16263": "|**2025-06-19**|**CapsDT: Diffusion-Transformer for Capsule Robot Manipulation**|Hongliang Ren Team|[2506.16263](http://arxiv.org/abs/2506.16263)|null|\n", "2506.16211": "|**2025-06-19**|**ControlVLA: Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models**|Siyuan Huang Team|[2506.16211](http://arxiv.org/abs/2506.16211)|null|\n", "2506.17811": "|**2025-07-07**|**RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models**|Marco Pavone Team|[2506.17811](http://arxiv.org/abs/2506.17811)|null|\n", "2506.17639": "|**2025-06-21**|**RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models**|Xiao Li Team|[2506.17639](http://arxiv.org/abs/2506.17639)|null|\n", "2506.17561": "|**2025-06-21**|**VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models**|Lin Shao Team|[2506.17561](http://arxiv.org/abs/2506.17561)|null|\n", "2506.19850": "|**2025-06-24**|**Unified Vision-Language-Action Model**|Zhaoxiang Zhang Team|[2506.19850](http://arxiv.org/abs/2506.19850)|null|\n", "2506.19816": "|**2025-06-24**|**CronusVLA: Transferring Latent Motion Across Time for Multi-Frame Prediction in Manipulation**|Jiangmiao Pang Team|[2506.19816](http://arxiv.org/abs/2506.19816)|null|\n", "2506.21539": "|**2025-06-26**|**WorldVLA: Towards Autoregressive Action World Model**|Hao Chen Team|[2506.21539](http://arxiv.org/abs/2506.21539)|null|\n", "2506.20966": "|**2025-06-26**|**Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends**|Zeng-Guang Hou Team|[2506.20966](http://arxiv.org/abs/2506.20966)|null|\n", "2506.22242": "|**2025-06-27**|**4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration**|Li Zhang Team|[2506.22242](http://arxiv.org/abs/2506.22242)|null|\n", "2506.24044": "|**2025-06-30**|**A Survey on Vision-Language-Action Models for Autonomous Driving**|Lijun Sun Team|[2506.24044](http://arxiv.org/abs/2506.24044)|null|\n", "2507.01925": "|**2025-07-02**|**A Survey on Vision-Language-Action Models: An Action Tokenization Perspective**|Yaodong Yang Team|[2507.01925](http://arxiv.org/abs/2507.01925)|null|\n", "2507.01843": "|**2025-07-02**|**MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics**|Nadiya Shvai Team|[2507.01843](http://arxiv.org/abs/2507.01843)|null|\n", "2507.01424": "|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Yanwei Fu Team|[2507.01424](http://arxiv.org/abs/2507.01424)|null|\n", "2507.01016": "|**2025-07-01**|**VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers**|Tong He Team|[2507.01016](http://arxiv.org/abs/2507.01016)|null|\n", "2507.00416": "|**2025-07-01**|**Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding**|Bo Zhao Team|[2507.00416](http://arxiv.org/abs/2507.00416)|null|\n", "2507.02747": "|**2025-07-03**|**DexVLG: Dexterous Vision-Language-Grasp Model at Scale**|He Wang Team|[2507.02747](http://arxiv.org/abs/2507.02747)|null|\n", "2507.02190": "|**2025-07-02**|**cVLA: Towards Efficient Camera-Space VLAs**|Thomas Brox Team|[2507.02190](http://arxiv.org/abs/2507.02190)|null|\n", "2507.05227": "|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Cheng Lu Team|[2507.05227](http://arxiv.org/abs/2507.05227)|null|\n", "2507.05116": "|**2025-07-10**|**VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting**|Yanzhi Wang Team|[2507.05116](http://arxiv.org/abs/2507.05116)|null|\n", "2507.04447": "|**2025-07-17**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Xin Jin Team|[2507.04447](http://arxiv.org/abs/2507.04447)|null|\n", "2507.04227": "|**2025-07-06**|**Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged Third Parties**|Yunxin Liu Team|[2507.04227](http://arxiv.org/abs/2507.04227)|null|\n", "2507.06484": "|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Nick Haber Team|[2507.06484](http://arxiv.org/abs/2507.06484)|**[link](https://ai.stanford.edu/~sunfanyun/3d-generalist/)**|\n", "2507.09160": "|**2025-07-12**|**Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization**|Yang Gao Team|[2507.09160](http://arxiv.org/abs/2507.09160)|null|\n", "2507.10672": "|**2025-07-14**|**Vision Language Action Models in Robotic Manipulation: A Systematic Review**|Irfan Hussain Team|[2507.10672](http://arxiv.org/abs/2507.10672)|null|\n", "2507.12440": "|**2025-07-18**|**EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos**|Xiaolong Wang Team|[2507.12440](http://arxiv.org/abs/2507.12440)|**[link](https://rchalyang.github.io/EgoVLA)**|\n", "2507.12911": "|**2025-07-23**|**LaViPlan : Language-Guided Visual Path Planning with RLVR**|Hayeon Oh Team|[2507.12911](http://arxiv.org/abs/2507.12911)|null|\n", "2507.12768": "|**2025-07-17**|**AnyPos: Automated Task-Agnostic Actions for Bimanual Manipulation**|Jun Zhu Team|[2507.12768](http://arxiv.org/abs/2507.12768)|null|\n", "2507.14049": "|**2025-07-18**|**EdgeVLA: Efficient Vision-Language-Action Models**|Benjamin Bolte Team|[2507.14049](http://arxiv.org/abs/2507.14049)|null|\n", "2507.15597": "|**2025-07-21**|**Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos**|Zongqing Lu Team|[2507.15597](http://arxiv.org/abs/2507.15597)|null|\n", "2507.15493": "|**2025-07-22**|**GR-3 Technical Report**|Yichu Yang Team|[2507.15493](http://arxiv.org/abs/2507.15493)|**[link](https://seed.bytedance.com/GR3/)**|\n", "2507.16815": "|**2025-07-22**|**ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning**|Fu-En Yang Team|[2507.16815](http://arxiv.org/abs/2507.16815)|**[link](https://jasper0314-huang.github.io/thinkact-vla/)**|\n", "2507.17520": "|**2025-07-23**|**InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation**|Jiangmiao Pang Team|[2507.17520](http://arxiv.org/abs/2507.17520)|null|\n", "2507.17462": "|**2025-07-23**|**ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents**|Hesheng Wang Team|[2507.17462](http://arxiv.org/abs/2507.17462)|null|\n", "2507.17383": "|**2025-07-23**|**Confidence Calibration in Vision-Language-Action Models**|Richard Zemel Team|[2507.17383](http://arxiv.org/abs/2507.17383)|null|\n", "2507.17294": "|**2025-07-29**|**VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback**|Harold Soh Team|[2507.17294](http://arxiv.org/abs/2507.17294)|null|\n", "2508.00097": "|**2025-07-31**|**XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation**|Ning Yang Team|[2508.00097](http://arxiv.org/abs/2508.00097)|**[link](https://github.com/XR-Robotics)**|\n", "2507.23682": "|**2025-07-31**|**villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models**|Jiang Bian Team|[2507.23682](http://arxiv.org/abs/2507.23682)|**[link](https://aka.ms/villa-x)**|\n", "2507.23540": "|**2025-07-31**|**A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving**|Alois Knoll Team|[2507.23540](http://arxiv.org/abs/2507.23540)|null|\n", "2507.23318": "|**2025-08-02**|**FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning**|Shanghang Zhang Team|[2507.23318](http://arxiv.org/abs/2507.23318)|null|\n", "2507.22424": "|**2025-07-30**|**Spec-VLA: Speculative Decoding for Vision-Language-Action Models with Relaxed Acceptance**|Derek F. Wong Team|[2507.22424](http://arxiv.org/abs/2507.22424)|null|\n", "2508.04681": "|**2025-08-06**|**Perceiving and Acting in First-Person: A Dataset and Benchmark for Egocentric Human-Object-Human Interactions**|Xiaokang Yang Team|[2508.04681](http://arxiv.org/abs/2508.04681)|**[link](https://liangxuy.github.io/InterVLA/)**|\n", "2508.02549": "|**2025-08-04**|**MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming**|Zhaoxin Fan Team|[2508.02549](http://arxiv.org/abs/2508.02549)|null|\n", "2508.02219": "|**2025-08-04**|**CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning**|Chunhe Xia Team|[2508.02219](http://arxiv.org/abs/2508.02219)|null|\n", "2508.02190": "|**2025-08-04**|**FedVLA: Federated Vision-Language-Action Learning with Dual Gating Mixture-of-Experts for Robotic Manipulation**|Xiaodong Wang Team|[2508.02190](http://arxiv.org/abs/2508.02190)|null|\n", "2508.02062": "|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Insup Lee Team|[2508.02062](http://arxiv.org/abs/2508.02062)|null|\n", "2508.05342": "|**2025-08-07**|**Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control**|Hamid Reza Karimi Team|[2508.05342](http://arxiv.org/abs/2508.05342)|null|\n", "2508.05294": "|**2025-08-14**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Jorge Pe\u00f1a Queralta Team|[2508.05294](http://arxiv.org/abs/2508.05294)|null|\n", "2508.05186": "|**2025-08-07**|**Learning to See and Act: Task-Aware View Planning for Robotic Manipulation**|Liang Lin Team|[2508.05186](http://arxiv.org/abs/2508.05186)|**[link](https://hcplab-sysu.github.io/TAVP)**|\n", "2508.08189": "|**2025-08-14**|**Reinforcement Learning in Vision: A Survey**|Mike Zheng Shou Team|[2508.08189](http://arxiv.org/abs/2508.08189)|null|\n", "2508.07917": "|**2025-08-12**|**MolmoAct: Action Reasoning Models that can Reason in Space**|Ranjay Krishna Team|[2508.07917](http://arxiv.org/abs/2508.07917)|**[link](https://allenai.org/blog/molmoact)**|\n", "2508.07770": "|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Lei Han Team|[2508.07770](http://arxiv.org/abs/2508.07770)|null|\n", "2508.07650": "|**2025-08-23**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Hong Zhang Team|[2508.07650](http://arxiv.org/abs/2508.07650)|null|\n", "2508.06571": "|**2025-08-15**|**IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model**|Li Sun Team|[2508.06571](http://arxiv.org/abs/2508.06571)|null|\n", "2508.06553": "|**2025-08-06**|**Static and Plugged: Make Embodied Evaluation Simple**|Guangtao Zhai Team|[2508.06553](http://arxiv.org/abs/2508.06553)|null|\n", "2508.06547": "|**2025-08-06**|**A tutorial note on collecting simulated data for vision-language-action models**|Jingfeng Zhang Team|[2508.06547](http://arxiv.org/abs/2508.06547)|null|\n", "2508.09071": "|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Jiale Cao Team|[2508.09071](http://arxiv.org/abs/2508.09071)|**[link](https://linsun449.github.io/GeoVLA/)**|\n", "2508.09032": "|**2025-08-12**|**Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding**|Aleksandr I. Panov Team|[2508.09032](http://arxiv.org/abs/2508.09032)|null|\n", "2508.08706": "|**2025-08-22**|**OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing**|Hengdi Zhang Team|[2508.08706](http://arxiv.org/abs/2508.08706)|**[link](https://readerek.github.io/Objtac.github.io)**|\n", "2508.10416": "|**2025-08-14**|**CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model**|Hao Dong Team|[2508.10416](http://arxiv.org/abs/2508.10416)|null|\n", "2508.10399": "|**2025-08-14**|**Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning**|Ping Kuang Team|[2508.10399](http://arxiv.org/abs/2508.10399)|null|\n", "2508.10333": "|**2025-08-14**|**ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver**|Haoang Li Team|[2508.10333](http://arxiv.org/abs/2508.10333)|null|\n", "2508.13103": "|**2025-08-18**|**Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy**|Zhi Hou Team|[2508.13103](http://arxiv.org/abs/2508.13103)|null|\n", "2508.13073": "|**2025-09-01**|**Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey**|Liqiang Nie Team|[2508.13073](http://arxiv.org/abs/2508.13073)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|\n", "2508.12211": "|**2025-08-17**|**Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search**|Glen Berseth Team|[2508.12211](http://arxiv.org/abs/2508.12211)|null|\n", "2508.11960": "|**2025-08-16**|**Toward General Physical Intelligence for Resilient Agile Manufacturing Automation**|Sunny Katyara Team|[2508.11960](http://arxiv.org/abs/2508.11960)|null|\n", "2508.13446": "|**2025-08-19**|**CAST: Counterfactual Labels Improve Instruction Following in Vision-Language-Action Models**|Sergey Levine Team|[2508.13446](http://arxiv.org/abs/2508.13446)|null|\n", "2508.15201": "|**2025-08-21**|**Survey of Vision-Language-Action Models for Embodied Manipulation**|Dongbin Zhao Team|[2508.15201](http://arxiv.org/abs/2508.15201)|null|\n", "2508.16292": "|**2025-08-22**|**Do What? Teaching Vision-Language-Action Models to Reject the Impossible**|David M. Chan Team|[2508.16292](http://arxiv.org/abs/2508.16292)|null|\n", "2508.18269": "|**2025-08-26**|**FlowVLA: Thinking in Motion with a Visual Chain of Thought**|Haoang Li Team|[2508.18269](http://arxiv.org/abs/2508.18269)|null|\n", "2508.17230": "|**2025-09-06**|**4D Visual Pre-training for Robot Learning**|Huazhe Xu Team|[2508.17230](http://arxiv.org/abs/2508.17230)|null|\n", "2508.16845": "|**2025-08-23**|**NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows**|Vladislav Kurenkov Team|[2508.16845](http://arxiv.org/abs/2508.16845)|null|\n", "2508.19236": "|**2025-08-26**|**MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation**|Gao Huang Team|[2508.19236](http://arxiv.org/abs/2508.19236)|**[link](https://shihao1895.github.io/MemoryVLA)**|\n", "2508.20072": "|**2025-08-27**|**Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies**|Ping Luo Team|[2508.20072](http://arxiv.org/abs/2508.20072)|null|\n", "2508.19958": "|**2025-08-28**|**Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation**|Donglin Wang Team|[2508.19958](http://arxiv.org/abs/2508.19958)|**[link](https://long-vla.github.io)**|\n", "2508.19852": "|**2025-08-28**|**Ego-centric Predictive Model Conditioned on Hand Trajectories**|Mike Zheng Shou Team|[2508.19852](http://arxiv.org/abs/2508.19852)|null|\n", "2508.19257": "|**2025-08-15**|**TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models**|Huiling Duan Team|[2508.19257](http://arxiv.org/abs/2508.19257)|null|\n", "2508.21046": "|**2025-08-28**|**CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification**|Liqiang Nie Team|[2508.21046](http://arxiv.org/abs/2508.21046)|**[link](https://jiutian-vl.github.io/CogVLA-page)**|\n", "2508.21112": "|**2025-09-09**|**EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control**|Dong Wang Team|[2508.21112](http://arxiv.org/abs/2508.21112)|null|\n", "2509.03383": "|**2025-09-03**|**ANNIE: Be Careful of Your Robots**|Yiming Gan Team|[2509.03383](http://arxiv.org/abs/2509.03383)|null|\n", "2509.02055": "|**2025-09-05**|**Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance**|Xuelong Li Team|[2509.02055](http://arxiv.org/abs/2509.02055)|null|\n", "2509.01944": "|**2025-09-02**|**AutoDrive-R$^2$: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving**|Shuo Li Team|[2509.01944](http://arxiv.org/abs/2509.01944)|null|\n", "2509.00789": "|**2025-08-31**|**OmniReason: A Temporal-Guided Vision-Language-Action Framework for Autonomous Driving**|Jun Ma Team|[2509.00789](http://arxiv.org/abs/2509.00789)|null|\n", "2509.00576": "|**2025-08-30**|**Galaxea Open-World Dataset and G0 Dual-System VLA Model**|Hang Zhao Team|[2509.00576](http://arxiv.org/abs/2509.00576)|**[link](https://opengalaxea.github.io/G0/)**|\n", "2509.00328": "|**2025-08-30**|**Mechanistic interpretability for steering vision-language-action models**|Claire Tomlin Team|[2509.00328](http://arxiv.org/abs/2509.00328)|**[link](https://vla-mech-interp.github.io/)**|\n", "2509.04063": "|**2025-09-04**|**Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models**|Donglin Wang Team|[2509.04063](http://arxiv.org/abs/2509.04063)|null|\n", "2509.04018": "|**2025-09-04**|**FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction**|Jingtai Liu Team|[2509.04018](http://arxiv.org/abs/2509.04018)|null|\n", "2509.04996": "|**2025-09-05**|**FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies**|Rudolf Lioutikov Team|[2509.04996](http://arxiv.org/abs/2509.04996)|null|\n", "2509.06951": "|**2025-09-09**|**F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions**|Jiangmiao Pang Team|[2509.06951](http://arxiv.org/abs/2509.06951)|**[link](https://aopolin-lv.github.io/F1-VLA/)**|\n", "2509.06932": "|**2025-09-10**|**LLaDA-VLA: Vision Language Diffusion Action Models**|Xiaoyan Sun Team|[2509.06932](http://arxiv.org/abs/2509.06932)|null|\n", "2509.06819": "|**2025-09-08**|**CRISP -- Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation**|Angela P. Sch\u00f6llig Team|[2509.06819](http://arxiv.org/abs/2509.06819)|null|\n", "2509.05614": "|**2025-09-06**|**SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning**|Guohao Dai Team|[2509.05614](http://arxiv.org/abs/2509.05614)|null|\n", "2509.05578": "|**2025-09-06**|**OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision**|Hang Zhao Team|[2509.05578](http://arxiv.org/abs/2509.05578)|null|\n", "2509.05513": "|**2025-09-05**|**OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation**|Yu Xiang Team|[2509.05513](http://arxiv.org/abs/2509.05513)|null|\n", "2509.07962": "|**2025-09-09**|**TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models**|Hao Zhao Team|[2509.07962](http://arxiv.org/abs/2509.07962)|**[link](https://zzongzheng0918.github.io/Torque-Aware-VLA.github.io/})**|\n", "2509.07957": "|**2025-09-09**|**Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation**|Yingbai Hu Team|[2509.07957](http://arxiv.org/abs/2509.07957)|null|\n", "2509.08820": "|**2025-09-10**|**RoboChemist: Long-Horizon and Safety-Compliant Robotic Chemical Experimentation**|Hao Zhao Team|[2509.08820](http://arxiv.org/abs/2509.08820)|**[link](https://zzongzheng0918.github.io/RoboChemist.github.io/)**|\n", "2509.09674": "|**2025-09-11**|**SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning**|Ning Ding Team|[2509.09674](http://arxiv.org/abs/2509.09674)|null|\n", "2509.09372": "|**2025-09-22**|**VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model**|Donglin Wang Team|[2509.09372](http://arxiv.org/abs/2509.09372)|**[link](https://vla-adapter.github.io/)**|\n", "2509.09090": "|**2025-09-11**|**SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models**|Huanrui Yang Team|[2509.09090](http://arxiv.org/abs/2509.09090)|null|\n", "2509.11480": "|**2025-09-15**|**Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs**|Yanzhi Wang Team|[2509.11480](http://arxiv.org/abs/2509.11480)|null|\n", "2509.11417": "|**2025-09-17**|**Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations**|Xuanlin Li Team|[2509.11417](http://arxiv.org/abs/2509.11417)|**[link](https://gen-vla.github.io/)**|\n", "2509.12594": "|**2025-09-21**|**The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning**|Xianpeng Lang Team|[2509.12594](http://arxiv.org/abs/2509.12594)|**[link](https://liauto-research.github.io/LightVLA)**|\n", "2509.14143": "|**2025-09-17**|**CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping**|Lifeng Zhou Team|[2509.14143](http://arxiv.org/abs/2509.14143)|null|\n", "2509.14138": "|**2025-09-17**|**SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model**|Yiming Feng Team|[2509.14138](http://arxiv.org/abs/2509.14138)|null|\n", "2509.14117": "|**2025-09-22**|**GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model**|Dezhen Song Team|[2509.14117](http://arxiv.org/abs/2509.14117)|null|\n", "2509.13774": "|**2025-09-17**|**Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach**|Yangwei You Team|[2509.13774](http://arxiv.org/abs/2509.13774)|null|\n", "2509.13769": "|**2025-09-17**|**AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving**|Zhi-xin Yang Team|[2509.13769](http://arxiv.org/abs/2509.13769)|null|\n", "2509.11839": "|**2025-09-17**|**TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning**|Donglin Wang Team|[2509.11839](http://arxiv.org/abs/2509.11839)|null|\n", "2509.13347": "|**2025-09-13**|**OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft**|Yitao Liang Team|[2509.13347](http://arxiv.org/abs/2509.13347)|null|\n", "2509.15212": "|**2025-09-18**|**RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation**|Xin Li Team|[2509.15212](http://arxiv.org/abs/2509.15212)|**[link](https://github.com/alibaba-damo-academy/RynnVLA-001)**|\n", "2509.14932": "|**2025-09-18**|**Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale**|Florian Walter Team|[2509.14932](http://arxiv.org/abs/2509.14932)|null|\n", "2509.14889": "|**2025-09-18**|**CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human**|Huaping Liu Team|[2509.14889](http://arxiv.org/abs/2509.14889)|null|\n", "2509.14687": "|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Tao Shen Team|[2509.14687](http://arxiv.org/abs/2509.14687)|null|\n", "2509.14630": "|**2025-09-18**|**Toward Embodiment Equivariant Vision-Language-Action Policy**|Yue Wang Team|[2509.14630](http://arxiv.org/abs/2509.14630)|null|\n", "2509.15968": "|**2025-09-19**|**CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine**|Jian Sun Team|[2509.15968](http://arxiv.org/abs/2509.15968)|null|\n", "2509.15937": "|**2025-09-19**|**A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning**|Jiangmiao Pang Team|[2509.15937](http://arxiv.org/abs/2509.15937)|null|\n", "2509.19012": "|**2025-09-25**|**Pure Vision Language Action (VLA) Models: A Comprehensive Survey**|Qingguo Zhou Team|[2509.19012](http://arxiv.org/abs/2509.19012)|null|\n", "2509.18953": "|**2025-09-23**|**Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations**|Wen Yao Team|[2509.18953](http://arxiv.org/abs/2509.18953)|null|\n", "2509.18428": "|**2025-09-22**|**Latent Action Pretraining Through World Modeling**|Ian Reid Team|[2509.18428](http://arxiv.org/abs/2509.18428)|null|\n", "2509.18183": "|**2025-09-18**|**VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation**|Anzhou Hou Team|[2509.18183](http://arxiv.org/abs/2509.18183)|null|\n", "2509.20109": "|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Xianpeng Lang Team|[2509.20109](http://arxiv.org/abs/2509.20109)|null|\n", "2509.19870": "|**2025-09-24**|**FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models**|Yu-Gang Jiang Team|[2509.19870](http://arxiv.org/abs/2509.19870)|null|\n", "2509.19752": "|**2025-09-24**|**Beyond Human Demonstrations: Diffusion-Based Reinforcement Learning to Generate Data for VLA Training**|Yi Chen Team|[2509.19752](http://arxiv.org/abs/2509.19752)|null|\n", "2509.19571": "|**2025-09-23**|**Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action**|Liam Paull Team|[2509.19571](http://arxiv.org/abs/2509.19571)|**[link](https://montrealrobotics.ca/agentic-scene-policies.github.io/)**|\n", "2509.19480": "|**2025-09-23**|**OmniVLA: An Omni-Modal Vision-Language-Action Model for Robot Navigation**|Sergey Levine Team|[2509.19480](http://arxiv.org/abs/2509.19480)|null|\n", "2509.21243": "|**2025-09-25**|**RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models**|Andrew Jaeyong Choi Team|[2509.21243](http://arxiv.org/abs/2509.21243)|null|\n", "2509.22643": "|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Ziwei Wang Team|[2509.22643](http://arxiv.org/abs/2509.22643)|null|\n", "2509.22441": "|**2025-09-26**|**UnderwaterVLA: Dual-brain Vision-Language-Action architecture for Autonomous Underwater Navigation**|Dixia Fan Team|[2509.22441](http://arxiv.org/abs/2509.22441)|null|\n", "2509.22407": "|**2025-09-26**|**EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer**|Guan Huang Team|[2509.22407](http://arxiv.org/abs/2509.22407)|null|\n", "2509.22199": "|**2025-09-29**|**MimicDreamer: Aligning Human and Robot Demonstrations for Scalable VLA Training**|Xingang Wang Team|[2509.22199](http://arxiv.org/abs/2509.22199)|null|\n", "2509.22195": "|**2025-09-26**|**Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting**|Anirudha Majumdar Team|[2509.22195](http://arxiv.org/abs/2509.22195)|null|\n", "2509.22093": "|**2025-09-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Chang Xu Team|[2509.22093](http://arxiv.org/abs/2509.22093)|null|\n", "2509.21986": "|**2025-09-26**|**Developing Vision-Language-Action Model from Egocentric Videos**|Shinsuke Mori Team|[2509.21986](http://arxiv.org/abs/2509.21986)|null|\n", "2509.21354": "|**2025-09-20**|**KV-Efficient VLA: A Method of Speed up Vision Language Model with RNN-Gated Chunked KV Cache**|Long Zhuang Team|[2509.21354](http://arxiv.org/abs/2509.21354)|null|\n", "2509.25032": "|**2025-09-29**|**AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation**|Tetsuya Ogata Team|[2509.25032](http://arxiv.org/abs/2509.25032)|null|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Qing Zhang Team|[2509.24948](http://arxiv.org/abs/2509.24948)|null|\n", "2509.24768": "|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Ville Kyrki Team|[2509.24768](http://arxiv.org/abs/2509.24768)|null|\n", "2509.24559": "|**2025-09-29**|**Emergent World Representations in OpenVLA**|Omar G. Younis Team|[2509.24559](http://arxiv.org/abs/2509.24559)|null|\n", "2509.24524": "|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Xianyuan Zhan Team|[2509.24524](http://arxiv.org/abs/2509.24524)|null|\n", "2509.23931": "|**2025-09-28**|**AutoPrune: Each Complexity Deserves a Pruning Policy**|Zhipeng Zhang Team|[2509.23931](http://arxiv.org/abs/2509.23931)|null|\n", "2509.23823": "|**2025-09-28**|**Control Your Robot: A Unified System for Robot Control and Policy Deployment**|Bingshan Hu Team|[2509.23823](http://arxiv.org/abs/2509.23823)|**[link](https://github.com/Tian-Nian/control_your_robot)**|\n", "2509.23655": "|**2025-09-28**|**Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models**|Pietro Mazzaglia Team|[2509.23655](http://arxiv.org/abs/2509.23655)|null|\n", "2509.23224": "|**2025-09-27**|**Leave No Observation Behind: Real-time Correction for VLA Action Chunks**|Yusuke Iwasawa Team|[2509.23224](http://arxiv.org/abs/2509.23224)|null|\n", "2509.23121": "|**2025-09-27**|**Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges**|Zhibo Pang Team|[2509.23121](http://arxiv.org/abs/2509.23121)|null|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Shanghang Zhang Team|[2509.26642](http://arxiv.org/abs/2509.26642)|null|\n", "2509.25966": "|**2025-09-30**|**MUVLA: Learning to Explore Object Navigation via Map Understanding**|Jianye Hao Team|[2509.25966](http://arxiv.org/abs/2509.25966)|null|\n", "2509.25746": "|**2025-09-30**|**TacRefineNet: Tactile-Only Grasp Refinement Between Arbitrary In-Hand Object Poses**|Yangwei You Team|[2509.25746](http://arxiv.org/abs/2509.25746)|null|\n", "2509.25718": "|**2025-09-30**|**VLA Model Post-Training via Action-Chunked PPO and Self Behavior Cloning**|Zeng-Guang Hou Team|[2509.25718](http://arxiv.org/abs/2509.25718)|null|\n", "2509.25681": "|**2025-09-30**|**dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought**|Yi Xu Team|[2509.25681](http://arxiv.org/abs/2509.25681)|null|\n", "2509.26251": "|**2025-09-30**|**Seeing Space and Motion: Enhancing Latent Actions with Spatial and Dynamic Awareness for VLA**|Ruqi Huang Team|[2509.26251](http://arxiv.org/abs/2509.26251)|null|\n", "2510.01711": "|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Jinwoo Shin Team|[2510.01711](http://arxiv.org/abs/2510.01711)|null|\n", "2510.01642": "|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Bihan Wen Team|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|\n", "2510.01623": "|**2025-10-02**|**VLA-R1: Enhancing Reasoning in Vision-Language-Action Models**|Zheng Zhu Team|[2510.01623](http://arxiv.org/abs/2510.01623)|null|\n", "2510.01389": "|**2025-10-01**|**INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models**|Tesca FItzgerald Team|[2510.01389](http://arxiv.org/abs/2510.01389)|null|\n", "2510.01068": "|**2025-10-01**|**Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition**|Andrew F. Luo Team|[2510.01068](http://arxiv.org/abs/2510.01068)|**[link](https://sagecao1125.github.io/GPC-Site/)**|\n", "2510.00695": "|**2025-10-02**|**HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy**|Jinwoo Shin Team|[2510.00695](http://arxiv.org/abs/2510.00695)|**[link](https://myungkyukoo.github.io/hamlet/)**|\n", "2510.00600": "|**2025-10-01**|**Hybrid Training for Vision-Language-Action Models**|Daniel Dijkman Team|[2510.00600](http://arxiv.org/abs/2510.00600)|null|\n", "2510.00406": "|**2025-10-01**|**VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators**|Weihua Su Team|[2510.00406](http://arxiv.org/abs/2510.00406)|null|\n", "2510.03142": "|**2025-10-03**|**MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning**|He Wang Team|[2510.03142](http://arxiv.org/abs/2510.03142)|**[link](https://pku-epic.github.io/MM-Nav-Web/)**|\n", "2510.04898": "|**2025-10-06**|**HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks**|Shimon Whiteson Team|[2510.04898](http://arxiv.org/abs/2510.04898)|null|\n", "2510.04246": "|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Jinwoo Shin Team|[2510.04246](http://arxiv.org/abs/2510.04246)|**[link](https://huiwon-jang.github.io/contextvla)**|\n", "2510.04041": "|**2025-10-05**|**SITCOM: Scaling Inference-Time COMpute for VLAs**|Esha Pahwa Team|[2510.04041](http://arxiv.org/abs/2510.04041)|null|\n", "2510.03896": "|**2025-10-04**|**Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert**|Chunhua Shen Team|[2510.03896](http://arxiv.org/abs/2510.03896)|null|\n", "2510.03895": "|**2025-10-04**|**NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation**|Chunhua Shen Team|[2510.03895](http://arxiv.org/abs/2510.03895)|null|\n", "2510.03827": "|**2025-10-04**|**LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization**|Lichao Sun Team|[2510.03827](http://arxiv.org/abs/2510.03827)|null|\n", "2510.03342": "|**2025-10-02**|**Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer**|Yuxiang Zhou Team|[2510.03342](http://arxiv.org/abs/2510.03342)|null|\n", "2510.06207": "|**2025-10-07**|**EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model**|Zhaoxiang Zhang Team|[2510.06207](http://arxiv.org/abs/2510.06207)|**[link](https://anonymous.4open.science/w/Embodied-Coder/)**|\n", "2510.05681": "|**2025-10-07**|**Verifier-free Test-Time Sampling for Vision Language Action Models**|Jinwoo Shin Team|[2510.05681](http://arxiv.org/abs/2510.05681)|null|\n", "2510.05580": "|**2025-10-07**|**MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption**|Marios Savvides Team|[2510.05580](http://arxiv.org/abs/2510.05580)|null|\n", "2510.07134": "|**2025-10-08**|**TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking**|He Wang Team|[2510.07134](http://arxiv.org/abs/2510.07134)|**[link](https://pku-epic.github.io/TrackVLA-plus-plus-Web/)**|\n", "2510.07077": "|**2025-10-08**|**Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications**|Yuke Zhu Team|[2510.07077](http://arxiv.org/abs/2510.07077)|**[link](https://vla-survey.github.io)**|\n", "2510.07067": "|**2025-10-08**|**Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models**|Elena Tutubalina Team|[2510.07067](http://arxiv.org/abs/2510.07067)|null|\n", "2510.06710": "|**2025-10-08**|**RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training**|Yu Wang Team|[2510.06710](http://arxiv.org/abs/2510.06710)|**[link](https://github.com/RLinf/RLinf)**|\n", "2510.08464": "|**2025-10-09**|**Don't Run with Scissors: Pruning Breaks VLA Models but They Can Be Recovered**|Shayegan Omidshafiei Team|[2510.08464](http://arxiv.org/abs/2510.08464)|null|\n", "2510.07869": "|**2025-10-15**|**USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots**|Zhengxing Wu Team|[2510.07869](http://arxiv.org/abs/2510.07869)|**[link](https://vincentgu2000.github.io/u0project/)**|\n", "2510.07778": "|**2025-10-09**|**IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction**|Liqiang Nie Team|[2510.07778](http://arxiv.org/abs/2510.07778)|null|\n", "2510.07730": "|**2025-10-09**|**DEAS: DEtached value learning with Action Sequence for Scalable Offline RL**|Yuke Zhu Team|[2510.07730](http://arxiv.org/abs/2510.07730)|**[link](https://changyeon.site/deas)**|\n", "2510.09607": "|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Caifeng Shan Team|[2510.09607](http://arxiv.org/abs/2510.09607)|**[link](https://ltbai.github.io/VITA-VLA/)**|\n", "2510.09507": "|**2025-10-10**|**PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs**|Ying-Cong Chen Team|[2510.09507](http://arxiv.org/abs/2510.09507)|null|\n", "2510.09269": "|**2025-10-10**|**Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects**|Jingfeng Zhang Team|[2510.09269](http://arxiv.org/abs/2510.09269)|null|\n", "2510.11660": "|**2025-10-14**|**ManiAgent: An Agentic Framework for General Robotic Manipulation**|Xudong Liu Team|[2510.11660](http://arxiv.org/abs/2510.11660)|null|\n", "2510.11027": "|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Zhi Hou Team|[2510.11027](http://arxiv.org/abs/2510.11027)|null|\n", "2510.10975": "|**2025-10-14**|**RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model**|Xinyu Wu Team|[2510.10975](http://arxiv.org/abs/2510.10975)|null|\n", "2510.10932": "|**2025-10-13**|**TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models**|Yu-Gang Jiang Team|[2510.10932](http://arxiv.org/abs/2510.10932)|null|\n", "2510.10274": "|**2025-10-11**|**X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model**|Xianyuan Zhan Team|[2510.10274](http://arxiv.org/abs/2510.10274)|null|\n", "2510.10181": "|**2025-10-11**|**Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback**|Hongtao Lu Team|[2510.10181](http://arxiv.org/abs/2510.10181)|null|\n", "2510.09976": "|**2025-10-11**|**Reinforcement Fine-Tuning of Flow-Matching Policies for Vision-Language-Action Models**|Yi Zeng Team|[2510.09976](http://arxiv.org/abs/2510.09976)|null|\n", "2510.09667": "|**2025-10-08**|**OmniSAT: Compact Action Token, Faster Auto Regression**|Changsheng Xu Team|[2510.09667](http://arxiv.org/abs/2510.09667)|null|\n", "2510.12796": "|**2025-12-18**|**DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving**|Zhaoxiang Zhang Team|[2510.12796](http://arxiv.org/abs/2510.12796)|null|\n", "2510.12710": "|**2025-10-14**|**Reflection-Based Task Adaptation for Self-Improving VLA**|Hongbin Zha Team|[2510.12710](http://arxiv.org/abs/2510.12710)|null|\n", "2510.12276": "|**2025-10-17**|**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**|Haoang Li Team|[2510.12276](http://arxiv.org/abs/2510.12276)|null|\n", "2510.13778": "|**2025-10-15**|**InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy**|Yangkun Zhu Team|[2510.13778](http://arxiv.org/abs/2510.13778)|null|\n", "2510.13626": "|**2025-10-24**|**LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models**|Xipeng Qiu Team|[2510.13626](http://arxiv.org/abs/2510.13626)|null|\n", "2510.13375": "|**2025-10-15**|**DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning**|Hang Zhao Team|[2510.13375](http://arxiv.org/abs/2510.13375)|null|\n", "2510.13237": "|**2025-10-15**|**Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models**|Jingfeng Zhang Team|[2510.13237](http://arxiv.org/abs/2510.13237)|null|\n", "2510.13054": "|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Fabio Ramos Team|[2510.13054](http://arxiv.org/abs/2510.13054)|null|\n", "2510.14968": "|**2025-10-16**|**RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks**|Jiachen Li Team|[2510.14968](http://arxiv.org/abs/2510.14968)|null|\n", "2510.14952": "|**2025-10-17**|**From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance**|Chang Xu Team|[2510.14952](http://arxiv.org/abs/2510.14952)|null|\n", "2510.14902": "|**2025-10-16**|**VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation**|Donglin Wang Team|[2510.14902](http://arxiv.org/abs/2510.14902)|null|\n", "2510.14836": "|**2025-10-16**|**QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models**|Haoran Li Team|[2510.14836](http://arxiv.org/abs/2510.14836)|null|\n", "2510.14300": "|**2025-10-16**|**Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning**|Yao Mu Team|[2510.14300](http://arxiv.org/abs/2510.14300)|null|\n", "2510.15446": "|**2025-10-17**|**VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving**|Zufeng Zhang Team|[2510.15446](http://arxiv.org/abs/2510.15446)|null|\n", "2510.17640": "|**2025-10-24**|**RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation**|Ziwei Wang Team|[2510.17640](http://arxiv.org/abs/2510.17640)|null|\n", "2510.17439": "|**2025-10-20**|**From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors**|Pan Zhou Team|[2510.17439](http://arxiv.org/abs/2510.17439)|**[link](https://falcon-vla.github.io/)**|\n", "2510.17369": "|**2025-10-20**|**Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots**|Josie Hughes Team|[2510.17369](http://arxiv.org/abs/2510.17369)|null|\n", "2510.17148": "|**2025-11-04**|**DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment**|Sun Hao Team|[2510.17148](http://arxiv.org/abs/2510.17148)|null|\n", "2510.17111": "|**2025-10-23**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Jian Cheng Team|[2510.17111](http://arxiv.org/abs/2510.17111)|null|\n", "2510.16617": "|**2025-10-18**|**MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation**|Ufuk Topcu Team|[2510.16617](http://arxiv.org/abs/2510.16617)|null|\n", "2510.16281": "|**2025-10-18**|**Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification**|Claudia P'erez-D'Arpino Team|[2510.16281](http://arxiv.org/abs/2510.16281)|null|\n", "2510.16263": "|**2025-10-21**|**NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?**|Yu Yin Team|[2510.16263](http://arxiv.org/abs/2510.16263)|**[link](https://vulab-ai.github.io/NEBULA-Alpha/)**|\n", "2510.16240": "|**2025-11-03**|**Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning**|Sean Huver Team|[2510.16240](http://arxiv.org/abs/2510.16240)|null|\n", "2510.18337": "|**2025-10-23**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Heng Yang Team|[2510.18337](http://arxiv.org/abs/2510.18337)|null|\n", "2510.19752": "|**2025-10-22**|**Learning Affordances at Inference-Time for Vision-Language-Action Models**|Sergey Levine Team|[2510.19752](http://arxiv.org/abs/2510.19752)|null|\n", "2510.19430": "|**2025-12-04**|**GigaBrain-0: A World Model-Powered Vision-Language-Action Model**|Zheng Zhu Team|[2510.19430](http://arxiv.org/abs/2510.19430)|**[link](https://gigabrain0.github.io/)**|\n", "2510.19400": "|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Baining Guo Team|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|\n", "2510.20818": "|**2025-10-23**|**VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation**|Abhishek Gupta Team|[2510.20818](http://arxiv.org/abs/2510.20818)|null|\n", "2510.20328": "|**2025-10-23**|**MemER: Scaling Up Memory for Robot Control via Experience Retrieval**|Chelsea Finn Team|[2510.20328](http://arxiv.org/abs/2510.20328)|**[link](https://jen-pan.github.io/memer/)**|\n", "2510.21571": "|**2025-10-24**|**Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos**|Baining Guo Team|[2510.21571](http://arxiv.org/abs/2510.21571)|**[link](https://microsoft.github.io/VITRA/)**|\n", "2510.20965": "|**2025-10-23**|**SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing**|Axel Krieger Team|[2510.20965](http://arxiv.org/abs/2510.20965)|null|\n", "2510.23576": "|**2025-10-27**|**UrbanVLA: A Vision-Language-Action Model for Urban Micromobility**|He Wang Team|[2510.23576](http://arxiv.org/abs/2510.23576)|null|\n", "2510.23511": "|**2025-10-27**|**Dexbotic: Open-Source Vision-Language-Action Toolbox**|Ziyu Zhang Team|[2510.23511](http://arxiv.org/abs/2510.23511)|**[link](https://dexbotic.com/.)**|\n", "2510.22201": "|**2025-10-25**|**ACG: Action Coherence Guidance for Flow-based VLA models**|Jaegul Choo Team|[2510.22201](http://arxiv.org/abs/2510.22201)|null|\n", "2510.21860": "|**2025-10-23**|**Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence**|Elias Aronsson Team|[2510.21860](http://arxiv.org/abs/2510.21860)|null|\n", "2510.21817": "|**2025-10-21**|**VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting**|Ran He Team|[2510.21817](http://arxiv.org/abs/2510.21817)|**[link](https://lxysl.github.io/VITA-E/)**|\n", "2510.24161": "|**2025-10-28**|**BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning**|Heng Tao Shen Team|[2510.24161](http://arxiv.org/abs/2510.24161)|null|\n", "2510.23763": "|**2025-11-01**|**RoboOmni: Proactive Robot Manipulation in Omni-modal Context**|Xipeng Qiu Team|[2510.23763](http://arxiv.org/abs/2510.23763)|null|\n", "2510.25713": "|**2025-10-29**|**Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models**|Robert Katzschmann Team|[2510.25713](http://arxiv.org/abs/2510.25713)|null|\n", "2510.25616": "|**2025-10-29**|**Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization**|Aleksandr I. Panov Team|[2510.25616](http://arxiv.org/abs/2510.25616)|null|\n", "2510.25122": "|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jinghui Lu Team|[2510.25122](http://arxiv.org/abs/2510.25122)|null|\n", "2510.24795": "|**2025-10-27**|**A Survey on Efficient Vision-Language-Action Models**|Heng Tao Shen Team|[2510.24795](http://arxiv.org/abs/2510.24795)|null|\n", "2510.26536": "|**2025-10-30**|**RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration**|Shanghang Zhang Team|[2510.26536](http://arxiv.org/abs/2510.26536)|null|\n", "2510.26406": "|**2025-10-30**|**Human-in-the-loop Online Rejection Sampling for Robotic Manipulation**|Yansong Tang Team|[2510.26406](http://arxiv.org/abs/2510.26406)|null|\n", "2510.25889": "|**2025-11-27**|**$\u03c0_\\texttt{RL}$: Online RL Fine-tuning for Flow-based Vision-Language-Action Models**|Chao Yu Team|[2510.25889](http://arxiv.org/abs/2510.25889)|null|\n", "2510.27607": "|**2025-11-04**|**Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model**|Jinwoo Shin Team|[2510.27607](http://arxiv.org/abs/2510.27607)|null|\n", "2510.27545": "|**2025-10-31**|**EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities**|Luhui Hu Team|[2510.27545](http://arxiv.org/abs/2510.27545)|null|\n", "2511.02832": "|**2025-11-04**|**TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System**|C. Karen Liu Team|[2511.02832](http://arxiv.org/abs/2511.02832)|**[link](https://yanjieze.com/TWIST2)**|\n", "2511.02776": "|**2025-11-04**|**XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations**|Jian Tang Team|[2511.02776](http://arxiv.org/abs/2511.02776)|null|\n", "2511.01718": "|**2025-11-03**|**Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process**|Haoang Li Team|[2511.01718](http://arxiv.org/abs/2511.01718)|null|\n", "2511.01571": "|**2025-11-03**|**PixelVLA: Advancing Pixel-level Understanding in Vision-Language-Action Model**|Yang Cong Team|[2511.01571](http://arxiv.org/abs/2511.01571)|null|\n", "2511.01331": "|**2025-12-01**|**RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models**|Donglin Wang Team|[2511.01331](http://arxiv.org/abs/2511.01331)|null|\n", "2511.01224": "|**2025-11-03**|**Embodiment Transfer Learning for Vision-Language-Action Models**|Yaxin Peng Team|[2511.01224](http://arxiv.org/abs/2511.01224)|null|\n", "2511.01210": "|**2025-11-06**|**OmniVLA: Physically-Grounded Multimodal VLA with Unified Multi-Sensor Perception for Robotic Manipulation**|Lili Qiu Team|[2511.01210](http://arxiv.org/abs/2511.01210)|null|\n", "2511.01914": "|**2025-11-01**|**iFlyBot-VLA Technical Report**|Jia Pan Team|[2511.01914](http://arxiv.org/abs/2511.01914)|null|\n", "2511.00139": "|**2025-12-13**|**End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection**|Zhibin Li Team|[2511.00139](http://arxiv.org/abs/2511.00139)|null|\n", "2511.00091": "|**2025-10-30**|**Self-Improving Vision-Language-Action Models with Data Generation via Residual RL**|Yuke Zhu Team|[2511.00091](http://arxiv.org/abs/2511.00091)|null|\n", "2511.00088": "|**2025-10-30**|**Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail**|Marco Pavone Team|[2511.00088](http://arxiv.org/abs/2511.00088)|null|\n", "2512.15692": "|**2025-12-17**|**mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs**|Elvis Nava Team|[2512.15692](http://arxiv.org/abs/2512.15692)|null|\n", "2512.15411": "|**2025-12-17**|**MiVLA: Towards Generalizable Vision-Language-Action Model with Human-Robot Mutual Imitation Pre-training**|Heng Tao Shen Team|[2512.15411](http://arxiv.org/abs/2512.15411)|null|\n", "2512.15258": "|**2025-12-17**|**VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments**|Fei Gao Team|[2512.15258](http://arxiv.org/abs/2512.15258)|null|\n", "2512.14666": "|**2025-12-16**|**EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models**|Mike Zheng Shou Team|[2512.14666](http://arxiv.org/abs/2512.14666)|null|\n", "2512.14031": "|**2025-12-16**|**Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model**|Ci-Jyun Liang Team|[2512.14031](http://arxiv.org/abs/2512.14031)|null|\n", "2512.13636": "|**2025-12-16**|**MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning**|Xiang Bai Team|[2512.13636](http://arxiv.org/abs/2512.13636)|**[link](https://xiaomi-mlab.github.io/MindDrive/)**|\n", "2512.13080": "|**2025-12-15**|**Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos**|Zongqing Lu Team|[2512.13080](http://arxiv.org/abs/2512.13080)|null|\n", "2512.13030": "|**2025-12-15**|**Motus: A Unified Latent Action World Model**|Jun Zhu Team|[2512.13030](http://arxiv.org/abs/2512.13030)|null|\n", "2512.12799": "|**2025-12-14**|**DrivePI: Spatial-aware 4D MLLM for Unified Autonomous Driving Understanding, Perception, Prediction and Planning**|Hengshuang Zhao Team|[2512.12799](http://arxiv.org/abs/2512.12799)|null|\n", "2512.11769": "|**2025-12-12**|**BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models**|Yanfang Ye Team|[2512.11769](http://arxiv.org/abs/2512.11769)|**[link](https://github.com/JijiKing-Sam/BLURR-A-Boosted-Low-Resource-Inference-for-Vision-Language-Action-Model)**|\n", "2512.11612": "|**2025-12-12**|**Embodied Image Compression**|Guangtao Zhai Team|[2512.11612](http://arxiv.org/abs/2512.11612)|null|\n", "2512.11584": "|**2025-12-12**|**Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents**|Boris Kraychev Team|[2512.11584](http://arxiv.org/abs/2512.11584)|null|\n", "2512.11362": "|**2025-12-18**|**An Anatomy of Vision-Language-Action Models: From Modules to Milestones and Challenges**|Jiankang Deng Team|[2512.11362](http://arxiv.org/abs/2512.11362)|**[link](https://suyuz1.github.io/Survery/)**|\n", "2512.11315": "|**2025-12-12**|**Benchmarking the Generality of Vision-Language-Action Models**|Yangyue Wang Team|[2512.11315](http://arxiv.org/abs/2512.11315)|null|\n", "2512.11218": "|**2025-12-12**|**Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy**|Yue Wang Team|[2512.11218](http://arxiv.org/abs/2512.11218)|null|\n", "2512.11047": "|**2025-12-15**|**WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control**|Hongyang Li Team|[2512.11047](http://arxiv.org/abs/2512.11047)|null|\n", "2512.11921": "|**2025-12-11**|**Towards Accessible Physical AI: LoRA-Based Fine-Tuning of VLA Models for Real-World Robot Control**|Ibrahim Sheikh Mohamed Team|[2512.11921](http://arxiv.org/abs/2512.11921)|null|\n", "2512.10394": "|**2025-12-11**|**RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI**|Jian Cheng Team|[2512.10394](http://arxiv.org/abs/2512.10394)|null|\n", "2512.10226": "|**2025-12-11**|**Latent Chain-of-Thought World Modeling for End-to-End Driving**|Boris Ivanovic Team|[2512.10226](http://arxiv.org/abs/2512.10226)|null|\n", "2512.11908": "|**2025-12-10**|**Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models**|Arash Ajoudani Team|[2512.11908](http://arxiv.org/abs/2512.11908)|null|\n", "2512.16760": "|**2025-12-18**|**Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future**|Junwei Liang Team|[2512.16760](http://arxiv.org/abs/2512.16760)|**[link](https://github.com/worldbench/awesome-vla-for-ad)**|\n", "2512.15840": "|**2025-12-17**|**Large Video Planner Enables Generalizable Robot Control**|Yilun Du Team|[2512.15840](http://arxiv.org/abs/2512.15840)|null|\n", "2512.16811": "|**2025-12-18**|**GeoPredict: Leveraging Predictive Kinematics and 3D Gaussian Geometry for Precise VLA Manipulation**|Li Jiang Team|[2512.16811](http://arxiv.org/abs/2512.16811)|null|\n", "2512.16881": "|**2025-12-18**|**PolaRiS: Scalable Real-to-Sim Evaluations for Generalist Robot Policies**|Karl Pertsch Team|[2512.16881](http://arxiv.org/abs/2512.16881)|**[link](https://polaris-evals.github.io/)**|\n", "2512.14217": "|**2025-12-16**|**DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos**|Gitta Kutyniok Team|[2512.14217](http://arxiv.org/abs/2512.14217)|null|\n", "2512.13100": "|**2025-12-15**|**OXE-AugE: A Large-Scale Robot Augmentation of OXE for Scaling Cross-Embodiment Policy Learning**|Ken Goldberg Team|[2512.13100](http://arxiv.org/abs/2512.13100)|null|\n", "2512.10046": "|**2025-12-10**|**SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration**|Tianmin Shu Team|[2512.10046](http://arxiv.org/abs/2512.10046)|null|\n", "2512.09928": "|**2025-12-10**|**HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models**|Donglin Wang Team|[2512.09928](http://arxiv.org/abs/2512.09928)|**[link](https://hifvla.github.io)**|\n", "2512.09927": "|**2025-12-10**|**Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models**|Zhihe Lu Team|[2512.09927](http://arxiv.org/abs/2512.09927)|null|\n", "2512.09864": "|**2025-12-10**|**UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving**|Ying-Cong Chen Team|[2512.09864](http://arxiv.org/abs/2512.09864)|**[link](https://seed-uniugp.github.io/)**|\n", "2512.09619": "|**2025-12-10**|**GLaD: Geometric Latent Distillation for Vision-Language-Action Models**|Xiaojun Chang Team|[2512.09619](http://arxiv.org/abs/2512.09619)|null|\n", "2512.11891": "|**2025-12-09**|**VLSA: Vision-Language-Action Models with Plug-and-Play Safety Constraint Layer**|Xiao He Team|[2512.11891](http://arxiv.org/abs/2512.11891)|null|\n", "2512.08580": "|**2025-12-10**|**Mind to Hand: Purposeful Robotic Control via Embodied Reasoning**|Jianan Wang Team|[2512.08580](http://arxiv.org/abs/2512.08580)|null|\n", "2512.08333": "|**2025-12-18**|**Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging**|Sergey Levine Team|[2512.08333](http://arxiv.org/abs/2512.08333)|null|\n", "2512.07582": "|**2025-12-08**|**See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations**|Yufeng Yue Team|[2512.07582](http://arxiv.org/abs/2512.07582)|null|\n", "2512.07472": "|**2025-12-08**|**Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation**|Chang Xu Team|[2512.07472](http://arxiv.org/abs/2512.07472)|null|\n", "2512.06963": "|**2025-12-07**|**VideoVLA: Video Generators Can Be Generalizable Robot Manipulators**|Baining Guo Team|[2512.06963](http://arxiv.org/abs/2512.06963)|**[link](https://videovla-nips2025.github.io)**|\n", "2512.06951": "|**2025-12-07**|**Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge**|Akash Karnatak Team|[2512.06951](http://arxiv.org/abs/2512.06951)|null|\n", "2512.11872": "|**2025-12-06**|**WAM-Diff: A Masked Diffusion VLA Framework with MoE and Online Reinforcement Learning for Autonomous Driving**|Siyu Zhu Team|[2512.11872](http://arxiv.org/abs/2512.11872)|null|\n", "2512.06112": "|**2025-12-11**|**WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving**|Siyu Zhu Team|[2512.06112](http://arxiv.org/abs/2512.06112)|**[link](https://github.com/fudan-generative-vision/WAM-Flow)**|\n", "2512.05964": "|**2025-12-09**|**Training-Time Action Conditioning for Efficient Real-Time Chunking**|Sergey Levine Team|[2512.05964](http://arxiv.org/abs/2512.05964)|null|\n", "2512.11865": "|**2025-12-05**|**Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation**|Gun-Woo Kim Team|[2512.11865](http://arxiv.org/abs/2512.11865)|null|\n", "2512.05693": "|**2025-12-05**|**HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies**|Yu-Gang Jiang Team|[2512.05693](http://arxiv.org/abs/2512.05693)|null|\n", "2512.05230": "|**2025-12-04**|**Invariance Co-training for Robot Visual Generalization**|Dorsa Sadigh Team|[2512.05230](http://arxiv.org/abs/2512.05230)|null|\n", "2512.05107": "|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Benjamin Busam Team|[2512.05107](http://arxiv.org/abs/2512.05107)|null|\n", "2512.04952": "|**2025-12-08**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization**|Hang Zhao Team|[2512.04952](http://arxiv.org/abs/2512.04952)|null|\n", "2512.04733": "|**2025-12-04**|**E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving**|Chengzhong Xu Team|[2512.04733](http://arxiv.org/abs/2512.04733)|null|\n", "2512.04537": "|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Mike Zheng Shou Team|[2512.04537](http://arxiv.org/abs/2512.04537)|null|\n", "2512.04446": "|**2025-12-04**|**Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops**|Minghui Zheng Team|[2512.04446](http://arxiv.org/abs/2512.04446)|null|\n", "2512.03913": "|**2025-12-03**|**Hierarchical Vision Language Action Model Using Success and Failure Demonstrations**|Sungjoon Choi Team|[2512.03913](http://arxiv.org/abs/2512.03913)|**[link](https://vine-vla.github.io/)**|\n", "2512.03724": "|**2025-12-08**|**PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention**|Mingming Gong Team|[2512.03724](http://arxiv.org/abs/2512.03724)|null|\n", "2512.02902": "|**2025-12-02**|**VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling**|Guangrun Wang Team|[2512.02902](http://arxiv.org/abs/2512.02902)|null|\n", "2512.02834": "|**2025-12-02**|**Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach**|Xuelong Li Team|[2512.02834](http://arxiv.org/abs/2512.02834)|null|\n", "2512.02787": "|**2025-12-03**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Yong-Lu Li Team|[2512.02787](http://arxiv.org/abs/2512.02787)|null|\n", "2512.02729": "|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Haoqian Wang Team|[2512.02729](http://arxiv.org/abs/2512.02729)|null|\n", "2512.02013": "|**2025-12-01**|**ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation**|Shanghang Zhang Team|[2512.02013](http://arxiv.org/abs/2512.02013)|null|\n", "2512.01801": "|**2025-12-02**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yonghui Wu Team|[2512.01801](http://arxiv.org/abs/2512.01801)|null|\n", "2512.01773": "|**2025-12-01**|**IGen: Scalable Data Generation for Robot Learning from Open-World Images**|Zhi Wang Team|[2512.01773](http://arxiv.org/abs/2512.01773)|null|\n", "2512.01715": "|**2025-12-01**|**DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models**|Zongqing Lu Team|[2512.01715](http://arxiv.org/abs/2512.01715)|null|\n", "2512.01188": "|**2025-12-01**|**Real-World Reinforcement Learning of Active Perception Behaviors**|Dinesh Jayaraman Team|[2512.01188](http://arxiv.org/abs/2512.01188)|null|\n", "2512.01031": "|**2025-11-30**|**VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference**|Song Han Team|[2512.01031](http://arxiv.org/abs/2512.01031)|null|\n", "2512.01022": "|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Wei-Shi Zheng Team|[2512.01022](http://arxiv.org/abs/2512.01022)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|\n", "2512.00975": "|**2025-12-08**|**MM-ACT: Learn from Multimodal Parallel Generation to Act**|Ping Luo Team|[2512.00975](http://arxiv.org/abs/2512.00975)|null|\n", "2512.00903": "|**2025-11-30**|**SwiftVLA: Unlocking Spatiotemporal Dynamics for Lightweight VLA Models at Minimal Overhead**|Wenjun Mei Team|[2512.00903](http://arxiv.org/abs/2512.00903)|null|\n", "2512.00797": "|**2025-11-30**|**Transforming Monolithic Foundation Models into Embodied Multi-Agent Architectures for Human-Robot Collaboration**|Huaping Liu Team|[2512.00797](http://arxiv.org/abs/2512.00797)|null|\n", "2512.00783": "|**2025-12-02**|**Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment**|Libo Wang Team|[2512.00783](http://arxiv.org/abs/2512.00783)|**[link](https://huggingface.co/Veltraxor/Sigma)**|\n", "2511.23034": "|**2025-11-28**|**LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models**|Jianlong Fu Team|[2511.23034](http://arxiv.org/abs/2511.23034)|**[link](https://mm-robot.github.io/distill_latent_action/)**|\n", "2511.22780": "|**2025-11-27**|**Distracted Robot: How Visual Clutter Undermine Robotic Manipulation**|Xuan Zhao Team|[2511.22780](http://arxiv.org/abs/2511.22780)|null|\n", "2511.22777": "|**2025-11-27**|**Improving Robotic Manipulation Robustness via NICE Scene Surgery**|Amir Rasouli Team|[2511.22777](http://arxiv.org/abs/2511.22777)|null|\n", "2511.22697": "|**2025-11-27**|**Mechanistic Finetuning of Vision-Language-Action Models via Few-Shot Demonstrations**|Roei Herzig Team|[2511.22697](http://arxiv.org/abs/2511.22697)|null|\n", "2511.22555": "|**2025-11-27**|**Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention**|Meibao Yao Team|[2511.22555](http://arxiv.org/abs/2511.22555)|null|\n", "2511.22532": "|**2025-11-27**|**CoT4AD: A Vision-Language-Action Model with Explicit Chain-of-Thought Reasoning for Autonomous Driving**|Hao Tang Team|[2511.22532](http://arxiv.org/abs/2511.22532)|null|\n", "2511.22134": "|**2025-11-27**|**DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action**|Feng Zhao Team|[2511.22134](http://arxiv.org/abs/2511.22134)|null|\n", "2511.21663": "|**2025-11-26**|**Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models**|Nan Zhang Team|[2511.21663](http://arxiv.org/abs/2511.21663)|null|\n", "2511.21557": "|**2025-11-26**|**VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation**|Shaoshuai Shi Team|[2511.21557](http://arxiv.org/abs/2511.21557)|null|\n", "2511.21542": "|**2025-11-26**|**$\\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Guangrun Wang Team|[2511.21542](http://arxiv.org/abs/2511.21542)|null|\n", "2511.21428": "|**2025-11-26**|**From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings**|Alexander Kleiner Team|[2511.21428](http://arxiv.org/abs/2511.21428)|null|\n", "2511.21192": "|**2025-11-30**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Xudong Jiang Team|[2511.21192](http://arxiv.org/abs/2511.21192)|null|\n", "2511.20633": "|**2025-11-25**|**Reinforcing Action Policies by Prophesying**|Li Zhang Team|[2511.20633](http://arxiv.org/abs/2511.20633)|**[link](https://LogosRoboticsGroup.github.io/ProphRL)**|\n", "2511.20720": "|**2025-11-25**|**DeeAD: Dynamic Early Exit of Vision-Language Action for Efficient Autonomous Driving**|Chun Jason Xue Team|[2511.20720](http://arxiv.org/abs/2511.20720)|null|\n", "2511.19912": "|**2025-11-25**|**Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model for Autonomous Driving**|Tat-Seng Chua Team|[2511.19912](http://arxiv.org/abs/2511.19912)|null|\n", "2511.19878": "|**2025-11-25**|**MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization**|Zsolt Kira Team|[2511.19878](http://arxiv.org/abs/2511.19878)|null|\n", "2511.19861": "|**2025-11-30**|**GigaWorld-0: World Models as Data Engine to Empower Embodied AI**|Zheng Zhu Team|[2511.19861](http://arxiv.org/abs/2511.19861)|**[link](https://giga-world-0.github.io/)**|\n", "2511.19859": "|**2025-11-25**|**Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation**|Sanglu Lu Team|[2511.19859](http://arxiv.org/abs/2511.19859)|null|\n", "2511.19433": "|**2025-11-24**|**Mixture of Horizons in Action Chunking**|Mingyu Ding Team|[2511.19433](http://arxiv.org/abs/2511.19433)|null|\n", "2511.18960": "|**2025-12-02**|**AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention**|Xiaoyuan Yu Team|[2511.18960](http://arxiv.org/abs/2511.18960)|null|\n", "2511.18950": "|**2025-11-24**|**Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation**|Wenjing Qian Team|[2511.18950](http://arxiv.org/abs/2511.18950)|null|\n", "2511.19528": "|**2025-11-24**|**Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories**|Jiang Bian Team|[2511.19528](http://arxiv.org/abs/2511.19528)|null|\n", "2511.18810": "|**2025-11-24**|**MergeVLA: Cross-Skill Model Merging Toward a Generalist Vision-Language-Action Agent**|Yadan Luo Team|[2511.18810](http://arxiv.org/abs/2511.18810)|null|\n", "2511.18112": "|**2025-11-22**|**EchoVLA: Robotic Vision-Language-Action Model with Synergistic Declarative Memory for Mobile Manipulation**|Xiaodan Liang Team|[2511.18112](http://arxiv.org/abs/2511.18112)|null|\n", "2511.18085": "|**2025-11-25**|**Continually Evolving Skill Knowledge in Vision Language Action Model**|Hesheng Wang Team|[2511.18085](http://arxiv.org/abs/2511.18085)|null|\n", "2511.18082": "|**2025-11-22**|**ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models**|Guoli Yang Team|[2511.18082](http://arxiv.org/abs/2511.18082)|null|\n", "2511.17889": "|**2025-11-22**|**MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots**|Hao Tang Team|[2511.17889](http://arxiv.org/abs/2511.17889)|null|\n", "2511.17502": "|**2025-11-24**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Hao Chen Team|[2511.17502](http://arxiv.org/abs/2511.17502)|null|\n", "2511.17411": "|**2025-11-21**|**SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding**|Danda Pani Paudel Team|[2511.17411](http://arxiv.org/abs/2511.17411)|null|\n", "2511.17366": "|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Shanghang Zhang Team|[2511.17366](http://arxiv.org/abs/2511.17366)|null|\n", "2511.17199": "|**2025-11-21**|**VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation**|Gim Hee Lee Team|[2511.17199](http://arxiv.org/abs/2511.17199)|null|\n", "2511.17097": "|**2025-11-21**|**Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation**|Zhaoxin Fan Team|[2511.17097](http://arxiv.org/abs/2511.17097)|null|\n", "2511.16651": "|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Jiangmiao Pang Team|[2511.16651](http://arxiv.org/abs/2511.16651)|null|\n", "2511.16449": "|**2025-11-21**|**VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference**|Bo Zhao Team|[2511.16449](http://arxiv.org/abs/2511.16449)|null|\n", "2511.16233": "|**2025-11-20**|**FT-NCFM: An Influence-Aware Data Distillation Framework for Efficient VLA Models**|Mingsheng Shang Team|[2511.16233](http://arxiv.org/abs/2511.16233)|null|\n", "2511.16203": "|**2025-12-11**|**When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models**|Yaochu Jin Team|[2511.16203](http://arxiv.org/abs/2511.16203)|null|\n", "2511.16175": "|**2025-11-20**|**Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight**|Zhijie Deng Team|[2511.16175](http://arxiv.org/abs/2511.16175)|null|\n", "2511.16166": "|**2025-11-20**|**EvoVLA: Self-Evolving Vision-Language-Action Model**|Hao Tang Team|[2511.16166](http://arxiv.org/abs/2511.16166)|null|\n", "2511.15605": "|**2025-11-30**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Xipeng Qiu Team|[2511.15605](http://arxiv.org/abs/2511.15605)|null|\n", "2511.15279": "|**2025-11-19**|**Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception**|Wenzhao Lian Team|[2511.15279](http://arxiv.org/abs/2511.15279)|null|\n", "2511.14759": "|**2025-11-19**|**$\u03c0^{*}_{0.6}$: a VLA That Learns From Experience**|Zhiyuan Zhou Team|[2511.14759](http://arxiv.org/abs/2511.14759)|null|\n", "2511.14659": "|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Soujanya Poria Team|[2511.14659](http://arxiv.org/abs/2511.14659)|**[link](https://declare-lab.github.io/nora-1.5)**|\n", "2511.14499": "|**2025-11-18**|**Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM**|Siyuan Cheng Team|[2511.14499](http://arxiv.org/abs/2511.14499)|null|\n", "2511.14396": "|**2025-12-12**|**Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning**|Hongpeng Wang Team|[2511.14396](http://arxiv.org/abs/2511.14396)|**[link](https://qhemu.github.io/CCoL/)**|\n", "2511.14178": "|**2025-11-18**|**Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion**|Fei Chen Team|[2511.14178](http://arxiv.org/abs/2511.14178)|null|\n", "2511.14161": "|**2025-11-19**|**RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action**|Jiayu Chen Team|[2511.14161](http://arxiv.org/abs/2511.14161)|null|\n", "2511.14148": "|**2025-11-18**|**AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models**|Biqing Qi Team|[2511.14148](http://arxiv.org/abs/2511.14148)|null|\n", "2511.12405": "|**2025-11-16**|**VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving**|David Hyunchul Shim Team|[2511.12405](http://arxiv.org/abs/2511.12405)|null|\n", "2511.12149": "|**2025-11-15**|**AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models**|Yu-Gang Jiang Team|[2511.12149](http://arxiv.org/abs/2511.12149)|null|\n", "2511.11478": "|**2025-11-28**|**Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective**|Ngan Le Team|[2511.11478](http://arxiv.org/abs/2511.11478)|null|\n", "2511.11298": "|**2025-11-14**|**Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation**|Xi Zheng Team|[2511.11298](http://arxiv.org/abs/2511.11298)|null|\n", "2511.10560": "|**2025-11-14**|**OmniVGGT: Omni-Modality Driven Visual Geometry Grounded Transformer**|Ziwei Liu Team|[2511.10560](http://arxiv.org/abs/2511.10560)|**[link](https://livioni.github.io/OmniVGGT-official/)**|\n", "2511.10518": "|**2025-11-13**|**SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation**|Liqiang Nie Team|[2511.10518](http://arxiv.org/abs/2511.10518)|**[link](https://github.com/JiuTian-VL/SemanticVLA)**|\n", "2511.10008": "|**2025-11-13**|**Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks**|Wenyuan Xu Team|[2511.10008](http://arxiv.org/abs/2511.10008)|null|\n", "2511.09958": "|**2025-11-13**|**Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation**|Changbo Wang Team|[2511.09958](http://arxiv.org/abs/2511.09958)|null|\n", "2511.09516": "|**2025-11-12**|**MAP-VLA: Memory-Augmented Prompting for Vision-Language-Action Model in Robotic Manipulation**|Ziwei Wang Team|[2511.09516](http://arxiv.org/abs/2511.09516)|null|\n", "2511.09515": "|**2025-11-12**|**WMPO: World Model-based Policy Optimization for Vision-Language-Action Models**|Song Guo Team|[2511.09515](http://arxiv.org/abs/2511.09515)|**[link](https://wm-po.github.io)**|\n", "2511.09141": "|**2025-11-12**|**RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation**|Miao Li Team|[2511.09141](http://arxiv.org/abs/2511.09141)|null|\n", "2511.08865": "|**2025-11-12**|**MirrorLimb: Implementing hand pose acquisition and robot teleoperation based on RealMirror**|Tao Shen Team|[2511.08865](http://arxiv.org/abs/2511.08865)|null|\n", "2511.07820": "|**2025-12-04**|**SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control**|Yuke Zhu Team|[2511.07820](http://arxiv.org/abs/2511.07820)|**[link](https://nvlabs.github.io/SONIC/)**|\n", "2511.06619": "|**2025-11-10**|**How Do VLAs Effectively Inherit from VLMs?**|Jiang Bian Team|[2511.06619](http://arxiv.org/abs/2511.06619)|null|\n", "2511.06202": "|**2025-11-09**|**ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval**|Jeff Ichnowski Team|[2511.06202](http://arxiv.org/abs/2511.06202)|null|\n", "2511.05936": "|**2025-11-08**|**10 Open Challenges Steering the Future of Vision-Language-Action Models**|David Hsu Team|[2511.05936](http://arxiv.org/abs/2511.05936)|null|\n", "2511.05491": "|**2025-11-07**|**Visual Spatial Tuning**|Hengshuang Zhao Team|[2511.05491](http://arxiv.org/abs/2511.05491)|null|\n", "2511.05642": "|**2025-11-07**|**Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots**|Mrinmoy Sarkar Team|[2511.05642](http://arxiv.org/abs/2511.05642)|null|\n", "2511.05397": "|**2025-11-07**|**EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation**|Samuel Dickerson Team|[2511.05397](http://arxiv.org/abs/2511.05397)|null|\n", "2511.05275": "|**2025-11-07**|**TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models**|Youngwoon Lee Team|[2511.05275](http://arxiv.org/abs/2511.05275)|**[link](https://jellyho.github.io/TwinVLA/)**|\n", "2511.04555": "|**2025-12-05**|**Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment**|Bo Zhao Team|[2511.04555](http://arxiv.org/abs/2511.04555)|**[link](https://github.com/MINT-SJTU/Evo-1)**|\n", "2511.04357": "|**2025-11-06**|**GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies**|C\u00e9dric Buche Team|[2511.04357](http://arxiv.org/abs/2511.04357)|null|\n", "2511.01374": "|**2025-11-03**|**Learning Intractable Multimodal Policies with Reparameterization and Diversity Regularization**|Ling Pan Team|[2511.01374](http://arxiv.org/abs/2511.01374)|null|\n", "2511.01177": "|**2025-11-09**|**Scaling Cross-Embodiment World Models for Dexterous Manipulation**|Hao Su Team|[2511.01177](http://arxiv.org/abs/2511.01177)|null|\n", "2511.00917": "|**2025-11-18**|**Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots**|Dinesh Jayaraman Team|[2511.00917](http://arxiv.org/abs/2511.00917)|null|\n", "2512.00021": "|**2025-10-31**|**Foundation Models for Trajectory Planning in Autonomous Driving: A Review of Progress and Open Challenges**|Puneet K. Dokania Team|[2512.00021](http://arxiv.org/abs/2512.00021)|null|\n", "2511.15669": "|**2025-10-31**|**DeepThinkVLA: Enhancing Reasoning Capability of Vision-Language-Action Models**|Zhouping Yin Team|[2511.15669](http://arxiv.org/abs/2511.15669)|null|\n", "2510.26628": "|**2025-10-30**|**Low-Altitude UAV-Carried Movable Antenna for Joint Wireless Power Transfer and Covert Communications**|Tony Q. S. Quek Team|[2510.26628](http://arxiv.org/abs/2510.26628)|null|\n"}, "Humanoid": {"2504.01260": "|**2025-04-02**|**The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction**|Matthew K. X. J Pan Team|[2504.01260](http://arxiv.org/abs/2504.01260)|null|\n", "2504.01165": "|**2025-04-01**|**Extended Hybrid Zero Dynamics for Bipedal Walking of the Knee-less Robot SLIDER**|Petar Kormushev Team|[2504.01165](http://arxiv.org/abs/2504.01165)|null|\n", "2504.00614": "|**2025-04-11**|**Learning Bipedal Locomotion on Gear-Driven Humanoid Robot Using Foot-Mounted IMUs**|Masaya Kinoshita Team|[2504.00614](http://arxiv.org/abs/2504.00614)|null|\n", "2503.23601": "|**2025-03-30**|**Exploring GPT-4 for Robotic Agent Strategy with Real-Time State Feedback and a Reactive Behaviour Framework**|Ysobel Sims Team|[2503.23601](http://arxiv.org/abs/2503.23601)|null|\n", "2503.22459": "|**2025-03-28**|**Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models**|Nicolas Mansard Team|[2503.22459](http://arxiv.org/abs/2503.22459)|null|\n", "2503.22249": "|**2025-03-28**|**FLAM: Foundation Model-Based Body Stabilization for Humanoid Locomotion and Manipulation**|Debin Zhao Team|[2503.22249](http://arxiv.org/abs/2503.22249)|null|\n", "2503.21257": "|**2025-03-27**|**OminiAdapt: Learning Cross-Task Invariance for Robust and Environment-Aware Robotic Manipulation**|Wanting Li Team|[2503.21257](http://arxiv.org/abs/2503.21257)|null|\n", "2503.20842": "|**2025-03-26**|**Anti Robot Speciesism**|Miklos Sarvary Team|[2503.20842](http://arxiv.org/abs/2503.20842)|null|\n", "2503.19356": "|**2025-03-25**|**Can Vision-Language Models Answer Face to Face Questions in the Real-World?**|Roland Memisevic Team|[2503.19356](http://arxiv.org/abs/2503.19356)|null|\n", "2503.15082": "|**2025-03-19**|**StyleLoco: Generative Adversarial Distillation for Natural Humanoid Robot Locomotion**|Siyuan Huang Team|[2503.15082](http://arxiv.org/abs/2503.15082)|null|\n", "2503.14734": "|**2025-03-27**|**GR00T N1: An Open Foundation Model for Generalist Humanoid Robots**|Yuke Zhu Team|[2503.14734](http://arxiv.org/abs/2503.14734)|null|\n", "2503.13441": "|**2025-03-24**|**Humanoid Policy ~ Human Policy**|Xiaolong Wang Team|[2503.13441](http://arxiv.org/abs/2503.13441)|null|\n", "2503.12725": "|**2025-03-17**|**Humanoids in Hospitals: A Technical Study of Humanoid Surrogates for Dexterous Medical Interventions**|Michael Yip Team|[2503.12725](http://arxiv.org/abs/2503.12725)|null|\n", "2503.12533": "|**2025-03-16**|**Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills**|Zongqing Lu Team|[2503.12533](http://arxiv.org/abs/2503.12533)|null|\n", "2503.11020": "|**2025-03-14**|**Fast and Robust Localization for Humanoid Soccer Robot via Iterative Landmark Matching**|Dennis W. Hong Team|[2503.11020](http://arxiv.org/abs/2503.11020)|null|\n", "2503.10626": "|**2025-03-13**|**NIL: No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models**|Michael Black Team|[2503.10626](http://arxiv.org/abs/2503.10626)|null|\n", "2503.10554": "|**2025-03-13**|**NuExo: A Wearable Exoskeleton Covering all Upper Limb ROM for Outdoor Data Collection and Teleoperation of Humanoid Robots**|Huimin Lu Team|[2503.10554](http://arxiv.org/abs/2503.10554)|null|\n", "2503.09015": "|**2025-03-12**|**Natural Humanoid Robot Locomotion with Generative Motion Prior**|Rong Xiong Team|[2503.09015](http://arxiv.org/abs/2503.09015)|null|\n", "2503.09010": "|**2025-03-13**|**HumanoidPano: Hybrid Spherical Panoramic-LiDAR Cross-Modal Perception for Humanoid Robots**|Renjing Xu Team|[2503.09010](http://arxiv.org/abs/2503.09010)|null|\n", "2503.08349": "|**2025-03-11**|**LiPS: Large-Scale Humanoid Robot Reinforcement Learning with Parallel-Series Structures**|Renjing Xu Team|[2503.08349](http://arxiv.org/abs/2503.08349)|null|\n", "2504.05046": "|**2025-04-07**|**MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond**|Xun Cao Team|[2504.05046](http://arxiv.org/abs/2504.05046)|null|\n", "2504.04970": "|**2025-04-07**|**A High-Force Gripper with Embedded Multimodal Sensing for Powerful and Perception Driven Grasping**|Nikos G. Tsagarakis Team|[2504.04970](http://arxiv.org/abs/2504.04970)|null|\n", "2504.04488": "|**2025-04-06**|**Public speech recognition transcripts as a configuring parameter**|Christian Licoppe Team|[2504.04488](http://arxiv.org/abs/2504.04488)|null|\n", "2504.08246": "|**2025-04-11**|**Spectral Normalization for Lipschitz-Constrained Policies on Learning Humanoid Locomotion**|Jaeheung Park Team|[2504.08246](http://arxiv.org/abs/2504.08246)|null|\n", "2504.10390": "|**2025-04-14**|**Teacher Motion Priors: Enhancing Robot Locomotion over Challenging Terrain**|Zhengtao Zhang Team|[2504.10390](http://arxiv.org/abs/2504.10390)|null|\n", "2504.09833": "|**2025-04-14**|**PreCi: Pretraining and Continual Improvement of Humanoid Locomotion via Model-Assumption-Based Regularization**|Sehoon Ha Team|[2504.09833](http://arxiv.org/abs/2504.09833)|null|\n", "2504.09532": "|**2025-04-13**|**Embodied Chain of Action Reasoning with Multi-Modal Foundation Model for Humanoid Loco-manipulation**|Yi Fang Team|[2504.09532](http://arxiv.org/abs/2504.09532)|null|\n", "2504.12125": "|**2025-04-16**|**EmoACT: a Framework to Embed Emotions into Artificial Agents Based on Affect Control Theory**|Carmine Tommaso Recchiuto Team|[2504.12125](http://arxiv.org/abs/2504.12125)|null|\n", "2504.13619": "|**2025-04-18**|**Robust Humanoid Walking on Compliant and Uneven Terrain with Deep Reinforcement Learning**|Fumio Kanehiro Team|[2504.13619](http://arxiv.org/abs/2504.13619)|**[link](https://github.com/rohanpsingh/learninghumanoidwalking)**|\n", "2504.14477": "|**2025-04-20**|**ExFace: Expressive Facial Control for Humanoid Robots with Diffusion Transformers and Bootstrap Training**|Jiahao Chen Team|[2504.14477](http://arxiv.org/abs/2504.14477)|null|\n", "2504.14305": "|**2025-04-19**|**Adversarial Locomotion and Motion Imitation for Humanoid Policy Learning**|Xuelong Li Team|[2504.14305](http://arxiv.org/abs/2504.14305)|null|\n", "2504.17249": "|**2025-04-24**|**Demonstrating Berkeley Humanoid Lite: An Open-source, Accessible, and Customizable 3D-printed Humanoid Robot**|Koushil Sreenath Team|[2504.17249](http://arxiv.org/abs/2504.17249)|null|\n", "2504.20808": "|**2025-04-29**|**SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings**|Jianwei Zhang Team|[2504.20808](http://arxiv.org/abs/2504.20808)|null|\n", "2504.20109": "|**2025-04-27**|**Personalized Artificial General Intelligence (AGI) via Neuroscience-Inspired Continuous Learning Systems**|Jairaj Singh Shaktawat Team|[2504.20109](http://arxiv.org/abs/2504.20109)|null|\n", "2504.21738": "|**2025-04-30**|**LangWBC: Language-directed Humanoid Whole-Body Control via End-to-end Learning**|Koushil Sreenath Team|[2504.21738](http://arxiv.org/abs/2504.21738)|null|\n", "2505.02833": "|**2025-05-05**|**TWIST: Teleoperated Whole-Body Imitation System**|C. Karen Liu Team|[2505.02833](http://arxiv.org/abs/2505.02833)|null|\n", "2505.03738": "|**2025-05-06**|**AMO: Adaptive Motion Optimization for Hyper-Dexterous Humanoid Whole-Body Control**|Xiaolong Wang Team|[2505.03738](http://arxiv.org/abs/2505.03738)|null|\n", "2505.03729": "|**2025-05-13**|**Visual Imitation Enables Contextual Humanoid Control**|Angjoo Kanazawa Team|[2505.03729](http://arxiv.org/abs/2505.03729)|null|\n", "2505.04769": "|**2025-05-07**|**Vision-Language-Action Models: Concepts, Progress, Applications and Challenges**|Manoj Karkee Team|[2505.04769](http://arxiv.org/abs/2505.04769)|null|\n", "2505.06218": "|**2025-05-09**|**Let Humanoids Hike! Integrative Skill Development on Complex Trails**|Stella X. Yu Team|[2505.06218](http://arxiv.org/abs/2505.06218)|null|\n", "2505.06053": "|**2025-05-09**|**Safe-EF: Error Feedback for Nonsmooth Constrained Optimization**|Ilyas Fatkhullin Team|[2505.06053](http://arxiv.org/abs/2505.06053)|null|\n", "2505.05773": "|**2025-05-09**|**Human-Robot Collaboration for the Remote Control of Mobile Humanoid Robots with Torso-Arm Coordination**|Zhi Li Team|[2505.05773](http://arxiv.org/abs/2505.05773)|null|\n", "2505.07634": "|**2025-05-14**|**Neural Brain: A Neuroscience-inspired Framework for Embodied Agents**|Lin Wang Team|[2505.07634](http://arxiv.org/abs/2505.07634)|**[link](https://github.com/CNJianLiu/Neural-Brain-for-Embodied-Agents)**|\n", "2505.07294": "|**2025-05-12**|**HuB: Learning Extreme Humanoid Balance**|Yang Gao Team|[2505.07294](http://arxiv.org/abs/2505.07294)|null|\n", "2505.06794": "|**2025-05-11**|**Dynamic Safety in Complex Environments: Synthesizing Safety Filters with Poisson's Equation**|Aaron D. Ames Team|[2505.06794](http://arxiv.org/abs/2505.06794)|null|\n", "2505.06584": "|**2025-05-10**|**JAEGER: Dual-Level Humanoid Whole-Body Controller**|Zongqing Lu Team|[2505.06584](http://arxiv.org/abs/2505.06584)|null|\n", "2505.08712": "|**2025-05-15**|**NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged Information Guidance**|Jiangmiao Pang Team|[2505.08712](http://arxiv.org/abs/2505.08712)|null|\n", "2505.08216": "|**2025-05-13**|**Rethink Repeatable Measures of Robot Performance with Statistical Query**|Dylan Khor Team|[2505.08216](http://arxiv.org/abs/2505.08216)|null|\n", "2505.11495": "|**2025-05-16**|**Bracing for Impact: Robust Humanoid Push Recovery and Locomotion with Reduced Order Models**|Aaron D. Ames Team|[2505.11495](http://arxiv.org/abs/2505.11495)|null|\n", "2505.11146": "|**2025-05-16**|**X2C: A Dataset Featuring Nuanced Facial Expressions for Realistic Humanoid Imitation**|Xiaohan Yu Team|[2505.11146](http://arxiv.org/abs/2505.11146)|**[link](https://github.com/lipzh5/x2cnet)**|\n", "2505.12705": "|**2025-05-19**|**DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories**|Linxi Fan Team|[2505.12705](http://arxiv.org/abs/2505.12705)|null|\n", "2505.12679": "|**2025-05-19**|**Dribble Master: Learning Agile Humanoid Dribbling Through Legged Locomotion**|Qi Wu Team|[2505.12679](http://arxiv.org/abs/2505.12679)|null|\n", "2505.13549": "|**2025-05-19**|**TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion**|Minh Nhat Vu Team|[2505.13549](http://arxiv.org/abs/2505.13549)|null|\n", "2505.16478": "|**2025-05-22**|**Unified Multi-Rate Model Predictive Control for a Jet-Powered Humanoid Robot**|Daniele Pucci Team|[2505.16478](http://arxiv.org/abs/2505.16478)|null|\n", "2505.18078": "|**2025-05-23**|**DanceTogether! Identity-Preserving Multi-Person Interactive Video Generation**|Ruqi Huang Team|[2505.18078](http://arxiv.org/abs/2505.18078)|null|\n", "2505.19803": "|**2025-05-26**|**Integrating emotional intelligence, memory architecture, and gestures to achieve empathetic humanoid robot interaction in an educational setting**|Paul Craig Team|[2505.19803](http://arxiv.org/abs/2505.19803)|null|\n", "2505.19717": "|**2025-05-26**|**Extremum Flow Matching for Offline Goal Conditioned Reinforcement Learning**|Jean-Baptiste Mouret Team|[2505.19717](http://arxiv.org/abs/2505.19717)|null|\n", "2505.19580": "|**2025-05-26**|**Whole-body Multi-contact Motion Control for Humanoid Robots Based on Distributed Tactile Sensors**|Eiichi Yoshida Team|[2505.19580](http://arxiv.org/abs/2505.19580)|**[link](https://github.com/isri-aist/MultiContactController)**|\n", "2505.19530": "|**2025-05-26**|**Heavy lifting tasks via haptic teleoperation of a wheeled humanoid**|Joao Ramos Team|[2505.19530](http://arxiv.org/abs/2505.19530)|null|\n", "2505.19463": "|**2025-05-26**|**SMAP: Self-supervised Motion Adaptation for Physically Plausible Humanoid Whole-body Control**|Junting Dong Team|[2505.19463](http://arxiv.org/abs/2505.19463)|null|\n", "2505.19339": "|**2025-05-25**|**Towards Humanoid Robot Autonomy: A Dynamic Architecture Integrating Continuous thought Machines (CTM) and Model Context Protocol (MCP)**|Libo Wang Team|[2505.19339](http://arxiv.org/abs/2505.19339)|**[link](https://github.com/brucewang123456789/GeniusTrail)**|\n", "2505.19026": "|**2025-05-25**|**Staircase Recognition and Location Based on Polarization Vision**|Zhiying Tan Team|[2505.19026](http://arxiv.org/abs/2505.19026)|null|\n", "2505.20829": "|**2025-05-27**|**Learning Unified Force and Position Control for Legged Loco-Manipulation**|Siyuan Huang Team|[2505.20829](http://arxiv.org/abs/2505.20829)|null|\n", "2505.20619": "|**2025-05-27**|**Gait-Conditioned Reinforcement Learning with Multi-Phase Curriculum for Humanoid Locomotion**|CHengxu Zhou Team|[2505.20619](http://arxiv.org/abs/2505.20619)|null|\n", "2505.22642": "|**2025-06-01**|**FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control**|Pieter Abbeel Team|[2505.22642](http://arxiv.org/abs/2505.22642)|null|\n", "2505.23505": "|**2025-05-29**|**Humanoid Loco-manipulation Planning based on Graph Search and Reachability Maps**|Abderrahmane Kheddar Team|[2505.23505](http://arxiv.org/abs/2505.23505)|null|\n", "2505.23499": "|**2025-05-29**|**Centroidal Trajectory Generation and Stabilization based on Preview Control for Humanoid Multi-contact Motion**|Fumio Kanehiro Team|[2505.23499](http://arxiv.org/abs/2505.23499)|**[link](https://github.com/isri-aist/MultiContactController)**|\n", "2505.24266": "|**2025-06-05**|**SignBot: Learning Human-to-Humanoid Sign Language Interaction**|Guiliang Liu Team|[2505.24266](http://arxiv.org/abs/2505.24266)|null|\n", "2505.24116": "|**2025-05-30**|**Humanoid Loco-Manipulations Pattern Generation and Stabilization Control**|Abderrahmane Kheddar Team|[2505.24116](http://arxiv.org/abs/2505.24116)|null|\n", "2506.02507": "|**2025-06-03**|**AURA: Agentic Upskilling via Reinforced Abstractions**|Dennis Hong Team|[2506.02507](http://arxiv.org/abs/2506.02507)|null|\n", "2506.02206": "|**2025-06-02**|**Reinforcement Learning with Data Bootstrapping for Dynamic Subgoal Pursuit in Humanoid Robot Navigation**|Ayonga Hereid Team|[2506.02206](http://arxiv.org/abs/2506.02206)|null|\n", "2506.01756": "|**2025-06-02**|**Learning with pyCub: A New Simulation and Exercise Framework for Humanoid Robotics**|Matej Hoffmann Team|[2506.01756](http://arxiv.org/abs/2506.01756)|null|\n", "2506.01563": "|**2025-06-05**|**Hierarchical Intention-Aware Expressive Motion Generation for Humanoid Robots**|Chengxu Zhou Team|[2506.01563](http://arxiv.org/abs/2506.01563)|null|\n", "2506.01182": "|**2025-06-01**|**Humanoid World Models: Open World Foundation Models for Humanoid Robotics**|Mohammad Al-Sharman Team|[2506.01182](http://arxiv.org/abs/2506.01182)|null|\n", "2506.01125": "|**2025-06-01**|**iRonCub 3: The Jet-Powered Flying Humanoid Robot**|Daniele Pucci Team|[2506.01125](http://arxiv.org/abs/2506.01125)|null|\n", "2506.00305": "|**2025-05-30**|**Learning Aerodynamics for the Control of Flying Humanoid Robots**|Daniele Pucci Team|[2506.00305](http://arxiv.org/abs/2506.00305)|null|\n", "2506.00098": "|**2025-05-30**|**Interactive Imitation Learning for Dexterous Robotic Manipulation: Challenges and Perspectives -- A Survey**|Rania Rayyes Team|[2506.00098](http://arxiv.org/abs/2506.00098)|null|\n", "2506.03856": "|**2025-06-04**|**Phase-based Nonlinear Model Predictive Control for Humanoid Walking Stabilization with Single and Double Support Time Adjustments**|Jaeheung Park Team|[2506.03856](http://arxiv.org/abs/2506.03856)|null|\n", "2506.05117": "|**2025-06-05**|**Realizing Text-Driven Motion Generation on NAO Robot: A Reinforcement Learning-Optimized Control Pipeline**|Qijun Chen Team|[2506.05117](http://arxiv.org/abs/2506.05117)|**[link](https://github.com/southwestCat/text2motion-nao)**|\n", "2506.08856": "|**2025-06-10**|**Fast Estimation of Globally Optimal Independent Contact Regions for Robust Grasping and Manipulation**|Nancy S. Pollard Team|[2506.08856](http://arxiv.org/abs/2506.08856)|null|\n", "2506.08840": "|**2025-06-12**|**MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains**|Xuelong Li Team|[2506.08840](http://arxiv.org/abs/2506.08840)|null|\n", "2506.08416": "|**2025-06-10**|**Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots**|Lijun Zhu Team|[2506.08416](http://arxiv.org/abs/2506.08416)|null|\n", "2506.09979": "|**2025-06-11**|**Locomotion on Constrained Footholds via Layered Architectures and Model Predictive Control**|Aaron D. Ames Team|[2506.09979](http://arxiv.org/abs/2506.09979)|null|\n", "2506.09588": "|**2025-06-11**|**Attention-Based Map Encoding for Learning Generalized Legged Locomotion**|Marco Hutter Team|[2506.09588](http://arxiv.org/abs/2506.09588)|null|\n", "2506.09383": "|**2025-06-11**|**Bipedal Balance Control with Whole-body Musculoskeletal Standing and Falling Simulations**|Yanan Sui Team|[2506.09383](http://arxiv.org/abs/2506.09383)|null|\n", "2506.09366": "|**2025-06-11**|**SkillBlender: Towards Versatile Humanoid Whole-Body Loco-Manipulation via Skill Blending**|Yue Wang Team|[2506.09366](http://arxiv.org/abs/2506.09366)|**[link](https://github.com/Humanoid-SkillBlender/SkillBlender)**|\n", "2506.10170": "|**2025-06-11**|**Exploring EEG Responses during Observation of Actions Performed by Human Actor and Humanoid Robot**|Michelle J. Johnson Team|[2506.10170](http://arxiv.org/abs/2506.10170)|null|\n", "2506.11916": "|**2025-06-13**|**mimic-one: a Scalable Model Recipe for General Purpose Robot Dexterity**|Robert K. Katzschmann Team|[2506.11916](http://arxiv.org/abs/2506.11916)|null|\n", "2506.12851": "|**2025-06-15**|**KungfuBot: Physics-Based Humanoid Whole-Body Control for Learning Highly-Dynamic Skills**|Xuelong Li Team|[2506.12851](http://arxiv.org/abs/2506.12851)|null|\n", "2506.12779": "|**2025-06-19**|**From Experts to a Generalist: Toward General Whole-Body Control for Humanoid Robots**|Zongqing Lu Team|[2506.12779](http://arxiv.org/abs/2506.12779)|null|\n", "2506.12769": "|**2025-06-15**|**RL from Physical Feedback: Aligning Large Motion Models with Humanoid Control**|Zongqing Lu Team|[2506.12769](http://arxiv.org/abs/2506.12769)|null|\n", "2506.12314": "|**2025-06-14**|**Explosive Output to Enhance Jumping Ability: A Variable Reduction Ratio Design Paradigm for Humanoid Robots Knee Joint**|Qiang Huang Team|[2506.12314](http://arxiv.org/abs/2506.12314)|null|\n", "2506.14770": "|**2025-06-17**|**GMT: General Motion Tracking for Humanoid Whole-Body Control**|Xiaolong Wang Team|[2506.14770](http://arxiv.org/abs/2506.14770)|null|\n", "2506.14278": "|**2025-06-17**|**Whole-Body Control Framework for Humanoid Robots with Heavy Limbs: A Model-Based Approach**|Yun-Hui Liu Team|[2506.14278](http://arxiv.org/abs/2506.14278)|null|\n", "2506.15146": "|**2025-06-18**|**TACT: Humanoid Whole-body Contact Manipulation through Deep Imitation Learning with Tactile Modality**|Eiichi Yoshida Team|[2506.15146](http://arxiv.org/abs/2506.15146)|null|\n", "2506.15132": "|**2025-06-18**|**Booster Gym: An End-to-End Reinforcement Learning Framework for Humanoid Robot Locomotion**|Mingguo Zhao Team|[2506.15132](http://arxiv.org/abs/2506.15132)|**[link](https://github.com/BoosterRobotics/booster_gym)**|\n", "2506.16012": "|**2025-06-19**|**DualTHOR: A Dual-Arm Humanoid Simulation Platform for Contingency-Aware Planning**|Zongqing Lu Team|[2506.16012](http://arxiv.org/abs/2506.16012)|**[link](https://github.com/ds199895/dualthor)**|\n", "2506.20487": "|**2025-07-18**|**A Survey of Behavior Foundation Model: Next-Generation Whole-Body Control System of Humanoid Robots**|Wenjun Zeng Team|[2506.20487](http://arxiv.org/abs/2506.20487)|null|\n", "2506.21628": "|**2025-07-14**|**Ark: An Open-source Python-based Framework for Robot Learning**|Haitham Bou-Ammar Team|[2506.21628](http://arxiv.org/abs/2506.21628)|null|\n", "2506.23152": "|**2025-07-02**|**DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover**|Yuexin Ma Team|[2506.23152](http://arxiv.org/abs/2506.23152)|**[link](https://dexh2r.github.io/)**|\n", "2506.23125": "|**2025-06-29**|**Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots**|Yue Gao Team|[2506.23125](http://arxiv.org/abs/2506.23125)|null|\n", "2506.22827": "|**2025-07-10**|**Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation**|Navid Azizan Team|[2506.22827](http://arxiv.org/abs/2506.22827)|null|\n", "2506.22473": "|**2025-06-20**|**Unsupervised Discovery of Behavioral Primitives from Sensorimotor Dynamic Functional Connectivity**|Matej Hoffmann Team|[2506.22473](http://arxiv.org/abs/2506.22473)|null|\n", "2507.00833": "|**2025-11-16**|**HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning**|Chenjia Bai Team|[2507.00833](http://arxiv.org/abs/2507.00833)|**[link](https://openhumanoidgen.github.io)**|\n", "2507.00273": "|**2025-10-30**|**Mechanical Intelligence-Aware Curriculum Reinforcement Learning for Humanoids with Parallel Actuation**|Dennis Hong Team|[2507.00273](http://arxiv.org/abs/2507.00273)|null|\n", "2507.04140": "|**2025-07-05**|**Learning Humanoid Arm Motion via Centroidal Momentum Regularized Multi-Agent Reinforcement Learning**|Sangbae Kim Team|[2507.04140](http://arxiv.org/abs/2507.04140)|null|\n", "2507.06905": "|**2025-07-09**|**ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation**|Zongwu Xie Team|[2507.06905](http://arxiv.org/abs/2507.06905)|null|\n", "2507.06404": "|**2025-07-08**|**Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction**|Alessio Del Bue Team|[2507.06404](http://arxiv.org/abs/2507.06404)|null|\n", "2507.07356": "|**2025-09-18**|**UniTracker: Learning Universal Whole-Body Motion Tracker for Humanoid Robots**|Weinan Zhang Team|[2507.07356](http://arxiv.org/abs/2507.07356)|null|\n", "2507.08303": "|**2025-11-13**|**Keep on Going: Learning Robust Humanoid Motion Skills via Selective Adversarial Training**|Yue Gao Team|[2507.08303](http://arxiv.org/abs/2507.08303)|null|\n", "2507.10105": "|**2025-07-14**|**Physics-Informed Neural Networks with Unscented Kalman Filter for Sensorless Joint Torque Estimation in Humanoid Robots**|Daniele Pucci Team|[2507.10105](http://arxiv.org/abs/2507.10105)|null|\n", "2507.11498": "|**2025-07-16**|**Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming**|Loris Roveda Team|[2507.11498](http://arxiv.org/abs/2507.11498)|null|\n", "2507.11402": "|**2025-07-15**|**From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League**|Shohei Yasuda Team|[2507.11402](http://arxiv.org/abs/2507.11402)|null|\n", "2507.15649": "|**2025-07-21**|**EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation**|Rong Xiong Team|[2507.15649](http://arxiv.org/abs/2507.15649)|null|\n", "2507.16369": "|**2025-07-22**|**Humanoid Robot Whole-body Geometric Calibration with Embedded Sensors and a Single Plane**|Florent Lamiraux Team|[2507.16369](http://arxiv.org/abs/2507.16369)|null|\n", "2507.15895": "|**2025-07-20**|**Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture**|Lisa Dargasz Team|[2507.15895](http://arxiv.org/abs/2507.15895)|null|\n", "2508.00362": "|**2025-08-01**|**A Whole-Body Motion Imitation Framework from Human Data for Full-Size Humanoid Robot**|Rong Xiong Team|[2508.00362](http://arxiv.org/abs/2508.00362)|null|\n", "2508.00355": "|**2025-08-01**|**TOP: Time Optimization Policy for Stable and Accurate Standing Manipulation with Humanoid Robots**|Rong Xiong Team|[2508.00355](http://arxiv.org/abs/2508.00355)|null|\n", "2508.00162": "|**2025-09-24**|**CHILD (Controller for Humanoid Imitation and Live Demonstration): a Whole-Body Humanoid Teleoperation System**|Joohyung Kim Team|[2508.00162](http://arxiv.org/abs/2508.00162)|null|\n", "2508.00088": "|**2025-07-31**|**The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking**|Taih\u00fa Pire Team|[2508.00088](http://arxiv.org/abs/2508.00088)|null|\n", "2507.20530": "|**2025-07-28**|**Binaural Sound Event Localization and Detection based on HRTF Cues for Humanoid Robots**|Yong-Hwa Park Team|[2507.20530](http://arxiv.org/abs/2507.20530)|null|\n", "2507.20509": "|**2025-07-28**|**LLMs-guided adaptive compensator: Bringing Adaptivity to Automatic Control Systems with Large Language Models**|Yusuke Iwasawa Team|[2507.20509](http://arxiv.org/abs/2507.20509)|null|\n", "2507.20217": "|**2025-07-29**|**Humanoid Occupancy: Enabling A Generalized Multimodal Occupancy Perception System on Humanoid Robots**|Qiang Zhang Team|[2507.20217](http://arxiv.org/abs/2507.20217)|null|\n", "2507.20174": "|**2025-07-27**|**LRR-Bench: Left, Right or Rotate? Vision-Language models Still Struggle With Spatial Understanding Tasks**|Xiaoshuang Shi Team|[2507.20174](http://arxiv.org/abs/2507.20174)|null|\n", "2507.19335": "|**2025-07-25**|**How Age Influences the Interpretation of Emotional Body Language in Humanoid Robots -- long paper version**|Giuseppe Palestra Team|[2507.19335](http://arxiv.org/abs/2507.19335)|null|\n", "2507.18502": "|**2025-07-24**|**Experimental Comparison of Whole-Body Control Formulations for Humanoid Robots in Task Acceleration and Task Force Spaces**|Christian Ott Team|[2507.18502](http://arxiv.org/abs/2507.18502)|**[link](https://youtu.be/Nfm50ycz-FU)**|\n", "2508.04333": "|**2025-08-06**|**Binaural Sound Event Localization and Detection Neural Network based on HRTF Localization Cues for Humanoid Robots**|Gyeong-Tae Lee Team|[2508.04333](http://arxiv.org/abs/2508.04333)|null|\n", "2508.02505": "|**2025-08-08**|**Would you let a humanoid play storytelling with your child? A usability study on LLM-powered narrative Human-Robot Interaction**|Agnieszka Wykowska Team|[2508.02505](http://arxiv.org/abs/2508.02505)|null|\n", "2508.02106": "|**2025-08-04**|**Towards Immersive Human-X Interaction: A Real-Time Framework for Physically Plausible Motion Synthesis**|Jingya Wang Team|[2508.02106](http://arxiv.org/abs/2508.02106)|null|\n", "2508.01247": "|**2025-11-16**|**Coordinated Humanoid Robot Locomotion with Symmetry Equivariant Reinforcement Learning Policy**|Yue Gao Team|[2508.01247](http://arxiv.org/abs/2508.01247)|null|\n", "2508.05104": "|**2025-08-07**|**Examining the legibility of humanoid robot arm movements in a pointing task**|Igor Farka\u0161 Team|[2508.05104](http://arxiv.org/abs/2508.05104)|null|\n", "2508.04931": "|**2025-08-06**|**INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM**|Nikos Tsagarakis Team|[2508.04931](http://arxiv.org/abs/2508.04931)|**[link](https://robo-intention.github.io)**|\n", "2508.04834": "|**2025-08-06**|**On the causality between affective impact and coordinated human-robot reactions**|Kasper St\u00f8y Team|[2508.04834](http://arxiv.org/abs/2508.04834)|null|\n", "2508.07945": "|**2025-08-11**|**PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF**|Lorenzo Natale Team|[2508.07945](http://arxiv.org/abs/2508.07945)|null|\n", "2508.07611": "|**2025-08-11**|**End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy**|Junwei Liang Team|[2508.07611](http://arxiv.org/abs/2508.07611)|null|\n", "2508.06779": "|**2025-08-09**|**Learning a Vision-Based Footstep Planner for Hierarchical Walking Control**|Michael Posa Team|[2508.06779](http://arxiv.org/abs/2508.06779)|null|\n", "2508.10423": "|**2025-08-14**|**MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion**|Yanjie Li Team|[2508.10423](http://arxiv.org/abs/2508.10423)|null|\n", "2508.09960": "|**2025-08-13**|**GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation**|Jun-Guo Lu Team|[2508.09960](http://arxiv.org/abs/2508.09960)|null|\n", "2508.11520": "|**2025-08-15**|**A Comparative Study of Floating-Base Space Parameterizations for Agile Whole-Body Motion Planning**|Konstantinos Chatzilygeroudis Team|[2508.11520](http://arxiv.org/abs/2508.11520)|null|\n", "2508.11275": "|**2025-08-15**|**Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation**|Fumio Kanehiro Team|[2508.11275](http://arxiv.org/abs/2508.11275)|null|\n", "2508.11129": "|**2025-08-15**|**Geometry-Aware Predictive Safety Filters on Humanoids: From Poisson Safety Functions to CBF Constrained MPC**|Aaron D. Ames Team|[2508.11129](http://arxiv.org/abs/2508.11129)|null|\n", "2508.12980": "|**2025-08-18**|**Scaling Whole-body Multi-contact Manipulation with Contact Optimization**|Sethu Vijayakumar Team|[2508.12980](http://arxiv.org/abs/2508.12980)|null|\n", "2508.12586": "|**2025-08-18**|**Foundation Model for Skeleton-Based Human Action Understanding**|Liang Wang Team|[2508.12586](http://arxiv.org/abs/2508.12586)|**[link](https://github.com/wengwanjiang/FoundSkelModel)**|\n", "2508.12252": "|**2025-08-26**|**Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids**|Shuran Song Team|[2508.12252](http://arxiv.org/abs/2508.12252)|null|\n", "2508.12184": "|**2025-08-17**|**Humanoid Motion Scripting with Postural Synergies**|Oussama Khatib Team|[2508.12184](http://arxiv.org/abs/2508.12184)|null|\n", "2508.11885": "|**2025-08-16**|**Contact-Rich and Deformable Foot Modeling for Locomotion Control of the Human Musculoskeletal System**|Yanan Sui Team|[2508.11885](http://arxiv.org/abs/2508.11885)|null|\n", "2508.11884": "|**2025-08-16**|**From Screen to Stage: Kid Cosmo, A Life-Like, Torque-Controlled Humanoid for Entertainment Robotics**|Dennis W. Hong Team|[2508.11884](http://arxiv.org/abs/2508.11884)|null|\n", "2508.11802": "|**2025-08-15**|**Anticipatory and Adaptive Footstep Streaming for Teleoperated Bipedal Robots**|Robert Griffin Team|[2508.11802](http://arxiv.org/abs/2508.11802)|null|\n", "2508.14466": "|**2025-08-20**|**LookOut: Real-World Humanoid Egocentric Navigation**|Leonidas J. Guibas Team|[2508.14466](http://arxiv.org/abs/2508.14466)|null|\n", "2508.17481": "|**2025-09-01**|**SoK: Cybersecurity Assessment of Humanoid Ecosystem**|Yuval Elovici Team|[2508.17481](http://arxiv.org/abs/2508.17481)|null|\n", "2508.18238": "|**2025-08-21**|**PriorFormer: A Transformer for Real-time Monocular 3D Human Pose Estimation with Versatile Geometric Priors**|Vincent Bonnet Team|[2508.18238](http://arxiv.org/abs/2508.18238)|null|\n", "2508.19002": "|**2025-08-26**|**HuBE: Cross-Embodiment Human-like Behavior Execution for Humanoid Robots**|Guodong Guo Team|[2508.19002](http://arxiv.org/abs/2508.19002)|null|\n", "2508.21043": "|**2025-09-04**|**HITTER: A HumanoId Table TEnnis Robot via Hierarchical Planning and Learning**|S. Shankar Sastry Team|[2508.21043](http://arxiv.org/abs/2508.21043)|null|\n", "2509.03222": "|**2025-09-03**|**The Role of Embodiment in Intuitive Whole-Body Teleoperation for Mobile Manipulation**|Georgia Chalvatzaki Team|[2509.03222](http://arxiv.org/abs/2509.03222)|null|\n", "2509.01819": "|**2025-09-01**|**ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training**|Dieter Fox Team|[2509.01819](http://arxiv.org/abs/2509.01819)|null|\n", "2509.04722": "|**2025-09-05**|**Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots**|Aaron D. Ames Team|[2509.04722](http://arxiv.org/abs/2509.04722)|null|\n", "2509.06469": "|**2025-09-09**|**Interactive Shaping of Granular Media Using Reinforcement Learning**|Maren Bennewitz Team|[2509.06469](http://arxiv.org/abs/2509.06469)|null|\n", "2509.05581": "|**2025-09-06**|**Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids**|Dennis W. Hong Team|[2509.05581](http://arxiv.org/abs/2509.05581)|null|\n", "2509.08126": "|**2025-09-09**|**Attribute-based Object Grounding and Robot Grasp Detection with Spatial Reasoning**|Changhyun Choi Team|[2509.08126](http://arxiv.org/abs/2509.08126)|null|\n", "2509.09364": "|**2025-09-11**|**AGILOped: Agile Open-Source Humanoid Robot for Research**|Sven Behnke Team|[2509.09364](http://arxiv.org/abs/2509.09364)|null|\n", "2509.10353": "|**2025-12-16**|**Data-fused MPC with Guarantees: Application to Flying Humanoid Robots**|Daniele Pucci Team|[2509.10353](http://arxiv.org/abs/2509.10353)|null|\n", "2509.09769": "|**2025-09-11**|**MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos**|Yuke Zhu Team|[2509.09769](http://arxiv.org/abs/2509.09769)|null|\n", "2509.11388": "|**2025-09-14**|**Quantum deep reinforcement learning for humanoid robot navigation task**|Ahmed Biyabani Team|[2509.11388](http://arxiv.org/abs/2509.11388)|null|\n", "2509.11109": "|**2025-10-16**|**FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers**|Zhigong Song Team|[2509.11109](http://arxiv.org/abs/2509.11109)|null|\n", "2509.13200": "|**2025-09-18**|**StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening**|Shayegan Omidshafiei Team|[2509.13200](http://arxiv.org/abs/2509.13200)|null|\n", "2508.20661": "|**2025-09-22**|**Traversing Narrow Paths: A Two-Stage Reinforcement Learning Framework for Robust and Safe Humanoid Walking**|Shiwu Zhang Team|[2508.20661](http://arxiv.org/abs/2508.20661)|**[link](https://huangtc233.github.io/Traversing-the-Narrow-Path/)**|\n", "2509.14139": "|**2025-09-23**|**Cybersecurity AI: Humanoid Robots as Attack Vectors**|Kevin Finisterre Team|[2509.14139](http://arxiv.org/abs/2509.14139)|null|\n", "2509.14096": "|**2025-09-17**|**The Cybersecurity of a Humanoid Robot**|V\u00edctor Mayoral-Vilches Team|[2509.14096](http://arxiv.org/abs/2509.14096)|null|\n", "2509.13780": "|**2025-09-17**|**Behavior Foundation Model for Humanoid Robots**|Jiangmiao Pang Team|[2509.13780](http://arxiv.org/abs/2509.13780)|null|\n", "2509.13733": "|**2025-11-25**|**FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph**|Zhizhong Su Team|[2509.13733](http://arxiv.org/abs/2509.13733)|**[link](https://horizonrobotics.github.io/robot_lab/fsr-vln/)**|\n", "2509.13534": "|**2025-09-16**|**Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning**|Jun Ma Team|[2509.13534](http://arxiv.org/abs/2509.13534)|null|\n", "2509.14935": "|**2025-09-18**|**CAD-Driven Co-Design for Flight-Ready Jet-Powered Humanoids**|Daniele Pucci Team|[2509.14935](http://arxiv.org/abs/2509.14935)|null|\n", "2509.14687": "|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Tao Shen Team|[2509.14687](http://arxiv.org/abs/2509.14687)|null|\n", "2509.16032": "|**2025-09-19**|**A Matter of Height: The Impact of a Robotic Object on Human Compliance**|Hadas Erel Team|[2509.16032](http://arxiv.org/abs/2509.16032)|null|\n", "2509.15443": "|**2025-09-18**|**Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning**|Haodong Zhang Team|[2509.15443](http://arxiv.org/abs/2509.15443)|null|\n", "2509.16757": "|**2025-09-27**|**HDMI: Learning Interactive Humanoid Whole-Body Control from Human Videos**|Guanya Shi Team|[2509.16757](http://arxiv.org/abs/2509.16757)|null|\n", "2509.16638": "|**2025-09-20**|**KungfuBot2: Learning Versatile Motion Skills for Humanoid Whole-Body Control**|Chenjia Bai Team|[2509.16638](http://arxiv.org/abs/2509.16638)|null|\n", "2509.16469": "|**2025-09-19**|**A Framework for Optimal Ankle Design of Humanoid Robots**|Daniele Pucci Team|[2509.16469](http://arxiv.org/abs/2509.16469)|null|\n", "2509.19301": "|**2025-09-25**|**Residual Off-Policy RL for Finetuning Behavior Cloning Policies**|Anusha Nagabandi Team|[2509.19301](http://arxiv.org/abs/2509.19301)|**[link](https://residual-offpolicy-rl.github.io)**|\n", "2509.20322": "|**2025-11-13**|**VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation**|Jiajun Wu Team|[2509.20322](http://arxiv.org/abs/2509.20322)|**[link](https://visualmimic.github.io)**|\n", "2509.20263": "|**2025-09-25**|**HL-IK: A Lightweight Implementation of Human-Like Inverse Kinematics in Humanoid Arms**|Houde Liu Team|[2509.20263](http://arxiv.org/abs/2509.20263)|null|\n", "2509.19573": "|**2025-09-23**|**Chasing Stability: Humanoid Running via Control Lyapunov Function Guided Reinforcement Learning**|Aaron D. Ames Team|[2509.19573](http://arxiv.org/abs/2509.19573)|null|\n", "2509.19545": "|**2025-09-23**|**RoMoCo: Robotic Motion Control Toolbox for Reduced-Order Model-Based Locomotion on Bipedal and Humanoid Robots**|Aaron D. Ames Team|[2509.19545](http://arxiv.org/abs/2509.19545)|null|\n", "2509.21231": "|**2025-09-25**|**SEEC: Stable End-Effector Control with Model-Enhanced Residual Learning for Humanoid Loco-Manipulation**|Ye Zhao Team|[2509.21231](http://arxiv.org/abs/2509.21231)|null|\n", "2509.20696": "|**2025-09-25**|**RuN: Residual Policy for Natural Humanoid Locomotion**|Yong Liu Team|[2509.20696](http://arxiv.org/abs/2509.20696)|null|\n", "2509.20579": "|**2025-09-24**|**Large Pre-Trained Models for Bimanual Manipulation in 3D**|David Meger Team|[2509.20579](http://arxiv.org/abs/2509.20579)|null|\n", "2509.24697": "|**2025-09-29**|**Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering**|Daniele Pucci Team|[2509.24697](http://arxiv.org/abs/2509.24697)|null|\n", "2509.24530": "|**2025-09-29**|**Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game**|Alessandra Sciutti Team|[2509.24530](http://arxiv.org/abs/2509.24530)|null|\n", "2509.24163": "|**2025-09-29**|**Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models**|Sethu Vijayakumar Team|[2509.24163](http://arxiv.org/abs/2509.24163)|null|\n", "2509.23852": "|**2025-11-08**|**SIG-Chat: Spatial Intent-Guided Conversational Gesture Generation Involving How, When and Where**|Chuanchen Luo Team|[2509.23852](http://arxiv.org/abs/2509.23852)|null|\n", "2509.26633": "|**2025-10-08**|**OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction**|Guanya Shi Team|[2509.26633](http://arxiv.org/abs/2509.26633)|**[link](https://omniretarget.github.io)**|\n", "2509.26236": "|**2025-09-30**|**ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm**|Katherine J. Kuchenbecker Team|[2509.26236](http://arxiv.org/abs/2509.26236)|null|\n", "2509.26082": "|**2025-09-30**|**Evolutionary Continuous Adaptive RL-Powered Co-Design for Humanoid Chin-Up Performance**|Frank Kirchner Team|[2509.26082](http://arxiv.org/abs/2509.26082)|null|\n", "2509.25443": "|**2025-10-06**|**CoTaP: Compliant Task Pipeline and Reinforcement Learning of Its Controller with Compliance Modulation**|Yoshihiko Nakamura Team|[2509.25443](http://arxiv.org/abs/2509.25443)|null|\n", "2510.02252": "|**2025-10-02**|**Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking**|C. Karen Liu Team|[2510.02252](http://arxiv.org/abs/2510.02252)|null|\n", "2510.02129": "|**2025-10-02**|**Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control**|Tim Laue Team|[2510.02129](http://arxiv.org/abs/2510.02129)|null|\n", "2510.01843": "|**2025-10-02**|**Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots**|Peng Lu Team|[2510.01843](http://arxiv.org/abs/2510.01843)|null|\n", "2510.00329": "|**2025-09-30**|**Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning**|Ludovic Righetti Team|[2510.00329](http://arxiv.org/abs/2510.00329)|null|\n", "2510.03081": "|**2025-10-03**|**Embracing Evolution: A Call for Body-Control Co-Design in Embodied Humanoid Robot**|Kui Jia Team|[2510.03081](http://arxiv.org/abs/2510.03081)|null|\n", "2510.03022": "|**2025-10-03**|**HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton**|Yi Xu Team|[2510.03022](http://arxiv.org/abs/2510.03022)|null|\n", "2510.05001": "|**2025-10-06**|**Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot**|Abhishek Warrier Team|[2510.05001](http://arxiv.org/abs/2510.05001)|null|\n", "2510.04353": "|**2025-10-05**|**Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation**|Robert Griffin Team|[2510.04353](http://arxiv.org/abs/2510.04353)|null|\n", "2510.03529": "|**2025-10-03**|**LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy**|Michael C. Yip Team|[2510.03529](http://arxiv.org/abs/2510.03529)|null|\n", "2510.05923": "|**2025-10-07**|**A Co-Design Framework for Energy-Aware Monoped Jumping with Detailed Actuator Modeling**|Shishir Kolathaya Team|[2510.05923](http://arxiv.org/abs/2510.05923)|null|\n", "2510.07152": "|**2025-10-10**|**DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction**|Qiang Zhang Team|[2510.07152](http://arxiv.org/abs/2510.07152)|null|\n", "2510.08475": "|**2025-10-09**|**DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos**|Tsung-Wei Ke Team|[2510.08475](http://arxiv.org/abs/2510.08475)|**[link](https://embodiedai-ntu.github.io/dexman/index.html)**|\n", "2510.08406": "|**2025-10-09**|**Reliability of Single-Level Equality-Constrained Inverse Optimal Control**|Vincent Bonnet Team|[2510.08406](http://arxiv.org/abs/2510.08406)|null|\n", "2510.07882": "|**2025-10-15**|**Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots**|Zongqing Lu Team|[2510.07882](http://arxiv.org/abs/2510.07882)|null|\n", "2510.08807": "|**2025-10-09**|**Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation**|Yue Wang Team|[2510.08807](http://arxiv.org/abs/2510.08807)|null|\n", "2510.11682": "|**2025-10-13**|**Ego-Vision World Model for Humanoid Contact Planning**|Koushil Sreenath Team|[2510.11682](http://arxiv.org/abs/2510.11682)|null|\n", "2510.11539": "|**2025-11-26**|**Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization**|Xiaobin Xiong Team|[2510.11539](http://arxiv.org/abs/2510.11539)|null|\n", "2510.11401": "|**2025-10-13**|**Path and Motion Optimization for Efficient Multi-Location Inspection with Humanoid Robots**|Yao Su Team|[2510.11401](http://arxiv.org/abs/2510.11401)|null|\n", "2510.11258": "|**2025-10-13**|**DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation**|Zongqing Lu Team|[2510.11258](http://arxiv.org/abs/2510.11258)|null|\n", "2510.11072": "|**2025-10-13**|**PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System**|Jiangmiao Pang Team|[2510.11072](http://arxiv.org/abs/2510.11072)|**[link](https://why618188.github.io/physhsi/)**|\n", "2510.10851": "|**2025-10-12**|**Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion**|Mingguo Zhao Team|[2510.10851](http://arxiv.org/abs/2510.10851)|null|\n", "2510.10206": "|**2025-10-11**|**It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots**|Siheng Chen Team|[2510.10206](http://arxiv.org/abs/2510.10206)|null|\n", "2510.09786": "|**2025-10-10**|**Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks**|Zhicheng He Team|[2510.09786](http://arxiv.org/abs/2510.09786)|null|\n", "2510.12346": "|**2025-10-14**|**PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing**|Yucong Wu Team|[2510.12346](http://arxiv.org/abs/2510.12346)|null|\n", "2510.13625": "|**2025-10-15**|**A Modular Object Detection System for Humanoid Robots Using YOLO**|Meng Cheng Lau Team|[2510.13625](http://arxiv.org/abs/2510.13625)|null|\n", "2510.13594": "|**2025-10-15**|**Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots**|Meng Cheng Lau Team|[2510.13594](http://arxiv.org/abs/2510.13594)|null|\n", "2510.14959": "|**2025-10-19**|**CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions**|Aaron D. Ames Team|[2510.14959](http://arxiv.org/abs/2510.14959)|null|\n", "2510.14952": "|**2025-10-17**|**From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance**|Chang Xu Team|[2510.14952](http://arxiv.org/abs/2510.14952)|null|\n", "2510.14454": "|**2025-10-16**|**Towards Adaptable Humanoid Control via Adaptive Motion Tracking**|Jiangmiao Pang Team|[2510.14454](http://arxiv.org/abs/2510.14454)|null|\n", "2510.17792": "|**2025-10-20**|**SoftMimic: Learning Compliant Whole-body Control from Examples**|Pulkit Agrawal Team|[2510.17792](http://arxiv.org/abs/2510.17792)|**[link](https://gmargo11.github.io/softmimic/)**|\n", "2510.18544": "|**2025-11-18**|**SLICE: SLO-Driven Scheduling for LLM Inference on Edge Computing Devices**|Will Chow Team|[2510.18544](http://arxiv.org/abs/2510.18544)|null|\n", "2510.18002": "|**2025-10-20**|**Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints**|Jiangmiao Pang Team|[2510.18002](http://arxiv.org/abs/2510.18002)|null|\n", "2510.23059": "|**2025-10-27**|**Awakening Facial Emotional Expressions in Human-Robot**|Jianwei Zhang Team|[2510.23059](http://arxiv.org/abs/2510.23059)|null|\n", "2510.22336": "|**2025-11-05**|**Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery**|Guiliang Liu Team|[2510.22336](http://arxiv.org/abs/2510.22336)|null|\n", "2510.25725": "|**2025-11-13**|**A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation**|Kyung-Joong Kim Team|[2510.25725](http://arxiv.org/abs/2510.25725)|null|\n", "2510.26082": "|**2025-11-01**|**Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse**|Renkai Ma Team|[2510.26082](http://arxiv.org/abs/2510.26082)|null|\n", "2511.02832": "|**2025-11-04**|**TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System**|C. Karen Liu Team|[2511.02832](http://arxiv.org/abs/2511.02832)|**[link](https://yanjieze.com/TWIST2)**|\n", "2511.00840": "|**2025-11-27**|**Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches**|Roman Gorbachev Team|[2511.00840](http://arxiv.org/abs/2511.00840)|null|\n", "2511.00153": "|**2025-10-31**|**EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations**|Philipp Wu Team|[2511.00153](http://arxiv.org/abs/2511.00153)|null|\n", "2512.14689": "|**2025-12-16**|**CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation**|Yuke Zhu Team|[2512.14689](http://arxiv.org/abs/2512.14689)|**[link](https://nvlabs.github.io/CHIP/)**|\n", "2512.13304": "|**2025-12-15**|**Humanoid Robot Running Through Random Stepping Stones and Jumping Over Obstacles: Step Adaptation Using Spring-Mass Trajectories**|Christian Ott Team|[2512.13304](http://arxiv.org/abs/2512.13304)|**[link](https://youtu.be/HlAg2nbNct4)**|\n", "2512.13093": "|**2025-12-15**|**PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations**|Wenjun Zeng Team|[2512.13093](http://arxiv.org/abs/2512.13093)|null|\n", "2512.12437": "|**2025-12-13**|**Sim2Real Reinforcement Learning for Soccer skills**|Jonathan Spraggett Team|[2512.12437](http://arxiv.org/abs/2512.12437)|null|\n", "2512.12230": "|**2025-12-13**|**Learning to Get Up Across Morphologies: Zero-Shot Recovery with a Unified Humanoid Policy**|Jonathan Spraggett Team|[2512.12230](http://arxiv.org/abs/2512.12230)|null|\n", "2512.12208": "|**2025-12-13**|**A Hybrid Deep Learning Framework for Emotion Recognition in Children with Autism During NAO Robot-Mediated Interaction**|Bishakh Bhattacharya Team|[2512.12208](http://arxiv.org/abs/2512.12208)|null|\n", "2512.11047": "|**2025-12-15**|**WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control**|Hongyang Li Team|[2512.11047](http://arxiv.org/abs/2512.11047)|null|\n", "2512.10477": "|**2025-12-14**|**Symphony: A Heuristic Normalized Calibrated Advantage Actor and Critic Algorithm in application for Humanoid Robots**|J\u00f3zsef Dombi Team|[2512.10477](http://arxiv.org/abs/2512.10477)|**[link](https://github.com/SuspensionRailway/symphony)**|\n", "2512.09431": "|**2025-12-10**|**A Hierarchical, Model-Based System for High-Performance Humanoid Soccer**|Dennis W. Hong Team|[2512.09431](http://arxiv.org/abs/2512.09431)|null|\n", "2512.08518": "|**2025-12-10**|**SensHRPS: Sensing Comfortable Human-Robot Proxemics and Personal Space With Eye-Tracking**|Karsten Berns Team|[2512.08518](http://arxiv.org/abs/2512.08518)|null|\n", "2512.07819": "|**2025-12-08**|**Efficient and Compliant Control Framework for Versatile Human-Humanoid Collaborative Transportation**|Panagiotis Artemiadis Team|[2512.07819](http://arxiv.org/abs/2512.07819)|null|\n", "2512.07464": "|**2025-12-08**|**Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction**|Houqiang Li Team|[2512.07464](http://arxiv.org/abs/2512.07464)|null|\n", "2512.07041": "|**2025-12-07**|**CERNet: Class-Embedding Predictive-Coding RNN for Unified Robot Motion, Recognition, and Confidence Estimation**|Mathias Quoy Team|[2512.07041](http://arxiv.org/abs/2512.07041)|null|\n", "2512.06571": "|**2025-12-10**|**Learning Agile Striker Skills for Humanoid Soccer Robots from Noisy Sensory Input**|Peter Stone Team|[2512.06571](http://arxiv.org/abs/2512.06571)|null|\n", "2512.05094": "|**2025-12-11**|**From Generated Human Videos to Physically Plausible Robot Trajectories**|Roei Herzig Team|[2512.05094](http://arxiv.org/abs/2512.05094)|**[link](https://genmimic.github.io)**|\n", "2512.04973": "|**2025-12-04**|**Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist**|Giorgio Grioli Team|[2512.04973](http://arxiv.org/abs/2512.04973)|**[link](https://doi.org/10.1007/978-3-031-64057-5_9)**|\n", "2512.04537": "|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Mike Zheng Shou Team|[2512.04537](http://arxiv.org/abs/2512.04537)|null|\n", "2512.01336": "|**2025-12-01**|**Discovering Self-Protective Falling Policy for Humanoid Robot via Deep Reinforcement Learning**|Donglin Wang Team|[2512.01336](http://arxiv.org/abs/2512.01336)|null|\n", "2512.01022": "|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Wei-Shi Zheng Team|[2512.01022](http://arxiv.org/abs/2512.01022)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|\n", "2512.00971": "|**2025-11-30**|**H-Zero: Cross-Humanoid Locomotion Pretraining Enables Few-shot Novel Embodiment Transfer**|Weinan Zhang Team|[2512.00971](http://arxiv.org/abs/2512.00971)|null|\n", "2512.16793": "|**2025-12-18**|**PhysBrain: Human Egocentric Data as a Bridge from Vision Language Models to Physical Intelligence**|Kai Chen Team|[2512.16793](http://arxiv.org/abs/2512.16793)|null|\n", "2512.12842": "|**2025-12-14**|**SAGA: Open-World Mobile Manipulation via Structured Affordance Grounding**|Jiuguang Wang Team|[2512.12842](http://arxiv.org/abs/2512.12842)|null|\n", "2512.07765": "|**2025-12-08**|**Toward Seamless Physical Human-Humanoid Interaction: Insights from Control, Intent, and Modeling with a Vision for What Comes Next**|Panagiotis Artemiadis Team|[2512.07765](http://arxiv.org/abs/2512.07765)|null|\n", "2512.01061": "|**2025-11-30**|**Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer**|Yuke Zhu Team|[2512.01061](http://arxiv.org/abs/2512.01061)|**[link](https://doorman-humanoid.github.io/)**|\n", "2512.00783": "|**2025-12-02**|**Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment**|Libo Wang Team|[2512.00783](http://arxiv.org/abs/2512.00783)|**[link](https://huggingface.co/Veltraxor/Sigma)**|\n", "2511.23300": "|**2025-11-28**|**SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot**|Dzmitry Tsetserukou Team|[2511.23300](http://arxiv.org/abs/2511.23300)|null|\n", "2511.22963": "|**2025-11-28**|**Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary**|Jingya Wang Team|[2511.22963](http://arxiv.org/abs/2511.22963)|**[link](https://humanoidlla.github.io/)**|\n", "2512.08952": "|**2025-11-28**|**Learning When to Ask: Simulation-Trained Humanoids for Mental-Health Diagnosis**|Longbing Cao Team|[2512.08952](http://arxiv.org/abs/2512.08952)|null|\n", "2511.21169": "|**2025-11-26**|**Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation**|Qijun Chen Team|[2511.21169](http://arxiv.org/abs/2511.21169)|null|\n", "2511.20275": "|**2025-12-04**|**HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments**|Bin He Team|[2511.20275](http://arxiv.org/abs/2511.20275)|null|\n", "2512.00077": "|**2025-11-25**|**A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs**|Bowen Zhi Team|[2512.00077](http://arxiv.org/abs/2512.00077)|null|\n", "2511.19236": "|**2025-11-24**|**SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control**|Zongqing Lu Team|[2511.19236](http://arxiv.org/abs/2511.19236)|null|\n", "2511.18857": "|**2025-11-24**|**AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion**|Mingguo Zhao Team|[2511.18857](http://arxiv.org/abs/2511.18857)|null|\n", "2511.18509": "|**2025-11-23**|**SafeFall: Learning Protective Control for Humanoid Robots**|Siyuan Huang Team|[2511.18509](http://arxiv.org/abs/2511.18509)|null|\n", "2511.17925": "|**2025-12-08**|**Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game**|Tianyu Li Team|[2511.17925](http://arxiv.org/abs/2511.17925)|null|\n", "2511.17373": "|**2025-11-24**|**Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data**|Hongyang Li Team|[2511.17373](http://arxiv.org/abs/2511.17373)|null|\n", "2511.16306": "|**2025-11-20**|**InEKFormer: A Hybrid State Estimator for Humanoid Robots**|Frank Kirchner Team|[2511.16306](http://arxiv.org/abs/2511.16306)|null|\n", "2511.15200": "|**2025-11-27**|**VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation**|Yuke Zhu Team|[2511.15200](http://arxiv.org/abs/2511.15200)|**[link](https://viral-humanoid.github.io/)**|\n", "2511.14756": "|**2025-11-18**|**HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation**|Xiaolong Wang Team|[2511.14756](http://arxiv.org/abs/2511.14756)|null|\n", "2511.12390": "|**2025-11-15**|**Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control**|Sanjar Atamuradov Team|[2511.12390](http://arxiv.org/abs/2511.12390)|null|\n", "2511.11218": "|**2025-12-09**|**Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning**|Xiaoyu Ren Team|[2511.11218](http://arxiv.org/abs/2511.11218)|**[link](https://humanoid-badminton.github.io/Humanoid-Whole-Body-Badminton-via-Multi-Stage-Reinforcement-Learning)**|\n", "2511.10021": "|**2025-11-13**|**DecARt Leg: Design and Evaluation of a Novel Humanoid Robot Leg with Decoupled Actuation for Agile Locomotion**|Roman Gorbachev Team|[2511.10021](http://arxiv.org/abs/2511.10021)|null|\n", "2511.09241": "|**2025-12-07**|**Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots**|Siheng Chen Team|[2511.09241](http://arxiv.org/abs/2511.09241)|null|\n", "2511.09141": "|**2025-11-12**|**RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation**|Miao Li Team|[2511.09141](http://arxiv.org/abs/2511.09141)|null|\n", "2511.07820": "|**2025-12-04**|**SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control**|Yuke Zhu Team|[2511.07820](http://arxiv.org/abs/2511.07820)|**[link](https://nvlabs.github.io/SONIC/)**|\n", "2511.07407": "|**2025-11-10**|**Unified Humanoid Fall-Safety Policy from a Few Demonstrations**|Stella X. Yu Team|[2511.07407](http://arxiv.org/abs/2511.07407)|null|\n", "2511.06796": "|**2025-11-10**|**Human-Level Actuation for Humanoids**|MD-Nazmus Sunbeam Team|[2511.06796](http://arxiv.org/abs/2511.06796)|null|\n", "2511.06397": "|**2025-11-09**|**Whole-Body Control With Terrain Estimation of A 6-DoF Wheeled Bipedal Robot**|Ximin Lyu Team|[2511.06397](http://arxiv.org/abs/2511.06397)|null|\n", "2511.06371": "|**2025-11-11**|**Towards Adaptive Humanoid Control via Multi-Behavior Distillation and Reinforced Fine-Tuning**|Chenjia Bai Team|[2511.06371](http://arxiv.org/abs/2511.06371)|null|\n", "2511.06036": "|**2025-11-08**|**Towards Human-AI-Robot Collaboration and AI-Agent based Digital Twins for Parkinson's Disease Management: Review and Outlook**|Tareq Y. Al-Naffouri Team|[2511.06036](http://arxiv.org/abs/2511.06036)|null|\n", "2511.04831": "|**2025-11-06**|**Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning**|Gavriel State Team|[2511.04831](http://arxiv.org/abs/2511.04831)|**[link](https://github.com/isaac-sim/IsaacLab)**|\n", "2511.04758": "|**2025-11-06**|**ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling**|Fabio Ramos Team|[2511.04758](http://arxiv.org/abs/2511.04758)|**[link](https://schedulestream.github.io)**|\n", "2511.04679": "|**2025-11-06**|**GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction**|C. Karen Liu Team|[2511.04679](http://arxiv.org/abs/2511.04679)|**[link](https://gentle-humanoid.axell.top)**|\n", "2511.04131": "|**2025-11-06**|**BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning**|Guanya Shi Team|[2511.04131](http://arxiv.org/abs/2511.04131)|null|\n", "2511.03996": "|**2025-11-06**|**Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots**|Mingguo Zhao Team|[2511.03996](http://arxiv.org/abs/2511.03996)|**[link](https://humanoid-kick.github.io)**|\n", "2511.03571": "|**2025-11-05**|**OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera**|Kaiwei Wang Team|[2511.03571](http://arxiv.org/abs/2511.03571)|**[link](https://github.com/MasterHow/OneOcc)**|\n", "2510.21773": "|**2025-12-12**|**Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots**|Van Nam Dinh Team|[2510.21773](http://arxiv.org/abs/2510.21773)|null|\n", "2510.12332": "|**2025-10-14**|**Shape-Aware Whole-Body Control for Continuum Robots with Application in Endoluminal Surgical Robotics**|Mohsen Khadem Team|[2510.12332](http://arxiv.org/abs/2510.12332)|null|\n", "2510.09980": "|**2025-10-11**|**ATRos: Learning Energy-Efficient Agile Locomotion for Wheeled-legged Robots**|Mingyu Zhang Team|[2510.09980](http://arxiv.org/abs/2510.09980)|null|\n", "2510.09221": "|**2025-10-10**|**HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation**|Qingyi Si Team|[2510.09221](http://arxiv.org/abs/2510.09221)|null|\n", "2510.01708": "|**2025-10-14**|**PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via Multi-Simulator Dynamics Randomization**|Siheng Chen Team|[2510.01708](http://arxiv.org/abs/2510.01708)|null|\n", "2509.22815": "|**2025-09-26**|**Teleoperator-Aware and Safety-Critical Adaptive Nonlinear MPC for Shared Autonomy in Obstacle Avoidance of Legged Robots**|Kaveh Akbari Hamed Team|[2509.22815](http://arxiv.org/abs/2509.22815)|null|\n", "2509.13595": "|**2025-09-16**|**Leg-Arm Coordinated Operation for Curtain Wall Installation**|Wei Feng Team|[2509.13595](http://arxiv.org/abs/2509.13595)|null|\n", "2509.11839": "|**2025-09-17**|**TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning**|Donglin Wang Team|[2509.11839](http://arxiv.org/abs/2509.11839)|null|\n", "2509.04094": "|**2025-09-04**|**Object-Reconstruction-Aware Whole-body Control of Mobile Manipulators**|Wei Pan Team|[2509.04094](http://arxiv.org/abs/2509.04094)|null|\n", "2508.20959": "|**2025-08-28**|**Scaling Fabric-Based Piezoresistive Sensor Arrays for Whole-Body Tactile Sensing**|Marc D. Killpack Team|[2508.20959](http://arxiv.org/abs/2508.20959)|null|\n", "2508.13444": "|**2025-08-19**|**Switch4EAI: Leveraging Console Game Platform for Benchmarking Robotic Athletics**|Sehoon Ha Team|[2508.13444](http://arxiv.org/abs/2508.13444)|null|\n", "2508.14120": "|**2025-08-18**|**SimGenHOI: Physically Realistic Whole-Body Humanoid-Object Interaction via Generative Modeling and Reinforcement Learning**|Xingxing Zuo Team|[2508.14120](http://arxiv.org/abs/2508.14120)|null|\n", "2508.10538": "|**2025-11-12**|**MLM: Learning Multi-task Loco-Manipulation Whole-Body Control for Quadruped Robot with Arm**|Xuelong Li Team|[2508.10538](http://arxiv.org/abs/2508.10538)|null|\n", "2508.08241": "|**2025-11-13**|**BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion**|C. Karen Liu Team|[2508.08241](http://arxiv.org/abs/2508.08241)|**[link](https://beyondmimic.github.io/)**|\n", "2508.08240": "|**2025-08-11**|**ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks**|Chunhua Shen Team|[2508.08240](http://arxiv.org/abs/2508.08240)|null|\n", "2508.08328": "|**2025-08-10**|**Whole-Body Coordination for Dynamic Object Grasping with Legged Manipulators**|Runhao Zeng Team|[2508.08328](http://arxiv.org/abs/2508.08328)|null|\n", "2508.03068": "|**2025-08-07**|**Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching**|C. Karen Liu Team|[2508.03068](http://arxiv.org/abs/2508.03068)|null|\n", "2507.22042": "|**2025-07-29**|**A Nonlinear MPC Framework for Loco-Manipulation of Quadrupedal Robots with Non-Negligible Manipulator Dynamics**|Kaveh Akbari Hamed Team|[2507.22042](http://arxiv.org/abs/2507.22042)|null|\n", "2507.13662": "|**2025-07-18**|**Iteratively Learning Muscle Memory for Legged Robots to Master Adaptive and High Precision Locomotion**|Amit K. Sanyal Team|[2507.13662](http://arxiv.org/abs/2507.13662)|null|\n", "2508.08258": "|**2025-07-17**|**Humanoid Robot Acrobatics Utilizing Complete Articulated Rigid Body Dynamics**|Gerald Brantner Team|[2508.08258](http://arxiv.org/abs/2508.08258)|null|\n", "2507.08656": "|**2025-08-28**|**Multi-critic Learning for Whole-body End-effector Twist Tracking**|Marco Hutter Team|[2507.08656](http://arxiv.org/abs/2507.08656)|null|\n", "2507.04791": "|**2025-07-07**|**Safe Bimanual Teleoperation with Language-Guided Collision Avoidance**|Serena Ivaldi Team|[2507.04791](http://arxiv.org/abs/2507.04791)|null|\n", "2507.01961": "|**2025-07-05**|**AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation**|Shanghang Zhang Team|[2507.01961](http://arxiv.org/abs/2507.01961)|**[link](https://ac-dit.github.io/)**|\n"}, "Dexterous": {"2503.23120": "|**2025-03-29**|**Dexterous Non-Prehensile Manipulation for Ungraspable Object via Extrinsic Dexterity**|Yuanpei Chen Team|[2503.23120](http://arxiv.org/abs/2503.23120)|null|\n", "2503.21860": "|**2025-03-27**|**ManipTrans: Efficient Dexterous Bimanual Manipulation Transfer via Residual Learning**|Siyuan Huang Team|[2503.21860](http://arxiv.org/abs/2503.21860)|null|\n", "2503.19457": "|**2025-07-20**|**G-DexGrasp: Generalizable Dexterous Grasping Synthesis Via Part-Aware Prior Retrieval and Prior-Assisted Generation**|Ruizhen Hu Team|[2503.19457](http://arxiv.org/abs/2503.19457)|null|\n", "2503.12533": "|**2025-05-11**|**Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills**|Zongqing Lu Team|[2503.12533](http://arxiv.org/abs/2503.12533)|null|\n", "2503.10966": "|**2025-06-06**|**Is Your Imitation Learning Policy Better than Mine? Policy Comparison with Near-Optimal Stopping**|Haruki Nishimura Team|[2503.10966](http://arxiv.org/abs/2503.10966)|null|\n", "2503.09078": "|**2025-08-02**|**Sequential Multi-Object Grasping with One Dexterous Hand**|Daniel Seita Team|[2503.09078](http://arxiv.org/abs/2503.09078)|**[link](https://hesic73.github.io/SeqMultiGrasp/)**|\n", "2503.08257": "|**2025-03-16**|**DexGrasp Anything: Towards Universal Robotic Dexterous Grasping with Physics Awareness**|Yuexin Ma Team|[2503.08257](http://arxiv.org/abs/2503.08257)|null|\n", "2503.06669": "|**2025-03-13**|**AgiBot World Colosseo: A Large-scale Manipulation Platform for Scalable and Intelligent Embodied Systems**|Jianchao Zhu Team|[2503.06669](http://arxiv.org/abs/2503.06669)|**[link](https://github.com/opendrivelab/agibot-world)**|\n", "2503.05995": "|**2025-03-08**|**ReJSHand: Efficient Real-Time Hand Pose Estimation and Mesh Reconstruction Using Refined Joint and Skeleton Features**|Hong Zhang Team|[2503.05995](http://arxiv.org/abs/2503.05995)|**[link](https://github.com/daishipeng/rejshand)**|\n", "2503.05231": "|**2025-03-07**|**Kaiwu: A Multimodal Manipulation Dataset and Framework for Robot Learning and Human-Robot Interaction**|Bin He Team|[2503.05231](http://arxiv.org/abs/2503.05231)|null|\n", "2503.04014": "|**2025-03-06**|**Dexterous Hand Manipulation via Efficient Imitation-Bootstrapped Online Reinforcement Learning**|Xiaodong He Team|[2503.04014](http://arxiv.org/abs/2503.04014)|null|\n", "2503.03890": "|**2025-03-05**|**LensDFF: Language-enhanced Sparse Feature Distillation for Efficient Few-Shot Dexterous Manipulation**|Alois Knoll Team|[2503.03890](http://arxiv.org/abs/2503.03890)|null|\n", "2503.03102": "|**2025-03-05**|**Selective Tweezing and Immobilization of Colloids for Dexterous Manipulation of Biological Materials**|Kimani C. Toussaint Jr Team|[2503.03102](http://arxiv.org/abs/2503.03102)|null|\n", "2503.01789": "|**2025-03-03**|**TacCap: A Wearable FBG-Based Tactile Sensor for Seamless Human-to-Robot Skill Transfer**|Mark R. Cutkosky Team|[2503.01789](http://arxiv.org/abs/2503.01789)|null|\n", "2503.01616": "|**2025-03-03**|**RoboDexVLM: Visual Language Model-Enabled Task Planning and Motion Control for Dexterous Robot Manipulation**|Jun Ma Team|[2503.01616](http://arxiv.org/abs/2503.01616)|null|\n", "2503.01543": "|**2025-03-03**|**Exo-ViHa: A Cross-Platform Exoskeleton System with Visual and Haptic Feedback for Efficient Dexterous Skill Learning**|Wenbo Ding Team|[2503.01543](http://arxiv.org/abs/2503.01543)|null|\n", "2503.01078": "|**2025-03-03**|**KineSoft: Learning Proprioceptive Manipulation Policies with Soft Robot Hands**|Jeffrey Ichnowski Team|[2503.01078](http://arxiv.org/abs/2503.01078)|null|\n", "2502.20396": "|**2025-02-27**|**Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids**|Yuke Zhu Team|[2502.20396](http://arxiv.org/abs/2502.20396)|null|\n", "2502.19250": "|**2025-02-28**|**ObjectVLA: End-to-End Open-World Object Manipulation Without Demonstration**|Feifei Feng Team|[2502.19250](http://arxiv.org/abs/2502.19250)|null|\n", "2502.18423": "|**2025-02-26**|**Retrieval Dexterity: Efficient Object Retrieval in Clutters with Dexterous Hand**|Yuanpei Chen Team|[2502.18423](http://arxiv.org/abs/2502.18423)|null|\n", "2504.03515": "|**2025-12-17**|**Dexterous Manipulation through Imitation Learning: A Survey**|Hong Zhang Team|[2504.03515](http://arxiv.org/abs/2504.03515)|null|\n", "2504.04573": "|**2025-04-06**|**DexTOG: Learning Task-Oriented Dexterous Grasp with Language**|Cewu Lu Team|[2504.04573](http://arxiv.org/abs/2504.04573)|null|\n", "2504.04516": "|**2025-10-25**|**DexSinGrasp: Learning a Unified Policy for Dexterous Object Singulation and Grasping in Densely Cluttered Environments**|Lin Shao Team|[2504.04516](http://arxiv.org/abs/2504.04516)|null|\n", "2504.04259": "|**2025-09-17**|**ORCA: An Open-Source, Reliable, Cost-Effective, Anthropomorphic Robotic Hand for Uninterrupted Dexterous Task Learning**|Robert K. Katzschmann Team|[2504.04259](http://arxiv.org/abs/2504.04259)|null|\n", "2504.06156": "|**2025-09-01**|**ViTaMIn: Learning Contact-Rich Tasks Through Robot-Free Visuo-Tactile Manipulation Interface**|Rui Chen Team|[2504.06156](http://arxiv.org/abs/2504.06156)|null|\n", "2504.07143": "|**2025-04-08**|**Functionally graded keratin facilitates tactile sensing in elephant whiskers**|Katherine J. Kuchenbecker Team|[2504.07143](http://arxiv.org/abs/2504.07143)|null|\n", "2504.10280": "|**2025-04-14**|**Look-to-Touch: A Vision-Enhanced Proximity and Tactile Sensor for Distance and Geometry Perception in Robotic Manipulation**|Guoying Gu Team|[2504.10280](http://arxiv.org/abs/2504.10280)|null|\n", "2504.13165": "|**2025-04-17**|**RUKA: Rethinking the Design of Humanoid Hands with Learning**|Lerrel Pinto Team|[2504.13165](http://arxiv.org/abs/2504.13165)|**[link](https://ruka-hand.github.io/)**|\n", "2504.13056": "|**2025-08-22**|**Adaptive Task Space Non-Singular Terminal Super-Twisting Sliding Mode Control of a 7-DOF Robotic Manipulator**|E. Witrant Team|[2504.13056](http://arxiv.org/abs/2504.13056)|null|\n", "2504.12967": "|**2025-04-17**|**Krysalis Hand: A Lightweight, High-Payload, 18-DoF Anthropomorphic End-Effector for Robotic Learning and Dexterous Manipulation**|Iman Soltani Team|[2504.12967](http://arxiv.org/abs/2504.12967)|null|\n", "2504.12609": "|**2025-08-16**|**Crossing the Human-Robot Embodiment Gap with Sim-to-Real RL using One Human Demonstration**|Jeannette Bohg Team|[2504.12609](http://arxiv.org/abs/2504.12609)|null|\n", "2504.13618": "|**2025-10-27**|**On the Importance of Tactile Sensing for Imitation Learning: A Case Study on Robotic Match Lighting**|Jan Peters Team|[2504.13618](http://arxiv.org/abs/2504.13618)|null|\n", "2504.14857": "|**2025-04-21**|**SuFIA-BC: Generating High Quality Demonstration Data for Visuomotor Policy Learning in Surgical Subtasks**|Animesh Garg Team|[2504.14857](http://arxiv.org/abs/2504.14857)|null|\n", "2504.14712": "|**2025-10-06**|**BiDexHand: Design and Evaluation of an Open-Source 16-DoF Biomimetic Dexterous Hand**|Zhengyang Kris Weng Team|[2504.14712](http://arxiv.org/abs/2504.14712)|null|\n", "2504.16054": "|**2025-04-22**|**$\u03c0_{0.5}$: a Vision-Language-Action Model with Open-World Generalization**|Ury Zhilinsky Team|[2504.16054](http://arxiv.org/abs/2504.16054)|null|\n", "2504.15472": "|**2025-04-21**|**LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning**|Boyuan Chen Team|[2504.15472](http://arxiv.org/abs/2504.15472)|null|\n", "2504.16649": "|**2025-06-18**|**PP-Tac: Paper Picking Using Tactile Feedback in Dexterous Robotic Hands**|Ziyuan Jiao Team|[2504.16649](http://arxiv.org/abs/2504.16649)|**[link](https://peilin-666.github.io/projects/PP-Tac/)**|\n", "2504.19341": "|**2025-04-27**|**PolyTouch: A Robust Multi-Modal Tactile Sensor for Contact-rich Manipulation Using Tactile-Diffusion Policies**|Edward Adelson Team|[2504.19341](http://arxiv.org/abs/2504.19341)|null|\n", "2504.21585": "|**2025-04-30**|**Multi-Goal Dexterous Hand Manipulation using Probabilistic Model-based Reinforcement Learning**|Yunduan Cui Team|[2504.21585](http://arxiv.org/abs/2504.21585)|null|\n", "2505.01083": "|**2025-05-02**|**DexFlow: A Unified Approach for Dexterous Hand Pose Retargeting and Interaction**|Miao Li Team|[2505.01083](http://arxiv.org/abs/2505.01083)|null|\n", "2505.00991": "|**2025-05-02**|**DexCtrl: Towards Sim-to-Real Dexterity with Adaptive Controller Learning**|Masayoshi Tomizuka Team|[2505.00991](http://arxiv.org/abs/2505.00991)|null|\n", "2505.02232": "|**2025-05-04**|**Prompt-responsive Object Retrieval with Memory-augmented Student-Teacher Learning**|Sven Behnke Team|[2505.02232](http://arxiv.org/abs/2505.02232)|null|\n", "2505.01974": "|**2025-05-04**|**KineDex: Learning Tactile-Informed Visuomotor Policies via Kinesthetic Teaching for Dexterous Manipulation**|Yang Gao Team|[2505.01974](http://arxiv.org/abs/2505.01974)|null|\n", "2505.05287": "|**2025-09-01**|**Morphologically Symmetric Reinforcement Learning for Ambidextrous Bimanual Manipulation**|Georgia Chalvatzaki Team|[2505.05287](http://arxiv.org/abs/2505.05287)|null|\n", "2505.07813": "|**2025-05-12**|**DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies**|Deepak Pathak Team|[2505.07813](http://arxiv.org/abs/2505.07813)|**[link](https://dexwild.github.io)**|\n", "2505.08213": "|**2025-05-13**|**HandCept: A Visual-Inertial Fusion Framework for Accurate Proprioception in Dexterous Hands**|Yunhui Liu Team|[2505.08213](http://arxiv.org/abs/2505.08213)|null|\n", "2505.10251": "|**2025-07-08**|**SRT-H: A Hierarchical Framework for Autonomous Surgery via Language Conditioned Imitation Learning**|Axel Krieger Team|[2505.10251](http://arxiv.org/abs/2505.10251)|null|\n", "2505.11420": "|**2025-05-16**|**Self-supervised perception for tactile skin covered dexterous hands**|Mustafa Mukadam Team|[2505.11420](http://arxiv.org/abs/2505.11420)|null|\n", "2505.11366": "|**2025-05-16**|**Learning Multimodal AI Algorithms for Amplifying Limited User Input into High-dimensional Control Space**|Reza Abiri Team|[2505.11366](http://arxiv.org/abs/2505.11366)|null|\n", "2505.10884": "|**2025-05-16**|**Estimating Deformable-Rigid Contact Interactions for a Deformable Tool via Learning and Model-Based Optimization**|Nima Fazeli Team|[2505.10884](http://arxiv.org/abs/2505.10884)|null|\n", "2505.13350": "|**2025-05-19**|**Approximating Global Contact-Implicit MPC via Sampling and Local Complementarity**|Michael Posa Team|[2505.13350](http://arxiv.org/abs/2505.13350)|**[link](https://approximating-global-ci-mpc.github.io)**|\n", "2505.12748": "|**2025-09-15**|**TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation**|Jiangmiao Pang Team|[2505.12748](http://arxiv.org/abs/2505.12748)|**[link](https://gorgeous2002.github.io/TeleOpBench/)**|\n", "2505.12294": "|**2025-05-18**|**PartDexTOG: Generating Dexterous Task-Oriented Grasping via Language-driven Part Analysis**|Zhipong Cai Team|[2505.12294](http://arxiv.org/abs/2505.12294)|null|\n", "2505.11917": "|**2025-05-17**|**OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning**|Yang Gao Team|[2505.11917](http://arxiv.org/abs/2505.11917)|null|\n", "2505.11709": "|**2025-08-20**|**EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video**|Jian Zhang Team|[2505.11709](http://arxiv.org/abs/2505.11709)|null|\n", "2505.13982": "|**2025-07-21**|**Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation**|Hao Dong Team|[2505.13982](http://arxiv.org/abs/2505.13982)|null|\n", "2505.15098": "|**2025-05-21**|**Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation**|Xiaodong He Team|[2505.15098](http://arxiv.org/abs/2505.15098)|null|\n", "2505.16289": "|**2025-08-28**|**TacCompress: A Benchmark for Multi-Point Tactile Data Compression in Dexterous Hand**|Li Song Team|[2505.16289](http://arxiv.org/abs/2505.16289)|null|\n", "2505.19086": "|**2025-05-25**|**MaskedManipulator: Versatile Whole-Body Control for Loco-Manipulation**|Xue Bin Peng Team|[2505.19086](http://arxiv.org/abs/2505.19086)|null|\n", "2505.18899": "|**2025-05-24**|**Beyond Domain Randomization: Event-Inspired Perception for Visually Robust Adversarial Imitation from Videos**|Mario Bijelic Team|[2505.18899](http://arxiv.org/abs/2505.18899)|null|\n", "2505.18876": "|**2025-05-24**|**DiffusionRL: Efficient Training of Diffusion Policies for Robotic Grasping Using RL-Adapted Large-Scale Datasets**|Dzmitry Tsetserukou Team|[2505.18876](http://arxiv.org/abs/2505.18876)|null|\n", "2505.18763": "|**2025-05-27**|**GenPO: Generative Diffusion Models Meet On-Policy Reinforcement Learning**|Ye Shi Team|[2505.18763](http://arxiv.org/abs/2505.18763)|null|\n", "2505.20795": "|**2025-05-27**|**Learning Generalizable Robot Policy with Human Demonstration Video as a Prompt**|Jianyu Chen Team|[2505.20795](http://arxiv.org/abs/2505.20795)|null|\n", "2505.22159": "|**2025-09-18**|**ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation**|Wenqiang Zhang Team|[2505.22159](http://arxiv.org/abs/2505.22159)|null|\n", "2505.21864": "|**2025-10-02**|**DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation**|Shuran Song Team|[2505.21864](http://arxiv.org/abs/2505.21864)|null|\n", "2505.24853": "|**2025-05-30**|**DexMachina: Functional Retargeting for Bimanual Dexterous Manipulation**|Shuran Song Team|[2505.24853](http://arxiv.org/abs/2505.24853)|null|\n", "2506.02577": "|**2025-06-03**|**Reachability Weighted Offline Goal-conditioned Resampling**|Joni Pajarinen Team|[2506.02577](http://arxiv.org/abs/2506.02577)|null|\n", "2506.00098": "|**2025-08-11**|**Interactive Imitation Learning for Dexterous Robotic Manipulation: Challenges and Perspectives -- A Survey**|Rania Rayyes Team|[2506.00098](http://arxiv.org/abs/2506.00098)|null|\n", "2506.04982": "|**2025-12-05**|**GEX: Democratizing Dexterity with Fully-Actuated Dexterous Hand and Exoskeleton Glove**|Zelin Deng Team|[2506.04982](http://arxiv.org/abs/2506.04982)|null|\n", "2506.04941": "|**2025-06-06**|**ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning**|Jian Tang Team|[2506.04941](http://arxiv.org/abs/2506.04941)|null|\n", "2506.07490": "|**2025-06-09**|**RAPID Hand: A Robust, Affordable, Perception-Integrated, Dexterous Manipulation Platform for Generalist Robot Autonomy**|Hui Cheng Team|[2506.07490](http://arxiv.org/abs/2506.07490)|null|\n", "2506.08291": "|**2025-06-09**|**TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation**|Monroe Kennedy Team|[2506.08291](http://arxiv.org/abs/2506.08291)|null|\n", "2506.09523": "|**2025-06-30**|**Adaptive event-triggered robust tracking control of soft robots**|Marios M. Polycarpou Team|[2506.09523](http://arxiv.org/abs/2506.09523)|null|\n", "2506.09384": "|**2025-06-11**|**Analyzing Key Objectives in Human-to-Robot Retargeting for Dexterous Manipulation**|Xiang Li Team|[2506.09384](http://arxiv.org/abs/2506.09384)|null|\n", "2506.11775": "|**2025-09-24**|**ExoStart: Efficient learning for dexterous manipulation with sensorized exoskeleton demonstrations**|Maria Bauza Team|[2506.11775](http://arxiv.org/abs/2506.11775)|null|\n", "2506.13725": "|**2025-06-16**|**CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding**|Haoang Li Team|[2506.13725](http://arxiv.org/abs/2506.13725)|null|\n", "2506.12239": "|**2025-06-13**|**ViTaSCOPE: Visuo-tactile Implicit Representation for In-hand Pose and Extrinsic Contact Estimation**|Nima Fazeli Team|[2506.12239](http://arxiv.org/abs/2506.12239)|**[link](https://jayjunlee.github.io/vitascope/)**|\n", "2506.14754": "|**2025-06-17**|**Tactile Beyond Pixels: Multisensory Touch Representations for Robot Manipulation**|Mustafa Mukadam Team|[2506.14754](http://arxiv.org/abs/2506.14754)|null|\n", "2506.17198": "|**2025-06-20**|**Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation**|Xiaolong Wang Team|[2506.17198](http://arxiv.org/abs/2506.17198)|**[link](https://jianglongye.com/dex1b)**|\n", "2506.15953": "|**2025-06-19**|**ViTacFormer: Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation**|Jitendra Malik Team|[2506.15953](http://arxiv.org/abs/2506.15953)|null|\n", "2506.17561": "|**2025-06-21**|**VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models**|Lin Shao Team|[2506.17561](http://arxiv.org/abs/2506.17561)|null|\n", "2506.19212": "|**2025-11-16**|**Scaffolding Dexterous Manipulation with Vision-Language Models**|Dorsa Sadigh Team|[2506.19212](http://arxiv.org/abs/2506.19212)|null|\n", "2506.19201": "|**2025-06-24**|**The MOTIF Hand: A Robotic Hand for Multimodal Observations with Thermal, Inertial, and Force Sensors**|Daniel Seita Team|[2506.19201](http://arxiv.org/abs/2506.19201)|null|\n", "2506.21417": "|**2025-06-26**|**Lightweight Fingernail Haptic Device: Unobstructed Fingerpad Force and Vibration Feedback for Enhanced Virtual Dexterous Manipulation**|Shoichi Hasegawa Team|[2506.21417](http://arxiv.org/abs/2506.21417)|null|\n", "2507.01857": "|**2025-07-02**|**TypeTele: Releasing Dexterity in Teleoperation by Dexterous Manipulation Types**|Wei-Shi Zheng Team|[2507.01857](http://arxiv.org/abs/2507.01857)|**[link](https://isee-laboratory.github.io/TypeTele)**|\n", "2507.00833": "|**2025-11-16**|**HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning**|Chenjia Bai Team|[2507.00833](http://arxiv.org/abs/2507.00833)|**[link](https://openhumanoidgen.github.io)**|\n", "2507.02747": "|**2025-07-03**|**DexVLG: Dexterous Vision-Language-Grasp Model at Scale**|He Wang Team|[2507.02747](http://arxiv.org/abs/2507.02747)|null|\n", "2507.04452": "|**2025-07-06**|**SimLauncher: Launching Sample-Efficient Real-world Robotic Reinforcement Learning via Simulation Pre-training**|Hao Dong Team|[2507.04452](http://arxiv.org/abs/2507.04452)|null|\n", "2507.05331": "|**2025-07-07**|**A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation**|Russ Tedrake Team|[2507.05331](http://arxiv.org/abs/2507.05331)|null|\n", "2507.06822": "|**2025-07-09**|**Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand**|Xinjun Sheng Team|[2507.06822](http://arxiv.org/abs/2507.06822)|null|\n", "2507.09985": "|**2025-07-14**|**Demonstrating the Octopi-1.5 Visual-Tactile-Language Model**|Harold Soh Team|[2507.09985](http://arxiv.org/abs/2507.09985)|null|\n", "2507.11840": "|**2025-11-18**|**The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey**|Jiming Chen Team|[2507.11840](http://arxiv.org/abs/2507.11840)|null|\n", "2507.13602": "|**2025-07-18**|**Improving Low-Cost Teleoperation: Augmenting GELLO with Force**|Kai Arulkumaran Team|[2507.13602](http://arxiv.org/abs/2507.13602)|null|\n", "2507.14538": "|**2025-07-19**|**A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0**|Erbao Dong Team|[2507.14538](http://arxiv.org/abs/2507.14538)|null|\n", "2508.00795": "|**2025-08-01**|**Video Generators are Robot Policies**|Carl Vondrick Team|[2508.00795](http://arxiv.org/abs/2508.00795)|null|\n", "2508.00097": "|**2025-11-05**|**XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation**|Ning Yang Team|[2508.00097](http://arxiv.org/abs/2508.00097)|**[link](http://xr-robotics.github.io/)**|\n", "2507.23682": "|**2025-09-25**|**villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models**|Jiang Bian Team|[2507.23682](http://arxiv.org/abs/2507.23682)|**[link](https://aka.ms/villa-x)**|\n", "2508.03339": "|**2025-12-01**|**UniFucGrasp: Human-Hand-Inspired Unified Functional Grasp Annotation Strategy and Dataset for Diverse Dexterous Hands**|Yaonan Wang Team|[2508.03339](http://arxiv.org/abs/2508.03339)|**[link](https://haochen611.github.io/UFG)**|\n", "2508.01695": "|**2025-08-03**|**DexReMoE:In-hand Reorientation of General Object via Mixtures of Experts**|Yunlong Dong Team|[2508.01695](http://arxiv.org/abs/2508.01695)|null|\n", "2508.07945": "|**2025-10-13**|**PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF**|Lorenzo Natale Team|[2508.07945](http://arxiv.org/abs/2508.07945)|null|\n", "2508.07118": "|**2025-12-05**|**DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit**|Monroe Kennedy Team|[2508.07118](http://arxiv.org/abs/2508.07118)|null|\n", "2508.08896": "|**2025-11-11**|**Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors**|Hua Zou Team|[2508.08896](http://arxiv.org/abs/2508.08896)|null|\n", "2508.08706": "|**2025-08-22**|**OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing**|Hengdi Zhang Team|[2508.08706](http://arxiv.org/abs/2508.08706)|**[link](https://readerek.github.io/Objtac.github.io)**|\n", "2508.12439": "|**2025-08-17**|**Geodesic Tracing-Based Kinematic Integration of Rolling and Sliding Contact on Manifold Meshes for Dexterous In-Hand Manipulation**|Nancy S. Pollard Team|[2508.12439](http://arxiv.org/abs/2508.12439)|null|\n", "2508.14441": "|**2025-08-20**|**FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy**|Cewu Lu Team|[2508.14441](http://arxiv.org/abs/2508.14441)|null|\n", "2508.15669": "|**2025-08-21**|**Exploiting Policy Idling for Dexterous Manipulation**|Dushyant Rao Team|[2508.15669](http://arxiv.org/abs/2508.15669)|null|\n", "2508.15002": "|**2025-08-20**|**GraspQP: Differentiable Optimization of Force Closure for Diverse and Robust Dexterous Grasping**|Marco Hutter Team|[2508.15002](http://arxiv.org/abs/2508.15002)|null|\n", "2508.17547": "|**2025-08-24**|**LodeStar: Long-horizon Dexterity via Synthetic Data Augmentation from Human Demonstrations**|Hao Su Team|[2508.17547](http://arxiv.org/abs/2508.17547)|null|\n", "2508.20085": "|**2025-08-31**|**HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation**|Huazhe Xu Team|[2508.20085](http://arxiv.org/abs/2508.20085)|null|\n", "2508.21112": "|**2025-10-15**|**EO-1: Interleaved Vision-Text-Action Pretraining for General Robot Control**|Dong Wang Team|[2508.21112](http://arxiv.org/abs/2508.21112)|null|\n", "2509.04441": "|**2025-09-08**|**DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation**|Pulkit Agrawal Team|[2509.04441](http://arxiv.org/abs/2509.04441)|**[link](https://dex-op.github.io)**|\n", "2509.05513": "|**2025-09-05**|**OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation**|Yu Xiang Team|[2509.05513](http://arxiv.org/abs/2509.05513)|null|\n", "2509.07445": "|**2025-09-09**|**Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions**|Nathan F. Lepora Team|[2509.07445](http://arxiv.org/abs/2509.07445)|null|\n", "2509.08354": "|**2025-09-10**|**Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration**|Huimin Lu Team|[2509.08354](http://arxiv.org/abs/2509.08354)|null|\n", "2509.09671": "|**2025-09-11**|**Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration**|Wei Yang Team|[2509.09671](http://arxiv.org/abs/2509.09671)|null|\n", "2509.13074": "|**2025-10-03**|**Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five**|Robert K. Katzschmann Team|[2509.13074](http://arxiv.org/abs/2509.13074)|null|\n", "2509.12714": "|**2025-09-16**|**Moir\u00e9Tac: A Dual-Mode Visuotactile Sensor for Multidimensional Perception Using Moir\u00e9 Pattern Amplification**|Wenbo Ding Team|[2509.12714](http://arxiv.org/abs/2509.12714)|null|\n", "2509.14010": "|**2025-09-17**|**Whole-body Motion Control of an Omnidirectional Wheel-Legged Mobile Manipulator via Contact-Aware Dynamic Optimization**|Yiqun Li Team|[2509.14010](http://arxiv.org/abs/2509.14010)|null|\n", "2509.14178": "|**2025-09-16**|**\\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video**|Rui Huang Team|[2509.14178](http://arxiv.org/abs/2509.14178)|null|\n", "2509.14939": "|**2025-09-18**|**A Novel Task-Driven Diffusion-Based Policy with Affordance Learning for Generalizable Manipulation of Articulated Objects**|Yongduan Song Team|[2509.14939](http://arxiv.org/abs/2509.14939)|null|\n", "2509.14530": "|**2025-09-18**|**Learning to Pick: A Visuomotor Policy for Clustered Strawberry Picking**|Chen Peng Team|[2509.14530](http://arxiv.org/abs/2509.14530)|null|\n", "2509.14349": "|**2025-09-17**|**LeVR: A Modular VR Teleoperation Framework for Imitation Learning in Dexterous Manipulation**|Han Liu Team|[2509.14349](http://arxiv.org/abs/2509.14349)|null|\n", "2509.17450": "|**2025-09-22**|**Learning Dexterous Manipulation with Quantized Hand State**|Cewu Lu Team|[2509.17450](http://arxiv.org/abs/2509.17450)|null|\n", "2509.19301": "|**2025-09-25**|**Residual Off-Policy RL for Finetuning Behavior Cloning Policies**|Anusha Nagabandi Team|[2509.19301](http://arxiv.org/abs/2509.19301)|**[link](https://residual-offpolicy-rl.github.io)**|\n", "2509.18937": "|**2025-09-23**|**Lang2Morph: Language-Driven Morphological Design of Robotic Hands**|Josie Hughes Team|[2509.18937](http://arxiv.org/abs/2509.18937)|null|\n", "2509.18455": "|**2025-10-05**|**Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands**|Daniel Seita Team|[2509.18455](http://arxiv.org/abs/2509.18455)|null|\n", "2509.22149": "|**2025-09-26**|**DemoGrasp: Universal Dexterous Grasping from a Single Demonstration**|Zongqing Lu Team|[2509.22149](http://arxiv.org/abs/2509.22149)|null|\n", "2509.23829": "|**2025-09-28**|**DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation**|Yuanpei Chen Team|[2509.23829](http://arxiv.org/abs/2509.23829)|null|\n", "2509.26236": "|**2025-09-30**|**ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm**|Katherine J. Kuchenbecker Team|[2509.26236](http://arxiv.org/abs/2509.26236)|null|\n", "2510.06068": "|**2025-10-07**|**Cross-Embodiment Dexterous Hand Articulation Generation via Morphology-Aware Learning**|Yan Wu Team|[2510.06068](http://arxiv.org/abs/2510.06068)|null|\n", "2510.05382": "|**2025-10-06**|**A multi-modal tactile fingertip design for robotic hands to enhance dexterous manipulation**|Zeynep Temel Team|[2510.05382](http://arxiv.org/abs/2510.05382)|null|\n", "2510.08556": "|**2025-10-09**|**DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model**|Li Yi Team|[2510.08556](http://arxiv.org/abs/2510.08556)|**[link](https://meowuu7.github.io/DexNDM/)**|\n", "2510.08475": "|**2025-10-09**|**DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos**|Tsung-Wei Ke Team|[2510.08475](http://arxiv.org/abs/2510.08475)|**[link](https://embodiedai-ntu.github.io/dexman/index.html)**|\n", "2510.07548": "|**2025-10-08**|**AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation**|Dmitry Berenson Team|[2510.07548](http://arxiv.org/abs/2510.07548)|null|\n", "2510.09229": "|**2025-10-10**|**Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System**|Pai Zheng Team|[2510.09229](http://arxiv.org/abs/2510.09229)|null|\n", "2510.09209": "|**2025-10-10**|**PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation**|Kazutoshi Tanaka Team|[2510.09209](http://arxiv.org/abs/2510.09209)|null|\n", "2510.12724": "|**2025-10-14**|**T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping**|Lin Shao Team|[2510.12724](http://arxiv.org/abs/2510.12724)|null|\n", "2510.12866": "|**2025-10-14**|**Learning to Grasp Anything by Playing with Random Toys**|Roei Herzig Team|[2510.12866](http://arxiv.org/abs/2510.12866)|null|\n", "2510.14771": "|**2025-10-16**|**Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation**|Shan An Team|[2510.14771](http://arxiv.org/abs/2510.14771)|null|\n", "2510.14768": "|**2025-10-16**|**Leveraging Neural Descriptor Fields for Learning Contact-Aware Dynamic Recovery**|Dmitry Berenson Team|[2510.14768](http://arxiv.org/abs/2510.14768)|null|\n", "2510.14647": "|**2025-10-16**|**Spatially anchored Tactile Awareness for Robust Dexterous Manipulation**|Kaifeng Zhang Team|[2510.14647](http://arxiv.org/abs/2510.14647)|null|\n", "2510.14467": "|**2025-10-16**|**Restoring Noisy Demonstration for Imitation Learning With Diffusion Models**|Shao-Hua Sun Team|[2510.14467](http://arxiv.org/abs/2510.14467)|null|\n", "2510.15786": "|**2025-10-23**|**DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation**|Yiwen Lu Team|[2510.15786](http://arxiv.org/abs/2510.15786)|null|\n", "2510.16931": "|**2025-10-21**|**RAPID Hand Prototype: Design of an Affordable, Fully-Actuated Biomimetic Hand for Dexterous Teleoperation**|Hui Cheng Team|[2510.16931](http://arxiv.org/abs/2510.16931)|null|\n", "2510.21571": "|**2025-10-24**|**Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos**|Baining Guo Team|[2510.21571](http://arxiv.org/abs/2510.21571)|**[link](https://microsoft.github.io/VITRA/)**|\n", "2510.20965": "|**2025-10-23**|**SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing**|Axel Krieger Team|[2510.20965](http://arxiv.org/abs/2510.20965)|null|\n", "2510.23119": "|**2025-10-27**|**OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback**|Wei-Shi Zheng Team|[2510.23119](http://arxiv.org/abs/2510.23119)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|\n", "2510.25725": "|**2025-11-13**|**A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation**|Kyung-Joong Kim Team|[2510.25725](http://arxiv.org/abs/2510.25725)|null|\n", "2510.27048": "|**2025-10-30**|**SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation**|Matei Ciocarlie Team|[2510.27048](http://arxiv.org/abs/2510.27048)|null|\n", "2511.02832": "|**2025-11-04**|**TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System**|C. Karen Liu Team|[2511.02832](http://arxiv.org/abs/2511.02832)|**[link](https://yanjieze.com/TWIST2)**|\n", "2511.01791": "|**2025-11-03**|**GenDexHand: Generative Simulation for Dexterous Hands**|Yi Ma Team|[2511.01791](http://arxiv.org/abs/2511.01791)|null|\n", "2511.01177": "|**2025-11-09**|**Scaling Cross-Embodiment World Models for Dexterous Manipulation**|Hao Su Team|[2511.01177](http://arxiv.org/abs/2511.01177)|null|\n", "2511.00139": "|**2025-12-13**|**End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection**|Zhibin Li Team|[2511.00139](http://arxiv.org/abs/2511.00139)|null|\n", "2512.15020": "|**2025-12-17**|**ISS Policy : Scalable Diffusion Policy with Implicit Scene Supervision**|Jie Mei Team|[2512.15020](http://arxiv.org/abs/2512.15020)|null|\n", "2512.13644": "|**2025-12-15**|**World Models Can Leverage Human Videos for Dexterous Manipulation**|Yann LeCun Team|[2512.13644](http://arxiv.org/abs/2512.13644)|null|\n", "2512.11047": "|**2025-12-15**|**WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control**|Hongyang Li Team|[2512.11047](http://arxiv.org/abs/2512.11047)|null|\n", "2512.10349": "|**2025-12-11**|**Design and Validation of an Under-actuated Robotic Finger with Synchronous Tendon Routing**|Weibang Bai Team|[2512.10349](http://arxiv.org/abs/2512.10349)|null|\n", "2512.06517": "|**2025-12-06**|**Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments**|Simon B\u00f8gh Team|[2512.06517](http://arxiv.org/abs/2512.06517)|null|\n", "2512.03743": "|**2025-12-03**|**Cross-embodied Co-design for Dexterous Hands**|Xiaolong Wang Team|[2512.03743](http://arxiv.org/abs/2512.03743)|null|\n", "2512.02951": "|**2025-12-02**|**Experimental Characterization of Fingertip Trajectory following for a 3-DoF Series-Parallel Hybrid Robotic Finger**|Nilanjan Chakraborty Team|[2512.02951](http://arxiv.org/abs/2512.02951)|null|\n", "2512.02729": "|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Haoqian Wang Team|[2512.02729](http://arxiv.org/abs/2512.02729)|null|\n", "2512.02011": "|**2025-12-01**|**Learning Dexterous Manipulation Skills from Imperfect Simulations**|Haozhi Qi Team|[2512.02011](http://arxiv.org/abs/2512.02011)|null|\n", "2512.01801": "|**2025-12-02**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yonghui Wu Team|[2512.01801](http://arxiv.org/abs/2512.01801)|null|\n", "2512.01022": "|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Wei-Shi Zheng Team|[2512.01022](http://arxiv.org/abs/2512.01022)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|\n", "2512.00324": "|**2025-11-29**|**MILE: A Mechanically Isomorphic Exoskeleton Data Collection System with Fingertip Visuotactile Sensing for Dexterous Manipulation**|Xiangyang Zhu Team|[2512.00324](http://arxiv.org/abs/2512.00324)|null|\n", "2511.22100": "|**2025-11-27**|**Design of an Adaptive Modular Anthropomorphic Dexterous Hand for Human-like Manipulation**|Yaonan Wang Team|[2511.22100](http://arxiv.org/abs/2511.22100)|null|\n", "2511.21169": "|**2025-11-26**|**Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation**|Qijun Chen Team|[2511.21169](http://arxiv.org/abs/2511.21169)|null|\n", "2511.20887": "|**2025-11-25**|**ACE-F: A Cross Embodiment Foldable System with Force Feedback for Dexterous Teleoperation**|Xiaolong Wang Team|[2511.20887](http://arxiv.org/abs/2511.20887)|null|\n", "2511.17366": "|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Shanghang Zhang Team|[2511.17366](http://arxiv.org/abs/2511.17366)|null|\n", "2511.15200": "|**2025-11-27**|**VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation**|Yuke Zhu Team|[2511.15200](http://arxiv.org/abs/2511.15200)|**[link](https://viral-humanoid.github.io/)**|\n", "2511.14416": "|**2025-11-18**|**Toward Robust and Harmonious Adaptation for Cross-modal Retrieval**|Xi Peng Team|[2511.14416](http://arxiv.org/abs/2511.14416)|null|\n", "2511.13710": "|**2025-11-17**|**From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands**|Xiaolong Wang Team|[2511.13710](http://arxiv.org/abs/2511.13710)|**[link](https://jianglongye.com/power-to-precision)**|\n", "2511.10987": "|**2025-11-14**|**Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment**|Yi Sun Team|[2511.10987](http://arxiv.org/abs/2511.10987)|null|\n", "2512.04399": "|**2025-12-04**|**Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation**|Hesheng Wang Team|[2512.04399](http://arxiv.org/abs/2512.04399)|null|\n", "2511.12912": "|**2025-11-17**|**DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping**|Dongbin Zhao Team|[2511.12912](http://arxiv.org/abs/2511.12912)|null|\n", "2511.10087": "|**2025-11-13**|**Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning**|Xiaocong Li Team|[2511.10087](http://arxiv.org/abs/2511.10087)|null|\n", "2511.09484": "|**2025-11-12**|**SPIDER: Scalable Physics-Informed Dexterous Retargeting**|Francois Hogan Team|[2511.09484](http://arxiv.org/abs/2511.09484)|**[link](https://jc-bao.github.io/spider-project/)**|\n", "2511.08865": "|**2025-11-12**|**MirrorLimb: Implementing hand pose acquisition and robot teleoperation based on RealMirror**|Tao Shen Team|[2511.08865](http://arxiv.org/abs/2511.08865)|null|\n", "2511.07418": "|**2025-11-10**|**Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields**|Pieter Abbeel Team|[2511.07418](http://arxiv.org/abs/2511.07418)|**[link](https://github.com/zhaohengyin/lightning-grasp)**|\n", "2511.04831": "|**2025-11-06**|**Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning**|Gavriel State Team|[2511.04831](http://arxiv.org/abs/2511.04831)|**[link](https://github.com/isaac-sim/IsaacLab)**|\n", "2511.03481": "|**2025-11-09**|**Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control**|Sheng Yi Team|[2511.03481](http://arxiv.org/abs/2511.03481)|null|\n", "2510.26362": "|**2025-10-30**|**Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations**|Sylvain Calinon Team|[2510.26362](http://arxiv.org/abs/2510.26362)|null|\n", "2510.25268": "|**2025-10-29**|**SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation**|Dan Guo Team|[2510.25268](http://arxiv.org/abs/2510.25268)|null|\n", "2510.20774": "|**2025-10-28**|**FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation**|Yao Mu Team|[2510.20774](http://arxiv.org/abs/2510.20774)|**[link](https://fieldgen.github.io/)**|\n", "2510.08884": "|**2025-12-11**|**Model-Based Lookahead Reinforcement Learning for in-hand manipulation**|Plinio Moreno Team|[2510.08884](http://arxiv.org/abs/2510.08884)|null|\n", "2510.07030": "|**2025-10-08**|**Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation**|Dmitry Berenson Team|[2510.07030](http://arxiv.org/abs/2510.07030)|null|\n", "2509.23075": "|**2025-10-06**|**In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer**|Michael Yip Team|[2509.23075](http://arxiv.org/abs/2509.23075)|null|\n", "2509.20646": "|**2025-09-25**|**Suction Leap-Hand: Suction Cups on a Multi-fingered Hand Enable Embodied Dexterity and In-Hand Teleoperation**|Robert B. Fisher Team|[2509.20646](http://arxiv.org/abs/2509.20646)|null|\n", "2509.17812": "|**2025-11-18**|**Tac2Motion: Contact-Aware Reinforcement Learning with Tactile Feedback for Robotic Hand Manipulation**|Christoffer Sloth Team|[2509.17812](http://arxiv.org/abs/2509.17812)|null|\n", "2509.17053": "|**2025-09-21**|**FILIC: Dual-Loop Force-Guided Imitation Learning with Impedance Torque Control for Contact-Rich Manipulation Tasks**|Guyue Zhou Team|[2509.17053](http://arxiv.org/abs/2509.17053)|null|\n", "2509.14984": "|**2025-09-18**|**The Role of Touch: Towards Optimal Tactile Sensing Distribution in Anthropomorphic Hands for Dexterous In-Hand Manipulation**|Jos\u00e9 Santos-Victor Team|[2509.14984](http://arxiv.org/abs/2509.14984)|null|\n", "2509.08522": "|**2025-09-16**|**RoboMatch: A Unified Mobile-Manipulation Teleoperation Platform with Auto-Matching Network Architecture for Long-Horizon Tasks**|Zhigong Song Team|[2509.08522](http://arxiv.org/abs/2509.08522)|null|\n", "2509.07916": "|**2025-09-09**|**Programmable Locking Cells (PLC) for Modular Robots with High Stiffness Tunability and Morphological Adaptability**|Masayoshi Tomizuka Team|[2509.07916](http://arxiv.org/abs/2509.07916)|null|\n", "2508.09836": "|**2025-08-13**|**Embodied Tactile Perception of Soft Objects Properties**|Etienne Burdet Team|[2508.09836](http://arxiv.org/abs/2508.09836)|null|\n", "2507.13654": "|**2025-10-29**|**Control Modes of Teleoperated Surgical Robotic System's Tools in Ophthalmic Surgery**|Jacob Rosen Team|[2507.13654](http://arxiv.org/abs/2507.13654)|null|\n", "2507.04425": "|**2025-07-06**|**TeleSim: A Network-Aware Testbed and Benchmark Dataset for Telerobotic Applications**|Longhao Zou Team|[2507.04425](http://arxiv.org/abs/2507.04425)|null|\n", "2507.03227": "|**2025-07-04**|**Dexterous Teleoperation of 20-DoF ByteDexter Hand via Human Motion Retargeting**|Zeyu Ren Team|[2507.03227](http://arxiv.org/abs/2507.03227)|**[link](https://byte-dexter.github.io/)**|\n", "2507.01008": "|**2025-09-25**|**DexWrist: A Robotic Wrist for Constrained and Dynamic Manipulation**|Pulkit Agrawal Team|[2507.01008](http://arxiv.org/abs/2507.01008)|null|\n", "2506.12676": "|**2025-06-15**|**Goal-based Self-Adaptive Generative Adversarial Imitation Learning (Goal-SAGAIL) for Multi-goal Robotic Manipulation Tasks**|George Vogiatzis Team|[2506.12676](http://arxiv.org/abs/2506.12676)|null|\n", "2505.22882": "|**2025-05-28**|**TwinTrack: Bridging Vision and Contact Physics for Real-Time Tracking of Unknown Dynamic Objects**|Wanxin Jin Team|[2505.22882](http://arxiv.org/abs/2505.22882)|null|\n", "2505.17738": "|**2025-05-23**|**Object Classification Utilizing Neuromorphic Proprioceptive Signals in Active Exploration: Validated on a Soft Anthropomorphic Hand**|Gordon Cheng Team|[2505.17738](http://arxiv.org/abs/2505.17738)|null|\n", "2505.17389": "|**2025-05-23**|**Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space**|Hui Cheng Team|[2505.17389](http://arxiv.org/abs/2505.17389)|null|\n", "2505.13253": "|**2025-05-19**|**Composing Dextrous Grasping and In-hand Manipulation via Scoring with a Reinforcement Learning Critic**|Berthold B\u00e4uml Team|[2505.13253](http://arxiv.org/abs/2505.13253)|null|\n", "2505.09099": "|**2025-05-14**|**Imitation Learning for Adaptive Control of a Virtual Soft Exoglove**|Letizia Gionfrida Team|[2505.09099](http://arxiv.org/abs/2505.09099)|null|\n", "2505.04978": "|**2025-05-08**|**Robust Model-Based In-Hand Manipulation with Integrated Real-Time Motion-Contact Planning and Tracking**|Xiang Li Team|[2505.04978](http://arxiv.org/abs/2505.04978)|null|\n", "2505.02915": "|**2025-05-05**|**Zero-shot Sim2Real Transfer for Magnet-Based Tactile Sensor on Insertion Tasks**|Jia Deng Team|[2505.02915](http://arxiv.org/abs/2505.02915)|null|\n", "2505.02291": "|**2025-11-03**|**Dexterous Contact-Rich Manipulation via the Contact Trust Region**|Russ Tedrake Team|[2505.02291](http://arxiv.org/abs/2505.02291)|null|\n", "2505.01059": "|**2025-08-02**|**Model Tensor Planning**|Jan Peters Team|[2505.01059](http://arxiv.org/abs/2505.01059)|null|\n", "2504.19502": "|**2025-08-05**|**Simultaneous Pick and Place Detection by Combining SE(3) Diffusion Models with Differential Kinematics**|Koichi Nishiwaki Team|[2504.19502](http://arxiv.org/abs/2504.19502)|null|\n", "2504.09532": "|**2025-10-06**|**Humanoid Agent via Embodied Chain-of-Action Reasoning with Multimodal Foundation Models for Zero-Shot Loco-Manipulation**|Yi Fang Team|[2504.09532](http://arxiv.org/abs/2504.09532)|**[link](https://humanoid-coa.github.io/)**|\n", "2504.08986": "|**2025-04-11**|**High-Throughput Transition-State Searches in Zeolite Nanopores**|Rafael G\u00f3mez-Bombarelli Team|[2504.08986](http://arxiv.org/abs/2504.08986)|null|\n", "2504.06084": "|**2025-12-08**|**MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From Egocentric Videos**|Marc Pollefeys Team|[2504.06084](http://arxiv.org/abs/2504.06084)|null|\n", "2503.19893": "|**2025-03-25**|**Visuo-Tactile Object Pose Estimation for a Multi-Finger Robot Hand with Low-Resolution In-Hand Tactile Sensing**|Joerg Stueckler Team|[2503.19893](http://arxiv.org/abs/2503.19893)|null|\n", "2503.19037": "|**2025-11-12**|**Evolutionary Policy Optimization**|Deepak Pathak Team|[2503.19037](http://arxiv.org/abs/2503.19037)|**[link](https://yifansu1301.github.io/EPO/)**|\n"}, "Long-Horizon": {"2512.16861": "|**2025-12-18**|**ReinforceGen: Hybrid Skill Policies with Automated Data Generation and Reinforcement Learning**|Caelan Garrett Team|[2512.16861](http://arxiv.org/abs/2512.16861)|null|\n", "2512.16791": "|**2025-12-18**|**KineST: A Kinematics-guided Spatiotemporal State Space Model for Human Motion Tracking from Sparse Signals**|Xinrong Chen Team|[2512.16791](http://arxiv.org/abs/2512.16791)|null|\n", "2512.16733": "|**2025-12-18**|**Discovering and Learning Probabilistic Models of Black-Box AI Capabilities**|Siddharth Srivastava Team|[2512.16733](http://arxiv.org/abs/2512.16733)|null|\n", "2512.16723": "|**2025-12-18**|**KOSS: Kalman-Optimal Selective State Spaces for Long-Term Sequence Modeling**|Ying Zhang Team|[2512.16723](http://arxiv.org/abs/2512.16723)|null|\n", "2512.16615": "|**2025-12-18**|**Trainable Log-linear Sparse Attention for Efficient Diffusion Transformers**|Xingang Pan Team|[2512.16615](http://arxiv.org/abs/2512.16615)|**[link](https://github.com/SingleZombie/LLSA)**|\n", "2512.16581": "|**2025-12-18**|**Abacus: Self-Supervised Event Counting-Aligned Distributional Pretraining for Sequential User Modeling**|Nadir El Manouzi Team|[2512.16581](http://arxiv.org/abs/2512.16581)|null|\n", "2512.16501": "|**2025-12-18**|**VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for Diverse Grounding Tasks**|Shuheng Shen Team|[2512.16501](http://arxiv.org/abs/2512.16501)|null|\n", "2512.16302": "|**2025-12-18**|**ManiLong-Shot: Interaction-Aware One-Shot Imitation Learning for Long-Horizon Manipulation**|Yang Gao Team|[2512.16302](http://arxiv.org/abs/2512.16302)|null|\n", "2512.16234": "|**2025-12-18**|**ARMFlow: AutoRegressive MeanFlow for Online 3D Human Reaction Generation**|Ajmal Mian Team|[2512.16234](http://arxiv.org/abs/2512.16234)|null|\n", "2512.15973": "|**2025-12-17**|**Dynamic Rank Reinforcement Learning for Adaptive Low-Rank Multi-Head Self Attention in Large Language Models**|Caner Erden Team|[2512.15973](http://arxiv.org/abs/2512.15973)|null|\n", "2512.15933": "|**2025-12-17**|**City Navigation in the Wild: Exploring Emergent Navigation from Web-Scale Knowledge in MLLMs**|Nebojsa Jojic Team|[2512.15933](http://arxiv.org/abs/2512.15933)|null|\n", "2512.15692": "|**2025-12-17**|**mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs**|Elvis Nava Team|[2512.15692](http://arxiv.org/abs/2512.15692)|null|\n", "2512.15653": "|**2025-12-17**|**Characterizing Mamba's Selective Memory using Auto-Encoders**|Alejandro Jaimes Team|[2512.15653](http://arxiv.org/abs/2512.15653)|null|\n", "2512.15503": "|**2025-12-17**|**Attention in Motion: Secure Platooning via Transformer-based Misbehavior Detection**|Panos Papadimitratos Team|[2512.15503](http://arxiv.org/abs/2512.15503)|null|\n", "2512.15362": "|**2025-12-17**|**Drift estimation for a partially observed mixed fractional Ornstein--Uhlenbeck process**|Chunhao Cai Team|[2512.15362](http://arxiv.org/abs/2512.15362)|null|\n", "2512.15340": "|**2025-12-17**|**Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics**|Xun Yang Team|[2512.15340](http://arxiv.org/abs/2512.15340)|null|\n", "2512.15302": "|**2025-12-17**|**Towards Proactive Personalization through Profile Customization for Individual Users in Dialogues**|Zuozhu Liu Team|[2512.15302](http://arxiv.org/abs/2512.15302)|null|\n", "2512.15810": "|**2025-12-17**|**Adaptive Kalman Filter for Systems with Unknown Initial Values**|Yury A Kutoyants Team|[2512.15810](http://arxiv.org/abs/2512.15810)|null|\n", "2512.15149": "|**2025-12-17**|**Offline Multi-Task Multi-Objective Data-Driven Evolutionary Algorithm with Language Surrogate Model and Implicit Q-Learning**|Jun Zhang Team|[2512.15149](http://arxiv.org/abs/2512.15149)|null|\n", "2512.15115": "|**2025-12-17**|**How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models**|Ali Ghodsi Team|[2512.15115](http://arxiv.org/abs/2512.15115)|null|\n", "2512.15036": "|**2025-12-17**|**Spectral Representation-based Reinforcement Learning**|Bo Dai Team|[2512.15036](http://arxiv.org/abs/2512.15036)|null|\n", "2512.14925": "|**2025-12-18**|**Multiscale Aggregated Hierarchical Attention (MAHA): A Game Theoretic and Optimization Driven Approach to Efficient Contextual Modeling in Large Language Models**|Caner Erden Team|[2512.14925](http://arxiv.org/abs/2512.14925)|null|\n", "2512.14876": "|**2025-12-16**|**Isolated Sign Language Recognition with Segmentation and Pose Estimation**|Galen Flanagan Team|[2512.14876](http://arxiv.org/abs/2512.14876)|null|\n", "2512.14617": "|**2025-12-16**|**Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes**|Fabio Patrizi Team|[2512.14617](http://arxiv.org/abs/2512.14617)|null|\n", "2512.14309": "|**2025-12-16**|**PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition**|Mohammad Awrangjeb Team|[2512.14309](http://arxiv.org/abs/2512.14309)|null|\n", "2512.14233": "|**2025-12-16**|**PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design**|Xiaofei Xie Team|[2512.14233](http://arxiv.org/abs/2512.14233)|null|\n", "2512.14151": "|**2025-12-16**|**Adaptive Cache Pollution Control for Large Language Model Inference Workloads Using Temporal CNN-Based Prediction and Priority-Aware Replacement**|Shaowen Wang Team|[2512.14151](http://arxiv.org/abs/2512.14151)|null|\n", "2512.14099": "|**2025-12-16**|**ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models**|Xuelong Li Team|[2512.14099](http://arxiv.org/abs/2512.14099)|null|\n", "2512.14057": "|**2025-12-17**|**Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning**|Homayoun Najjaran Team|[2512.14057](http://arxiv.org/abs/2512.14057)|null|\n", "2512.14023": "|**2025-12-16**|**Multivariate Time Series Forecasting with Hybrid Euclidean-SPD Manifold Graph Neural Networks**|Er-Ping Li Team|[2512.14023](http://arxiv.org/abs/2512.14023)|null|\n", "2512.13961": "|**2025-12-15**|**Olmo 3**|Hannaneh Hajishirzi Team|[2512.13961](http://arxiv.org/abs/2512.13961)|null|\n", "2512.13921": "|**2025-12-15**|**Sliding Window Recurrences for Sequence Models**|Stefano Massaroli Team|[2512.13921](http://arxiv.org/abs/2512.13921)|null|\n", "2512.13890": "|**2025-12-15**|**Group-Theoretic Reinforcement Learning of Dynamical Decoupling Sequences**|Murray J. Holland Team|[2512.13890](http://arxiv.org/abs/2512.13890)|null|\n", "2512.13841": "|**2025-12-15**|**Parameter Estimation for Partially Observed Stable Continuous-State Branching Processes**|Arno Siri-J\u00e9gousse Team|[2512.13841](http://arxiv.org/abs/2512.13841)|null|\n", "2512.13618": "|**2025-12-16**|**Temporal Tokenization Strategies for Event Sequence Modeling with Large Language Models**|Shi-Xiong Zhang Team|[2512.13618](http://arxiv.org/abs/2512.13618)|null|\n", "2512.13552": "|**2025-12-15**|**PrahokBART: A Pre-trained Sequence-to-Sequence Model for Khmer Natural Language Generation**|Masao Utiyama Team|[2512.13552](http://arxiv.org/abs/2512.13552)|null|\n", "2512.13415": "|**2025-12-15**|**USTM: Unified Spatial and Temporal Modeling for Continuous Sign Language Recognition**|Hamzah Luqman Team|[2512.13415](http://arxiv.org/abs/2512.13415)|null|\n", "2512.13368": "|**2025-12-15**|**BlossomRec: Block-level Fused Sparse Attention Mechanism for Sequential Recommendations**|Xiangyu Zhao Team|[2512.13368](http://arxiv.org/abs/2512.13368)|null|\n", "2512.13319": "|**2025-12-15**|**Temporal parallelisation of continuous-time maximum-a-posteriori trajectory estimation**|Simo S\u00e4rkk\u00e4 Team|[2512.13319](http://arxiv.org/abs/2512.13319)|null|\n", "2512.13283": "|**2025-12-15**|**Determining social mechanisms for sequential decision-making in a virtual pedestrian route choice experiment**|Nikolai W. F. Bode Team|[2512.13283](http://arxiv.org/abs/2512.13283)|null|\n", "2512.13758": "|**2025-12-15**|**Network-Wide Traffic Volume Estimation from Speed Profiles using a Spatio-Temporal Graph Neural Network with Directed Spatial Attention**|Laurent Najman Team|[2512.13758](http://arxiv.org/abs/2512.13758)|null|\n", "2512.13093": "|**2025-12-15**|**PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations**|Wenjun Zeng Team|[2512.13093](http://arxiv.org/abs/2512.13093)|null|\n", "2512.13037": "|**2025-12-15**|**Progressive Refinement of E-commerce Search Ranking Based on Short-Term Activities of the Buyer**|Jinming Feng Team|[2512.13037](http://arxiv.org/abs/2512.13037)|null|\n", "2512.13033": "|**2025-12-15**|**Scaling Bidirectional Spans and Span Violations in Attention Mechanism**|Sukjin Yoon Team|[2512.13033](http://arxiv.org/abs/2512.13033)|null|\n", "2512.13019": "|**2025-12-15**|**SneakPeek: Future-Guided Instructional Streaming Video Generation**|Albert Pumarola Team|[2512.13019](http://arxiv.org/abs/2512.13019)|null|\n", "2512.12967": "|**2025-12-15**|**QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management**|Ming Yan Team|[2512.12967](http://arxiv.org/abs/2512.12967)|null|\n", "2512.12929": "|**2025-12-15**|**MADTempo: An Interactive System for Multi-Event Temporal Video Retrieval with Query Augmentation**|Thanh-Huong Le Team|[2512.12929](http://arxiv.org/abs/2512.12929)|null|\n", "2512.12740": "|**2025-12-14**|**FuXi-$\u03b3$: Efficient Sequential Recommendation with Exponential-Power Temporal Encoder and Diagonal-Sparse Positional Mechanism**|Ye Lu Team|[2512.12740](http://arxiv.org/abs/2512.12740)|null|\n", "2512.12730": "|**2025-12-14**|**NL2Repo-Bench: Towards Long-Horizon Repository Generation Evaluation of Coding Agents**|Ge Zhang Team|[2512.12730](http://arxiv.org/abs/2512.12730)|null|\n", "2512.12710": "|**2025-12-14**|**Practical Hybrid Quantum Language Models with Observable Readout on Real Hardware**|Adrian Iftene Team|[2512.12710](http://arxiv.org/abs/2512.12710)|null|\n", "2512.12692": "|**2025-12-14**|**WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment**|Md Rizwan Parvez Team|[2512.12692](http://arxiv.org/abs/2512.12692)|**[link](https://kagnlp.github.io/WebOperator/)**|\n", "2512.12669": "|**2025-12-14**|**DynaGen: Unifying Temporal Knowledge Graph Reasoning with Dynamic Subgraphs and Generative Regularization**|Shimin Di Team|[2512.12669](http://arxiv.org/abs/2512.12669)|null|\n", "2512.15778": "|**2025-12-14**|**RAMBO: Reliability Analysis for Mamba through Bit-flip attack Optimization**|Kanad Basu Team|[2512.15778](http://arxiv.org/abs/2512.15778)|null|\n", "2512.12595": "|**2025-12-14**|**Vision-Enhanced Large Language Models for High-Resolution Image Synthesis and Multimodal Data Interpretation**|Karthikeya KV Team|[2512.12595](http://arxiv.org/abs/2512.12595)|null|\n", "2512.12526": "|**2025-12-14**|**Empirical Mode Decomposition and Graph Transformation of the MSCI World Index: A Multiscale Topological Analysis for Graph Neural Network Modeling**|Le\u00f3n Bele\u00f1a Team|[2512.12526](http://arxiv.org/abs/2512.12526)|null|\n", "2512.12506": "|**2025-12-14**|**Explainable Artificial Intelligence for Economic Time Series: A Comprehensive Review and a Systematic Taxonomy of Methods and Concepts**|Julio E. Sandubete Team|[2512.12506](http://arxiv.org/abs/2512.12506)|null|\n", "2512.12301": "|**2025-12-13**|**TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting**|Aditya Maheshwari Team|[2512.12301](http://arxiv.org/abs/2512.12301)|null|\n", "2512.12273": "|**2025-12-13**|**GRC-Net: Gram Residual Co-attention Net for epilepsy prediction**|Jiping Cui Team|[2512.12273](http://arxiv.org/abs/2512.12273)|null|\n", "2512.12154": "|**2025-12-13**|**Keep the Lights On, Keep the Lengths in Check: Plug-In Adversarial Detection for Time-Series LLMs in Energy Forecasting**|Ling Liu Team|[2512.12154](http://arxiv.org/abs/2512.12154)|null|\n", "2512.11503": "|**2025-12-12**|**TSkel-Mamba: Temporal Dynamic Modeling via State Space Model for Human Skeleton-based Action Recognition**|Qiuhong Ke Team|[2512.11503](http://arxiv.org/abs/2512.11503)|null|\n", "2512.11406": "|**2025-12-12**|**Network Estimation for Stationary Time Series**|Matthew A. Nunes Team|[2512.11406](http://arxiv.org/abs/2512.11406)|null|\n", "2512.11393": "|**2025-12-12**|**The N-Body Problem: Parallel Execution from Single-Person Egocentric Video**|Dima Damen Team|[2512.11393](http://arxiv.org/abs/2512.11393)|**[link](https://zhifanzhu.github.io/ego-nbody)**|\n", "2512.11350": "|**2025-12-12**|**Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture**|Long T. Truong Team|[2512.11350](http://arxiv.org/abs/2512.11350)|null|\n", "2512.11348": "|**2025-12-16**|**PhraseVAE and PhraseLDM: Latent Diffusion for Full-Song Multitrack Symbolic Music Generation**|Ye Wang Team|[2512.11348](http://arxiv.org/abs/2512.11348)|null|\n", "2512.11327": "|**2025-12-12**|**Physics-Informed Video Flare Synthesis and Removal Leveraging Motion Independence between Flare and Scene**|Hua Huang Team|[2512.11327](http://arxiv.org/abs/2512.11327)|null|\n", "2512.11930": "|**2025-12-12**|**Evolutionary Reinforcement Learning based AI tutor for Socratic Interdisciplinary Instruction**|Aimin Zhou Team|[2512.11930](http://arxiv.org/abs/2512.11930)|null|\n", "2512.11239": "|**2025-12-12**|**Cross-modal Prompting for Balanced Incomplete Multi-modal Emotion Recognition**|Zheng Zhang Team|[2512.11239](http://arxiv.org/abs/2512.11239)|null|\n", "2512.15756": "|**2025-12-12**|**ReactorFold: Generative discovery of nuclear reactor cores via emergent physical reasoning**|Yoonpyo Lee Team|[2512.15756](http://arxiv.org/abs/2512.15756)|null|\n", "2512.11225": "|**2025-12-12**|**VFMF: World Modeling by Forecasting Vision Foundation Model Features**|Andrea Vedaldi Team|[2512.11225](http://arxiv.org/abs/2512.11225)|null|\n", "2512.11179": "|**2025-12-11**|**Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning**|Junyu Xuan Team|[2512.11179](http://arxiv.org/abs/2512.11179)|null|\n", "2512.11169": "|**2025-12-11**|**CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound**|Sebastien Gros Team|[2512.11169](http://arxiv.org/abs/2512.11169)|null|\n", "2512.11082": "|**2025-12-11**|**Memoryless Policy Iteration for Episodic POMDPs**|Duarte Antunes Team|[2512.11082](http://arxiv.org/abs/2512.11082)|null|\n", "2512.10938": "|**2025-12-11**|**Stronger Normalization-Free Transformers**|Zhuang Liu Team|[2512.10938](http://arxiv.org/abs/2512.10938)|null|\n", "2512.10937": "|**2025-12-11**|**On Decision-Making Agents and Higher-Order Causal Processes**|Matt Wilson Team|[2512.10937](http://arxiv.org/abs/2512.10937)|null|\n", "2512.10934": "|**2025-12-11**|**Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit**|Julien Seinturier Team|[2512.10934](http://arxiv.org/abs/2512.10934)|null|\n", "2512.10877": "|**2025-12-11**|**Guided Transfer Learning for Discrete Diffusion Models**|Mauricio Tec Team|[2512.10877](http://arxiv.org/abs/2512.10877)|null|\n", "2512.11012": "|**2025-12-11**|**On a class of constrained Bayesian filters and their numerical implementation in high-dimensional state-space Markov models**|Joaquin Miguez Team|[2512.11012](http://arxiv.org/abs/2512.11012)|null|\n", "2512.10492": "|**2025-12-11**|**UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning**|Xueqian Wang Team|[2512.10492](http://arxiv.org/abs/2512.10492)|null|\n", "2512.10398": "|**2025-12-17**|**Confucius Code Agent: Scalable Agent Scaffolding for Real-World Codebases**|Ying Zhang Team|[2512.10398](http://arxiv.org/abs/2512.10398)|null|\n", "2512.10371": "|**2025-12-11**|**AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management**|Yuanchun Li Team|[2512.10371](http://arxiv.org/abs/2512.10371)|null|\n", "2512.10313": "|**2025-12-12**|**EpiPlanAgent: Agentic Automated Epidemic Response Planning**|Jie Xu Team|[2512.10313](http://arxiv.org/abs/2512.10313)|null|\n", "2512.10069": "|**2025-12-10**|**Incorporating Partial Adherence for Estimation of Dynamic Treatment Regimes**|Erica E. M. Moodie Team|[2512.10069](http://arxiv.org/abs/2512.10069)|null|\n", "2512.10051": "|**2025-12-10**|**DB2-TransF: All You Need Is Learnable Daubechies Wavelets for Time Series Forecasting**|Achyut Mani Tripathi Team|[2512.10051](http://arxiv.org/abs/2512.10051)|null|\n", "2512.10032": "|**2025-12-10**|**Cluster-Dags as Powerful Background Knowledge For Causal Discovery**|Niki Kilbertus Team|[2512.10032](http://arxiv.org/abs/2512.10032)|null|\n", "2512.09928": "|**2025-12-10**|**HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models**|Donglin Wang Team|[2512.09928](http://arxiv.org/abs/2512.09928)|**[link](https://hifvla.github.io)**|\n", "2512.09872": "|**2025-12-10**|**FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning**|Khaza Anuarul Hoque Team|[2512.09872](http://arxiv.org/abs/2512.09872)|null|\n", "2512.09850": "|**2025-12-10**|**Conformal Bandits: Bringing statistical validity and reward efficiency to the small-gap regime**|Nina Deliu Team|[2512.09850](http://arxiv.org/abs/2512.09850)|null|\n", "2512.09829": "|**2025-12-10**|**RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning**|Khaza Anuarul Hoque Team|[2512.09829](http://arxiv.org/abs/2512.09829)|null|\n", "2512.09788": "|**2025-12-10**|**Optimal strategy against straightforward bidding in clock auctions**|St\u00e9phane Gaubert Team|[2512.09788](http://arxiv.org/abs/2512.09788)|null|\n", "2512.09565": "|**2025-12-10**|**From Graphs to Gates: DNS-HyXNet, A Lightweight and Deployable Sequential Model for Real-Time DNS Tunnel Detection**|Muzammil Behzad Team|[2512.09565](http://arxiv.org/abs/2512.09565)|null|\n", "2512.09495": "|**2025-12-10**|**On Mobile Ad Hoc Networks for Coverage of Partially Observable Worlds**|Gregory Dudek Team|[2512.09495](http://arxiv.org/abs/2512.09495)|null|\n", "2512.09329": "|**2025-12-10**|**Self Distillation Fine-Tuning of Protein Language Models Improves Versatility in Protein Design**|Anima Anandkumar Team|[2512.09329](http://arxiv.org/abs/2512.09329)|null|\n", "2512.08829": "|**2025-12-09**|**InfiniteVL: Synergizing Linear and Sparse Attention for Highly-Efficient, Unlimited-Input Vision-Language Models**|Xinggang Wang Team|[2512.08829](http://arxiv.org/abs/2512.08829)|null|\n", "2512.14726": "|**2025-12-09**|**Quantum Decision Transformers (QDT): Synergistic Entanglement and Interference for Offline Reinforcement Learning**|Abraham Itzhak Weinberg Team|[2512.14726](http://arxiv.org/abs/2512.14726)|null|\n", "2512.08591": "|**2025-12-09**|**Long-Sequence LSTM Modeling for NBA Game Outcome Prediction Using a Novel Multi-Season Dataset**|Nikolaos Polatidis Team|[2512.08591](http://arxiv.org/abs/2512.08591)|null|\n", "2512.08436": "|**2025-12-09**|**Beyond Wave Variables: A Data-Driven Ensemble Approach for Enhanced Teleoperation Transparency and Stability**|Mourad Oussalah Team|[2512.08436](http://arxiv.org/abs/2512.08436)|null|\n", "2512.08322": "|**2025-12-09**|**Collaborative Intelligence for UAV-Satellite Network Slicing: Towards a Joint QoS-Energy-Fairness MADRL Optimization**|Symeon Chatzinotas Team|[2512.08322](http://arxiv.org/abs/2512.08322)|null|\n", "2512.14718": "|**2025-12-18**|**SEED: Spectral Entropy-Guided Evaluation of SpatialTemporal Dependencies for Multivariate Time Series Forecasting**|Jianhong Lin Team|[2512.14718](http://arxiv.org/abs/2512.14718)|null|\n", "2512.08188": "|**2025-12-09**|**Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model**|Rui Chen Team|[2512.08188](http://arxiv.org/abs/2512.08188)|**[link](https://embodied-tree-of-thoughts.github.io)**|\n", "2512.08061": "|**2025-12-08**|**LUNA: Linear Universal Neural Attention with Generalization Guarantees**|Soheil Kolouri Team|[2512.08061](http://arxiv.org/abs/2512.08061)|null|\n", "2512.08052": "|**2025-12-11**|**An Introduction to Deep Reinforcement and Imitation Learning**|Pedro Santana Team|[2512.08052](http://arxiv.org/abs/2512.08052)|null|\n", "2512.08012": "|**2025-12-08**|**Benchmarking Offline Multi-Objective Reinforcement Learning in Critical Care**|Divya Sharma Team|[2512.08012](http://arxiv.org/abs/2512.08012)|null|\n", "2512.07723": "|**2025-12-10**|**Enabling Delayed-Full Charging Through Transformer-Based Real-Time-to-Departure Modeling for EV Battery Longevity**|Youngtae Noh Team|[2512.07723](http://arxiv.org/abs/2512.07723)|null|\n", "2512.07602": "|**2025-12-11**|**Algorithm-hardware co-design of neuromorphic networks with dual memory pathways**|Danyal Akarca Team|[2512.07602](http://arxiv.org/abs/2512.07602)|null|\n", "2512.07571": "|**2025-12-08**|**A Simple Method to Enhance Pre-trained Language Models with Speech Tokens for Classification**|Valentin Barriere Team|[2512.07571](http://arxiv.org/abs/2512.07571)|null|\n", "2512.07539": "|**2025-12-09**|**FRWKV:Frequency-Domain Linear Attention for Long-Term Time Series Forecasting**|Zehua Gan Team|[2512.07539](http://arxiv.org/abs/2512.07539)|null|\n", "2512.07385": "|**2025-12-08**|**How Far are Modern Trackers from UAV-Anti-UAV? A Million-Scale Benchmark and New Baseline**|Yanfeng Wang Team|[2512.07385](http://arxiv.org/abs/2512.07385)|**[link](https://github.com/983632847/Awesome-Multimodal-Object-Tracking)**|\n", "2512.07350": "|**2025-12-08**|**Communication-Efficient Serving for Video Diffusion Models with Latent Parallelism**|Yong Wang Team|[2512.07350](http://arxiv.org/abs/2512.07350)|null|\n", "2512.07216": "|**2025-12-08**|**MUSE: A Simple Yet Effective Multimodal Search-Based Framework for Lifelong User Interest Modeling**|Bo Zheng Team|[2512.07216](http://arxiv.org/abs/2512.07216)|null|\n", "2512.07094": "|**2025-12-09**|**VIGIL: A Reflective Runtime for Self-Healing Agents**|Christopher Cruz Team|[2512.07094](http://arxiv.org/abs/2512.07094)|null|\n", "2512.06990": "|**2025-12-07**|**Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients**|Paras Goel Team|[2512.06990](http://arxiv.org/abs/2512.06990)|null|\n", "2512.06932": "|**2025-12-07**|**Hidden Leaks in Time Series Forecasting: How Data Leakage Affects LSTM Evaluation Across Configurations and Validation Strategies**|Moataz Ahmed Team|[2512.06932](http://arxiv.org/abs/2512.06932)|null|\n", "2512.06929": "|**2025-12-07**|**Adaptive Normalization Mamba with Multi Scale Trend Decomposition and Patch MoE Encoding**|MinCheol Jeon Team|[2512.06929](http://arxiv.org/abs/2512.06929)|null|\n", "2512.06926": "|**2025-12-07**|**Evaluating the Sensitivity of BiLSTM Forecasting Models to Sequence Length and Input Noise**|Moataz Ahmed Team|[2512.06926](http://arxiv.org/abs/2512.06926)|null|\n", "2512.06912": "|**2025-12-09**|**Khalasi: Energy-Efficient Navigation for Surface Vehicles in Vortical Flow Fields**|Sandeep Manjanna Team|[2512.06912](http://arxiv.org/abs/2512.06912)|null|\n", "2512.06725": "|**2025-12-07**|**Decoding Motor Behavior Using Deep Learning and Reservoir Computing**|Tian Lan Team|[2512.06725](http://arxiv.org/abs/2512.06725)|null|\n", "2512.06688": "|**2025-12-07**|**PersonaMem-v2: Towards Personalized Intelligence via Learning Implicit User Personas and Agentic Memory**|Camillo Jose Taylor Team|[2512.06688](http://arxiv.org/abs/2512.06688)|**[link](https://huggingface.co/datasets/bowen-upenn/PersonaMem-v2)**|\n", "2512.06682": "|**2025-12-07**|**Partially Observable Markov Decision Process Framework for Operating Condition Optimization Using Real-Time Degradation Signals**|Feng Ju Team|[2512.06682](http://arxiv.org/abs/2512.06682)|null|\n", "2512.06657": "|**2025-12-07**|**TextMamba: Scene Text Detector with Mamba**|Da-Han Wang Team|[2512.06657](http://arxiv.org/abs/2512.06657)|null|\n", "2512.06592": "|**2025-12-06**|**On fine-tuning Boltz-2 for protein-protein affinity prediction**|Joshua Meyers Team|[2512.06592](http://arxiv.org/abs/2512.06592)|null|\n", "2512.06582": "|**2025-12-06**|**QL-LSTM: A Parameter-Efficient LSTM for Stable Long-Sequence Modeling**|Isaac Kofi Nti Team|[2512.06582](http://arxiv.org/abs/2512.06582)|null|\n", "2512.06471": "|**2025-12-06**|**Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control**|Ali Mesbah Team|[2512.06471](http://arxiv.org/abs/2512.06471)|null|\n", "2512.06274": "|**2025-12-06**|**Networked Restless Multi-Arm Bandits with Reinforcement Learning**|Kai Wang Team|[2512.06274](http://arxiv.org/abs/2512.06274)|null|\n", "2512.05893": "|**2025-12-05**|**NeuroMemFPP: A recurrent neural approach for memory-aware parameter estimation in fractional Poisson process**|Aditya Maheshwari Team|[2512.05893](http://arxiv.org/abs/2512.05893)|null|\n", "2512.05790": "|**2025-12-16**|**Learnability Window in Gated Recurrent Neural Networks**|Lorenzo Livi Team|[2512.05790](http://arxiv.org/abs/2512.05790)|null|\n", "2512.05680": "|**2025-12-05**|**Meta-Learning Multi-armed Bandits for Beam Tracking in 5G and 6G Networks**|Christopher Mutschler Team|[2512.05680](http://arxiv.org/abs/2512.05680)|null|\n", "2512.05667": "|**2025-12-05**|**On Dynamic Programming Theory for Leader-Follower Stochastic Games**|Fran\u00e7ois Schwarzentruber Team|[2512.05667](http://arxiv.org/abs/2512.05667)|null|\n", "2512.05650": "|**2025-12-05**|**Efficient sequential Bayesian inference for state-space epidemic models using ensemble data assimilation**|Jason Wyse Team|[2512.05650](http://arxiv.org/abs/2512.05650)|null|\n", "2512.05549": "|**2025-12-05**|**PAC One-Step Safety Certification for Black-Box Discrete-Time Stochastic Systems**|Bai Xue Team|[2512.05549](http://arxiv.org/abs/2512.05549)|null|\n", "2512.11862": "|**2025-12-05**|**Hierarchical Task Offloading and Trajectory Optimization in Low-Altitude Intelligent Networks Via Auction and Diffusion-based MARL**|Zhu Han Team|[2512.11862](http://arxiv.org/abs/2512.11862)|null|\n", "2512.05361": "|**2025-12-05**|**FieldSeer I: Physics-Guided World Models for Long-Horizon Electromagnetic Dynamics under Partial Observability**|Yang Bu Team|[2512.05361](http://arxiv.org/abs/2512.05361)|null|\n", "2512.05337": "|**2025-12-05**|**Symmetric Linear Dynamical Systems are Learnable from Few Observations**|Marc Vuffray Team|[2512.05337](http://arxiv.org/abs/2512.05337)|null|\n", "2512.05105": "|**2025-12-04**|**Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning**|Sennur Ulukus Team|[2512.05105](http://arxiv.org/abs/2512.05105)|null|\n", "2512.05079": "|**2025-12-04**|**Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints**|Michael Posa Team|[2512.05079](http://arxiv.org/abs/2512.05079)|**[link](https://contactgen3d.github.io/)**|\n", "2512.05073": "|**2025-12-04**|**David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?**|Chandan Karfa Team|[2512.05073](http://arxiv.org/abs/2512.05073)|null|\n", "2512.05058": "|**2025-12-04**|**Meta-Learning for Quantum Optimization via Quantum Sequence Model**|Samuel Yen-Chi Chen Team|[2512.05058](http://arxiv.org/abs/2512.05058)|null|\n", "2512.04952": "|**2025-12-08**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization**|Hang Zhao Team|[2512.04952](http://arxiv.org/abs/2512.04952)|null|\n", "2512.04939": "|**2025-12-04**|**LiteVGGT: Boosting Vanilla VGGT via Geometry-aware Cached Token Merging**|Xiao-Xiao Long Team|[2512.04939](http://arxiv.org/abs/2512.04939)|null|\n", "2512.04877": "|**2025-12-07**|**Balancing information and dissipation with partially observed fluctuating signals**|Daniel Maria Busiello Team|[2512.04877](http://arxiv.org/abs/2512.04877)|null|\n", "2512.04829": "|**2025-12-08**|**Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing**|Haitham Bou-Ammar Team|[2512.04829](http://arxiv.org/abs/2512.04829)|null|\n", "2512.09939": "|**2025-12-04**|**Norm-Governed Multi-Agent Decision-Making in Simulator-Coupled Environments:The Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP)**|Stella C. Dong Team|[2512.09939](http://arxiv.org/abs/2512.09939)|null|\n", "2512.04653": "|**2025-12-04**|**Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control**|Monireh Abdoos Team|[2512.04653](http://arxiv.org/abs/2512.04653)|null|\n", "2512.04554": "|**2025-12-04**|**Counterfeit Answers: Adversarial Forgery against OCR-Free Document Visual Question Answering**|Battista Biggio Team|[2512.04554](http://arxiv.org/abs/2512.04554)|null|\n", "2512.04487": "|**2025-12-04**|**Controllable Long-term Motion Generation with Extended Joint Targets**|Jihoon Kim Team|[2512.04487](http://arxiv.org/abs/2512.04487)|null|\n", "2512.04404": "|**2025-12-04**|**Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation**|Changju Wu Team|[2512.04404](http://arxiv.org/abs/2512.04404)|null|\n", "2512.04385": "|**2025-12-04**|**STeP-Diff: Spatio-Temporal Physics-Informed Diffusion Models for Mobile Fine-Grained Pollution Forecasting**|Xinlei Chen Team|[2512.04385](http://arxiv.org/abs/2512.04385)|null|\n", "2512.04307": "|**2025-12-03**|**Evaluating Long-Context Reasoning in LLM-Based WebAgents**|Joyce Chai Team|[2512.04307](http://arxiv.org/abs/2512.04307)|null|\n", "2512.04282": "|**2025-12-03**|**Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer**|Srinjoy Das Team|[2512.04282](http://arxiv.org/abs/2512.04282)|null|\n", "2512.04219": "|**2025-12-03**|**Generalized Event Partonomy Inference with Structured Hierarchical Predictive Learning**|Sathyanarayanan N. Aakur\\\\ Team|[2512.04219](http://arxiv.org/abs/2512.04219)|null|\n", "2512.04217": "|**2025-12-03**|**High-Resolution Retrieval of Atmospheric Boundary Layers with Nonstationary Gaussian Processes**|Christopher J. Geoga Team|[2512.04217](http://arxiv.org/abs/2512.04217)|null|\n", "2512.04213": "|**2025-12-03**|**Look Around and Pay Attention: Multi-camera Point Tracking Reimagined with Transformers**|Sarah Ostadabbas Team|[2512.04213](http://arxiv.org/abs/2512.04213)|null|\n", "2512.04207": "|**2025-12-09**|**Orchestrator Multi-Agent Clinical Decision Support System for Secondary Headache Diagnosis in Primary Care**|Yanshan Wang Team|[2512.04207](http://arxiv.org/abs/2512.04207)|null|\n", "2512.03963": "|**2025-12-04**|**TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning**|Limin Wang Team|[2512.03963](http://arxiv.org/abs/2512.03963)|null|\n", "2512.03918": "|**2025-12-03**|**UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework**|Yebin Liu Team|[2512.03918](http://arxiv.org/abs/2512.03918)|**[link](https://carlyx.github.io/UniMo/)**|\n", "2512.03891": "|**2025-12-03**|**Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning**|Wei Chen Team|[2512.03891](http://arxiv.org/abs/2512.03891)|null|\n", "2512.03870": "|**2025-12-03**|**Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers**|Bo Zheng Team|[2512.03870](http://arxiv.org/abs/2512.03870)|null|\n", "2512.03852": "|**2025-12-03**|**Traffic Image Restoration under Adverse Weather via Frequency-Aware Mamba**|Juncheng Li Team|[2512.03852](http://arxiv.org/abs/2512.03852)|null|\n", "2512.03804": "|**2025-12-07**|**EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification**|Di Wu Team|[2512.03804](http://arxiv.org/abs/2512.03804)|null|\n", "2512.03424": "|**2025-12-17**|**DM3D: Deformable Mamba via Offset-Guided Gaussian Sequencing for Point Cloud Understanding**|Xuelian Liu Team|[2512.03424](http://arxiv.org/abs/2512.03424)|null|\n", "2512.03204": "|**2025-12-02**|**Scaling Internal-State Policy-Gradient Methods for POMDPs**|Jonathan Baxter Team|[2512.03204](http://arxiv.org/abs/2512.03204)|null|\n", "2512.03004": "|**2025-12-02**|**DGGT: Feedforward 4D Reconstruction of Dynamic Driving Scenes using Unposed Images**|Hao Zhao Team|[2512.03004](http://arxiv.org/abs/2512.03004)|null|\n", "2512.02835": "|**2025-12-02**|**ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning**|Yanwei Fu Team|[2512.02835](http://arxiv.org/abs/2512.02835)|null|\n", "2512.02823": "|**2025-12-02**|**Tempering the Bayes Filter towards Improved Model-Based Estimation**|Duarte J. Antunes Team|[2512.02823](http://arxiv.org/abs/2512.02823)|null|\n", "2512.02667": "|**2025-12-02**|**Graph VQ-Transformer (GVT): Fast and Accurate Molecular Generation via High-Fidelity Discrete Latents**|Yang Liu Team|[2512.02667](http://arxiv.org/abs/2512.02667)|null|\n", "2512.02614": "|**2025-12-02**|**Stranger Things: A Grid-based Survey of Strange Modes in Post-Main Sequence Models**|M. Joyce Team|[2512.02614](http://arxiv.org/abs/2512.02614)|null|\n", "2512.02552": "|**2025-12-02**|**What Signals Really Matter for Misinformation Tasks? Evaluating Fake-News Detection and Virality Prediction under Real-World Constraints**|Florian Cafiero Team|[2512.02552](http://arxiv.org/abs/2512.02552)|null|\n", "2512.02492": "|**2025-12-02**|**YingVideo-MV: Music-Driven Multi-Stage Video Generation**|Zihao Chen Team|[2512.02492](http://arxiv.org/abs/2512.02492)|null|\n", "2512.02447": "|**2025-12-02**|**Temporal Dynamics Enhancer for Directly Trained Spiking Object Detectors**|Yanfeng Lu Team|[2512.02447](http://arxiv.org/abs/2512.02447)|null|\n", "2512.03109": "|**2025-12-02**|**E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing**|Hanchen Wang Team|[2512.03109](http://arxiv.org/abs/2512.03109)|null|\n", "2512.02392": "|**2025-12-02**|**From Detection to Association: Learning Discriminative Object Embeddings for Multi-Object Tracking**|Xiao Sun Team|[2512.02392](http://arxiv.org/abs/2512.02392)|null|\n", "2512.06002": "|**2025-12-02**|**POrTAL: Plan-Orchestrated Tree Assembly for Lookahead**|Laura M. Hiatt Team|[2512.06002](http://arxiv.org/abs/2512.06002)|null|\n", "2512.02352": "|**2025-12-03**|**Visibility-Graph Asymmetry as a Structural Indicator of Volatility Clustering**|Micha\u0142 Sikorski Team|[2512.02352](http://arxiv.org/abs/2512.02352)|null|\n", "2512.02228": "|**2025-12-01**|**STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls**|Hima Patel Team|[2512.02228](http://arxiv.org/abs/2512.02228)|null|\n", "2512.01987": "|**2025-12-02**|**Forecasting in Offline Reinforcement Learning for Non-stationary Environments**|Erhan Oztop Team|[2512.01987](http://arxiv.org/abs/2512.01987)|null|\n", "2512.01977": "|**2025-12-01**|**AI-Driven Optimization under Uncertainty for Mineral Processing Operations**|Jef K. Caers Team|[2512.01977](http://arxiv.org/abs/2512.01977)|null|\n", "2512.01906": "|**2025-12-01**|**Delays in Spiking Neural Networks: A State Space Model Approach**|Ay\u00e7a \u00d6z\u00e7elikkale Team|[2512.01906](http://arxiv.org/abs/2512.01906)|null|\n", "2512.01643": "|**2025-12-01**|**ViT$^3$: Unlocking Test-Time Training in Vision**|Gao Huang Team|[2512.01643](http://arxiv.org/abs/2512.01643)|null|\n", "2512.01559": "|**2025-12-01**|**LLM2Fx-Tools: Tool Calling For Music Post-Production**|Yuki Mitsufuji Team|[2512.01559](http://arxiv.org/abs/2512.01559)|null|\n", "2512.01540": "|**2025-12-01**|**FlashVGGT: Efficient and Scalable Visual Geometry Transformers with Compressed Descriptor Attention**|Dan Xu Team|[2512.01540](http://arxiv.org/abs/2512.01540)|null|\n", "2512.01512": "|**2025-12-01**|**MCAT: Scaling Many-to-Many Speech-to-Text Translation with MLLMs to 70 Languages**|YaoWei Wang Team|[2512.01512](http://arxiv.org/abs/2512.01512)|null|\n", "2512.01502": "|**2025-12-01**|**Formal Verification of Noisy Quantum Reinforcement Learning Policies**|Dennis Gross Team|[2512.01502](http://arxiv.org/abs/2512.01502)|null|\n", "2512.01245": "|**2025-12-01**|**Bayesian Optimization for Non-Cooperative Game-Based Radio Resource Management**|Robert C. Qiu Team|[2512.01245](http://arxiv.org/abs/2512.01245)|null|\n", "2512.01244": "|**2025-12-01**|**Virtual Observability in Sequential Play**|Po-Hsuan Lin Team|[2512.01244](http://arxiv.org/abs/2512.01244)|null|\n", "2512.01188": "|**2025-12-01**|**Real-World Reinforcement Learning of Active Perception Behaviors**|Dinesh Jayaraman Team|[2512.01188](http://arxiv.org/abs/2512.01188)|null|\n", "2512.01061": "|**2025-11-30**|**Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer**|Yuke Zhu Team|[2512.01061](http://arxiv.org/abs/2512.01061)|**[link](https://doorman-humanoid.github.io/)**|\n", "2512.01054": "|**2025-12-15**|**Adaptive-lambda Subtracted Importance Sampled Scores in Machine Unlearning for DDPMs and VAEs**|Human Jafari Team|[2512.01054](http://arxiv.org/abs/2512.01054)|null|\n", "2512.00883": "|**2025-11-30**|**Audio-Visual World Models: Towards Multisensory Imagination in Sight and Sound**|Yaoxin Mao Team|[2512.00883](http://arxiv.org/abs/2512.00883)|null|\n", "2512.00838": "|**2025-11-30**|**A Novel MDP Decomposition Framework for Scalable UAV Mission Planning in Complex and Uncertain Environments**|Sami ELFerik Team|[2512.00838](http://arxiv.org/abs/2512.00838)|null|\n", "2512.00806": "|**2025-11-30**|**Entropy-Driven Sensor Deployment and Source Detection in Hypergraphs**|Xiu-Xiu Zhan Team|[2512.00806](http://arxiv.org/abs/2512.00806)|null|\n", "2512.00777": "|**2025-11-30**|**Sign Language Recognition using Bidirectional Reservoir Computing**|Hakaru Tamukoh Team|[2512.00777](http://arxiv.org/abs/2512.00777)|null|\n", "2512.00760": "|**2025-11-30**|**Forecasting India's Demographic Transition Under Fertility Policy Scenarios Using hybrid LSTM-PINN Model**|Indu Bala Team|[2512.00760](http://arxiv.org/abs/2512.00760)|null|\n", "2512.00722": "|**2025-11-30**|**SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs**|Guohao Dai Team|[2512.00722](http://arxiv.org/abs/2512.00722)|null|\n", "2512.00598": "|**2025-11-29**|**Developing Fairness-Aware Task Decomposition to Improve Equity in Post-Spinal Fusion Complication Prediction**|May D. Wang Team|[2512.00598](http://arxiv.org/abs/2512.00598)|null|\n", "2512.00592": "|**2025-11-29**|**HAVEN: Hierarchical Adversary-aware Visibility-Enabled Navigation with Cover Utilization using Deep Transformer Q-Networks**|Aniket Bera Team|[2512.00592](http://arxiv.org/abs/2512.00592)|null|\n", "2512.00513": "|**2025-12-02**|**Truthful and Trustworthy IoT AI Agents via Immediate-Penalty Enforcement under Approximate VCG Mechanisms**|Mianxiong Dong Team|[2512.00513](http://arxiv.org/abs/2512.00513)|null|\n", "2512.00504": "|**2025-11-29**|**G-KV: Decoding-Time KV Cache Eviction with Global Attention**|Huaiyu Wan Team|[2512.00504](http://arxiv.org/abs/2512.00504)|null|\n", "2512.00436": "|**2025-11-29**|**RECTor: Robust and Efficient Correlation Attack on Tor**|Mohan Gurusamy Team|[2512.00436](http://arxiv.org/abs/2512.00436)|null|\n", "2512.00375": "|**2025-11-29**|**DPNet: Doppler LiDAR Motion Planning for Highly-Dynamic Environments**|Chengzhong Xu Team|[2512.00375](http://arxiv.org/abs/2512.00375)|null|\n", "2512.00370": "|**2025-11-29**|**Multi-Task Temporal Fusion Transformer for Joint Sales and Inventory Forecasting in Amazon E-Commerce Supply Chain**|Hanwu Li Team|[2512.00370](http://arxiv.org/abs/2512.00370)|null|\n", "2512.00357": "|**2025-11-29**|**Learning Causal States Under Partial Observability and Perturbation**|Yamin Wang Team|[2512.00357](http://arxiv.org/abs/2512.00357)|null|\n"}, "Temporal-Consistency": {"2512.16924": "|**2025-12-18**|**The World is Your Canvas: Painting Promptable Events with Reference Images, Trajectories, and Text**|Qifeng Chen Team|[2512.16924](http://arxiv.org/abs/2512.16924)|**[link](https://worldcanvas.github.io/)**|\n", "2512.16920": "|**2025-12-18**|**EasyV2V: A High-quality Instruction-based Video Editing Framework**|Ashkan Mirzaei Team|[2512.16920](http://arxiv.org/abs/2512.16920)|**[link](https://snap-research.github.io/easyv2v/)**|\n", "2512.16906": "|**2025-12-18**|**VIVA: VLM-Guided Instruction-Based Video Editing with Reward Optimization**|Chongyang Ma Team|[2512.16906](http://arxiv.org/abs/2512.16906)|null|\n", "2512.16900": "|**2025-12-18**|**FlashPortrait: 6x Faster Infinite Portrait Animation with Adaptive Latent Prediction**|Zuxuan Wu Team|[2512.16900](http://arxiv.org/abs/2512.16900)|null|\n", "2512.16893": "|**2025-12-18**|**Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation**|Koki Nagano Team|[2512.16893](http://arxiv.org/abs/2512.16893)|**[link](https://research.nvidia.com/labs/amri/projects/instant4d)**|\n", "2512.16793": "|**2025-12-18**|**PhysBrain: Human Egocentric Data as a Bridge from Vision Language Models to Physical Intelligence**|Kai Chen Team|[2512.16793](http://arxiv.org/abs/2512.16793)|null|\n", "2512.16791": "|**2025-12-18**|**KineST: A Kinematics-guided Spatiotemporal State Space Model for Human Motion Tracking from Sparse Signals**|Xinrong Chen Team|[2512.16791](http://arxiv.org/abs/2512.16791)|null|\n", "2512.16776": "|**2025-12-18**|**Kling-Omni Technical Report**|Yongjie Zhu Team|[2512.16776](http://arxiv.org/abs/2512.16776)|null|\n", "2512.16670": "|**2025-12-18**|**FrameDiffuser: G-Buffer-Conditioned Diffusion for Neural Forward Frame Rendering**|Hendrik P. A. Lensch Team|[2512.16670](http://arxiv.org/abs/2512.16670)|**[link](https://framediffuser.jdihlmann.com/)**|\n", "2512.16461": "|**2025-12-18**|**SNOW: Spatio-Temporal Scene Understanding with World Knowledge for Open-World Embodied Reasoning**|Eric Sax Team|[2512.16461](http://arxiv.org/abs/2512.16461)|null|\n", "2512.16397": "|**2025-12-18**|**Using Gaussian Splats to Create High-Fidelity Facial Geometry and Texture**|Ronald Fedkiw Team|[2512.16397](http://arxiv.org/abs/2512.16397)|null|\n", "2512.16371": "|**2025-12-18**|**Factorized Video Generation: Decoupling Scene Construction and Temporal Synthesis in Text-to-Video Diffusion Models**|Alexandre Alahi Team|[2512.16371](http://arxiv.org/abs/2512.16371)|null|\n", "2512.16093": "|**2025-12-18**|**TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times**|Jun Zhu Team|[2512.16093](http://arxiv.org/abs/2512.16093)|null|\n", "2512.16023": "|**2025-12-17**|**CoVAR: Co-generation of Video and Action for Robotic Manipulation via Multi-Modal Diffusion**|Abhinav Valada Team|[2512.16023](http://arxiv.org/abs/2512.16023)|null|\n", "2512.16001": "|**2025-12-17**|**Concurrence: A dependence criterion for time series, applied to biological data**|Birkan Tunc Team|[2512.16001](http://arxiv.org/abs/2512.16001)|null|\n", "2512.15716": "|**2025-12-17**|**Spatia: Video Generation with Updatable Spatial Memory**|Yan Lu Team|[2512.15716](http://arxiv.org/abs/2512.15716)|**[link](https://zhaojingjing713.github.io/Spatia/)**|\n", "2512.15702": "|**2025-12-17**|**End-to-End Training for Autoregressive Video Diffusion via Self-Resampling**|Dahua Lin Team|[2512.15702](http://arxiv.org/abs/2512.15702)|**[link](https://guoyww.github.io/projects/resampling-forcing/)**|\n", "2512.15693": "|**2025-12-17**|**Skyra: AI-Generated Video Detection via Grounded Artifact Reasoning**|Jiwen Lu Team|[2512.15693](http://arxiv.org/abs/2512.15693)|**[link](https://github.com/JoeLeelyf/Skyra)**|\n", "2512.15635": "|**2025-12-17**|**IC-Effect: Precise and Efficient Video Effects Editing via In-Context Learning**|Qi Mao Team|[2512.15635](http://arxiv.org/abs/2512.15635)|null|\n", "2512.15577": "|**2025-12-17**|**MoonSeg3R: Monocular Online Zero-Shot Segment Anything in 3D with Reconstructive Foundation Priors**|Hakan Bilen Team|[2512.15577](http://arxiv.org/abs/2512.15577)|null|\n", "2512.15560": "|**2025-12-17**|**GRAN-TED: Generating Robust, Aligned, and Nuanced Text Embedding for Diffusion Models**|Yuanxing zhang Team|[2512.15560](http://arxiv.org/abs/2512.15560)|null|\n", "2512.15542": "|**2025-12-17**|**BLANKET: Anonymizing Faces in Infant Video Recordings**|Matej Hoffmann Team|[2512.15542](http://arxiv.org/abs/2512.15542)|**[link](https://github.com/ctu-vras/blanket-infant-face-anonym)**|\n", "2512.15524": "|**2025-12-17**|**DeX-Portrait: Disentangled and Expressive Portrait Animation via Explicit and Latent Motion Representations**|Ligang Liu Team|[2512.15524](http://arxiv.org/abs/2512.15524)|**[link](https://syx132.github.io/DeX-Portrait/)**|\n", "2512.15818": "|**2025-12-17**|**Unveiling the Attribute Misbinding Threat in Identity-Preserving Models**|Jianquan Yang Team|[2512.15818](http://arxiv.org/abs/2512.15818)|null|\n", "2512.15469": "|**2025-12-17**|**Metanetworks as Regulatory Operators: Learning to Edit for Requirement Compliance**|Yannis Panagakis Team|[2512.15469](http://arxiv.org/abs/2512.15469)|null|\n", "2512.15445": "|**2025-12-17**|**ST-DETrack: Identity-Preserving Branch Tracking in Entangled Plant Canopies via Dual Spatiotemporal Evidence**|Jo Hepworth Team|[2512.15445](http://arxiv.org/abs/2512.15445)|null|\n", "2512.15340": "|**2025-12-17**|**Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics**|Xun Yang Team|[2512.15340](http://arxiv.org/abs/2512.15340)|null|\n", "2512.15262": "|**2025-12-17**|**Audio-Visual Cross-Modal Compression for Generative Face Video Coding**|Jian Zhang Team|[2512.15262](http://arxiv.org/abs/2512.15262)|null|\n", "2512.15160": "|**2025-12-17**|**EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence**|Yifan Yang Team|[2512.15160](http://arxiv.org/abs/2512.15160)|null|\n", "2512.15126": "|**2025-12-17**|**3DProxyImg: Controllable 3D-Aware Animation Synthesis from Single Image via 2D-3D Aligned Proxy Embedding**|Bingbing Ni Team|[2512.15126](http://arxiv.org/abs/2512.15126)|null|\n", "2512.15067": "|**2025-12-17**|**EMFusion: Conditional Diffusion Framework for Trustworthy Frequency Selective EMF Forecasting in Wireless Networks**|Luca Chiaraviglio Team|[2512.15067](http://arxiv.org/abs/2512.15067)|null|\n", "2512.15066": "|**2025-12-17**|**Tracking spatial temporal details in ultrasound long video via wavelet analysis and memory bank**|Junchen Wang Team|[2512.15066](http://arxiv.org/abs/2512.15066)|null|\n", "2512.14938": "|**2025-12-16**|**TalkVerse: Democratizing Minute-Long Audio-Driven Video Generation**|Bing Zhou Team|[2512.14938](http://arxiv.org/abs/2512.14938)|null|\n", "2512.14699": "|**2025-12-16**|**MemFlow: Flowing Adaptive Memory for Consistent and Efficient Long Video Narratives**|Hengshuang Zhao Team|[2512.14699](http://arxiv.org/abs/2512.14699)|**[link](https://sihuiji.github.io/MemFlow.github.io/)**|\n", "2512.14691": "|**2025-12-17**|**MMGR: Multi-Modal Generative Reasoning**|Junjie Hu Team|[2512.14691](http://arxiv.org/abs/2512.14691)|null|\n", "2512.14614": "|**2025-12-16**|**WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling**|Chunchao Guo Team|[2512.14614](http://arxiv.org/abs/2512.14614)|**[link](https://3d-models.hunyuan.tencent.com/world/)**|\n", "2512.14559": "|**2025-12-16**|**Counterfactual Explanations for Time Series Should be Human-Centered and Temporally Coherent in Interventions**|Mykola Pechenizkiy Team|[2512.14559](http://arxiv.org/abs/2512.14559)|null|\n", "2512.14542": "|**2025-12-16**|**HiFi-Portrait: Zero-shot Identity-preserved Portrait Generation with High-fidelity Multi-face Fusion**|Sidan Du Team|[2512.14542](http://arxiv.org/abs/2512.14542)|null|\n", "2512.14440": "|**2025-12-16**|**S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation**|Timo Ropinski Team|[2512.14440](http://arxiv.org/abs/2512.14440)|**[link](https://leonsick.github.io/s2d/)**|\n", "2512.14421": "|**2025-12-16**|**LCMem: A Universal Model for Robust Image Memorization Detection**|Bernhard Kainz Team|[2512.14421](http://arxiv.org/abs/2512.14421)|null|\n", "2512.14352": "|**2025-12-16**|**HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis**|Yong-Jin Liu Team|[2512.14352](http://arxiv.org/abs/2512.14352)|null|\n", "2512.14284": "|**2025-12-16**|**SS4D: Native 4D Generative Model via Structured Spacetime Latents**|Dahua Lin Team|[2512.14284](http://arxiv.org/abs/2512.14284)|null|\n", "2512.14273": "|**2025-12-16**|**Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in**|Ryo Hachiuma Team|[2512.14273](http://arxiv.org/abs/2512.14273)|**[link](https://xiaoqian-shen.github.io/Zoom-Zero/)**|\n", "2512.14217": "|**2025-12-16**|**DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos**|Gitta Kutyniok Team|[2512.14217](http://arxiv.org/abs/2512.14217)|null|\n", "2512.14200": "|**2025-12-16**|**Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination**|Wufan Zhao Team|[2512.14200](http://arxiv.org/abs/2512.14200)|null|\n", "2512.14133": "|**2025-12-16**|**AnimaMimic: Imitating 3D Animation from Video Priors**|Chenfanfu Jiang Team|[2512.14133](http://arxiv.org/abs/2512.14133)|null|\n", "2512.14095": "|**2025-12-16**|**AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation**|Kai Xu Team|[2512.14095](http://arxiv.org/abs/2512.14095)|null|\n", "2512.14056": "|**2025-12-16**|**FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling**|Tae-Hyun Oh Team|[2512.14056](http://arxiv.org/abs/2512.14056)|**[link](https://facedit.github.io/)**|\n", "2512.14017": "|**2025-12-16**|**KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding**|Jianquan Liu Team|[2512.14017](http://arxiv.org/abs/2512.14017)|null|\n", "2512.13874": "|**2025-12-15**|**SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning**|Humphrey Shi Team|[2512.13874](http://arxiv.org/abs/2512.13874)|**[link](https://praeclarumjj3.github.io/sage/)**|\n", "2512.13690": "|**2025-12-15**|**DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders**|Jui-Hsien Wang Team|[2512.13690](http://arxiv.org/abs/2512.13690)|**[link](https://susunghong.github.io/DiffusionBrowser)**|\n", "2512.13665": "|**2025-12-15**|**Grab-3D: Detecting AI-Generated Videos from 3D Geometric Temporal Consistency**|Theo Gevers Team|[2512.13665](http://arxiv.org/abs/2512.13665)|null|\n", "2512.13604": "|**2025-12-15**|**LongVie 2: Multimodal Controllable Ultra-Long Video World Model**|Ziwei Liu Team|[2512.13604](http://arxiv.org/abs/2512.13604)|**[link](https://vchitect.github.io/LongVie2-project/)**|\n", "2512.13507": "|**2025-12-16**|**Seedance 1.5 pro: A Native Audio-Visual Joint Generation Foundation Model**|Feilong Zuo Team|[2512.13507](http://arxiv.org/abs/2512.13507)|null|\n", "2512.13495": "|**2025-12-15**|**Soul: Breathe Life into Digital Human for High-fidelity Long-term Multimodal Animation**|Chengjie Wang Team|[2512.13495](http://arxiv.org/abs/2512.13495)|**[link](https://zhangzjn.github.io/projects/Soul/)**|\n", "2512.13492": "|**2025-12-15**|**Transform Trained Transformer: Accelerating Naive 4K Video Generation Over 10$\\times$**|Chengjie Wang Team|[2512.13492](http://arxiv.org/abs/2512.13492)|**[link](https://zhangzjn.github.io/projects/T3-Video)**|\n", "2512.13465": "|**2025-12-15**|**PoseAnything: Universal Pose-guided Video Generation with Part-aware Temporal Coherence**|Lizhuang Ma Team|[2512.13465](http://arxiv.org/abs/2512.13465)|null|\n", "2512.13393": "|**2025-12-15**|**QoS-Aware State-Augmented Learnable Framework for 5G NR-U/Wi-Fi Coexistence: Impact of Parameter Selection and Enhanced Collision Resolution**|Brian L. Mark Team|[2512.13393](http://arxiv.org/abs/2512.13393)|null|\n", "2512.13392": "|**2025-12-16**|**Beyond the Visible: Disocclusion-Aware Editing via Proxy Dynamic Graphs**|Niloy J. Mitra Team|[2512.13392](http://arxiv.org/abs/2512.13392)|null|\n", "2512.13313": "|**2025-12-15**|**KlingAvatar 2.0 Technical Report**|Yan Zhou Team|[2512.13313](http://arxiv.org/abs/2512.13313)|null|\n", "2512.13290": "|**2025-12-15**|**LINA: Learning INterventions Adaptively for Physical Alignment and Generalization in Diffusion Models**|Chaochao Lu Team|[2512.13290](http://arxiv.org/abs/2512.13290)|null|\n", "2512.13281": "|**2025-12-18**|**Video Reality Test: Can AI-Generated ASMR Videos fool VLMs and Humans?**|Kevin Qinghong Lin Team|[2512.13281](http://arxiv.org/abs/2512.13281)|**[link](https://github.com/video-reality-test/video-reality-test)**|\n", "2512.13247": "|**2025-12-15**|**STARCaster: Spatio-Temporal AutoRegressive Video Diffusion for Identity- and View-Aware Talking Portraits**|Stefanos Zafeiriou Team|[2512.13247](http://arxiv.org/abs/2512.13247)|**[link](https://foivospar.github.io/STARCaster/)**|\n", "2512.13169": "|**2025-12-15**|**Integrated Semantic and Temporal Alignment for Interactive Video Retrieval**|Tinh-Anh Nguyen Nhu Team|[2512.13169](http://arxiv.org/abs/2512.13169)|null|\n", "2512.13030": "|**2025-12-15**|**Motus: A Unified Latent Action World Model**|Jun Zhu Team|[2512.13030](http://arxiv.org/abs/2512.13030)|null|\n", "2512.13019": "|**2025-12-15**|**SneakPeek: Future-Guided Instructional Streaming Video Generation**|Albert Pumarola Team|[2512.13019](http://arxiv.org/abs/2512.13019)|null|\n", "2512.13015": "|**2025-12-15**|**What Happens Next? Next Scene Prediction with a Unified Video Model**|Vimal Bhat Team|[2512.13015](http://arxiv.org/abs/2512.13015)|null|\n", "2512.12935": "|**2025-12-15**|**Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion**|Anh Nguyen Nhu Tinh Team|[2512.12935](http://arxiv.org/abs/2512.12935)|null|\n", "2512.12751": "|**2025-12-14**|**GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation**|Hengshuang Zhao Team|[2512.12751](http://arxiv.org/abs/2512.12751)|**[link](https://huster-yzy.github.io/geniedrive_project_page/)**|\n", "2512.12534": "|**2025-12-14**|**Animus3D: Text-driven 3D Animation via Motion Score Distillation**|Jing Liao Team|[2512.12534](http://arxiv.org/abs/2512.12534)|null|\n", "2512.12508": "|**2025-12-14**|**Generative Spatiotemporal Data Augmentation**|Jeong Joon Park Team|[2512.12508](http://arxiv.org/abs/2512.12508)|null|\n", "2512.12430": "|**2025-12-13**|**Endless World: Real-Time 3D-Aware Long Video Generation**|Vishal M. Patel Team|[2512.12430](http://arxiv.org/abs/2512.12430)|null|\n", "2512.12375": "|**2025-12-13**|**V-Warper: Appearance-Consistent Video Diffusion Personalization via Value Warping**|Seungryong Kim Team|[2512.12375](http://arxiv.org/abs/2512.12375)|**[link](https://cvlab-kaist.github.io/V-Warper)**|\n", "2512.12372": "|**2025-12-13**|**STAGE: Storyboard-Anchored Generation for Cinematic Multi-shot Narrative**|Boxin Shi Team|[2512.12372](http://arxiv.org/abs/2512.12372)|null|\n", "2512.12360": "|**2025-12-13**|**VideoARM: Agentic Reasoning over Hierarchical Memory for Long-Form Video Understanding**|Zhou Yu Team|[2512.12360](http://arxiv.org/abs/2512.12360)|null|\n", "2512.12283": "|**2025-12-13**|**Large Language Models have Chain-of-Affective**|Liang He Team|[2512.12283](http://arxiv.org/abs/2512.12283)|null|\n", "2512.12209": "|**2025-12-13**|**CineLOG: A Training Free Approach for Cinematic Long Video Generation**|Hamid R. Rabiee Team|[2512.12209](http://arxiv.org/abs/2512.12209)|null|\n", "2512.12196": "|**2025-12-13**|**AutoMV: An Automatic Multi-Agent System for Music Video Generation**|Yinghao Ma Team|[2512.12196](http://arxiv.org/abs/2512.12196)|null|\n", "2512.12193": "|**2025-12-13**|**SMRABooth: Subject and Motion Representation Alignment for Customized Video Generation**|Bing-Kun Bao Team|[2512.12193](http://arxiv.org/abs/2512.12193)|null|\n", "2512.12183": "|**2025-12-13**|**HydroDiffusion: Diffusion-Based Probabilistic Streamflow Forecasting with a State Space Backbone**|N. Benjamin Erichson Team|[2512.12183](http://arxiv.org/abs/2512.12183)|null|\n", "2512.12090": "|**2025-12-12**|**SPDMark: Selective Parameter Displacement for Robust Video Watermarking**|Karthik Nandakumar Team|[2512.12090](http://arxiv.org/abs/2512.12090)|null|\n", "2512.12080": "|**2025-12-12**|**BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models**|Gordon Wetzstein Team|[2512.12080](http://arxiv.org/abs/2512.12080)|**[link](https://ryanpo.com/bagger)**|\n", "2512.12060": "|**2025-12-12**|**CreativeVR: Diffusion-Prior-Guided Approach for Structure and Motion Restoration in Generative and Real Videos**|Xue Bai Team|[2512.12060](http://arxiv.org/abs/2512.12060)|null|\n", "2512.11961": "|**2025-12-12**|**Probing jet-induced optical variability across timescales in radio-loud NLSy1 galaxies**|Hum Chand Team|[2512.11961](http://arxiv.org/abs/2512.11961)|null|\n", "2512.11799": "|**2025-12-12**|**V-RGBX: Video Editing with Accurate Controls over Intrinsic Properties**|Tuanfeng Yang Wang Team|[2512.11799](http://arxiv.org/abs/2512.11799)|**[link](https://aleafy.github.io/vrgbx)**|\n", "2512.11797": "|**2025-12-12**|**AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis**|Vitor Guizilini Team|[2512.11797](http://arxiv.org/abs/2512.11797)|**[link](https://jay-ye.github.io/AnchorDream/)**|\n", "2512.11792": "|**2025-12-12**|**Structure From Tracking: Distilling Structure-Preserving Motion for Video Generation**|Benlin Liu Team|[2512.11792](http://arxiv.org/abs/2512.11792)|**[link](https://sam2videox.github.io/)**|\n", "2512.11782": "|**2025-12-12**|**MatAnyone 2: Scaling Video Matting via a Learned Quality Evaluator**|Qingyi Tao Team|[2512.11782](http://arxiv.org/abs/2512.11782)|**[link](https://pq-yang.github.io/projects/MatAnyone2/)**|\n", "2512.11720": "|**2025-12-12**|**Reframing Music-Driven 2D Dance Pose Generation as Multi-Channel Image Generation**|Zhenpeng Zhan Team|[2512.11720](http://arxiv.org/abs/2512.11720)|null|\n", "2512.11645": "|**2025-12-12**|**FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint**|Peihong Guo Team|[2512.11645](http://arxiv.org/abs/2512.11645)|**[link](https://tangjiapeng.github.io/FactorPortrait/)**|\n", "2512.11943": "|**2025-12-12**|**How AI Agents Follow the Herd of AI? Network Effects, History, and Machine Optimism**|Guangnan Ye Team|[2512.11943](http://arxiv.org/abs/2512.11943)|null|\n", "2512.11464": "|**2025-12-12**|**Exploring MLLM-Diffusion Information Transfer with MetaCanvas**|Chu Wang Team|[2512.11464](http://arxiv.org/abs/2512.11464)|**[link](https://metacanvas.github.io)**|\n", "2512.11438": "|**2025-12-12**|**Flowception: Temporally Expansive Flow Matching for Video Generation**|Ricky T. Q. Chen Team|[2512.11438](http://arxiv.org/abs/2512.11438)|null|\n", "2512.11423": "|**2025-12-12**|**JoyAvatar: Real-time and Infinite Audio-Driven Avatar Generation with Autoregressive Diffusion**|Xiaodong He Team|[2512.11423](http://arxiv.org/abs/2512.11423)|null|\n", "2512.11399": "|**2025-12-12**|**Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction**|Nancy F. Chen Team|[2512.11399](http://arxiv.org/abs/2512.11399)|null|\n", "2512.11331": "|**2025-12-12**|**AMBER: An Adaptive Multimodal Mask Transformer for Beam Prediction with Missing Modalities**|Jiangzhou Wang Team|[2512.11331](http://arxiv.org/abs/2512.11331)|null|\n", "2512.11293": "|**2025-12-12**|**Autoregressive Video Autoencoder with Decoupled Temporal and Spatial Context**|Gengdai Liu Team|[2512.11293](http://arxiv.org/abs/2512.11293)|null|\n", "2512.11274": "|**2025-12-12**|**FilmWeaver: Weaving Consistent Multi-Shot Videos with Cache-Guided Autoregressive Diffusion**|Shao-Lun Huang Team|[2512.11274](http://arxiv.org/abs/2512.11274)|null|\n", "2512.11253": "|**2025-12-12**|**PersonaLive! Expressive Portrait Image Animation for Live Streaming**|Xiaodong Cun Team|[2512.11253](http://arxiv.org/abs/2512.11253)|null|\n", "2512.11229": "|**2025-12-12**|**REST: Diffusion-based Real-time End-to-end Streaming Talking Head Generation via ID-Context Caching and Asynchronous Streaming Distillation**|Qingfeng Liu Team|[2512.11229](http://arxiv.org/abs/2512.11229)|null|\n", "2512.11225": "|**2025-12-12**|**VFMF: World Modeling by Forecasting Vision Foundation Model Features**|Andrea Vedaldi Team|[2512.11225](http://arxiv.org/abs/2512.11225)|null|\n", "2512.11203": "|**2025-12-15**|**AutoRefiner: Improving Autoregressive Video Diffusion Models via Reflective Refinement Over the Stochastic Sampling Path**|Yuki Mitsufuji Team|[2512.11203](http://arxiv.org/abs/2512.11203)|null|\n", "2512.10946": "|**2025-12-11**|**ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning**|Cewu Lu Team|[2512.10946](http://arxiv.org/abs/2512.10946)|**[link](https://implicit-rdp.github.io)**|\n", "2512.10943": "|**2025-12-11**|**AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation**|Sergey Tulyakov Team|[2512.10943](http://arxiv.org/abs/2512.10943)|**[link](https://snap-research.github.io/Video-AlcheMinT/snap-research.github.io/Video-AlcheMinT)**|\n", "2512.10940": "|**2025-12-11**|**OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis**|Ranjay Krishna Team|[2512.10940](http://arxiv.org/abs/2512.10940)|**[link](https://snap-research.github.io/OmniView/)**|\n", "2512.10939": "|**2025-12-11**|**GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting**|Steven McDonagh Team|[2512.10939](http://arxiv.org/abs/2512.10939)|null|\n", "2512.10881": "|**2025-12-11**|**MoCapAnything: Unified 3D Motion Capture for Arbitrary Skeletons from Monocular Videos**|Mingyuan Zhang Team|[2512.10881](http://arxiv.org/abs/2512.10881)|**[link](https://animotionlab.github.io/MoCapAnything/)**|\n", "2512.10860": "|**2025-12-11**|**SWiT-4D: Sliding-Window Transformer for Lossless and Parameter-Free Temporal 4D Generation**|Mingyuan Zhang Team|[2512.10860](http://arxiv.org/abs/2512.10860)|**[link](https://animotionlab.github.io/SWIT4D/)**|\n", "2512.10725": "|**2025-12-11**|**Video Depth Propagation**|Luc Van Gool Team|[2512.10725](http://arxiv.org/abs/2512.10725)|null|\n", "2512.10628": "|**2025-12-11**|**K-Track: Kalman-Enhanced Tracking for Accelerating Deep Point Trackers on Edge Devices**|Sarah Ostadabbas Team|[2512.10628](http://arxiv.org/abs/2512.10628)|null|\n", "2512.10617": "|**2025-12-11**|**Lang2Motion: Bridging Language and Motion through Joint Embedding Spaces**|Sarah Ostadabbas Team|[2512.10617](http://arxiv.org/abs/2512.10617)|null|\n", "2512.10571": "|**2025-12-11**|**Audio-sync Video Instance Editing with Granularity-Aware Mask Refiner**|Xinlong Wang Team|[2512.10571](http://arxiv.org/abs/2512.10571)|null|\n", "2512.10450": "|**2025-12-11**|**Error-Propagation-Free Learned Video Compression With Dual-Domain Progressive Temporal Alignment**|Hongkai Xiong Team|[2512.10450](http://arxiv.org/abs/2512.10450)|null|\n", "2512.10363": "|**2025-12-11**|**Point to Span: Zero-Shot Moment Retrieval for Navigating Unseen Hour-Long Videos**|Junyeoung Kim Team|[2512.10363](http://arxiv.org/abs/2512.10363)|null|\n", "2512.10352": "|**2025-12-11**|**Topology-Agnostic Animal Motion Generation from Text Prompt**|Ruqi Huang Team|[2512.10352](http://arxiv.org/abs/2512.10352)|null|\n", "2512.10286": "|**2025-12-11**|**ShotDirector: Directorially Controllable Multi-Shot Video Generation with Cinematographic Transitions**|Yu Qiao Team|[2512.10286](http://arxiv.org/abs/2512.10286)|**[link](https://uknowsth.github.io/ShotDirector/)**|\n", "2512.14734": "|**2025-12-11**|**Inference Time Feature Injection: A Lightweight Approach for Real-Time Recommendation Freshness**|Hongfei Li Team|[2512.14734](http://arxiv.org/abs/2512.14734)|null|\n", "2512.09924": "|**2025-12-11**|**ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning**|Yike Guo Team|[2512.09924](http://arxiv.org/abs/2512.09924)|**[link](https://github.com/Liuxinyv/ReViSE))**|\n", "2512.09864": "|**2025-12-10**|**UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving**|Ying-Cong Chen Team|[2512.09864](http://arxiv.org/abs/2512.09864)|**[link](https://seed-uniugp.github.io/)**|\n", "2512.09841": "|**2025-12-10**|**ChronusOmni: Improving Time Awareness of Omni Large Language Models**|Liyun Ru Team|[2512.09841](http://arxiv.org/abs/2512.09841)|**[link](https://github.com/YJCX330/Chronus/)**|\n", "2512.09646": "|**2025-12-10**|**VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification**|Christian Theobalt Team|[2512.09646](http://arxiv.org/abs/2512.09646)|null|\n", "2512.09608": "|**2025-12-10**|**Super4DR: 4D Radar-centric Self-supervised Odometry and Gaussian-based Map Optimization**|Zheng Fang Team|[2512.09608](http://arxiv.org/abs/2512.09608)|null|\n", "2512.09471": "|**2025-12-10**|**Temporal-Spatial Tubelet Embedding for Cloud-Robust MSI Reconstruction using MSI-SAR Fusion: A Multi-Head Self-Attention Video Vision Transformer Approach**|Radu State Team|[2512.09471](http://arxiv.org/abs/2512.09471)|null|\n", "2512.09418": "|**2025-12-10**|**Label-free Motion-Conditioned Diffusion Model for Cardiac Ultrasound Synthesis**|Bernhard Kainz Team|[2512.09418](http://arxiv.org/abs/2512.09418)|null|\n", "2512.09417": "|**2025-12-10**|**DirectSwap: Mask-Free Cross-Identity Training and Benchmarking for Expression-Consistent Video Head Swapping**|Xiaodan Liang Team|[2512.09417](http://arxiv.org/abs/2512.09417)|null|\n", "2512.09406": "|**2025-12-10**|**H2R-Grounder: A Paired-Data-Free Paradigm for Translating Human Interaction Videos into Physically Grounded Robot Videos**|Mike Zheng Shou Team|[2512.09406](http://arxiv.org/abs/2512.09406)|null|\n", "2512.09396": "|**2025-12-10**|**GAIR: GUI Automation via Information-Joint Reasoning and Group Reflection**|Fei Wu Team|[2512.09396](http://arxiv.org/abs/2512.09396)|null|\n", "2512.09363": "|**2025-12-11**|**StereoWorld: Geometry-Aware Monocular-to-Stereo Video Generation**|Yunchao Wei Team|[2512.09363](http://arxiv.org/abs/2512.09363)|null|\n", "2512.09354": "|**2025-12-10**|**Video-QTR: Query-Driven Temporal Reasoning Framework for Lightweight Video Understanding**|Jianwei Yin Team|[2512.09354](http://arxiv.org/abs/2512.09354)|null|\n", "2512.09302": "|**2025-12-10**|**Real-Time-Capable Betatron Tune Measurement from Schottky Spectra Using Deep Learning and Uncertainty-Aware Kalman Filtering**|Ying Shi Team|[2512.09302](http://arxiv.org/abs/2512.09302)|null|\n", "2512.09299": "|**2025-12-10**|**VABench: A Comprehensive Benchmark for Audio-Video Generation**|Wentao Zhang Team|[2512.09299](http://arxiv.org/abs/2512.09299)|null|\n", "2512.09270": "|**2025-12-10**|**MoRel: Long-Range Flicker-Free 4D Motion Modeling via Anchor Relay-based Bidirectional Blending with Hierarchical Densification**|Jihyong Oh Team|[2512.09270](http://arxiv.org/abs/2512.09270)|**[link](https://cmlab-korea.github.io/MoRel/)**|\n", "2512.09205": "|**2025-12-10**|**Activation of Polylactic Acid and Polycarbonate Surfaces with Non-Thermal Plasma**|Angel Gonzalez-Lizardo Team|[2512.09205](http://arxiv.org/abs/2512.09205)|null|\n", "2512.09112": "|**2025-12-09**|**GimbalDiffusion: Gravity-Aware Camera Control for Video Generation**|Jean-Fran\u00e7ois Lalonde Team|[2512.09112](http://arxiv.org/abs/2512.09112)|**[link](https://lvsn.github.io/GimbalDiffusion/)**|\n", "2512.08931": "|**2025-12-15**|**Astra: General Interactive World Model with Autoregressive Denoising**|Jiwen Lu Team|[2512.08931](http://arxiv.org/abs/2512.08931)|**[link](https://github.com/EternalEvan/Astra)**|\n", "2512.08905": "|**2025-12-09**|**Self-Evolving 3D Scene Generation from a Single Image**|Xin Eric Wang Team|[2512.08905](http://arxiv.org/abs/2512.08905)|null|\n", "2512.08765": "|**2025-12-09**|**Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance**|Yujiu Yang Team|[2512.08765](http://arxiv.org/abs/2512.08765)|**[link](https://github.com/ali-vilab/Wan-Move)**|\n", "2512.08577": "|**2025-12-09**|**Disturbance-Free Surgical Video Generation from Multi-Camera Shadowless Lamps for Open Surgery**|Mariko Isogawa Team|[2512.08577](http://arxiv.org/abs/2512.08577)|null|\n", "2512.08535": "|**2025-12-09**|**Photo3D: Advancing Photorealistic 3D Generation through Structure-Aligned Detail Enhancement**|Lei Zhang Team|[2512.08535](http://arxiv.org/abs/2512.08535)|null|\n", "2512.08467": "|**2025-12-09**|**Team-Aware Football Player Tracking with SAM: An Appearance-Based Approach to Occlusion Recovery**|Uthayasanker Thayasivam Team|[2512.08467](http://arxiv.org/abs/2512.08467)|null|\n", "2512.08410": "|**2025-12-09**|**Towards Effective and Efficient Long Video Understanding of Multimodal Large Language Models via One-shot Clip Retrieval**|Rongrong Ji Team|[2512.08410](http://arxiv.org/abs/2512.08410)|null|\n", "2512.08406": "|**2025-12-09**|**SAM-Body4D: Training-Free 4D Human Body Mesh Recovery from Videos**|Jungong Han Team|[2512.08406](http://arxiv.org/abs/2512.08406)|null|\n", "2512.08294": "|**2025-12-10**|**OpenSubject: Leveraging Video-Derived Identity and Diversity Priors for Subject-driven Image Generation and Manipulation**|Harry Yang Team|[2512.08294](http://arxiv.org/abs/2512.08294)|null|\n", "2512.08269": "|**2025-12-09**|**EgoX: Egocentric Video Generation from a Single Exocentric Video**|Jaegul Choo Team|[2512.08269](http://arxiv.org/abs/2512.08269)|**[link](https://keh0t0.github.io/EgoX)**|\n", "2512.08188": "|**2025-12-09**|**Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model**|Rui Chen Team|[2512.08188](http://arxiv.org/abs/2512.08188)|**[link](https://embodied-tree-of-thoughts.github.io)**|\n", "2512.08125": "|**2025-12-09**|**FlowSteer: Conditioning Flow Field for Consistent Image Restoration**|Stanley H. Chan Team|[2512.08125](http://arxiv.org/abs/2512.08125)|null|\n", "2512.08040": "|**2025-12-08**|**Lost in Translation, Found in Embeddings: Sign Language Translation and Alignment**|Andrew Zisserman Team|[2512.08040](http://arxiv.org/abs/2512.08040)|null|\n", "2512.07951": "|**2025-12-08**|**Preserving Source Video Realism: High-Fidelity Face Swapping for Cinematic Quality**|Chunhua Shen Team|[2512.07951](http://arxiv.org/abs/2512.07951)|**[link](https://aim-uofa.github.io/LivingSwap)**|\n", "2512.07831": "|**2025-12-08**|**UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation**|Jiaya Jia Team|[2512.07831](http://arxiv.org/abs/2512.07831)|**[link](https://jackailab.github.io/Projects/UnityVideo)**|\n", "2512.07826": "|**2025-12-16**|**OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing**|Lei Xie Team|[2512.07826](http://arxiv.org/abs/2512.07826)|**[link](https://lewandofskee.github.io/projects/OpenVE)**|\n", "2512.07821": "|**2025-12-08**|**WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling**|Qixing Huang Team|[2512.07821](http://arxiv.org/abs/2512.07821)|null|\n", "2512.07818": "|**2025-12-08**|**Provable Long-Range Benefits of Next-Token Prediction**|Santosh S. Vempala Team|[2512.07818](http://arxiv.org/abs/2512.07818)|null|\n", "2512.07802": "|**2025-12-08**|**OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory**|Tian Xie Team|[2512.07802](http://arxiv.org/abs/2512.07802)|**[link](https://zhaochongan.github.io/projects/OneStory)**|\n", "2512.07720": "|**2025-12-09**|**ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation**|Guosheng Lin Team|[2512.07720](http://arxiv.org/abs/2512.07720)|**[link](https://lhyfst.github.io/visa})**|\n", "2512.07633": "|**2025-12-08**|**Chiral transition in a Non-Abelian Quasi-Particle Model with three quark flavours**|Fotios K. Diakonos Team|[2512.07633](http://arxiv.org/abs/2512.07633)|null|\n", "2512.07574": "|**2025-12-08**|**Precise Liver Tumor Segmentation in CT Using a Hybrid Deep Learning-Radiomics Framework**|Yuanjie Zheng Team|[2512.07574](http://arxiv.org/abs/2512.07574)|null|\n", "2512.07500": "|**2025-12-12**|**MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer**|Yue Ma Team|[2512.07500](http://arxiv.org/abs/2512.07500)|null|\n", "2512.07498": "|**2025-12-08**|**Towards Robust DeepFake Detection under Unstable Face Sequences: Adaptive Sparse Graph Embedding with Order-Free Representation and Explicit Laplacian Spectral Prior**|Yi-Shiuan Chou Team|[2512.07498](http://arxiv.org/abs/2512.07498)|null|\n", "2512.07480": "|**2025-12-08**|**Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance**|Yan Lu Team|[2512.07480](http://arxiv.org/abs/2512.07480)|null|\n", "2512.07469": "|**2025-12-08**|**Unified Video Editing with Temporal Reasoner**|Qiang Wu Team|[2512.07469](http://arxiv.org/abs/2512.07469)|**[link](https://videocof.github.io/)**|\n", "2512.07350": "|**2025-12-08**|**Communication-Efficient Serving for Video Diffusion Models with Latent Parallelism**|Yong Wang Team|[2512.07350](http://arxiv.org/abs/2512.07350)|null|\n", "2512.07348": "|**2025-12-08**|**MICo-150K: A Comprehensive Dataset Advancing Multi-Image Composition**|Lei Zhang Team|[2512.07348](http://arxiv.org/abs/2512.07348)|**[link](https://MICo-150K.github.io/)**|\n", "2512.07328": "|**2025-12-08**|**ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation**|Yu-Wing Tai Team|[2512.07328](http://arxiv.org/abs/2512.07328)|null|\n", "2512.07237": "|**2025-12-08**|**Unified Camera Positional Encoding for Controlled Video Generation**|Jianfei Cai Team|[2512.07237](http://arxiv.org/abs/2512.07237)|**[link](https://github.com/chengzhag/UCPE)**|\n", "2512.07209": "|**2025-12-08**|**Coherent Audio-Visual Editing via Conditional Audio Generation Following Video Edits**|Yuki Mitsufuji Team|[2512.07209](http://arxiv.org/abs/2512.07209)|null|\n", "2512.14707": "|**2025-12-07**|**Boundaries in Hypernetwork Theory: Structure and Scope**|Richard D. Charlesworth Team|[2512.14707](http://arxiv.org/abs/2512.14707)|null|\n", "2512.06963": "|**2025-12-07**|**VideoVLA: Video Generators Can Be Generalizable Robot Manipulators**|Baining Guo Team|[2512.06963](http://arxiv.org/abs/2512.06963)|**[link](https://videovla-nips2025.github.io)**|\n", "2512.06905": "|**2025-12-07**|**Scaling Zero-Shot Reference-to-Video Generation**|Sen He Team|[2512.06905](http://arxiv.org/abs/2512.06905)|**[link](https://franciszzj.github.io/Saber/)**|\n", "2512.06866": "|**2025-12-07**|**Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior**|Zhuotao Tian Team|[2512.06866](http://arxiv.org/abs/2512.06866)|null|\n", "2512.06864": "|**2025-12-07**|**Boosting Unsupervised Video Instance Segmentation with Automatic Quality-Guided Self-Training**|Dim P. Papadopoulos Team|[2512.06864](http://arxiv.org/abs/2512.06864)|null|\n", "2512.06845": "|**2025-12-07**|**Pseudo Anomalies Are All You Need: Diffusion-Based Generation for Weakly-Supervised Video Anomaly Detection**|Mori Kurokawa Team|[2512.06845](http://arxiv.org/abs/2512.06845)|null|\n", "2512.06838": "|**2025-12-07**|**SparseCoop: Cooperative Perception with Kinematic-Grounded Queries**|Jianqiang Wang Team|[2512.06838](http://arxiv.org/abs/2512.06838)|null|\n", "2512.06674": "|**2025-12-07**|**RunawayEvil: Jailbreaking the Image-to-Video Generative Models**|Caifeng Shan Team|[2512.06674](http://arxiv.org/abs/2512.06674)|null|\n", "2512.06673": "|**2025-12-07**|**1 + 1 > 2: Detector-Empowered Video Large Language Model for Spatio-Temporal Grounding and Reasoning**|Nicu Sebe Team|[2512.06673](http://arxiv.org/abs/2512.06673)|null|\n", "2512.06628": "|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Xiu Li Team|[2512.06628](http://arxiv.org/abs/2512.06628)|null|\n", "2512.06505": "|**2025-12-06**|**Amortizing Perpetual Options**|Zachary Feinstein Team|[2512.06505](http://arxiv.org/abs/2512.06505)|null|\n", "2512.06438": "|**2025-12-10**|**AGORA: Adversarial Generation Of Real-time Animatable 3D Gaussian Head Avatars**|Ivan Laptev Team|[2512.06438](http://arxiv.org/abs/2512.06438)|null|\n", "2512.06376": "|**2025-12-06**|**Are AI-Generated Driving Videos Ready for Autonomous Driving? A Diagnostic Evaluation Framework**|Jiawei Zhang Team|[2512.06376](http://arxiv.org/abs/2512.06376)|null|\n", "2512.06230": "|**2025-12-06**|**GPU-GLMB: Assessing the Scalability of GPU-Accelerated Multi-Hypothesis Tracking**|Benjamin M. Marlin Team|[2512.06230](http://arxiv.org/abs/2512.06230)|null|\n", "2512.11869": "|**2025-12-05**|**Temporal-Anchor3DLane: Enhanced 3D Lane Detection with Multi-Task Losses and LSTM Fusion**|K. Muni Team|[2512.11869](http://arxiv.org/abs/2512.11869)|null|\n", "2512.06158": "|**2025-12-05**|**Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation**|Mei Chen Team|[2512.06158](http://arxiv.org/abs/2512.06158)|null|\n", "2512.06065": "|**2025-12-05**|**EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing**|Willi Menapace Team|[2512.06065](http://arxiv.org/abs/2512.06065)|**[link](https://snap-research.github.io/EgoEdit)**|\n", "2512.05927": "|**2025-12-05**|**World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty**|Anirudha Majumdar Team|[2512.05927](http://arxiv.org/abs/2512.05927)|null|\n", "2512.05905": "|**2025-12-05**|**SCAIL: Towards Studio-Grade Character Animation via In-Context Learning of 3D-Consistent Pose Representations**|Jie Tang Team|[2512.05905](http://arxiv.org/abs/2512.05905)|null|\n", "2512.05802": "|**2025-12-10**|**Bring Your Dreams to Life: Continual Text-to-Video Customization**|Fahad Shahbaz Khan Team|[2512.05802](http://arxiv.org/abs/2512.05802)|null|\n", "2512.05774": "|**2025-12-05**|**Active Video Perception: Iterative Evidence Seeking for Agentic Long Video Understanding**|Juan Carlos Niebles Team|[2512.05774](http://arxiv.org/abs/2512.05774)|**[link](https://activevideoperception.github.io/)**|\n", "2512.05754": "|**2025-12-05**|**USV: Unified Sparsification for Accelerating Video Diffusion Models**|Qinglin Lu Team|[2512.05754](http://arxiv.org/abs/2512.05754)|null|\n", "2512.08982": "|**2025-12-05**|**Consist-Retinex: One-Step Noise-Emphasized Consistency Training Accelerates High-Quality Retinex Enhancement**|Qibin Zhao Team|[2512.08982](http://arxiv.org/abs/2512.08982)|null|\n", "2512.05672": "|**2025-12-05**|**InverseCrafter: Efficient Video ReCapture as a Latent Domain Inverse Problem**|Jong Chul Ye Team|[2512.05672](http://arxiv.org/abs/2512.05672)|null|\n", "2512.05564": "|**2025-12-05**|**ProPhy: Progressive Physical Alignment for Dynamic World Simulation**|Xiaodan Liang Team|[2512.05564](http://arxiv.org/abs/2512.05564)|null|\n", "2512.05557": "|**2025-12-05**|**2K-Characters-10K-Stories: A Quality-Gated Stylized Narrative Dataset with Disentangled Control and Sequence Consistency**|Yin Zhang Team|[2512.05557](http://arxiv.org/abs/2512.05557)|null|\n", "2512.05515": "|**2025-12-05**|**DashFusion: Dual-stream Alignment with Hierarchical Bottleneck Fusion for Multimodal Sentiment Analysis**|Ya Li Team|[2512.05515](http://arxiv.org/abs/2512.05515)|null|\n", "2512.05492": "|**2025-12-05**|**WaterWave: Bridging Underwater Image Enhancement into Video Streams via Wavelet-based Temporal Consistency Field**|Feng Zhao Team|[2512.05492](http://arxiv.org/abs/2512.05492)|null|\n", "2512.11860": "|**2025-12-05**|**An Operator-Consistent Graph Neural Network for Learning Diffusion Dynamics on Irregular Meshes**|Andrew Rushing Hands Team|[2512.11860](http://arxiv.org/abs/2512.11860)|null|\n", "2512.05394": "|**2025-12-05**|**Delving into Latent Spectral Biasing of Video VAEs for Superior Diffusability**|Jie Tang Team|[2512.05394](http://arxiv.org/abs/2512.05394)|null|\n", "2512.05240": "|**2025-12-04**|**IE2Video: Adapting Pretrained Diffusion Models for Event-Based Video Reconstruction**|Yihui Ren Team|[2512.05240](http://arxiv.org/abs/2512.05240)|null|\n", "2512.05115": "|**2025-12-15**|**Light-X: Generative 4D Video Rendering with Camera and Illumination Control**|Ziwei Liu Team|[2512.05115](http://arxiv.org/abs/2512.05115)|**[link](https://lightx-ai.github.io/)**|\n", "2512.05106": "|**2025-12-07**|**NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation**|Rowan McAllister Team|[2512.05106](http://arxiv.org/abs/2512.05106)|null|\n", "2512.05103": "|**2025-12-08**|**TV2TV: A Unified Framework for Interleaved Language and Video Generation**|Emily Dinan Team|[2512.05103](http://arxiv.org/abs/2512.05103)|null|\n", "2512.05094": "|**2025-12-11**|**From Generated Human Videos to Physically Plausible Robot Trajectories**|Roei Herzig Team|[2512.05094](http://arxiv.org/abs/2512.05094)|**[link](https://genmimic.github.io)**|\n"}, "Memory": {"2512.16822": "|**2025-12-18**|**MEPIC: Memory Efficient Position Independent Caching for LLM Serving**|Zhenan Fan Team|[2512.16822](http://arxiv.org/abs/2512.16822)|null|\n", "2512.16765": "|**2025-12-18**|**Strain-Controlled Magnetic Phase Transitions through Anisotropic Exchange Interactions: A Combined DFT and Monte Carlo Study**|Kalpataru Pradhan Team|[2512.16765](http://arxiv.org/abs/2512.16765)|null|\n", "2512.16727": "|**2025-12-18**|**OMG-Bench: A New Challenging Benchmark for Skeleton-based Online Micro Hand Gesture Recognition**|Erwei Yin Team|[2512.16727](http://arxiv.org/abs/2512.16727)|**[link](https://omg-bench.github.io/)**|\n", "2512.16639": "|**2025-12-18**|**Fully Dynamic Algorithms for Chamfer Distance**|Qiaoyuan Yang Team|[2512.16639](http://arxiv.org/abs/2512.16639)|null|\n", "2512.16413": "|**2025-12-18**|**BrepLLM: Native Boundary Representation Understanding with Large Language Models**|Yilei Shi Team|[2512.16413](http://arxiv.org/abs/2512.16413)|null|\n", "2512.16311": "|**2025-12-18**|**Bunch-by-Bunch Prediction of Beam Transverse Position, Phase, and Length in a Storage Ring Using Neural Networks**|Yongbin Leng Team|[2512.16311](http://arxiv.org/abs/2512.16311)|null|\n", "2512.16179": "|**2025-12-18**|**Local Lyapunov Analysis via Micro-Ensembles: finite-time Lyapunov exponent Estimation and KNN-Based Predictive Comparison in Complex-Valued BAM Neural Networks**|Samidurai Rajendran Team|[2512.16179](http://arxiv.org/abs/2512.16179)|null|\n", "2512.16131": "|**2025-12-18**|**Recent progress in quantum spin liquids, fractional magnetization plateaus, and unconventional superconductivity in kagome lattices**|Jian-Xin Li Team|[2512.16131](http://arxiv.org/abs/2512.16131)|null|\n", "2512.16010": "|**2025-12-17**|**LSTM-MDNz: Estimating Quasar Photometric Redshifts with an LSTM-Augmented Mixture Density Network**|Chenggang Shu Team|[2512.16010](http://arxiv.org/abs/2512.16010)|null|\n", "2512.15891": "|**2025-12-17**|**Dynamical Mechanisms for Coordinating Long-term Working Memory Based on the Precision of Spike-timing in Cortical Neurons**|Terrence J. Sejnowski Team|[2512.15891](http://arxiv.org/abs/2512.15891)|null|\n", "2512.15862": "|**2025-12-17**|**Reusable theory representations for colliders: a demonstrator SMEFT foundation model**|Brandon Kriesten Team|[2512.15862](http://arxiv.org/abs/2512.15862)|null|\n", "2512.15716": "|**2025-12-17**|**Spatia: Video Generation with Updatable Spatial Memory**|Yan Lu Team|[2512.15716](http://arxiv.org/abs/2512.15716)|**[link](https://zhaojingjing713.github.io/Spatia/)**|\n", "2512.15713": "|**2025-12-17**|**DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models**|Xinggang Wang Team|[2512.15713](http://arxiv.org/abs/2512.15713)|null|\n", "2512.15705": "|**2025-12-17**|**Dynamic Rebatching for Efficient Early-Exit Inference with DREX**|Vincent Liu Team|[2512.15705](http://arxiv.org/abs/2512.15705)|null|\n", "2512.15621": "|**2025-12-17**|**OccSTeP: Benchmarking 4D Occupancy Spatio-Temporal Persistence**|Jiaming Zhang Team|[2512.15621](http://arxiv.org/abs/2512.15621)|null|\n", "2512.15829": "|**2025-12-17**|**Human-like Working Memory from Artificial Intrinsic Plasticity Neurons**|Kezhou Yang Team|[2512.15829](http://arxiv.org/abs/2512.15829)|null|\n", "2512.15569": "|**2025-12-17**|**Macroscopic fluctuation theory of interacting Brownian particles**|Olivier B\u00e9nichou Team|[2512.15569](http://arxiv.org/abs/2512.15569)|null|\n", "2512.15550": "|**2025-12-17**|**CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing**|Gang Chen Team|[2512.15550](http://arxiv.org/abs/2512.15550)|null|\n", "2512.15479": "|**2025-12-17**|**Correlations between rare events due to long-term memory**|Thomas Gu\u00e9rin Team|[2512.15479](http://arxiv.org/abs/2512.15479)|null|\n", "2512.15437": "|**2025-12-17**|**Functional renormalization group for extremely correlated electrons**|Andreas R\u00fcckriegel Team|[2512.15437](http://arxiv.org/abs/2512.15437)|null|\n", "2512.15310": "|**2025-12-17**|**SynthSeg-Agents: Multi-Agent Synthetic Data Generation for Zero-Shot Weakly Supervised Semantic Segmentation**|Jimin Xiao Team|[2512.15310](http://arxiv.org/abs/2512.15310)|null|\n", "2512.15231": "|**2025-12-17**|**CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications**|Bing Zhang Team|[2512.15231](http://arxiv.org/abs/2512.15231)|null|\n", "2512.15206": "|**2025-12-17**|**Chorus: Harmonizing Context and Sensing Signals for Data-Free Model Customization in IoT**|Xiaomin Ouyang Team|[2512.15206](http://arxiv.org/abs/2512.15206)|null|\n", "2512.15113": "|**2025-12-17**|**Adaptive Weighted Genetic Algorithm-Optimized SVR for Robust Long-Term Forecasting of Global Stock Indices for investment decisions**|Mohit Beniwal Team|[2512.15113](http://arxiv.org/abs/2512.15113)|null|\n", "2512.15066": "|**2025-12-17**|**Tracking spatial temporal details in ultrasound long video via wavelet analysis and memory bank**|Junchen Wang Team|[2512.15066](http://arxiv.org/abs/2512.15066)|null|\n", "2512.14946": "|**2025-12-16**|**EVICPRESS: Joint KV-Cache Compression and Eviction for Efficient LLM Serving**|Junchen Jiang Team|[2512.14946](http://arxiv.org/abs/2512.14946)|null|\n", "2512.14898": "|**2025-12-16**|**Predicting Forecast Error for the HRRR Using LSTM Neural Networks: A Comparative Study Using New York and Oklahoma State Mesonets**|Lauriana C. Gaudet Team|[2512.14898](http://arxiv.org/abs/2512.14898)|null|\n", "2512.14855": "|**2025-12-16**|**A Roadmap for Applying Graph Neural Networks to Numerical Data: Insights from Cementitious Materials**|Aditya Kumar Team|[2512.14855](http://arxiv.org/abs/2512.14855)|null|\n", "2512.14699": "|**2025-12-16**|**MemFlow: Flowing Adaptive Memory for Consistent and Efficient Long Video Narratives**|Hengshuang Zhao Team|[2512.14699](http://arxiv.org/abs/2512.14699)|**[link](https://sihuiji.github.io/MemFlow.github.io/)**|\n", "2512.14681": "|**2025-12-16**|**Fast and Accurate Causal Parallel Decoding using Jacobi Forcing**|Hao Zhang Team|[2512.14681](http://arxiv.org/abs/2512.14681)|null|\n", "2512.14631": "|**2025-12-16**|**Electrodrying in nanopores: from fundamentals to iontronic and memristive applications**|Alberto Giacomello Team|[2512.14631](http://arxiv.org/abs/2512.14631)|null|\n", "2512.15795": "|**2025-12-16**|**Localization from Infinitesimal Kinetic Grading: Critical Scaling and Kibble-Zurek Universality**|Debraj Rakshit Team|[2512.15795](http://arxiv.org/abs/2512.15795)|null|\n", "2512.14422": "|**2025-12-16**|**Hybrid Ensemble Method for Detecting Cyber-Attacks in Water Distribution Systems Using the BATADAL Dataset**|Waqas Ahmed Team|[2512.14422](http://arxiv.org/abs/2512.14422)|null|\n", "2512.14400": "|**2025-12-16**|**GRAFT: Grid-Aware Load Forecasting with Multi-Source Textual Alignment and Fusion**|Jinsong Tao Team|[2512.14400](http://arxiv.org/abs/2512.14400)|null|\n", "2512.14391": "|**2025-12-16**|**RePo: Language Models with Context Re-Positioning**|Richard Sproat Team|[2512.14391](http://arxiv.org/abs/2512.14391)|null|\n", "2512.14222": "|**2025-12-17**|**History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation**|Jie Qin Team|[2512.14222](http://arxiv.org/abs/2512.14222)|null|\n", "2512.14149": "|**2025-12-18**|**A sine-square deformation approach to quantum critical points in one-dimensional systems**|Daisuke Yamamoto Team|[2512.14149](http://arxiv.org/abs/2512.14149)|null|\n", "2512.14142": "|**2025-12-16**|**Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents**|Haisheng Tan Team|[2512.14142](http://arxiv.org/abs/2512.14142)|null|\n", "2512.14118": "|**2025-12-16**|**CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models**|Usman Naseem Team|[2512.14118](http://arxiv.org/abs/2512.14118)|null|\n", "2512.14067": "|**2025-12-16**|**Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed**|Pavlo Molchanov Team|[2512.14067](http://arxiv.org/abs/2512.14067)|null|\n", "2512.13944": "|**2025-12-15**|**Low-rank Covariate Balancing Estimators under Interference**|Georgia Papadogeorgou Team|[2512.13944](http://arxiv.org/abs/2512.13944)|null|\n", "2512.13910": "|**2025-12-15**|**Exploring Machine Learning, Deep Learning, and Explainable AI Methods for Seasonal Precipitation Prediction in South America**|Andr\u00e9 Estevam Costa Oliveira Team|[2512.13910](http://arxiv.org/abs/2512.13910)|null|\n", "2512.13902": "|**2025-12-15**|**KLO-Net: A Dynamic K-NN Attention U-Net with CSP Encoder for Efficient Prostate Gland Segmentation from MRI**|Jeongkyu Lee Team|[2512.13902](http://arxiv.org/abs/2512.13902)|null|\n", "2512.13668": "|**2025-12-15**|**A Scientific Reasoning Model for Organic Synthesis Procedure Generation**|Marwin Segler Team|[2512.13668](http://arxiv.org/abs/2512.13668)|null|\n", "2512.13632": "|**2025-12-15**|**StutterFuse: Mitigating Modality Collapse in Stuttering Detection with Jaccard-Weighted Metric Learning and Gated Fusion**|Md Shah Fahad Team|[2512.13632](http://arxiv.org/abs/2512.13632)|null|\n", "2512.13586": "|**2025-12-15**|**ReFusion: A Diffusion Large Language Model with Parallel Autoregressive Decoding**|Chongxuan Li Team|[2512.13586](http://arxiv.org/abs/2512.13586)|null|\n", "2512.13564": "|**2025-12-15**|**Memory in the Age of AI Agents**|Shuicheng Yan Team|[2512.13564](http://arxiv.org/abs/2512.13564)|null|\n", "2512.13540": "|**2025-12-15**|**The classical-quantum disproportionation transition and magnetic ordering in RNiO$_3$ nickelates**|Yu. D. Panov Team|[2512.13540](http://arxiv.org/abs/2512.13540)|**[link](https://journals.ioffe.ru/articles/61709)**|\n", "2512.13529": "|**2025-12-15**|**Enhancing lithological interpretation from petrophysical well log of IODP expedition 390/393 using machine learning**|Saumen Maiti Team|[2512.13529](http://arxiv.org/abs/2512.13529)|null|\n", "2512.13401": "|**2025-12-15**|**Riemannian gradient descent-based quantum algorithms for ground state preparation with guarantees**|Christian Arenz Team|[2512.13401](http://arxiv.org/abs/2512.13401)|null|\n", "2512.13250": "|**2025-12-15**|**Toward Ambulatory Vision: Learning Visually-Grounded Active View Selection**|Minhyuk Sung Team|[2512.13250](http://arxiv.org/abs/2512.13250)|**[link](https://active-view-selection.github.io/)**|\n", "2512.13227": "|**2025-12-15**|**Better LMO-based Momentum Methods with Second-Order Information**|Peter Richt\u00e1rik Team|[2512.13227](http://arxiv.org/abs/2512.13227)|null|\n", "2512.13055": "|**2025-12-15**|**Towards Test-time Efficient Visual Place Recognition via Asymmetric Query Processing**|Sung-Eui Yoon Team|[2512.13055](http://arxiv.org/abs/2512.13055)|null|\n", "2512.13031": "|**2025-12-15**|**Comprehensive Evaluation of Rule-Based, Machine Learning, and Deep Learning in Human Estimation Using Radio Wave Sensing: Accuracy, Spatial Generalization, and Output Granularity Trade-offs**|Ryo Yonemoto Team|[2512.13031](http://arxiv.org/abs/2512.13031)|null|\n", "2512.13019": "|**2025-12-15**|**SneakPeek: Future-Guided Instructional Streaming Video Generation**|Albert Pumarola Team|[2512.13019](http://arxiv.org/abs/2512.13019)|null|\n", "2512.13751": "|**2025-12-15**|**MIDUS: Memory-Infused Depth Up-Scaling**|Kyungwoo Song Team|[2512.13751](http://arxiv.org/abs/2512.13751)|null|\n", "2512.12977": "|**2025-12-18**|**VLCache: Computing 2% Vision Tokens and Reusing 98% for Vision-Language Inference**|Junyang Lin Team|[2512.12977](http://arxiv.org/abs/2512.12977)|null|\n", "2512.12945": "|**2025-12-15**|**SLIM-VDB: A Real-Time 3D Probabilistic Semantic Mapping Framework**|Katherine A. Skinner Team|[2512.12945](http://arxiv.org/abs/2512.12945)|null|\n", "2512.12860": "|**2025-12-14**|**Learning with Structure: Computing Consistent Subsets on Structurally-Regular Graphs**|Abhishek Sahu Team|[2512.12860](http://arxiv.org/abs/2512.12860)|null|\n", "2512.12832": "|**2025-12-14**|**Network Level Evaluation of Hangup Susceptibility of HRGCs using Deep Learning and Sensing Techniques: A Goal Towards Safer Future**|Jared Schwennesen Team|[2512.12832](http://arxiv.org/abs/2512.12832)|null|\n", "2512.12818": "|**2025-12-14**|**Hindsight is 20/20: Building Agent Memory that Retains, Recalls, and Reflects**|Naren Ramakrishnan Team|[2512.12818](http://arxiv.org/abs/2512.12818)|null|\n", "2512.12809": "|**2025-12-14**|**OPAL: Operator-Programmed Algorithms for Landscape-Aware Black-Box Optimization**|Huiling Chen Team|[2512.12809](http://arxiv.org/abs/2512.12809)|**[link](https://github.com/junbolian/OPAL.)**|\n", "2512.12786": "|**2025-12-14**|**Solar Energetic Particle Forecasting with Multi-Task Deep Learning: SEPNet**|Tamas Gombosi Team|[2512.12786](http://arxiv.org/abs/2512.12786)|null|\n", "2512.12767": "|**2025-12-14**|**Random matrix theory of sparse neuronal networks with heterogeneous timescales**|Weerawit Horinouchi Team|[2512.12767](http://arxiv.org/abs/2512.12767)|null|\n", "2512.15779": "|**2025-12-14**|**Hyperparameter Tuning-Based Optimized Performance Analysis of Machine Learning Algorithms for Network Intrusion Detection**|Bichitrananda Behera Team|[2512.15779](http://arxiv.org/abs/2512.15779)|null|\n", "2512.15777": "|**2025-12-14**|**Variable Record Table: A Unified Hardware-Assisted Framework for Runtime Security**|Love Kumar Sah Team|[2512.15777](http://arxiv.org/abs/2512.15777)|null|\n", "2512.12574": "|**2025-12-14**|**Mind the Jumps: A Scalable Robust Local Gaussian Process for Multidimensional Response Surfaces with Discontinuities**|Yiyuan She Team|[2512.12574](http://arxiv.org/abs/2512.12574)|null|\n", "2512.12499": "|**2025-12-13**|**Explainable Prediction of Economic Time Series Using IMFs and Neural Networks**|Agust\u00edn Garc\u00eda-Garc\u00eda Team|[2512.12499](http://arxiv.org/abs/2512.12499)|null|\n", "2512.12493": "|**2025-12-13**|**AI-Driven Early Warning Systems for Student Success: Discovering Static Feature Dominance in Temporal Prediction Models**|Rajib Mall Team|[2512.12493](http://arxiv.org/abs/2512.12493)|null|\n", "2512.12458": "|**2025-12-13**|**Breaking the Curse of Dimensionality: On the Stability of Modern Vector Retrieval**|Benjamin Coleman Team|[2512.12458](http://arxiv.org/abs/2512.12458)|null|\n", "2512.12398": "|**2025-12-13**|**Scalable Spatial Stream Network (S3N) Models**|Tyler H. McCormick Team|[2512.12398](http://arxiv.org/abs/2512.12398)|null|\n", "2512.12284": "|**2025-12-13**|**V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval**|Joo-Young Kim Team|[2512.12284](http://arxiv.org/abs/2512.12284)|null|\n", "2512.12250": "|**2025-12-13**|**Stochastic Volatility Modelling with LSTM Networks: A Hybrid Approach for S&P 500 Index Volatility Forecasting**|Robert \u015alepaczuk Team|[2512.12250](http://arxiv.org/abs/2512.12250)|null|\n", "2512.12228": "|**2025-12-13**|**Semantic Zone based 3D Map Management for Mobile Robot**|Seungho Yoo Team|[2512.12228](http://arxiv.org/abs/2512.12228)|null|\n", "2512.12184": "|**2025-12-13**|**DCAF-Net: Dual-Channel Attentive Fusion Network for Lower Limb Motion Intention Prediction in Stroke Rehabilitation Exoskeletons**|Xin Ma Team|[2512.12184](http://arxiv.org/abs/2512.12184)|null|\n", "2512.12183": "|**2025-12-13**|**HydroDiffusion: Diffusion-Based Probabilistic Streamflow Forecasting with a State Space Backbone**|N. Benjamin Erichson Team|[2512.12183](http://arxiv.org/abs/2512.12183)|null|\n", "2512.12104": "|**2025-12-13**|**Self-Consistent Renormalized Spin-Wave Theory of Magnetic and Topological Transitions in Two-Dimensional Honeycomb Ferromagnets**|Chien-Te Wu Team|[2512.12104](http://arxiv.org/abs/2512.12104)|null|\n", "2512.12008": "|**2025-12-12**|**Hold Onto That Thought: Assessing KV Cache Compression On Reasoning**|Kunpeng Zhang Team|[2512.12008](http://arxiv.org/abs/2512.12008)|null|\n", "2512.12002": "|**2025-12-12**|**Adversarial Attacks Against Deep Learning-Based Radio Frequency Fingerprint Identification**|Chip-Hong Chang Team|[2512.12002](http://arxiv.org/abs/2512.12002)|null|\n", "2512.11756": "|**2025-12-12**|**CNOT gates in inductively coupled multi-fluxonium systems**|Maxim G. Vavilov Team|[2512.11756](http://arxiv.org/abs/2512.11756)|null|\n", "2512.11744": "|**2025-12-12**|**The low-mass and structured stellar halo of M83 argues against a merger origin for its starburst and extended neutral hydrogen disk**|Adam Smercina Team|[2512.11744](http://arxiv.org/abs/2512.11744)|**[link](https://doi.org/10.5281/zenodo.17398573)**|\n", "2512.11550": "|**2025-12-12**|**PD-Swap: Prefill-Decode Logic Swapping for End-to-End LLM Inference on Edge FPGAs via Dynamic Partial Reconfiguration**|Sitao Huang Team|[2512.11550](http://arxiv.org/abs/2512.11550)|null|\n", "2512.11529": "|**2025-12-12**|**xGR: Efficient Generative Recommendation Serving at Scale**|Hailong Yang Team|[2512.11529](http://arxiv.org/abs/2512.11529)|null|\n", "2512.11941": "|**2025-12-12**|**DynaPURLS: Dynamic Refinement of Part-aware Representations for Skeleton-based Zero-Shot Action Recognition**|Qiuhong Ke Team|[2512.11941](http://arxiv.org/abs/2512.11941)|null|\n", "2512.11334": "|**2025-12-12**|**Spectral entropy prior-guided deep feature fusion architecture for magnetic core loss**|Jin Zhang Team|[2512.11334](http://arxiv.org/abs/2512.11334)|null|\n", "2512.11303": "|**2025-12-12**|**Unifying Dynamic Tool Creation and Cross-Task Experience Sharing through Cognitive Memory Architecture**|Peng Cao Team|[2512.11303](http://arxiv.org/abs/2512.11303)|null|\n", "2512.11229": "|**2025-12-12**|**REST: Diffusion-based Real-time End-to-end Streaming Talking Head Generation via ID-Context Caching and Asynchronous Streaming Distillation**|Qingfeng Liu Team|[2512.11229](http://arxiv.org/abs/2512.11229)|null|\n", "2512.11221": "|**2025-12-12**|**Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery: Sublinear Memory Growth for Efficient LLM Inference**|Gulnara D. Kabaeva Team|[2512.11221](http://arxiv.org/abs/2512.11221)|null|\n", "2512.11203": "|**2025-12-15**|**AutoRefiner: Improving Autoregressive Video Diffusion Models via Reflective Refinement Over the Stochastic Sampling Path**|Yuki Mitsufuji Team|[2512.11203](http://arxiv.org/abs/2512.11203)|null|\n", "2512.10755": "|**2025-12-11**|**Phase structure of the one-dimensional $\\mathbb{Z}_2$ lattice gauge theory with second nearest-neighbor interactions**|Agnieszka Cichy Team|[2512.10755](http://arxiv.org/abs/2512.10755)|null|\n", "2512.11920": "|**2025-12-11**|**CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving**|Yanxuan Yu Team|[2512.11920](http://arxiv.org/abs/2512.11920)|null|\n", "2512.10626": "|**2025-12-11**|**Deep Photonic Reservoir Computing with On-chip Nonlinearity**|Xuhan Guo Team|[2512.10626](http://arxiv.org/abs/2512.10626)|null|\n", "2512.10577": "|**2025-12-11**|**Binding of holes and competing spin-charge order in simple and extended Hubbard model on cylindrical lattice: An exact diagonalization study**|M. A. H. Ahsan Team|[2512.10577](http://arxiv.org/abs/2512.10577)|null|\n", "2512.10547": "|**2025-12-11**|**Unlocking the Address Book: Dissecting the Sparse Semantic Structure of LLM Key-Value Caches via Sparse Autoencoders**|Zhaofeng He Team|[2512.10547](http://arxiv.org/abs/2512.10547)|null|\n", "2512.10477": "|**2025-12-14**|**Symphony: A Heuristic Normalized Calibrated Advantage Actor and Critic Algorithm in application for Humanoid Robots**|J\u00f3zsef Dombi Team|[2512.10477](http://arxiv.org/abs/2512.10477)|**[link](https://github.com/SuspensionRailway/symphony)**|\n", "2512.10441": "|**2025-12-11**|**Decoding Student Minds: Leveraging Conversational Agents for Psychological and Learning Analysis**|Laid Kahloul Team|[2512.10441](http://arxiv.org/abs/2512.10441)|null|\n", "2512.10431": "|**2025-12-11**|**A Sampling Strategy Benchmark for Machine-Learning-Based Seismic Liquefaction Prediction**|Qianfeng Wang Team|[2512.10431](http://arxiv.org/abs/2512.10431)|null|\n", "2512.10398": "|**2025-12-17**|**Confucius Code Agent: Scalable Agent Scaffolding for Real-World Codebases**|Ying Zhang Team|[2512.10398](http://arxiv.org/abs/2512.10398)|null|\n", "2512.10386": "|**2025-12-11**|**Adaptive Dual-Weighted Gravitational Point Cloud Denoising Method**|Bin Liu Team|[2512.10386](http://arxiv.org/abs/2512.10386)|null|\n", "2512.10322": "|**2025-12-11**|**User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation**|Xiaojun Chang Team|[2512.10322](http://arxiv.org/abs/2512.10322)|null|\n", "2512.10254": "|**2025-12-11**|**Peace Sells, But Whose Songs Connect? Bayesian Multilayer Network Analysis of the Big 4 of Thrash Metal**|Danna L. Cruz-Reyes Team|[2512.10254](http://arxiv.org/abs/2512.10254)|null|\n", "2512.10252": "|**2025-12-11**|**GDKVM: Echocardiography Video Segmentation via Spatiotemporal Key-Value Memory with Gated Delta Rule**|Jing Qin Team|[2512.10252](http://arxiv.org/abs/2512.10252)|null|\n", "2512.10052": "|**2025-12-10**|**Spin-phonon interactions revisited: Far-infrared emission, Raman scattering, and high-resolution x-ray diffraction at the N\u00e9el temperature in LaFeO3**|Jos\u00e9 Antonio Alonso Team|[2512.10052](http://arxiv.org/abs/2512.10052)|null|\n", "2512.09835": "|**2025-12-10**|**Predicting the Containment Time of California Wildfires Using Machine Learning**|Shashank Bhardwaj Team|[2512.09835](http://arxiv.org/abs/2512.09835)|null|\n", "2512.09810": "|**2025-12-10**|**Incorporating Fairness in Neighborhood Graphs for Fair Spectral Clustering**|Bhanu Prasad Team|[2512.09810](http://arxiv.org/abs/2512.09810)|null|\n", "2512.09565": "|**2025-12-10**|**From Graphs to Gates: DNS-HyXNet, A Lightweight and Deployable Sequential Model for Real-Time DNS Tunnel Detection**|Muzammil Behzad Team|[2512.09565](http://arxiv.org/abs/2512.09565)|null|\n", "2512.09458": "|**2025-12-10**|**Architectures for Building Agentic AI**|S\u0142awomir Nowaczyk Team|[2512.09458](http://arxiv.org/abs/2512.09458)|null|\n", "2512.09360": "|**2025-12-10**|**A Granular Framework for Construction Material Price Forecasting: Econometric and Machine-Learning Approaches**|Junzhe Shi Team|[2512.09360](http://arxiv.org/abs/2512.09360)|null|\n", "2512.09331": "|**2025-12-10**|**Passing the Baton: High Throughput Distributed Disk-Based Vector Search with BatANN**|Ken Birman Team|[2512.09331](http://arxiv.org/abs/2512.09331)|null|\n", "2512.09238": "|**2025-12-10**|**Training-free Context-adaptive Attention for Efficient Long Context Modeling**|Mingkui Tan Team|[2512.09238](http://arxiv.org/abs/2512.09238)|null|\n", "2512.09032": "|**2025-12-09**|**Optimizing Photometric Redshift Training Sets I: Efficient Compression of the Galaxy Color-Redshift Relation with UMAP**|S. A. Stanford Team|[2512.09032](http://arxiv.org/abs/2512.09032)|**[link](https://finianashmead.github.io/#umap-cosmos2020-video.)**|\n", "2512.08829": "|**2025-12-09**|**InfiniteVL: Synergizing Linear and Sparse Attention for Highly-Efficient, Unlimited-Input Vision-Language Models**|Xinggang Wang Team|[2512.08829](http://arxiv.org/abs/2512.08829)|null|\n", "2512.08814": "|**2025-12-09**|**Ask, Answer, and Detect: Role-Playing LLMs for Personality Detection with Question-Conditioned Mixture-of-Experts**|Liang Zhang Team|[2512.08814](http://arxiv.org/abs/2512.08814)|null|\n", "2512.08699": "|**2025-12-09**|**An Additive Manufacturing Part Qualification Framework: Transferring Knowledge of Stress-strain Behaviors from Additively Manufactured Polymers to Metals**|Dazhong Wu Team|[2512.08699](http://arxiv.org/abs/2512.08699)|null|\n", "2512.08691": "|**2025-12-09**|**Order parameter for non-mean-field spin glasses**|Michele Castellana Team|[2512.08691](http://arxiv.org/abs/2512.08691)|null|\n", "2512.08648": "|**2025-12-13**|**Repulsor: Accelerating Generative Modeling with a Contrastive Memory Bank**|Junchi Yan Team|[2512.08648](http://arxiv.org/abs/2512.08648)|null|\n", "2512.14723": "|**2025-12-09**|**MS-Index: Fast Top-k Subsequence Search for Multivariate Time Series under Euclidean Distance**|Themis Palpanas Team|[2512.14723](http://arxiv.org/abs/2512.14723)|null|\n", "2512.08591": "|**2025-12-09**|**Long-Sequence LSTM Modeling for NBA Game Outcome Prediction Using a Novel Multi-Season Dataset**|Nikolaos Polatidis Team|[2512.08591](http://arxiv.org/abs/2512.08591)|null|\n", "2512.08340": "|**2025-12-13**|**Predicting California Bearing Ratio with Ensemble and Neural Network Models: A Case Study from Turkiye**|Caner Erden Team|[2512.08340](http://arxiv.org/abs/2512.08340)|null|\n", "2512.08089": "|**2025-12-08**|**NysX: An Accurate and Energy-Efficient FPGA Accelerator for Hyperdimensional Graph Classification at the Edge**|Viktor Prasanna Team|[2512.08089](http://arxiv.org/abs/2512.08089)|null|\n", "2512.07993": "|**2025-12-08**|**SkipKV: Selective Skipping of KV Generation and Storage for Efficient Inference with Large Reasoning Models**|Souvik Kundu Team|[2512.07993](http://arxiv.org/abs/2512.07993)|null|\n", "2512.07705": "|**2025-12-08**|**In-Context and Few-Shots Learning for Forecasting Time Series Data based on Large Language Models**|Akbar Siami Namin Team|[2512.07705](http://arxiv.org/abs/2512.07705)|null|\n", "2512.07173": "|**2025-12-08**|**Improving the Throughput of Diffusion-based Large Language Models via a Training-Free Confidence-Aware Calibration**|Souvik Kundu Team|[2512.07173](http://arxiv.org/abs/2512.07173)|null|\n", "2512.07165": "|**2025-12-08**|**MuSASplat: Efficient Sparse-View 3D Gaussian Splats via Lightweight Multi-Scale Adaptation**|Shijian Lu Team|[2512.07165](http://arxiv.org/abs/2512.07165)|null|\n", "2512.06993": "|**2025-12-07**|**Toward Reliable Machine Unlearning: Theory, Algorithms, and Evaluation**|Ali Ebrahimpour-Boroojeny Team|[2512.06993](http://arxiv.org/abs/2512.06993)|null|\n", "2512.06966": "|**2025-12-07**|**Neuro-Vesicles: Neuromodulation Should Be a Dynamical System, Not a Tensor Decoration**|Vicki Kane Team|[2512.06966](http://arxiv.org/abs/2512.06966)|null|\n", "2512.09946": "|**2025-12-07**|**ELANA: A Simple Energy and Latency Analyzer for LLMs**|Diana Marculescu Team|[2512.09946](http://arxiv.org/abs/2512.09946)|null|\n", "2512.06932": "|**2025-12-07**|**Hidden Leaks in Time Series Forecasting: How Data Leakage Affects LSTM Evaluation Across Configurations and Validation Strategies**|Moataz Ahmed Team|[2512.06932](http://arxiv.org/abs/2512.06932)|null|\n", "2512.06926": "|**2025-12-07**|**Evaluating the Sensitivity of BiLSTM Forecasting Models to Sequence Length and Input Noise**|Moataz Ahmed Team|[2512.06926](http://arxiv.org/abs/2512.06926)|null|\n", "2512.06869": "|**2025-12-07**|**Rhea: Role-aware Heuristic Episodic Attention for Conversational LLMs**|Dongsheng Li Team|[2512.06869](http://arxiv.org/abs/2512.06869)|null|\n", "2512.06736": "|**2025-12-07**|**Graph Convolutional Long Short-Term Memory Attention Network for Post-Stroke Compensatory Movement Detection Based on Skeleton Data**|Jichen Zhang Team|[2512.06736](http://arxiv.org/abs/2512.06736)|null|\n", "2512.06727": "|**2025-12-07**|**KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models**|Anand Raghunathan Team|[2512.06727](http://arxiv.org/abs/2512.06727)|null|\n", "2512.06636": "|**2025-12-07**|**Distribution-Aware Exploration for Adaptive HNSW Search**|Ren\u00e9e J. Miller Team|[2512.06636](http://arxiv.org/abs/2512.06636)|null|\n", "2512.06362": "|**2025-12-06**|**A 33.6-136.2 TOPS/W Nonlinear Analog Computing-In-Memory Macro for Multi-bit LSTM Accelerator in 65 nm CMOS**|Arindam Basu Team|[2512.06362](http://arxiv.org/abs/2512.06362)|null|\n", "2512.06316": "|**2025-12-06**|**Revealing Hidden Repeaters in the CHIME/FRB Catalog: Semi-Supervised Insights into the Fast Radio Burst Population**|S. Sanpa-arsa Team|[2512.06316](http://arxiv.org/abs/2512.06316)|null|\n", "2512.06270": "|**2025-12-06**|**Contextual Strongly Convex Simulation Optimization: Optimize then Predict with Inexact Solutions**|L. Jeff Hong Team|[2512.06270](http://arxiv.org/abs/2512.06270)|null|\n", "2512.06200": "|**2025-12-05**|**How Should We Evaluate Data Deletion in Graph-Based ANN Indexes?**|Yusuke Matsui Team|[2512.06200](http://arxiv.org/abs/2512.06200)|null|\n", "2512.05916": "|**2025-12-05**|**KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity**|Guillaume Rabusseau Team|[2512.05916](http://arxiv.org/abs/2512.05916)|null|\n", "2512.05893": "|**2025-12-05**|**NeuroMemFPP: A recurrent neural approach for memory-aware parameter estimation in fractional Poisson process**|Aditya Maheshwari Team|[2512.05893](http://arxiv.org/abs/2512.05893)|null|\n", "2512.05657": "|**2025-12-05**|**Over-the-Air Semantic Alignment with Stacked Intelligent Metasurfaces**|Paolo Di Lorenzo Team|[2512.05657](http://arxiv.org/abs/2512.05657)|null|\n", "2512.05109": "|**2025-12-04**|**Global phase diagram of two-dimensional dirty hyperbolic Dirac liquids**|Bitan Roy Team|[2512.05109](http://arxiv.org/abs/2512.05109)|null|\n", "2512.05081": "|**2025-12-04**|**Deep Forcing: Training-Free Long Video Generation with Deep Sink and Participative Compression**|Seungryong Kim Team|[2512.05081](http://arxiv.org/abs/2512.05081)|**[link](https://cvlab-kaist.github.io/DeepForcing/)**|\n", "2512.05058": "|**2025-12-04**|**Meta-Learning for Quantum Optimization via Quantum Sequence Model**|Samuel Yen-Chi Chen Team|[2512.05058](http://arxiv.org/abs/2512.05058)|null|\n", "2512.05049": "|**2025-12-04**|**QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory**|Hsi-Sheng Goan Team|[2512.05049](http://arxiv.org/abs/2512.05049)|null|\n", "2512.05014": "|**2025-12-13**|**Transverse response from anisotropic Fermi surfaces**|Abhiram Soori Team|[2512.05014](http://arxiv.org/abs/2512.05014)|null|\n", "2512.04996": "|**2025-12-04**|**A dynamic memory assignment strategy for dilation-based ICP algorithm on embedded GPUs**|Jun Miyazaki Team|[2512.04996](http://arxiv.org/abs/2512.04996)|null|\n", "2512.11851": "|**2025-12-04**|**KV Cache Recycling to Expand Usable Context Capacity in Low Parameter LLMs**|Prashant Pandey Team|[2512.11851](http://arxiv.org/abs/2512.11851)|null|\n", "2512.04857": "|**2025-12-04**|**Autoregressive Image Generation Needs Only a Few Lines of Cached Tokens**|Weiyao Lin Team|[2512.04857](http://arxiv.org/abs/2512.04857)|null|\n", "2512.04808": "|**2025-12-04**|**Setting up for failure: automatic discovery of the neural mechanisms of cognitive errors**|M\u00e1t\u00e9 Lengyel Team|[2512.04808](http://arxiv.org/abs/2512.04808)|null|\n", "2512.05159": "|**2025-12-04**|**Stellis: A Strategy Language for Purifying Separation Logic Entailments**|Zhenjiang Hu Team|[2512.05159](http://arxiv.org/abs/2512.05159)|null|\n", "2512.04540": "|**2025-12-16**|**VideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management**|Sijie Cheng Team|[2512.04540](http://arxiv.org/abs/2512.04540)|null|\n", "2512.04515": "|**2025-12-04**|**EgoLCD: Egocentric Video Generation with Long Context Diffusion**|Hao Tang Team|[2512.04515](http://arxiv.org/abs/2512.04515)|null|\n", "2512.04507": "|**2025-12-04**|**Collective vibrational resonance and mode selection in nonlinear resonator arrays**|Asesh Roy Chowdhury Team|[2512.04507](http://arxiv.org/abs/2512.04507)|null|\n", "2512.04476": "|**2025-12-04**|**Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems**|Liu Liu Team|[2512.04476](http://arxiv.org/abs/2512.04476)|null|\n", "2512.04183": "|**2025-12-03**|**PINN vs LSTM: A Comparative Study for Steam Temperature Control in Heat Recovery Steam Generators**|Mahdi Aliyari Shoorehdeli Team|[2512.04183](http://arxiv.org/abs/2512.04183)|null|\n", "2512.04145": "|**2025-12-03**|**Minuet: A Diffusion Autoencoder for Compact Semantic Compression of Multi-Band Galaxy Images**|V. A. Villar Team|[2512.04145](http://arxiv.org/abs/2512.04145)|null|\n", "2512.04040": "|**2025-12-03**|**RELIC: Interactive Video World Model with Long-Horizon Memory**|Hao Tan Team|[2512.04040](http://arxiv.org/abs/2512.04040)|null|\n", "2512.05153": "|**2025-12-03**|**Single-walled carbon nanotubes: the Bloch theory, reciprocal tubes, and a tight-binding approximation**|Yuri A. Antipov Team|[2512.05153](http://arxiv.org/abs/2512.05153)|null|\n", "2512.03939": "|**2025-12-03**|**MUT3R: Motion-aware Updating Transformer for Dynamic 3D Reconstruction**|Jingchuan Wang Team|[2512.03939](http://arxiv.org/abs/2512.03939)|null|\n", "2512.03870": "|**2025-12-03**|**Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers**|Bo Zheng Team|[2512.03870](http://arxiv.org/abs/2512.03870)|null|\n", "2512.03627": "|**2025-12-03**|**MemVerse: Multimodal Memory for Lifelong Learning Agents**|Ding Wang Team|[2512.03627](http://arxiv.org/abs/2512.03627)|null|\n", "2512.11833": "|**2025-12-03**|**Soft Decision Tree classifier: explainable and extendable PyTorch implementation**|Reuben R Shamir Team|[2512.11833](http://arxiv.org/abs/2512.11833)|null|\n", "2512.03608": "|**2025-12-03**|**KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing**|Weiwei Shan Team|[2512.03608](http://arxiv.org/abs/2512.03608)|null|\n", "2512.03526": "|**2025-12-03**|**Stretched Exponential Scaling of Parity-Restricted Energy Gaps in a Random Transverse-Field Ising Model**|Y. -K. Wu Team|[2512.03526](http://arxiv.org/abs/2512.03526)|null|\n", "2512.03510": "|**2025-12-03**|**CSMapping: Scalable Crowdsourced Semantic Mapping and Topology Inference for Autonomous Driving**|Shaojie Shen Team|[2512.03510](http://arxiv.org/abs/2512.03510)|null|\n", "2512.03423": "|**2025-12-03**|**Engineering photonic dispersion relation and atomic dynamics in waveguide QED setup via long-range hoppings**|Liantuan Xiao Team|[2512.03423](http://arxiv.org/abs/2512.03423)|null|\n", "2512.03397": "|**2025-12-04**|**Surfel-LIO: Fast LiDAR-Inertial Odometry with Pre-computed Surfels and Hierarchical Z-order Voxel Hashing**|Tae-Wan Kim Team|[2512.03397](http://arxiv.org/abs/2512.03397)|null|\n", "2512.03356": "|**2025-12-03**|**Immunity memory-based jailbreak detection: multi-agent adaptive guard for large language models**|Xi Zhang Team|[2512.03356](http://arxiv.org/abs/2512.03356)|null|\n", "2512.03324": "|**2025-12-03**|**Cache What Lasts: Token Retention for Memory-Bounded KV Cache in LLMs**|Rex Ying Team|[2512.03324](http://arxiv.org/abs/2512.03324)|null|\n", "2512.02947": "|**2025-12-02**|**Representation of Inorganic Synthesis Reactions and Prediction: Graphical Framework and Datasets**|Simon J. L. Billinge Team|[2512.02947](http://arxiv.org/abs/2512.02947)|**[link](https://github.com/8bitsam/actiongraph-testbench)**|\n", "2512.02777": "|**2025-12-02**|**CogDrive: Cognition-Driven Multimodal Prediction-Planning Fusion for Safe Autonomy**|Jianqiang Wang Team|[2512.02777](http://arxiv.org/abs/2512.02777)|null|\n", "2512.02775": "|**2025-12-02**|**Intrinsic Second-Order Topological Superconductors with Tunable Majorana Zero Modes**|Zhongbo Yan Team|[2512.02775](http://arxiv.org/abs/2512.02775)|null|\n", "2512.02644": "|**2025-12-02**|**On the relationship between Heider links and Ising spins**|Krzysztof Ku\u0142akowski Team|[2512.02644](http://arxiv.org/abs/2512.02644)|null|\n", "2512.02623": "|**2025-12-02**|**High-harmonic generation from two weakly coupled molecules: a simple tight-binding model**|Dieter Bauer Team|[2512.02623](http://arxiv.org/abs/2512.02623)|null|\n", "2512.02458": "|**2025-12-02**|**Vision to Geometry: 3D Spatial Memory for Sequential Embodied MLLM Reasoning and Exploration**|Yu Kong Team|[2512.02458](http://arxiv.org/abs/2512.02458)|null|\n", "2512.02425": "|**2025-12-02**|**WorldMM: Dynamic Multimodal Memory Agent for Long Video Reasoning**|Sung Ju Hwang Team|[2512.02425](http://arxiv.org/abs/2512.02425)|**[link](https://worldmm.github.io)**|\n", "2512.02406": "|**2025-12-02**|**Dynamic Configuration of On-Street Parking Spaces using Multi Agent Reinforcement Learning**|Shanika Karunasekera Team|[2512.02406](http://arxiv.org/abs/2512.02406)|null|\n", "2512.01953": "|**2025-12-01**|**KV Pareto: Systems-Level Optimization of KV Cache and Model Compression for Long Context Inference**|Elliott Delaye Team|[2512.01953](http://arxiv.org/abs/2512.01953)|null|\n", "2512.01889": "|**2025-12-01**|**KM-ViPE: Online Tightly Coupled Vision-Language-Geometry Fusion for Open-Vocabulary Semantic SLAM**|Sergey Kolyubin Team|[2512.01889](http://arxiv.org/abs/2512.01889)|null|\n", "2512.01781": "|**2025-12-01**|**Efficient Time Evolution of 2D Open-Quantum Lattice Models with Long-Range Interactions using Tensor Networks**|Marzena H. Szyma\u0144ska Team|[2512.01781](http://arxiv.org/abs/2512.01781)|null|\n", "2512.01710": "|**2025-12-04**|**MMAG: Mixed Memory-Augmented Generation for Large Language Models Applications**|Stefano Zeppieri Team|[2512.01710](http://arxiv.org/abs/2512.01710)|null|\n", "2512.01666": "|**2025-12-01**|**Demystifying Feature Engineering in Malware Analysis of API Call Sequences**|Zhi Li Team|[2512.01666](http://arxiv.org/abs/2512.01666)|null|\n", "2512.01626": "|**2025-12-01**|**Parallel Delayed Memory Units for Enhanced Temporal Modeling in Biomedical and Bioacoustic Signal Analysis**|Dick Botteldooren Team|[2512.01626](http://arxiv.org/abs/2512.01626)|null|\n", "2512.01513": "|**2025-12-01**|**Dynamic functional brain connectivity results depend on modeling assumptions: comparing frequentist and Bayesian hypothesis tests**|Max Hinne Team|[2512.01513](http://arxiv.org/abs/2512.01513)|null|\n", "2512.01504": "|**2025-12-01**|**Interatomic spin-orbit interaction in a $p$-orbital helical atomic chain**|Amnon Aharony Team|[2512.01504](http://arxiv.org/abs/2512.01504)|null|\n", "2512.01367": "|**2025-12-01**|**A Fine Evaluation Method for Cube Copying Test for Early Detection of Alzheimer's Disease**|Songqun Huang Team|[2512.01367](http://arxiv.org/abs/2512.01367)|null|\n", "2512.01357": "|**2025-12-01**|**Tangram: Accelerating Serverless LLM Loading through GPU Memory Reuse and Affinity**|Feng Chen Team|[2512.01357](http://arxiv.org/abs/2512.01357)|null|\n", "2512.01317": "|**2025-12-10**|**Data-Driven Learnability Transition of Measurement-Induced Entanglement**|Jing Wang Team|[2512.01317](http://arxiv.org/abs/2512.01317)|null|\n", "2512.01278": "|**2025-12-01**|**Accelerating Large-Scale Reasoning Model Inference with Sparse Self-Speculative Decoding**|Ion Stoica Team|[2512.01278](http://arxiv.org/abs/2512.01278)|null|\n", "2512.01208": "|**2025-12-01**|**Pay Attention Later: From Vector Space Diffusion to Linearithmic Spectral Phase-Locking**|\u0130brahim Y\u00fcceda\u011f Team|[2512.01208](http://arxiv.org/abs/2512.01208)|null|\n", "2512.01024": "|**2025-12-07**|**A data-driven framework to identify restenosis-prone regions in femoral arteries from geometric and inflow waveform parameters**|Stavroula Balabani Team|[2512.01024](http://arxiv.org/abs/2512.01024)|null|\n", "2512.01009": "|**2025-11-30**|**FOM-Nav: Frontier-Object Maps for Object Goal Navigation**|Cordelia Schmid Team|[2512.01009](http://arxiv.org/abs/2512.01009)|**[link](https://www.di.ens.fr/willow/research/fom-nav/)**|\n", "2512.00940": "|**2025-11-30**|**Memory-Integrated Reconfigurable Adapters: A Unified Framework for Settings with Multiple Tasks**|Vineeth N. Balasubramanian Team|[2512.00940](http://arxiv.org/abs/2512.00940)|null|\n", "2512.00863": "|**2025-11-30**|**Stacking-Induced Large-Chern-Number Quantum Anomalous Hall Phases**|V. Nam Do Team|[2512.00863](http://arxiv.org/abs/2512.00863)|null|\n", "2512.00851": "|**2025-11-30**|**City-Conditioned Memory for Multi-City Traffic and Mobility Forecasting**|Wenzhang Du Team|[2512.00851](http://arxiv.org/abs/2512.00851)|null|\n", "2512.00760": "|**2025-11-30**|**Forecasting India's Demographic Transition Under Fertility Policy Scenarios Using hybrid LSTM-PINN Model**|Indu Bala Team|[2512.00760](http://arxiv.org/abs/2512.00760)|null|\n", "2512.00722": "|**2025-11-30**|**SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs**|Guohao Dai Team|[2512.00722](http://arxiv.org/abs/2512.00722)|null|\n", "2512.00719": "|**2025-11-30**|**SIMPLE: Disaggregating Sampling from GPU Inference into a Decision Plane for Faster Distributed LLM Serving**|Yongchao He Team|[2512.00719](http://arxiv.org/abs/2512.00719)|null|\n", "2512.00504": "|**2025-11-29**|**G-KV: Decoding-Time KV Cache Eviction with Global Attention**|Huaiyu Wan Team|[2512.00504](http://arxiv.org/abs/2512.00504)|null|\n", "2512.00464": "|**2025-11-29**|**Characterizing topology at nonzero temperature**|Nigel R. Cooper Team|[2512.00464](http://arxiv.org/abs/2512.00464)|null|\n"}, "Planning-Recovery": {"2512.16909": "|**2025-12-18**|**MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning**|Koushil Sreenath Team|[2512.16909](http://arxiv.org/abs/2512.16909)|**[link](https://hybridrobotics.github.io/MomaGraph/)**|\n", "2512.16861": "|**2025-12-18**|**ReinforceGen: Hybrid Skill Policies with Automated Data Generation and Reinforcement Learning**|Caelan Garrett Team|[2512.16861](http://arxiv.org/abs/2512.16861)|null|\n", "2512.16624": "|**2025-12-18**|**Learning-based Approximate Model Predictive Control for an Impact Wrench Tool**|Andrea Carron Team|[2512.16624](http://arxiv.org/abs/2512.16624)|null|\n", "2512.16379": "|**2025-12-18**|**Economic versus energetic model predictive control of a cold production plant with thermal energy storage**|Manuel G. Ortega Team|[2512.16379](http://arxiv.org/abs/2512.16379)|null|\n", "2512.16069": "|**2025-12-18**|**A Task-Driven, Planner-in-the-Loop Computational Design Framework for Modular Manipulators**|Nikos Tsagarakis Team|[2512.16069](http://arxiv.org/abs/2512.16069)|null|\n", "2512.15916": "|**2025-12-17**|**A Comprehensive Benchmark Platform for Process Control Research of Outdoor Microalgae Raceway Reactors**|Manuel Berenguel Team|[2512.15916](http://arxiv.org/abs/2512.15916)|null|\n", "2512.15890": "|**2025-12-17**|**Universal and Maximal Entanglement Swapping in General Fermionic Gaussian States**|Xueda Wen Team|[2512.15890](http://arxiv.org/abs/2512.15890)|null|\n", "2512.15668": "|**2025-12-17**|**Enhancing industrial microalgae production through Economic Model Predictive Control**|Manuel Berenguel Team|[2512.15668](http://arxiv.org/abs/2512.15668)|null|\n", "2512.15568": "|**2025-12-17**|**Exact Learning of Linear Model Predictive Control Laws using Oblique Decision Trees with Linear Predictions**|Yankai Cao Team|[2512.15568](http://arxiv.org/abs/2512.15568)|null|\n", "2512.15533": "|**2025-12-17**|**Ising Machines for Model Predictive Path Integral-Based Optimal Control**|Pieter Simoens Team|[2512.15533](http://arxiv.org/abs/2512.15533)|null|\n", "2512.15476": "|**2025-12-17**|**QuantGraph: A Receding-Horizon Quantum Graph Solver**|Ioannis Havoutis Team|[2512.15476](http://arxiv.org/abs/2512.15476)|null|\n", "2512.15381": "|**2025-12-17**|**Gaussian Process Dual MPC using Active Inference: An Autonomous Vehicle Usecase**|Tom Lefebvre Team|[2512.15381](http://arxiv.org/abs/2512.15381)|null|\n", "2512.14666": "|**2025-12-16**|**EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models**|Mike Zheng Shou Team|[2512.14666](http://arxiv.org/abs/2512.14666)|null|\n", "2512.14510": "|**2025-12-16**|**Closed-Loop Consistent, Causal Data-Driven Predictive Control via SSARX**|Magnus Jansson Team|[2512.14510](http://arxiv.org/abs/2512.14510)|null|\n", "2512.14355": "|**2025-12-16**|**CoLD Fusion: A Real-time Capable Spline-based Fusion Algorithm for Collective Lane Detection**|Oliver Bringmann Team|[2512.14355](http://arxiv.org/abs/2512.14355)|null|\n", "2512.14350": "|**2025-12-16**|**Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization**|Sebastian Trimpe Team|[2512.14350](http://arxiv.org/abs/2512.14350)|null|\n", "2512.14336": "|**2025-12-16**|**Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure**|Jaegul Choo Team|[2512.14336](http://arxiv.org/abs/2512.14336)|null|\n", "2512.14111": "|**2025-12-16**|**Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field**|Fei Chen Team|[2512.14111](http://arxiv.org/abs/2512.14111)|null|\n", "2512.13894": "|**2025-12-15**|**AtLAST -- Cosmology with submillimetre galaxies magnification bias**|Hugo Messias Team|[2512.13894](http://arxiv.org/abs/2512.13894)|null|\n", "2512.13836": "|**2025-12-15**|**A Convex Obstacle Avoidance Formulation**|Iman Soltani Team|[2512.13836](http://arxiv.org/abs/2512.13836)|null|\n", "2512.13215": "|**2025-12-15**|**Multi-directional Safe Rectangle Corridor-Based MPC for Nonholonomic Robots Navigation in Cluttered Environment**|Shanlin Zhong Team|[2512.13215](http://arxiv.org/abs/2512.13215)|null|\n", "2512.13170": "|**2025-12-15**|**Iterative Tuning of Nonlinear Model Predictive Control for Robotic Manufacturing Tasks**|Alisa Rupenayan Team|[2512.13170](http://arxiv.org/abs/2512.13170)|null|\n", "2512.13090": "|**2025-12-15**|**Multi-Robot Motion Planning from Vision and Language using Heat-Inspired Diffusion**|Jongeun Choi Team|[2512.13090](http://arxiv.org/abs/2512.13090)|null|\n", "2512.13056": "|**2025-12-15**|**The Optimal Control Algorithm of Connected and Automated Vehicles at Roundabouts with Communication Delay**|Ronghui Hou Team|[2512.13056](http://arxiv.org/abs/2512.13056)|null|\n", "2512.12717": "|**2025-12-14**|**HMPCC: Human-Aware Model Predictive Coverage Control**|Lorenzo Sabattini Team|[2512.12717](http://arxiv.org/abs/2512.12717)|null|\n", "2512.12427": "|**2025-12-13**|**Unifying Quadrotor Motion Planning and Control by Chaining Different Fidelity Models**|Davide Scaramuzza Team|[2512.12427](http://arxiv.org/abs/2512.12427)|null|\n", "2512.12026": "|**2025-12-12**|**DT-MPC: Synthesizing Derivation-Free Model Predictive Control from Power Converter Netlists via Physics-Informed Neural Digital Twins**|Leopoldo G. Franquelo Team|[2512.12026](http://arxiv.org/abs/2512.12026)|null|\n", "2512.14746": "|**2025-12-12**|**BLINDSPOT: Enabling Bystander-Controlled Privacy Signaling for Camera-Enabled Devices**|Athina Markopoulou Team|[2512.14746](http://arxiv.org/abs/2512.14746)|null|\n", "2512.11713": "|**2025-12-12**|**Two-dimensional Decompositions of High-dimensional Configurations for Efficient Multi-vehicle Coordination at Intelligent Intersections**|Johan Thunberg Team|[2512.11713](http://arxiv.org/abs/2512.11713)|null|\n", "2512.11705": "|**2025-12-12**|**High-Dimensional Surrogate Modeling for Closed-Loop Learning of Neural-Network-Parameterized Model Predictive Control**|Rolf Findeisen Team|[2512.11705](http://arxiv.org/abs/2512.11705)|null|\n", "2512.11944": "|**2025-12-12**|**A Review of Learning-Based Motion Planning: Toward a Data-Driven Optimal Control Approach**|Haoran Wang Team|[2512.11944](http://arxiv.org/abs/2512.11944)|null|\n", "2512.11571": "|**2025-12-12**|**Cross-Entropy Optimization of Physically Grounded Task and Motion Plans**|Javier Alonso-Mora Team|[2512.11571](http://arxiv.org/abs/2512.11571)|null|\n", "2512.11481": "|**2025-12-12**|**A Robust Model Predictive Control Method for Networked Control Systems**|Sandra Hirche Team|[2512.11481](http://arxiv.org/abs/2512.11481)|null|\n", "2512.11308": "|**2025-12-12**|**Gig-work Management System with Chance-Constraints Verification Algorithm**|Riko Asanaka Team|[2512.11308](http://arxiv.org/abs/2512.11308)|null|\n", "2512.11226": "|**2025-12-12**|**FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model**|Zhen Li Team|[2512.11226](http://arxiv.org/abs/2512.11226)|null|\n", "2512.11096": "|**2025-12-11**|**Your plan may succeed, but what about failure? Investigating how people use ChatGPT for long-term life task planning**|Jiqun Liu Team|[2512.11096](http://arxiv.org/abs/2512.11096)|null|\n", "2512.10738": "|**2025-12-11**|**Distribution-Free Stochastic MPC for Joint-in-Time Chance-Constrained Linear Systems**|Dimos V. Dimarogonas Team|[2512.10738](http://arxiv.org/abs/2512.10738)|null|\n", "2512.10732": "|**2025-12-11**|**TriHaRd: Higher Resilience for TEE Trusted Time**|Anthony Simonet-Boulogne Team|[2512.10732](http://arxiv.org/abs/2512.10732)|null|\n", "2512.10605": "|**2025-12-11**|**LEO-RobotAgent: A General-purpose Robotic Agent for Language-driven Embodied Operator**|Jun Meng Team|[2512.10605](http://arxiv.org/abs/2512.10605)|null|\n", "2512.10595": "|**2025-12-11**|**Motion Planning for Safe Landing of a Human-Piloted Parafoil**|Anna Clarke Team|[2512.10595](http://arxiv.org/abs/2512.10595)|null|\n", "2512.10310": "|**2025-12-11**|**Efficient-VLN: A Training-Efficient Vision-Language Navigation Model**|Liwei Wang Team|[2512.10310](http://arxiv.org/abs/2512.10310)|null|\n", "2512.10116": "|**2025-12-10**|**Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks**|Tirthankar Bandyopadhyay Team|[2512.10116](http://arxiv.org/abs/2512.10116)|**[link](https://ssl.linklings.net/conferences/acra/acra2025_proceedings/views/includes/files/pap149s2.pdf)**|\n", "2512.09984": "|**2025-12-10**|**Clues from $\\mathcal{Q}$--A null test designed for line intensity mapping cross-correlation studies**|Adrian Liu Team|[2512.09984](http://arxiv.org/abs/2512.09984)|null|\n", "2512.09929": "|**2025-12-10**|**Closing the Train-Test Gap in World Models for Gradient-Based Planning**|Micah Goldblum Team|[2512.09929](http://arxiv.org/abs/2512.09929)|null|\n", "2512.09897": "|**2025-12-10**|**SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments**|Kaheer Suleman Team|[2512.09897](http://arxiv.org/abs/2512.09897)|null|\n", "2512.09833": "|**2025-12-10**|**Bridging the Basilisk Astrodynamics Framework with ROS 2 for Modular Spacecraft Simulation and Hardware Integration**|Christer Fuglesang Team|[2512.09833](http://arxiv.org/abs/2512.09833)|null|\n", "2512.09798": "|**2025-12-10**|**High-Resolution Water Sampling via a Solar-Powered Autonomous Surface Vehicle**|Edwin Salcedo Team|[2512.09798](http://arxiv.org/abs/2512.09798)|null|\n", "2512.09611": "|**2025-12-10**|**Real-Time Non-Smooth MPC for Switching Systems: Application to a Three-Tank Process**|Rolf Findeisen Team|[2512.09611](http://arxiv.org/abs/2512.09611)|null|\n", "2512.09445": "|**2025-12-10**|**All elastic amplitudes in the (black hole) eikonal phase**|Nico Groenenboom Team|[2512.09445](http://arxiv.org/abs/2512.09445)|null|\n", "2512.09434": "|**2025-12-10**|**CourtPressGER: A German Court Decision to Press Release Summarization Dataset**|Matthias Grabmair Team|[2512.09434](http://arxiv.org/abs/2512.09434)|null|\n", "2512.09310": "|**2025-12-10**|**Scene-agnostic Hierarchical Bimanual Task Planning via Visual Affordance Reasoning**|Sung-Hee Lee Team|[2512.09310](http://arxiv.org/abs/2512.09310)|null|\n", "2512.09213": "|**2025-12-10**|**MPC for momentum counter-balanced and zero-impulse contact with a free-spinning satellite**|Sarah H. Q. Li Team|[2512.09213](http://arxiv.org/abs/2512.09213)|null|\n", "2512.09960": "|**2025-12-09**|**Numerical Behavior of the Riemann Zeta Function Using Real-to-Complex Conversion Without Gram Points or Bracketing**|Jacob Orellana Real Team|[2512.09960](http://arxiv.org/abs/2512.09960)|null|\n", "2512.09083": "|**2025-12-09**|**Reactive Vehicle Guidance using Dynamic Maneuvering Cue**|Isaac Weintraub Team|[2512.09083](http://arxiv.org/abs/2512.09083)|null|\n", "2512.08757": "|**2025-12-09**|**Saturation-based robustly optimal hierarchical operation control of microgrids**|Steffen Hofmann Team|[2512.08757](http://arxiv.org/abs/2512.08757)|null|\n", "2512.08667": "|**2025-12-09**|**Direct transfer of optimized controllers to similar systems using dimensionless MPC**|S\u00e9bastien Gros Team|[2512.08667](http://arxiv.org/abs/2512.08667)|null|\n", "2512.08659": "|**2025-12-09**|**An Agentic AI System for Multi-Framework Communication Coding**|Chuan Hong Team|[2512.08659](http://arxiv.org/abs/2512.08659)|null|\n", "2512.08574": "|**2025-12-09**|**RVC-NMPC: Nonlinear Model Predictive Control with Reciprocal Velocity Constraints for Mutual Collision Avoidance in Agile UAV Flight**|Martin Saska Team|[2512.08574](http://arxiv.org/abs/2512.08574)|null|\n", "2512.08446": "|**2025-12-09**|**An Overview of Sensitivity-Based Distributed Optimization and Model Predictive Control**|Knut Graichen Team|[2512.08446](http://arxiv.org/abs/2512.08446)|null|\n", "2512.08206": "|**2025-12-09**|**High-Performance Dual-Arm Task and Motion Planning for Tabletop Rearrangement**|Jingjin Yu Team|[2512.08206](http://arxiv.org/abs/2512.08206)|null|\n", "2512.08145": "|**2025-12-09**|**Chat with UAV -- Human-UAV Interaction Based on Large Language Models**|Chuanghuang Li Team|[2512.08145](http://arxiv.org/abs/2512.08145)|null|\n", "2512.07767": "|**2025-12-08**|**Holography of quarter-BPS AdS bubbles**|Anthony Houppe Team|[2512.07767](http://arxiv.org/abs/2512.07767)|null|\n", "2512.07609": "|**2025-12-09**|**Obstacle Avoidance of UAV in Dynamic Environments Using Direction and Velocity-Adaptive Artificial Potential Field**|Manoranjan Sinha Team|[2512.07609](http://arxiv.org/abs/2512.07609)|null|\n", "2512.07316": "|**2025-12-08**|**Model Predictive Control for Cooperative Docking Between Autonomous Surface Vehicles with Disturbance Rejection**|Bart De Schutter Team|[2512.07316](http://arxiv.org/abs/2512.07316)|null|\n", "2512.07032": "|**2025-12-07**|**A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator**|Gordon Cheng Team|[2512.07032](http://arxiv.org/abs/2512.07032)|null|\n", "2512.06796": "|**2025-12-09**|**db-LaCAM: Fast and Scalable Multi-Robot Kinodynamic Motion Planning with Discontinuity-Bounded Search and Lightweight MAPF**|Wolfgang H\u00f6nig Team|[2512.06796](http://arxiv.org/abs/2512.06796)|null|\n", "2512.06746": "|**2025-12-07**|**Task-Model Alignment: A Simple Path to Generalizable AI-Generated Image Detection**|Shouhong Ding Team|[2512.06746](http://arxiv.org/abs/2512.06746)|null|\n", "2512.06628": "|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Xiu Li Team|[2512.06628](http://arxiv.org/abs/2512.06628)|null|\n", "2512.06574": "|**2025-12-06**|**General Computation using Slidable Tiles with Deterministic Global Forces**|Tim Wylie Team|[2512.06574](http://arxiv.org/abs/2512.06574)|null|\n", "2512.06404": "|**2025-12-06**|**GENIUS: An Agentic AI Framework for Autonomous Design and Execution of Simulation Protocols**|Celso Ricardo Caldeira R\u00eago Team|[2512.06404](http://arxiv.org/abs/2512.06404)|null|\n", "2512.06194": "|**2025-12-05**|**Explainable LP-MPC: Shadow Price Contributions Reveal MV-CV Pairings**|Daniel L. O'Connor Team|[2512.06194](http://arxiv.org/abs/2512.06194)|null|\n", "2512.06182": "|**2025-12-05**|**Situation-Aware Interactive MPC Switching for Autonomous Driving**|Sofie Haesaert Team|[2512.06182](http://arxiv.org/abs/2512.06182)|null|\n", "2512.06112": "|**2025-12-11**|**WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving**|Siyu Zhu Team|[2512.06112](http://arxiv.org/abs/2512.06112)|**[link](https://github.com/fudan-generative-vision/WAM-Flow)**|\n", "2512.05876": "|**2025-12-10**|**InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Power Grid Control**|Tongxin Li Team|[2512.05876](http://arxiv.org/abs/2512.05876)|null|\n", "2512.05827": "|**2025-12-05**|**Advanced Hybrid Automated Insulin Delivery System based on Successive Linearization Model Predictive Control: The UniBE System**|Jose Garcia-Tirado Team|[2512.05827](http://arxiv.org/abs/2512.05827)|null|\n", "2512.05815": "|**2025-12-05**|**Optimal Safety-Aware Scheduling for Multi-Agent Aerial 3D Printing with Utility Maximization under Dependency Constraints**|George Nikolakopoulos Team|[2512.05815](http://arxiv.org/abs/2512.05815)|null|\n", "2512.05711": "|**2025-12-05**|**Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning**|Carlo Regazzoni Team|[2512.05711](http://arxiv.org/abs/2512.05711)|null|\n", "2512.05692": "|**2025-12-05**|**IMMPC: An Internal Model Based MPC for Rejecting Unknown Disturbances**|Frank Allg\u00f6wer Team|[2512.05692](http://arxiv.org/abs/2512.05692)|null|\n", "2512.05686": "|**2025-12-05**|**LA-RL: Language Action-guided Reinforcement Learning with Safety Guarantees for Autonomous Highway Driving**|Chen Sun Team|[2512.05686](http://arxiv.org/abs/2512.05686)|null|\n", "2512.05505": "|**2025-12-05**|**Solving Multiparametric Generalized Nash Equilibrium Problems and Explicit Game-Theoretic Model Predictive Control**|Alberto Bemporad Team|[2512.05505](http://arxiv.org/abs/2512.05505)|null|\n", "2512.05400": "|**2025-12-05**|**Hybrid modeling approach for better identification of building thermal network model and improved prediction**|Donghun Kim Team|[2512.05400](http://arxiv.org/abs/2512.05400)|null|\n", "2512.04895": "|**2025-12-04**|**Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems**|Saud Satti Team|[2512.04895](http://arxiv.org/abs/2512.04895)|null|\n", "2512.04856": "|**2025-12-04**|**Safe model-based Reinforcement Learning via Model Predictive Control and Control Barrier Functions**|Azita Dabiri Team|[2512.04856](http://arxiv.org/abs/2512.04856)|null|\n", "2512.04647": "|**2025-12-04**|**Auto-Optimization with Active Learning in Uncertain Environment: A Predictive Control Approach**|Shihua Li Team|[2512.04647](http://arxiv.org/abs/2512.04647)|null|\n", "2512.04619": "|**2025-12-04**|**Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence**|Zhuzhong Qian Team|[2512.04619](http://arxiv.org/abs/2512.04619)|null|\n", "2512.04579": "|**2025-12-04**|**Gauss-Newton accelerated MPPI Control**|Johannes Reuter Team|[2512.04579](http://arxiv.org/abs/2512.04579)|null|\n", "2512.04446": "|**2025-12-04**|**Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops**|Minghui Zheng Team|[2512.04446](http://arxiv.org/abs/2512.04446)|null|\n", "2512.04404": "|**2025-12-04**|**Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation**|Changju Wu Team|[2512.04404](http://arxiv.org/abs/2512.04404)|null|\n", "2512.04303": "|**2025-12-03**|**Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications**|Olaf Hellwich Team|[2512.04303](http://arxiv.org/abs/2512.04303)|null|\n", "2512.04239": "|**2025-12-03**|**Configuration-Constrained Tube MPC for Periodic Operation**|Mario Eduardo Villanueva Team|[2512.04239](http://arxiv.org/abs/2512.04239)|null|\n", "2512.03992": "|**2025-12-03**|**DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation**|Xiaoqiang Team|[2512.03992](http://arxiv.org/abs/2512.03992)|null|\n", "2512.03774": "|**2025-12-03**|**Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving**|Christoph Stiller Team|[2512.03774](http://arxiv.org/abs/2512.03774)|null|\n", "2512.03772": "|**2025-12-03**|**Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control**|Alisa Rupenyan Team|[2512.03772](http://arxiv.org/abs/2512.03772)|null|\n", "2512.03756": "|**2025-12-03**|**Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models**|Christoph Stiller Team|[2512.03756](http://arxiv.org/abs/2512.03756)|null|\n", "2512.03746": "|**2025-12-03**|**Thinking with Programming Vision: Towards a Unified View for Thinking with Images**|Tao Jin Team|[2512.03746](http://arxiv.org/abs/2512.03746)|null|\n", "2512.03708": "|**2025-12-03**|**A Lyapunov-based MPC for Distributed Multi Agent Systems with Time Delays and Packet Dropouts using Hidden Markov Models**|Ayman El-Badawy Team|[2512.03708](http://arxiv.org/abs/2512.03708)|null|\n", "2512.03707": "|**2025-12-03**|**ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration**|Emma Li Team|[2512.03707](http://arxiv.org/abs/2512.03707)|null|\n", "2512.03639": "|**2025-12-03**|**Context-Triggered Contingency Games for Strategic Multi-Agent Interaction**|Anne-Kathrin Schmuck Team|[2512.03639](http://arxiv.org/abs/2512.03639)|null|\n", "2512.03630": "|**2025-12-03**|**Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations**|Naresh Marturi Team|[2512.03630](http://arxiv.org/abs/2512.03630)|null|\n", "2512.03619": "|**2025-12-08**|**LAMP: Language-Assisted Motion Planning for Controllable Video Generation**|Duygu Ceylan Team|[2512.03619](http://arxiv.org/abs/2512.03619)|**[link](https://cyberiada.github.io/LAMP/)**|\n", "2512.03615": "|**2025-12-03**|**Covariance Control for a class of Stochastic Discrete-time Linear Systems using the S-Variable Approach**|Dimitri Peaucelle Team|[2512.03615](http://arxiv.org/abs/2512.03615)|null|\n", "2512.03549": "|**2025-12-03**|**PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks**|Daisuke Okanohara Team|[2512.03549](http://arxiv.org/abs/2512.03549)|null|\n", "2512.03538": "|**2025-12-03**|**AdaPower: Specializing World Foundation Models for Predictive Manipulation**|Kai Xu Team|[2512.03538](http://arxiv.org/abs/2512.03538)|null|\n", "2512.03516": "|**2025-12-03**|**Mean-Square Stability of Continuous-Time Stochastic Model Predictive Control**|Enrique Zuazua Team|[2512.03516](http://arxiv.org/abs/2512.03516)|null|\n", "2512.03444": "|**2025-12-03**|**PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers**|Minghui Zheng Team|[2512.03444](http://arxiv.org/abs/2512.03444)|null|\n", "2512.03410": "|**2025-12-03**|**Suboptimal Shrinking Horizon MPC with a Lower Hessian Condition Number from Adjustable Terminal Cost**|Ilya Kolmanovsky Team|[2512.03410](http://arxiv.org/abs/2512.03410)|null|\n", "2512.03256": "|**2025-12-02**|**KALIKO: Kalman-Implicit Koopman Operator Learning For Prediction of Nonlinear Dynamical Systems**|Aaron D. Ames Team|[2512.03256](http://arxiv.org/abs/2512.03256)|null|\n", "2512.02311": "|**2025-12-02**|**Nonlinear MPC with PWM applied on a small satellite**|Jinaykumar Patel Team|[2512.02311](http://arxiv.org/abs/2512.02311)|null|\n", "2512.01832": "|**2025-12-01**|**A Privacy-Preserving Information-Sharing Protocol for Federated Authentication**|Carmen Licciardi Team|[2512.01832](http://arxiv.org/abs/2512.01832)|null|\n", "2512.01564": "|**2025-12-17**|**The emergence of inherently 9-dimensional one-loop effective action from T-duality**|Mohammad R. Garousi Team|[2512.01564](http://arxiv.org/abs/2512.01564)|null|\n", "2512.01550": "|**2025-12-01**|**NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction**|Mu Xu Team|[2512.01550](http://arxiv.org/abs/2512.01550)|null|\n", "2512.01358": "|**2025-12-01**|**Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1**|Songhwai Oh Team|[2512.01358](http://arxiv.org/abs/2512.01358)|null|\n", "2512.01185": "|**2025-12-01**|**DefenSee: Dissecting Threat from Sight and Text -- A Multi-View Defensive Pipeline for Multi-modal Jailbreaks**|Vrizlynn L. L. Thing Team|[2512.01185](http://arxiv.org/abs/2512.01185)|null|\n", "2512.01073": "|**2025-11-30**|**The Modeler Schema Theory of Consciousness, with a Falsifiable Experiment**|Frank Heile Team|[2512.01073](http://arxiv.org/abs/2512.01073)|null|\n", "2512.00975": "|**2025-12-08**|**MM-ACT: Learn from Multimodal Parallel Generation to Act**|Ping Luo Team|[2512.00975](http://arxiv.org/abs/2512.00975)|null|\n", "2512.00939": "|**2025-11-30**|**Constant-Time Motion Planning with Manipulation Behaviors**|Maxim Likhachev Team|[2512.00939](http://arxiv.org/abs/2512.00939)|null|\n", "2512.00375": "|**2025-11-29**|**DPNet: Doppler LiDAR Motion Planning for Highly-Dynamic Environments**|Chengzhong Xu Team|[2512.00375](http://arxiv.org/abs/2512.00375)|null|\n", "2511.23417": "|**2025-11-28**|**Detection of the Pairwise Kinematic Sunyaev-Zel'dovich Effect and Pairwise Velocity with DESI DR1 Galaxies and ACT DR6 and Planck CMB Data**|Hu Zou Team|[2511.23417](http://arxiv.org/abs/2511.23417)|null|\n", "2511.23407": "|**2025-11-28**|**From CAD to POMDP: Probabilistic Planning for Robotic Disassembly of End-of-Life Products**|J\u00fcrgen Fleischer Team|[2511.23407](http://arxiv.org/abs/2511.23407)|null|\n", "2511.23350": "|**2025-11-28**|**Generalised Symmetries and Manifest Duality I: Flat Spacetime**|Madhusudhan Raman Team|[2511.23350](http://arxiv.org/abs/2511.23350)|null|\n", "2511.23044": "|**2025-11-28**|**Geometry-Consistent 4D Gaussian Splatting for Sparse-Input Dynamic View Synthesis**|Yinfeng Cao Team|[2511.23044](http://arxiv.org/abs/2511.23044)|null|\n", "2511.22954": "|**2025-11-28**|**Adaptive Trajectory Bundle Method for Roll-to-Roll Manufacturing Systems**|Shihao Li Team|[2511.22954](http://arxiv.org/abs/2511.22954)|null|\n", "2511.22891": "|**2025-11-28**|**ORION: Teaching Language Models to Reason Efficiently in the Language of Thought**|Subhabrata Mukherjee Team|[2511.22891](http://arxiv.org/abs/2511.22891)|null|\n", "2511.22685": "|**2025-11-27**|**Deadlock-Free Hybrid RL-MAPF Framework for Zero-Shot Multi-Robot Navigation**|Mingyu Cai Team|[2511.22685](http://arxiv.org/abs/2511.22685)|null|\n", "2511.22528": "|**2025-11-27**|**A model predictive control framework with customer-priority tiers for virtual power plant resilience during extreme weather: A UK heatwave case study**|Aristides Kiprakis Team|[2511.22528](http://arxiv.org/abs/2511.22528)|null|\n", "2511.22502": "|**2025-11-27**|**Learning the MPC objective function from human preferences**|Alberto Bemporad Team|[2511.22502](http://arxiv.org/abs/2511.22502)|null|\n", "2511.22368": "|**2025-11-27**|**Distributed Koopman Operator Learning for Perception and Safe Navigation**|Gian Paolo Incremona Team|[2511.22368](http://arxiv.org/abs/2511.22368)|null|\n", "2511.22364": "|**2025-11-27**|**BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands**|Jonghyun Choi Team|[2511.22364](http://arxiv.org/abs/2511.22364)|null|\n", "2511.22354": "|**2025-11-27**|**LLM-Based Generalizable Hierarchical Task Planning and Execution for Heterogeneous Robot Teams with Event-Driven Replanning**|Madhu Vadali Team|[2511.22354](http://arxiv.org/abs/2511.22354)|null|\n", "2511.22123": "|**2025-11-27**|**Model Predictive Path Planning in Navier-Stokes Flow with POD-Based Reduced-Order Models**|Martin Guay Team|[2511.22123](http://arxiv.org/abs/2511.22123)|null|\n", "2511.21871": "|**2025-11-26**|**Bayesian Risk-averse Model Predictive Control with Consistency and Stability Guarantees**|Fumin Zhang Team|[2511.21871](http://arxiv.org/abs/2511.21871)|null|\n", "2511.21619": "|**2025-11-26**|**Robust Rule-Based Sizing and Control of Batteries for Peak Shaving Applications**|Vasco Medici Team|[2511.21619](http://arxiv.org/abs/2511.21619)|null|\n", "2511.21460": "|**2025-11-26**|**MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning**|Xi Sheryl Zhang Team|[2511.21460](http://arxiv.org/abs/2511.21460)|null|\n", "2511.21343": "|**2025-11-26**|**Model Predictive Control and Moving Horizon Estimation using Statistically Weighted Data-Based Ensemble Models**|Riccardo Scattolini Team|[2511.21343](http://arxiv.org/abs/2511.21343)|null|\n", "2511.21312": "|**2025-11-26**|**Neural NMPC through Signed Distance Field Encoding for Collision Avoidance**|Kostas Alexis Team|[2511.21312](http://arxiv.org/abs/2511.21312)|null|\n", "2511.21251": "|**2025-12-01**|**AVFakeBench: A Comprehensive Audio-Video Forgery Detection Benchmark for AV-LMMs**|Zekun Li Team|[2511.21251](http://arxiv.org/abs/2511.21251)|null|\n", "2511.21248": "|**2025-11-26**|**Stability of data-driven Koopman MPC with terminal conditions**|Lalo Magni Team|[2511.21248](http://arxiv.org/abs/2511.21248)|null|\n", "2511.20918": "|**2025-11-25**|**Magnetic corrections to the classical soft photon theorems at all orders**|Pabitra Ray Team|[2511.20918](http://arxiv.org/abs/2511.20918)|null|\n", "2511.20593": "|**2025-11-25**|**Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning**|Abdalla Swikir Team|[2511.20593](http://arxiv.org/abs/2511.20593)|null|\n", "2511.20431": "|**2025-11-26**|**BRIC: Bridging Kinematic Plans and Physical Control at Test Time**|Sungchan Kim Team|[2511.20431](http://arxiv.org/abs/2511.20431)|null|\n", "2511.20301": "|**2025-11-25**|**Quasi-Normal Mode Ringing of Binary Black Hole Mergers in Scalar-Gauss-Bonnet Gravity**|Lijing Shao Team|[2511.20301](http://arxiv.org/abs/2511.20301)|null|\n", "2511.20156": "|**2025-11-25**|**Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving**|Zhenning Li Team|[2511.20156](http://arxiv.org/abs/2511.20156)|null|\n", "2511.19899": "|**2025-12-01**|**VeriSciQA: An Auto-Verified Dataset for Scientific Visual Question Answering**|Yaliang Li Team|[2511.19899](http://arxiv.org/abs/2511.19899)|null|\n", "2511.19861": "|**2025-11-30**|**GigaWorld-0: World Models as Data Engine to Empower Embodied AI**|Zheng Zhu Team|[2511.19861](http://arxiv.org/abs/2511.19861)|**[link](https://giga-world-0.github.io/)**|\n", "2511.19859": "|**2025-11-25**|**Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation**|Sanglu Lu Team|[2511.19859](http://arxiv.org/abs/2511.19859)|null|\n", "2511.19709": "|**2025-11-24**|**Whole-Body Inverse Dynamics MPC for Legged Loco-Manipulation**|Stelian Coros Team|[2511.19709](http://arxiv.org/abs/2511.19709)|null|\n", "2511.19655": "|**2025-11-26**|**Development of a Testbed for Autonomous Vehicles: Integrating MPC Control with Monocular Camera Lane Detection**|Golam Sarowar Team|[2511.19655](http://arxiv.org/abs/2511.19655)|null|\n", "2511.19430": "|**2025-11-24**|**Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution**|Xiang Bai Team|[2511.19430](http://arxiv.org/abs/2511.19430)|**[link](https://github.com/H-EmbodVis/GRANT})**|\n", "2511.19383": "|**2025-11-24**|**A Hybrid Learning-to-Optimize Framework for Mixed-Integer Quadratic Programming**|Rahul Mangharam Team|[2511.19383](http://arxiv.org/abs/2511.19383)|null|\n", "2511.19336": "|**2025-11-24**|**Nonlinear MPC for Feedback-Interconnected Systems: a Suboptimal and Reduced-Order Model Approach**|Giuseppe Notarstefano Team|[2511.19336](http://arxiv.org/abs/2511.19336)|null|\n", "2511.19204": "|**2025-11-24**|**Reference-Free Sampling-Based Model Predictive Control**|Justin Carpentier Team|[2511.19204](http://arxiv.org/abs/2511.19204)|null|\n", "2511.19143": "|**2025-11-24**|**Optimal policy design for innovation diffusion: shaping today's incentives for transforming the future**|Mara Tanelli Team|[2511.19143](http://arxiv.org/abs/2511.19143)|null|\n", "2511.19135": "|**2025-11-24**|**Autonomous Docking of Multi-Rotor UAVs on Blimps under the Influence of Wind Gusts**|Aamir Ahmad Team|[2511.19135](http://arxiv.org/abs/2511.19135)|null|\n", "2511.19056": "|**2025-11-24**|**Latent-Space Non-Linear Model Predictive Control for Partially-Observable Systems**|Stefano Discetti Team|[2511.19056](http://arxiv.org/abs/2511.19056)|null|\n", "2512.00069": "|**2025-11-24**|**Enhancing Cognitive Robotics with Commonsense through LLM-Generated Preconditions and Subgoals**|Bar Gamliel Team|[2512.00069](http://arxiv.org/abs/2512.00069)|null|\n", "2511.18703": "|**2025-11-24**|**Asynchronous Distributed Multi-Robot Motion Planning Under Imperfect Communication**|Aaron M. Johnson Team|[2511.18703](http://arxiv.org/abs/2511.18703)|null|\n", "2511.18604": "|**2025-11-23**|**An Analysis of Constraint-Based Multi-Agent Pathfinding Algorithms**|Nancy M. Amato Team|[2511.18604](http://arxiv.org/abs/2511.18604)|null|\n", "2511.18170": "|**2025-11-22**|**Time-aware Motion Planning in Dynamic Environments with Conformal Prediction**|Cristian Ioan Vasile Team|[2511.18170](http://arxiv.org/abs/2511.18170)|null|\n", "2511.18165": "|**2025-11-22**|**Towards a General Framework for HTN Modeling with LLMs**|Juan Fern\u00e1ndez-Olivares Team|[2511.18165](http://arxiv.org/abs/2511.18165)|**[link](https://llmforplanning.github.io)**|\n", "2511.17865": "|**2025-11-22**|**Generative Model Predictive Control in Manufacturing Processes: A Review**|Hyunwoong Ko Team|[2511.17865](http://arxiv.org/abs/2511.17865)|null|\n", "2511.17798": "|**2025-11-21**|**SM2ITH: Safe Mobile Manipulation with Interactive Human Prediction via Task-Hierarchical Bilevel Model Predictive Control**|Angela P. Schoellig Team|[2511.17798](http://arxiv.org/abs/2511.17798)|null|\n", "2511.17777": "|**2025-11-21**|**See, Plan, Cut: MPC-Based Autonomous Volumetric Robotic Laser Surgery with OCT Guidance**|Leila J. Bridgeman Team|[2511.17777](http://arxiv.org/abs/2511.17777)|null|\n", "2511.17496": "|**2025-11-21**|**MDG: Masked Denoising Generation for Multi-Agent Behavior Modeling in Traffic Environments**|Jiaqi Ma Team|[2511.17496](http://arxiv.org/abs/2511.17496)|null|\n", "2511.17450": "|**2025-11-21**|**Planning with Sketch-Guided Verification for Physics-Aware Video Generation**|Mohit Bansal Team|[2511.17450](http://arxiv.org/abs/2511.17450)|**[link](https://sketchverify.github.io/)**|\n", "2511.17375": "|**2025-11-21**|**Vector Cost Behavioral Planning for Autonomous Robotic Systems with Contemporary Validation Strategies**|Metin G\u00f6ka\u015fan Team|[2511.17375](http://arxiv.org/abs/2511.17375)|null|\n", "2511.17233": "|**2025-11-21**|**Algorithmic design and implementation considerations of deep MPC**|Girish Chowdhary Team|[2511.17233](http://arxiv.org/abs/2511.17233)|null|\n", "2511.17186": "|**2025-11-28**|**Distributed Switching Model Predictive Control Meets Koopman Operator for Dynamic Obstacle Avoidance**|Patrizio Colaneri Team|[2511.17186](http://arxiv.org/abs/2511.17186)|null|\n", "2511.17131": "|**2025-11-21**|**UI-CUBE: Enterprise-Grade Computer Use Agent Benchmarking Beyond Task Accuracy to Operational Reliability**|Stefan Adam Team|[2511.17131](http://arxiv.org/abs/2511.17131)|**[link](https://github.com/UiPath/uipath_enterprise_benchmark)**|\n", "2511.17130": "|**2025-11-21**|**Asymptotics of motion planning complexity for control-affine systems**|Dario Prandi Team|[2511.17130](http://arxiv.org/abs/2511.17130)|null|\n", "2511.16518": "|**2025-11-20**|**MiMo-Embodied: X-Embodied Foundation Model Technical Report**|Long Chen Team|[2511.16518](http://arxiv.org/abs/2511.16518)|**[link](https://github.com/XiaomiMiMo/MiMo-Embodied)**|\n", "2511.16425": "|**2025-11-20**|**Tube-Based Model Predictive Control with Random Fourier Features for Nonlinear Systems**|\u00c1d\u00e1m Szab\u00f3 Team|[2511.16425](http://arxiv.org/abs/2511.16425)|null|\n", "2511.16424": "|**2025-11-20**|**Second-Order MPC-Based Distributed Q-Learning**|Bart De Schutter Team|[2511.16424](http://arxiv.org/abs/2511.16424)|null|\n", "2511.16297": "|**2025-11-20**|**Optimizing Operation Recipes with Reinforcement Learning for Safe and Interpretable Control of Chemical Processes**|Sergio Lucia Team|[2511.16297](http://arxiv.org/abs/2511.16297)|**[link](https://ml4cce-ecml.com/)**|\n", "2511.16195": "|**2025-11-20**|**Physics-informed Gaussian Processes as Linear Model Predictive Controller with Constraint Satisfaction**|Markus Lange-Hegermann Team|[2511.16195](http://arxiv.org/abs/2511.16195)|null|\n", "2511.16148": "|**2025-11-26**|**Enhancing Nuclear Reactor Core Simulation through Data-Based Surrogate Models**|Nicolas Vayatis Team|[2511.16148](http://arxiv.org/abs/2511.16148)|null|\n", "2511.15889": "|**2025-11-19**|**Development of a velocity form for a class of RNNs, with application to offset-free nonlinear MPC design**|Andrea Ballarino Team|[2511.15889](http://arxiv.org/abs/2511.15889)|null|\n", "2511.15630": "|**2025-11-19**|**Economic Linear Quadratic MPC With Non-Unique Optimal Solutions**|Mario Zanon Team|[2511.15630](http://arxiv.org/abs/2511.15630)|null|\n", "2511.15588": "|**2025-11-19**|**Real-Time Optimal Control via Transformer Networks and Bernstein Polynomials**|Irene Gregory Team|[2511.15588](http://arxiv.org/abs/2511.15588)|null|\n", "2511.15532": "|**2025-11-19**|**NMPC-based Motion Planning with Adaptive Weighting for Dynamic Object Interception**|Steven Liu Team|[2511.15532](http://arxiv.org/abs/2511.15532)|null|\n", "2511.15414": "|**2025-11-19**|**RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer**|Xiang Yin Team|[2511.15414](http://arxiv.org/abs/2511.15414)|null|\n", "2511.19452": "|**2025-11-19**|**A Data-Driven Model Predictive Control Framework for Multi-Aircraft TMA Routing Under Travel Time Uncertainty**|Yifang Yin Team|[2511.19452](http://arxiv.org/abs/2511.19452)|null|\n", "2511.15274": "|**2025-11-19**|**Behavior Trees vs Executable Ontologies: a Comparative Analysis of Robot Control Paradigms**|Alexander Boldachev Team|[2511.15274](http://arxiv.org/abs/2511.15274)|null|\n", "2511.19451": "|**2025-11-19**|**Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control**|Takashi Tanaka Team|[2511.19451](http://arxiv.org/abs/2511.19451)|null|\n", "2511.15023": "|**2025-11-19**|**Lie Group Control Architectures for UAVs: a Comparison of SE2(3)-Based Approaches in Simulation and Hardware**|Sidney Givigi Team|[2511.15023](http://arxiv.org/abs/2511.15023)|null|\n", "2511.14718": "|**2025-11-18**|**Natural Language Interfaces for Databases: What Do Users Think?**|Haotian Zheng Team|[2511.14718](http://arxiv.org/abs/2511.14718)|null|\n", "2511.14533": "|**2025-11-18**|**A Neuro-Symbolic Framework for Reasoning under Perceptual Uncertainty: Bridging Continuous Perception and Discrete Symbolic Planning**|Shengwen Yu Team|[2511.14533](http://arxiv.org/abs/2511.14533)|null|\n", "2511.14459": "|**2025-11-18**|**H\u00f6lder regularity in bang-bang type affine optimal control problems**|Vladimir Veliov Team|[2511.14459](http://arxiv.org/abs/2511.14459)|null|\n", "2511.14311": "|**2025-11-18**|**Multi-Timescale Model Predictive Control for Slow-Fast Systems**|Marco Pavone Team|[2511.14311](http://arxiv.org/abs/2511.14311)|null|\n", "2511.14185": "|**2025-11-19**|**PAVE: An End-to-End Dataset for Production Autonomous Vehicle Evaluation**|Ke Ma Team|[2511.14185](http://arxiv.org/abs/2511.14185)|null|\n", "2511.14158": "|**2025-11-18**|**Uncertainty Discounting in Deterministic Black Box Price Predictions for Energy Arbitrage**|Arnab Bhattacharjee Team|[2511.14158](http://arxiv.org/abs/2511.14158)|null|\n", "2511.14027": "|**2025-11-18**|**HiEAG: Evidence-Augmented Generation for Out-of-Context Misinformation Detection**|Guohong Fu Team|[2511.14027](http://arxiv.org/abs/2511.14027)|null|\n", "2511.13998": "|**2025-11-17**|**LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering**|Huan Wang Team|[2511.13998](http://arxiv.org/abs/2511.13998)|null|\n", "2511.13647": "|**2025-11-17**|**Part-X-MLLM: Part-aware 3D Multimodal Large Language Model**|Chunchao Guo Team|[2511.13647](http://arxiv.org/abs/2511.13647)|null|\n", "2511.13588": "|**2025-11-17**|**Data-driven Acceleration of MPC with Guarantees**|Enrique Mallada Team|[2511.13588](http://arxiv.org/abs/2511.13588)|null|\n", "2511.13188": "|**2025-11-17**|**Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control**|Emmanuel Dean Team|[2511.13188](http://arxiv.org/abs/2511.13188)|null|\n", "2511.13174": "|**2025-11-17**|**Warm-starting active-set solvers using graph neural networks**|Jens Sj\u00f6lund Team|[2511.13174](http://arxiv.org/abs/2511.13174)|null|\n", "2511.21705": "|**2025-11-17**|**Insight-A: Attribution-aware for Multimodal Misinformation Detection**|Guohong Fu Team|[2511.21705](http://arxiv.org/abs/2511.21705)|null|\n", "2511.12634": "|**2025-11-16**|**Approximate Tracking Controllability of Systems with Quadratic Nonlinearities**|Marius Tucsnak Team|[2511.12634](http://arxiv.org/abs/2511.12634)|null|\n", "2511.12615": "|**2025-12-10**|**A New Perspective on Double-S Curve Motions of Higher Order and Optimal Motion Planning**|Rico Z\u00f6llner Team|[2511.12615](http://arxiv.org/abs/2511.12615)|null|\n", "2511.12436": "|**2025-11-16**|**RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation**|Long Chen Team|[2511.12436](http://arxiv.org/abs/2511.12436)|null|\n"}, "World-Models": {"2512.16924": "|**2025-12-18**|**The World is Your Canvas: Painting Promptable Events with Reference Images, Trajectories, and Text**|Qifeng Chen Team|[2512.16924](http://arxiv.org/abs/2512.16924)|**[link](https://worldcanvas.github.io/)**|\n", "2512.16791": "|**2025-12-18**|**KineST: A Kinematics-guided Spatiotemporal State Space Model for Human Motion Tracking from Sparse Signals**|Xinrong Chen Team|[2512.16791](http://arxiv.org/abs/2512.16791)|null|\n", "2512.16723": "|**2025-12-18**|**KOSS: Kalman-Optimal Selective State Spaces for Long-Term Sequence Modeling**|Ying Zhang Team|[2512.16723](http://arxiv.org/abs/2512.16723)|null|\n", "2512.16463": "|**2025-12-18**|**Dynamic Prediction for Hospital Readmission in Patients with Chronic Heart Failure**|Silvia Metelli Team|[2512.16463](http://arxiv.org/abs/2512.16463)|null|\n", "2512.16461": "|**2025-12-18**|**SNOW: Spatio-Temporal Scene Understanding with World Knowledge for Open-World Embodied Reasoning**|Eric Sax Team|[2512.16461](http://arxiv.org/abs/2512.16461)|null|\n", "2512.16454": "|**2025-12-18**|**AG-MPBS: a Mobility-Aware Prediction and Behavior-Based Scheduling Framework for Air-Ground Unmanned Systems**|Bin Guo Team|[2512.16454](http://arxiv.org/abs/2512.16454)|null|\n", "2512.16315": "|**2025-12-18**|**CPMamba: Selective State Space Models for MIMO Channel Prediction in High-Mobility Environments**|Kaishun Wu Team|[2512.16315](http://arxiv.org/abs/2512.16315)|null|\n", "2512.16151": "|**2025-12-18**|**Artificial Intelligence-Enabled Holistic Design of Catalysts Tailored for Semiconducting Carbon Nanotube Growth**|Jin Zhang Team|[2512.16151](http://arxiv.org/abs/2512.16151)|null|\n", "2512.16117": "|**2025-12-18**|**Wake transitions and melting dynamics of a translating sphere in warm liquid**|Jie Zhang Team|[2512.16117](http://arxiv.org/abs/2512.16117)|null|\n", "2512.15946": "|**2025-12-17**|**AIE4ML: An End-to-End Framework for Compiling Neural Networks for the Next Generation of AMD AI Engines**|Maurizio Pierini Team|[2512.15946](http://arxiv.org/abs/2512.15946)|null|\n", "2512.15940": "|**2025-12-17**|**R4: Retrieval-Augmented Reasoning for Vision-Language Models in 4D Spatio-Temporal Space**|Eric Sax Team|[2512.15940](http://arxiv.org/abs/2512.15940)|null|\n", "2512.15931": "|**2025-12-17**|**BarcodeMamba+: Advancing State-Space Models for Fungal Biodiversity Research**|Graham W. Taylor Team|[2512.15931](http://arxiv.org/abs/2512.15931)|null|\n", "2512.15916": "|**2025-12-17**|**A Comprehensive Benchmark Platform for Process Control Research of Outdoor Microalgae Raceway Reactors**|Manuel Berenguel Team|[2512.15916](http://arxiv.org/abs/2512.15916)|null|\n", "2512.15712": "|**2025-12-17**|**Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants**|Jacob Steinhardt Team|[2512.15712](http://arxiv.org/abs/2512.15712)|null|\n", "2512.15692": "|**2025-12-17**|**mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs**|Elvis Nava Team|[2512.15692](http://arxiv.org/abs/2512.15692)|null|\n", "2512.15681": "|**2025-12-17**|**Radiomics and Clinical Features in Predictive Modelling of Brain Metastases Recurrence**|Victor Alves Team|[2512.15681](http://arxiv.org/abs/2512.15681)|null|\n", "2512.15653": "|**2025-12-17**|**Characterizing Mamba's Selective Memory using Auto-Encoders**|Alejandro Jaimes Team|[2512.15653](http://arxiv.org/abs/2512.15653)|null|\n", "2512.15628": "|**2025-12-17**|**Learning continuous SOC-dependent thermal decomposition kinetics for Li-ion cathodes using KA-CRNNs**|Sili Deng Team|[2512.15628](http://arxiv.org/abs/2512.15628)|null|\n", "2512.15622": "|**2025-12-17**|**Operator-Theoretic Joint Estimation of Aging-Aware State of Charge and Control-Informed State of Health**|Mahesh Krishnamurthy Team|[2512.15622](http://arxiv.org/abs/2512.15622)|null|\n", "2512.15621": "|**2025-12-17**|**OccSTeP: Benchmarking 4D Occupancy Spatio-Temporal Persistence**|Jiaming Zhang Team|[2512.15621](http://arxiv.org/abs/2512.15621)|null|\n", "2512.15534": "|**2025-12-17**|**Characterizing Open-Ended Evolution Through Undecidability Mechanisms in Random Boolean Networks**|Carlos Gershenson Team|[2512.15534](http://arxiv.org/abs/2512.15534)|null|\n", "2512.15493": "|**2025-12-17**|**Soft Geometric Inductive Bias for Object Centric Dynamics**|Christopher Buckley Team|[2512.15493](http://arxiv.org/abs/2512.15493)|null|\n", "2512.15439": "|**2025-12-17**|**Double Horizon Model-Based Policy Optimization**|Shin Ishii Team|[2512.15439](http://arxiv.org/abs/2512.15439)|**[link](https://github.com/4kubo/erl_lib)**|\n", "2512.15430": "|**2025-12-17**|**FM-EAC: Feature Model-based Enhanced Actor-Critic for Multi-Task Control in Dynamic Environments**|Yusheng Ji Team|[2512.15430](http://arxiv.org/abs/2512.15430)|null|\n", "2512.15386": "|**2025-12-17**|**See It Before You Grab It: Deep Learning-based Action Anticipation in Basketball**|Albert Clap\u00e9s Sintes Team|[2512.15386](http://arxiv.org/abs/2512.15386)|null|\n", "2512.15128": "|**2025-12-17**|**On non-stationarity of the Poisson gamma state space models**|Tevfik Aktekin Team|[2512.15128](http://arxiv.org/abs/2512.15128)|null|\n", "2512.15115": "|**2025-12-17**|**How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models**|Ali Ghodsi Team|[2512.15115](http://arxiv.org/abs/2512.15115)|null|\n", "2512.15036": "|**2025-12-17**|**Spectral Representation-based Reinforcement Learning**|Bo Dai Team|[2512.15036](http://arxiv.org/abs/2512.15036)|null|\n", "2512.15008": "|**2025-12-17**|**Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for Structural Price Run Extraction and Event Correlation in Equity Markets**|Sandeep Neela Team|[2512.15008](http://arxiv.org/abs/2512.15008)|null|\n", "2512.15803": "|**2025-12-16**|**An empirical analysis of zero-day vulnerabilities disclosed by the zero day initiative**|Izzat Alsmadi Team|[2512.15803](http://arxiv.org/abs/2512.15803)|null|\n", "2512.14953": "|**2025-12-16**|**A Dynamic Subgrid-Scale Model Based on Liutex Theory for Wall-Bounded Turbulent Flows**|Chaoqun Liu Team|[2512.14953](http://arxiv.org/abs/2512.14953)|null|\n", "2512.14840": "|**2025-12-16**|**Investigating the Efficacy of Topologically Derived Time Series for Flare Forecasting. II. XGBoost Model**|D. Shaun Bloomfield Team|[2512.14840](http://arxiv.org/abs/2512.14840)|null|\n", "2512.14691": "|**2025-12-17**|**MMGR: Multi-Modal Generative Reasoning**|Junjie Hu Team|[2512.14691](http://arxiv.org/abs/2512.14691)|null|\n", "2512.14617": "|**2025-12-16**|**Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes**|Fabio Patrizi Team|[2512.14617](http://arxiv.org/abs/2512.14617)|null|\n", "2512.14614": "|**2025-12-16**|**WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling**|Chunchao Guo Team|[2512.14614](http://arxiv.org/abs/2512.14614)|**[link](https://3d-models.hunyuan.tencent.com/world/)**|\n", "2512.14493": "|**2025-12-16**|**Graphene-Insulator-Superconductor junctions as thermoelectric bolometers**|Federico Paolucci Team|[2512.14493](http://arxiv.org/abs/2512.14493)|null|\n", "2512.14779": "|**2025-12-16**|**Evaluating Weather Forecasts from a Decision Maker's Perspective**|Nicole Ludwig Team|[2512.14779](http://arxiv.org/abs/2512.14779)|null|\n", "2512.14220": "|**2025-12-16**|**Estimating problem difficulty without ground truth using Large Language Model comparisons**|Vincent Ginis Team|[2512.14220](http://arxiv.org/abs/2512.14220)|null|\n", "2512.14136": "|**2025-12-16**|**Coordinated Fast Frequency Response from Electric Vehicles, Data Centers, and Battery Energy Storage Systems**|Rajit Gadh Team|[2512.14136](http://arxiv.org/abs/2512.14136)|null|\n", "2512.14128": "|**2025-12-16**|**Fast Frequency Response Potential of Data Centers through Workload Modulation and UPS Coordination**|Rajit Gadh Team|[2512.14128](http://arxiv.org/abs/2512.14128)|null|\n", "2512.14093": "|**2025-12-16**|**Quality-Aware Framework for Video-Derived Respiratory Signals**|Miguel Bordallo L\u00f3pez Team|[2512.14093](http://arxiv.org/abs/2512.14093)|null|\n", "2512.14085": "|**2025-12-16**|**Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study**|Tatsuya Kawahara Team|[2512.14085](http://arxiv.org/abs/2512.14085)|null|\n", "2512.14069": "|**2025-12-16**|**RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees**|Jinlong Li Team|[2512.14069](http://arxiv.org/abs/2512.14069)|null|\n", "2512.14043": "|**2025-12-16**|**Evaluating Small Language Models for Agentic On-Farm Decision Support Systems**|Miel Hostens Team|[2512.14043](http://arxiv.org/abs/2512.14043)|null|\n", "2512.14041": "|**2025-12-16**|**From Feature Interaction to Feature Generation: A Generative Paradigm of CTR Prediction Models**|Enhong Chen Team|[2512.14041](http://arxiv.org/abs/2512.14041)|null|\n", "2512.14014": "|**2025-12-16**|**MobileWorldBench: Towards Semantic World Modeling For Mobile Agents**|Aditya Grover Team|[2512.14014](http://arxiv.org/abs/2512.14014)|null|\n", "2512.14011": "|**2025-12-16**|**Accelerating MHC-II Epitope Discovery via Multi-Scale Prediction in Antigen Presentation**|Xiaowei Jia Team|[2512.14011](http://arxiv.org/abs/2512.14011)|null|\n", "2512.13977": "|**2025-12-16**|**XAI-Driven Diagnosis of Generalization Failure in State-Space Cerebrovascular Segmentation Models: A Case Study on Domain Shift Between RSNA and TopCoW Datasets**|Ahmad Al-Kabbany Team|[2512.13977](http://arxiv.org/abs/2512.13977)|null|\n", "2512.13910": "|**2025-12-15**|**Exploring Machine Learning, Deep Learning, and Explainable AI Methods for Seasonal Precipitation Prediction in South America**|Andr\u00e9 Estevam Costa Oliveira Team|[2512.13910](http://arxiv.org/abs/2512.13910)|null|\n", "2512.13897": "|**2025-12-15**|**Seismic wave propagation in viscoelastic media under Atangana-Baleanu fractional dynamics: Model formulation and numerical simulations**|Atakan Ko\u00e7yi\u011fit Team|[2512.13897](http://arxiv.org/abs/2512.13897)|null|\n", "2512.13821": "|**2025-12-15**|**The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces**|Jared Junkin Team|[2512.13821](http://arxiv.org/abs/2512.13821)|null|\n", "2512.13644": "|**2025-12-15**|**World Models Can Leverage Human Videos for Dexterous Manipulation**|Yann LeCun Team|[2512.13644](http://arxiv.org/abs/2512.13644)|null|\n", "2512.13604": "|**2025-12-15**|**LongVie 2: Multimodal Controllable Ultra-Long Video World Model**|Ziwei Liu Team|[2512.13604](http://arxiv.org/abs/2512.13604)|**[link](https://vchitect.github.io/LongVie2-project/)**|\n", "2512.13579": "|**2025-12-15**|**Machine-Learned Electrostatic Potentials for Accurate Hydration Free Energy Calculations**|Marco Kl\u00e4hn Team|[2512.13579](http://arxiv.org/abs/2512.13579)|null|\n", "2512.13517": "|**2025-12-15**|**A Deep Learning Model of Mental Rotation Informed by Interactive VR Experiments**|Stephane Deny Team|[2512.13517](http://arxiv.org/abs/2512.13517)|null|\n", "2512.13442": "|**2025-12-15**|**XNNTab -- Interpretable Neural Networks for Tabular Data using Sparse Autoencoders**|Christin Seifert Team|[2512.13442](http://arxiv.org/abs/2512.13442)|null|\n", "2512.13319": "|**2025-12-15**|**Temporal parallelisation of continuous-time maximum-a-posteriori trajectory estimation**|Simo S\u00e4rkk\u00e4 Team|[2512.13319](http://arxiv.org/abs/2512.13319)|null|\n", "2512.13271": "|**2025-12-15**|**Lightweight Dynamic Modeling of Cable-Driven Continuum Robots Based on Actuation-Space Energy Formulation**|Ke Wu Team|[2512.13271](http://arxiv.org/abs/2512.13271)|null|\n", "2512.13084": "|**2025-12-15**|**FlowClass.jl: Classifying Dynamical Systems by Structural Properties in Julia**|Michael P. H. Stumpf Team|[2512.13084](http://arxiv.org/abs/2512.13084)|null|\n", "2512.13030": "|**2025-12-15**|**Motus: A Unified Latent Action World Model**|Jun Zhu Team|[2512.13030](http://arxiv.org/abs/2512.13030)|null|\n", "2512.12881": "|**2025-12-14**|**Unsupervised learning of multiscale switching dynamical system models from multimodal neural data**|Maryam M. Shanechi Team|[2512.12881](http://arxiv.org/abs/2512.12881)|null|\n", "2512.12795": "|**2025-12-14**|**TRACER: Transfer Learning based Real-time Adaptation for Clinical Evolving Risk**|Chuan Hong Team|[2512.12795](http://arxiv.org/abs/2512.12795)|null|\n", "2512.12786": "|**2025-12-14**|**Solar Energetic Particle Forecasting with Multi-Task Deep Learning: SEPNet**|Tamas Gombosi Team|[2512.12786](http://arxiv.org/abs/2512.12786)|null|\n", "2512.12751": "|**2025-12-14**|**GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation**|Hengshuang Zhao Team|[2512.12751](http://arxiv.org/abs/2512.12751)|**[link](https://huster-yzy.github.io/geniedrive_project_page/)**|\n", "2512.15778": "|**2025-12-14**|**RAMBO: Reliability Analysis for Mamba through Bit-flip attack Optimization**|Kanad Basu Team|[2512.15778](http://arxiv.org/abs/2512.15778)|null|\n", "2512.12602": "|**2025-12-14**|**Error-Free Linear Attention is a Free Lunch: Exact Solution from Continuous-Time Dynamics**|Soujanya Poria Team|[2512.12602](http://arxiv.org/abs/2512.12602)|null|\n", "2512.12548": "|**2025-12-14**|**World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents**|Luis F. Giraldo Team|[2512.12548](http://arxiv.org/abs/2512.12548)|null|\n", "2512.12526": "|**2025-12-14**|**Empirical Mode Decomposition and Graph Transformation of the MSCI World Index: A Multiscale Topological Analysis for Graph Neural Network Modeling**|Le\u00f3n Bele\u00f1a Team|[2512.12526](http://arxiv.org/abs/2512.12526)|null|\n", "2512.12493": "|**2025-12-13**|**AI-Driven Early Warning Systems for Student Success: Discovering Static Feature Dominance in Temporal Prediction Models**|Rajib Mall Team|[2512.12493](http://arxiv.org/abs/2512.12493)|null|\n", "2512.12462": "|**2025-12-13**|**Dynamical modeling of nonlinear latent factors in multiscale neural activity with real-time inference**|Maryam M. Shanechi Team|[2512.12462](http://arxiv.org/abs/2512.12462)|**[link](https://github.com/ShanechiLab/mrine)**|\n", "2512.12449": "|**2025-12-13**|**Comparing Stochastic and Ray-tracing Datasets in Machine Learning for Wireless Applications**|Ahmed Alkhateeb Team|[2512.12449](http://arxiv.org/abs/2512.12449)|**[link](https://github.com/jmoraispk/StochasticRTcomparison)**|\n", "2512.12183": "|**2025-12-13**|**HydroDiffusion: Diffusion-Based Probabilistic Streamflow Forecasting with a State Space Backbone**|N. Benjamin Erichson Team|[2512.12183](http://arxiv.org/abs/2512.12183)|null|\n", "2512.12134": "|**2025-12-13**|**Modeling Dabrafenib Response Using Multi-Omics Modality Fusion and Protein Network Embeddings Based on Graph Convolutional Networks**|Yuszda K. Salimi Team|[2512.12134](http://arxiv.org/abs/2512.12134)|null|\n", "2512.12091": "|**2025-12-12**|**GraphPerf-RT: A Graph-Driven Performance Model for Hardware-Aware Scheduling of OpenMP Codes**|Ali Jannesari Team|[2512.12091](http://arxiv.org/abs/2512.12091)|null|\n", "2512.12080": "|**2025-12-12**|**BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models**|Gordon Wetzstein Team|[2512.12080](http://arxiv.org/abs/2512.12080)|**[link](https://ryanpo.com/bagger)**|\n", "2512.12026": "|**2025-12-12**|**DT-MPC: Synthesizing Derivation-Free Model Predictive Control from Power Converter Netlists via Physics-Informed Neural Digital Twins**|Leopoldo G. Franquelo Team|[2512.12026](http://arxiv.org/abs/2512.12026)|null|\n", "2512.11797": "|**2025-12-12**|**AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis**|Vitor Guizilini Team|[2512.11797](http://arxiv.org/abs/2512.11797)|**[link](https://jay-ye.github.io/AnchorDream/)**|\n", "2512.11748": "|**2025-12-12**|**Generative Parametric Design (GPD): A framework for real-time geometry generation and on-the-fly multiparametric approximation**|Francisco Chinesta Team|[2512.11748](http://arxiv.org/abs/2512.11748)|null|\n", "2512.11613": "|**2025-12-12**|**Boltzmann to Lindblad: Classical and Quantum Approaches to Out-of-Equilibrium Statistical Mechanics**|Ralf Blossey Team|[2512.11613](http://arxiv.org/abs/2512.11613)|null|\n", "2512.11532": "|**2025-12-12**|**Parallax: Runtime Parallelization for Operator Fallbacks in Heterogeneous Edge Systems**|Jagmohan Chauhan Team|[2512.11532](http://arxiv.org/abs/2512.11532)|null|\n", "2512.11503": "|**2025-12-12**|**TSkel-Mamba: Temporal Dynamic Modeling via State Space Model for Human Skeleton-based Action Recognition**|Qiuhong Ke Team|[2512.11503](http://arxiv.org/abs/2512.11503)|null|\n", "2512.11352": "|**2025-12-12**|**CAT: Can Trust be Predicted with Context-Awareness in Dynamic Heterogeneous Networks?**|Elisa Bertino Team|[2512.11352](http://arxiv.org/abs/2512.11352)|null|\n", "2512.11273": "|**2025-12-15**|**Integrated Prediction and Multi-period Portfolio Optimization**|Qi Deng Team|[2512.11273](http://arxiv.org/abs/2512.11273)|null|\n", "2512.11930": "|**2025-12-12**|**Evolutionary Reinforcement Learning based AI tutor for Socratic Interdisciplinary Instruction**|Aimin Zhou Team|[2512.11930](http://arxiv.org/abs/2512.11930)|null|\n", "2512.11226": "|**2025-12-12**|**FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model**|Zhen Li Team|[2512.11226](http://arxiv.org/abs/2512.11226)|null|\n", "2512.11225": "|**2025-12-12**|**VFMF: World Modeling by Forecasting Vision Foundation Model Features**|Andrea Vedaldi Team|[2512.11225](http://arxiv.org/abs/2512.11225)|null|\n", "2512.11154": "|**2025-12-11**|**Stabilising Learner Trajectories: A Doubly Robust Evaluation of AI-Guided Student Support using Activity Theory**|Anuradha Mathrani Team|[2512.11154](http://arxiv.org/abs/2512.11154)|null|\n", "2512.11081": "|**2025-12-11**|**Provable Recovery of Locally Important Signed Features and Interactions from Random Forest**|Merle Behr Team|[2512.11081](http://arxiv.org/abs/2512.11081)|null|\n", "2512.11061": "|**2025-12-11**|**VDAWorld: World Modelling via VLM-Directed Abstraction and Simulation**|Ayush Tewari Team|[2512.11061](http://arxiv.org/abs/2512.11061)|**[link](https://felixomahony.github.io/vdaworld/)**|\n", "2512.11048": "|**2025-12-11**|**Physics Informed Dynamical Modeling of Extrusion Based 3D Printing Processes**|Satadru Dey Team|[2512.11048](http://arxiv.org/abs/2512.11048)|null|\n", "2512.10958": "|**2025-12-11**|**WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World**|Ziwei Liu Team|[2512.10958](http://arxiv.org/abs/2512.10958)|**[link](https://worldbench.github.io/worldlens)**|\n", "2512.11017": "|**2025-12-11**|**Integrating Uncertainty Quantification into Computational Fluid Dynamics Models of Coronary Arteries Under Steady Flow**|Lucas H. Timmins Team|[2512.11017](http://arxiv.org/abs/2512.11017)|null|\n", "2512.10822": "|**2025-12-11**|**V-OCBF: Learning Safety Filters from Offline Data via Value-Guided Offline Control Barrier Functions**|Ravi Prakash Team|[2512.10822](http://arxiv.org/abs/2512.10822)|null|\n", "2512.11012": "|**2025-12-11**|**On a class of constrained Bayesian filters and their numerical implementation in high-dimensional state-space Markov models**|Joaquin Miguez Team|[2512.11012](http://arxiv.org/abs/2512.11012)|null|\n", "2512.10773": "|**2025-12-11**|**AERMANI-Diffusion: Regime-Conditioned Diffusion for Dynamics Learning in Aerial Manipulators**|Spandan Roy Team|[2512.10773](http://arxiv.org/abs/2512.10773)|null|\n", "2512.10723": "|**2025-12-11**|**Generalized Spherical Neural Operators: Green's Function Formulation**|Chao Li Team|[2512.10723](http://arxiv.org/abs/2512.10723)|null|\n", "2512.10675": "|**2025-12-11**|**Evaluating Gemini Robotics Policies in a Veo World Simulator**|Allan Zhou Team|[2512.10675](http://arxiv.org/abs/2512.10675)|null|\n", "2512.10672": "|**2025-12-11**|**Capability Accumulation and Conditional Convergence: Towards a Dynamic Theory of Economic Complexity**|Viktor Stojkoski Team|[2512.10672](http://arxiv.org/abs/2512.10672)|null|\n", "2512.10451": "|**2025-12-11**|**Metacognitive Sensitivity for Test-Time Dynamic Model Selection**|An Duc Nguyen Team|[2512.10451](http://arxiv.org/abs/2512.10451)|null|\n", "2512.10424": "|**2025-12-11**|**Neural Hamiltonian Deformation Fields for Dynamic Scene Rendering**|Jincheng Dai Team|[2512.10424](http://arxiv.org/abs/2512.10424)|**[link](https://qin-jingyun.github.io/NeHaD)**|\n", "2512.10371": "|**2025-12-11**|**AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management**|Yuanchun Li Team|[2512.10371](http://arxiv.org/abs/2512.10371)|null|\n", "2512.10353": "|**2025-12-11**|**Hybrid Transformer-Mamba Architecture for Weakly Supervised Volumetric Medical Segmentation**|Girish Dwivedi Team|[2512.10353](http://arxiv.org/abs/2512.10353)|null|\n", "2512.10294": "|**2025-12-11**|**Lies We Can Trust: Quantifying Action Uncertainty with Inaccurate Stochastic Dynamics through Conformalized Nonholonomic Lie Groups**|Dmitry Berenson Team|[2512.10294](http://arxiv.org/abs/2512.10294)|null|\n", "2512.10226": "|**2025-12-11**|**Latent Chain-of-Thought World Modeling for End-to-End Driving**|Boris Ivanovic Team|[2512.10226](http://arxiv.org/abs/2512.10226)|null|\n", "2512.10211": "|**2025-12-11**|**ID-PaS : Identity-Aware Predict-and-Search for General Mixed-Integer Linear Programs**|Bistra Dilkina Team|[2512.10211](http://arxiv.org/abs/2512.10211)|null|\n", "2512.10128": "|**2025-12-10**|**Inertial Magnetic SLAM Systems Using Low-Cost Sensors**|Isaac Skog Team|[2512.10128](http://arxiv.org/abs/2512.10128)|null|\n", "2512.10016": "|**2025-12-10**|**Latent Action World Models for Control with Unlabeled Trajectories**|Philip Becker-Ehmck Team|[2512.10016](http://arxiv.org/abs/2512.10016)|null|\n", "2512.09987": "|**2025-12-10**|**Orbital migration and heating history of the Galactic disc: a transition between the bimodal discs**|Sergey E. Koposov Team|[2512.09987](http://arxiv.org/abs/2512.09987)|null|\n", "2512.09929": "|**2025-12-10**|**Closing the Train-Test Gap in World Models for Gradient-Based Planning**|Micah Goldblum Team|[2512.09929](http://arxiv.org/abs/2512.09929)|null|\n", "2512.09864": "|**2025-12-10**|**UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving**|Ying-Cong Chen Team|[2512.09864](http://arxiv.org/abs/2512.09864)|**[link](https://seed-uniugp.github.io/)**|\n", "2512.09790": "|**2025-12-10**|**A Conversation with Mike West**|Filippo Ascolani Team|[2512.09790](http://arxiv.org/abs/2512.09790)|null|\n", "2512.09717": "|**2025-12-10**|**Innovation ARIMA models application to predict pressure variations in water supply networks with open-loop control. Case study in Noja (Cantabria, Spain)**|Alberto-Jesus Perea-Moreno Team|[2512.09717](http://arxiv.org/abs/2512.09717)|null|\n", "2512.11900": "|**2025-12-10**|**Data-driven Interpretable Hybrid Robot Dynamics**|Haitham Bou-Ammar Team|[2512.11900](http://arxiv.org/abs/2512.11900)|null|\n", "2512.09561": "|**2025-12-10**|**Neural posterior inference with state-space models for calibrating ice sheet simulators**|Noel Cressie Team|[2512.09561](http://arxiv.org/abs/2512.09561)|null|\n", "2512.09492": "|**2025-12-11**|**StateSpace-SSL: Linear-Time Self-supervised Learning for Plant Disease Detection**|Mohammad Awrangjeb Team|[2512.09492](http://arxiv.org/abs/2512.09492)|null|\n", "2512.09411": "|**2025-12-10**|**D$^2$GSLAM: 4D Dynamic Gaussian Splatting SLAM**|Hesheng Wang Team|[2512.09411](http://arxiv.org/abs/2512.09411)|null|\n", "2512.09387": "|**2025-12-10**|**The Statistical Analysis Of The Galactic Open Clusters' Structure**|Zhi-Yong Pu Team|[2512.09387](http://arxiv.org/abs/2512.09387)|null|\n", "2512.09372": "|**2025-12-10**|**Intelligent Resilience Testing for Decision-Making Agents with Dual-Mode Surrogate Adaptation**|Huaxin Pei Team|[2512.09372](http://arxiv.org/abs/2512.09372)|null|\n", "2512.09216": "|**2025-12-10**|**Bug Priority Change Prediction: An Exploratory Study on Apache Software**|Yutao Ma Team|[2512.09216](http://arxiv.org/abs/2512.09216)|null|\n", "2512.08931": "|**2025-12-15**|**Astra: General Interactive World Model with Autoregressive Denoising**|Jiwen Lu Team|[2512.08931](http://arxiv.org/abs/2512.08931)|**[link](https://github.com/EternalEvan/Astra)**|\n", "2512.08832": "|**2025-12-09**|**Forecasting Fails: Unveiling Evasion Attacks in Weather Prediction Models**|Bhavya Kailkhura Team|[2512.08832](http://arxiv.org/abs/2512.08832)|null|\n", "2512.08778": "|**2025-12-09**|**Backwards Gamma-Ray Bursts: Searching for Exploding Primordial Black Holes in Short-Duration GRB Catalogs**|Kally Wen Team|[2512.08778](http://arxiv.org/abs/2512.08778)|null|\n", "2512.08732": "|**2025-12-09**|**Neural Ordinary Differential Equations for Simulating Metabolic Pathway Dynamics from Time-Series Multiomics Data**|Andrei Lixandru Team|[2512.08732](http://arxiv.org/abs/2512.08732)|null|\n", "2512.08591": "|**2025-12-09**|**Long-Sequence LSTM Modeling for NBA Game Outcome Prediction Using a Novel Multi-Season Dataset**|Nikolaos Polatidis Team|[2512.08591](http://arxiv.org/abs/2512.08591)|null|\n", "2512.08495": "|**2025-12-16**|**Supervised Classification of LEO Debris Families Using Multi-Set Proper Elements**|Yang Yang Team|[2512.08495](http://arxiv.org/abs/2512.08495)|null|\n", "2512.08483": "|**2025-12-15**|**NeurIDA: Dynamic Modeling for Effective In-Database Analytics**|Beng Chin Ooi Team|[2512.08483](http://arxiv.org/abs/2512.08483)|null|\n", "2512.08478": "|**2025-12-09**|**Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform**|Zhihang Zhong Team|[2512.08478](http://arxiv.org/abs/2512.08478)|**[link](https://visionary-laboratory.github.io/visionary)**|\n", "2512.08471": "|**2025-12-09**|**Benchmarking First-Principles Approaches for Extracting Magnetic Exchange Interactions**|Mojtaba Alaei Team|[2512.08471](http://arxiv.org/abs/2512.08471)|null|\n", "2512.08415": "|**2025-12-09**|**Integration of AI-Driven CAD Systems in Designing Water and Power Transportation Infrastructure for Industrial and Remote Landscape Applications**|Sunggyu Park Team|[2512.08415](http://arxiv.org/abs/2512.08415)|null|\n", "2512.08411": "|**2025-12-09**|**Prismatic World Model: Learning Compositional Dynamics for Planning in Hybrid Systems**|Yaodong Yang Team|[2512.08411](http://arxiv.org/abs/2512.08411)|null|\n", "2512.08405": "|**2025-12-09**|**Learning Robot Manipulation from Audio World Models**|Michael Gienger Team|[2512.08405](http://arxiv.org/abs/2512.08405)|null|\n", "2512.09003": "|**2025-12-18**|**Digital Modeling of Spatial Pathway Activity from Histology Reveals Tumor Microenvironment Heterogeneity**|Richard Cote Team|[2512.09003](http://arxiv.org/abs/2512.09003)|null|\n", "2512.08296": "|**2025-12-17**|**Towards a Science of Scaling Agent Systems**|Xin Liu Team|[2512.08296](http://arxiv.org/abs/2512.08296)|null|\n", "2512.08291": "|**2025-12-09**|**Exposing and Defending Membership Leakage in Vulnerability Prediction Models**|Yicheng Sun Team|[2512.08291](http://arxiv.org/abs/2512.08291)|null|\n", "2512.08281": "|**2025-12-09**|**Probabilistic Multi-Agent Aircraft Landing Time Prediction**|Keumjin Lee Team|[2512.08281](http://arxiv.org/abs/2512.08281)|null|\n", "2512.08280": "|**2025-12-09**|**Model-Based Diffusion Sampling for Predictive Control in Offline Decision Making**|Yilun Du Team|[2512.08280](http://arxiv.org/abs/2512.08280)|null|\n", "2512.08271": "|**2025-12-09**|**Zero-Splat TeleAssist: A Zero-Shot Pose Estimation Framework for Semantic Teleoperation**|Dharini Raghavan Team|[2512.08271](http://arxiv.org/abs/2512.08271)|null|\n", "2512.08257": "|**2025-12-09**|**Geometric-Stochastic Multimodal Deep Learning for Predictive Modeling of SUDEP and Stroke Vulnerability**|Tanish Jain Team|[2512.08257](http://arxiv.org/abs/2512.08257)|null|\n", "2512.08230": "|**2025-12-09**|**Empowerment Gain and Causal Model Construction: Children and adults are sensitive to controllability and variability in their causal interventions**|Alison Gopnik Team|[2512.08230](http://arxiv.org/abs/2512.08230)|null|\n", "2512.08188": "|**2025-12-09**|**Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model**|Rui Chen Team|[2512.08188](http://arxiv.org/abs/2512.08188)|**[link](https://embodied-tree-of-thoughts.github.io)**|\n", "2512.08108": "|**2025-12-08**|**Scalable Offline Model-Based RL with Action Chunks**|Sergey Levine Team|[2512.08108](http://arxiv.org/abs/2512.08108)|null|\n", "2512.08029": "|**2025-12-08**|**CLARITY: Medical World Model for Guiding Treatment Decisions by Modeling Context-Aware Disease Trajectories in Latent Space**|Yu Tian Team|[2512.08029](http://arxiv.org/abs/2512.08029)|null|\n", "2512.14712": "|**2025-12-08**|**SepsisSuite: Beyond Risk Stratification -- A Comparative Analysis of Deep Fusion vs. Expert Stacking for Prescriptive Sepsis AI**|Ryan Cartularo Team|[2512.14712](http://arxiv.org/abs/2512.14712)|null|\n", "2512.07973": "|**2025-12-08**|**Bayesian Semiparametric Joint Dynamic Model for Multitype Recurrent Events and a Terminal Event**|AKM Fazlur Rahman Team|[2512.07973](http://arxiv.org/abs/2512.07973)|null|\n", "2512.07821": "|**2025-12-08**|**WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling**|Qixing Huang Team|[2512.07821](http://arxiv.org/abs/2512.07821)|null|\n", "2512.07757": "|**2025-12-08**|**Augmented Neural Ordinary Differential Equations for Power System Identification**|Christian A. Hans Team|[2512.07757](http://arxiv.org/abs/2512.07757)|null|\n", "2512.07733": "|**2025-12-08**|**SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery**|Xiaodan Liang Team|[2512.07733](http://arxiv.org/abs/2512.07733)|null|\n", "2512.07726": "|**2025-12-08**|**Multi-Generator Continual Learning for Robust Delay Prediction in 6G**|Andreas Johnsson Team|[2512.07726](http://arxiv.org/abs/2512.07726)|null|\n", "2512.07668": "|**2025-12-08**|**EgoCampus: Egocentric Pedestrian Eye Gaze Model and Dataset**|Kristin Dana Team|[2512.07668](http://arxiv.org/abs/2512.07668)|null|\n", "2512.07581": "|**2025-12-10**|**Dynamic Screening Effects on Auger Recombination in Metal-Halide Perovskites**|Sergei I. Simak Team|[2512.07581](http://arxiv.org/abs/2512.07581)|null|\n", "2512.07558": "|**2025-12-08**|**ReLaX: Reasoning with Latent Exploration for Large Reasoning Models**|Jibin Wu Team|[2512.07558](http://arxiv.org/abs/2512.07558)|null|\n", "2512.07542": "|**2025-12-08**|**RRAEDy: Adaptive Latent Linearization of Nonlinear Dynamical Systems**|Francisco Chinesta Team|[2512.07542](http://arxiv.org/abs/2512.07542)|null|\n", "2512.07528": "|**2025-12-08**|**Model-Based Reinforcement Learning Under Confounding**|Andreas A. Malikopoulos Team|[2512.07528](http://arxiv.org/abs/2512.07528)|null|\n", "2512.07437": "|**2025-12-08**|**KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models**|Xueyu Luan Team|[2512.07437](http://arxiv.org/abs/2512.07437)|null|\n", "2512.07385": "|**2025-12-08**|**How Far are Modern Trackers from UAV-Anti-UAV? A Million-Scale Benchmark and New Baseline**|Yanfeng Wang Team|[2512.07385](http://arxiv.org/abs/2512.07385)|**[link](https://github.com/983632847/Awesome-Multimodal-Object-Tracking)**|\n", "2512.07316": "|**2025-12-08**|**Model Predictive Control for Cooperative Docking Between Autonomous Surface Vehicles with Disturbance Rejection**|Bart De Schutter Team|[2512.07316](http://arxiv.org/abs/2512.07316)|null|\n", "2512.07237": "|**2025-12-08**|**Unified Camera Positional Encoding for Controlled Video Generation**|Jianfei Cai Team|[2512.07237](http://arxiv.org/abs/2512.07237)|**[link](https://github.com/chengzhag/UCPE)**|\n", "2512.07200": "|**2025-12-08**|**Less is More: Non-uniform Road Segments are Efficient for Bus Arrival Prediction**|Haitao Yu Team|[2512.07200](http://arxiv.org/abs/2512.07200)|null|\n", "2512.08991": "|**2025-12-08**|**Deterministic World Models for Verification of Closed-loop Vision-based Systems**|Ivan Ruchkin Team|[2512.08991](http://arxiv.org/abs/2512.08991)|null|\n", "2512.07091": "|**2025-12-08**|**A Flexible Funnel-Shaped Robotic Hand with an Integrated Single-Sheet Valve for Milligram-Scale Powder Handling**|Yoshitaka Ushiku Team|[2512.07091](http://arxiv.org/abs/2512.07091)|null|\n", "2512.07010": "|**2025-12-07**|**Always Keep Your Promises: DynamicLRP, A Model-Agnostic Solution To Layer-Wise Relevance Propagation**|Pablo Millan Arias Team|[2512.07010](http://arxiv.org/abs/2512.07010)|null|\n", "2512.06983": "|**2025-12-07**|**On Memory: A comparison of memory mechanisms in world models**|Corey Clark Team|[2512.06983](http://arxiv.org/abs/2512.06983)|null|\n", "2512.06982": "|**2025-12-11**|**LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding**|Li Jin Team|[2512.06982](http://arxiv.org/abs/2512.06982)|null|\n", "2512.06961": "|**2025-12-07**|**Self-organized criticality in complex model ecosystems**|Thibaut Arnoulx de Pirey Team|[2512.06961](http://arxiv.org/abs/2512.06961)|null|\n", "2512.06945": "|**2025-12-07**|**Symmetric Aggregation of Conformity Scores for Efficient Uncertainty Sets**|Souhaib Ben Taieb Team|[2512.06945](http://arxiv.org/abs/2512.06945)|null|\n", "2512.06865": "|**2025-12-07**|**Spatial Retrieval Augmented Autonomous Driving**|Yu-Gang Jiang Team|[2512.06865](http://arxiv.org/abs/2512.06865)|**[link](https://spatialretrievalad.github.io/)**|\n", "2512.06847": "|**2025-12-07**|**FGE: A Fast Free-Boundary Grad-Shafranov Evolutive Solver**|Olivier Sauter Team|[2512.06847](http://arxiv.org/abs/2512.06847)|null|\n", "2512.06813": "|**2025-12-10**|**Partial Inverse Design of High-Performance Concrete Using Cooperative Neural Networks for Constraint-Aware Mix Generation**|Jihwan Lee Team|[2512.06813](http://arxiv.org/abs/2512.06813)|null|\n", "2512.06699": "|**2025-12-07**|**Predictive Modeling of I/O Performance for Machine Learning Training Pipelines: A Data-Driven Approach to Storage Optimization**|Karthik Prabhakar Team|[2512.06699](http://arxiv.org/abs/2512.06699)|null|\n", "2512.06677": "|**2025-12-07**|**Learning-based Link Prediction Methods Integrating Network Topological Features and Embedding Representations**|Ke-Ke Shang Team|[2512.06677](http://arxiv.org/abs/2512.06677)|null|\n", "2512.06657": "|**2025-12-07**|**TextMamba: Scene Text Detector with Mamba**|Da-Han Wang Team|[2512.06657](http://arxiv.org/abs/2512.06657)|null|\n", "2512.06652": "|**2025-12-07**|**Adaptive Test-Time Training for Predicting Need for Invasive Mechanical Ventilation in Multi-Center Cohorts**|Shamim Nemati Team|[2512.06652](http://arxiv.org/abs/2512.06652)|null|\n", "2512.06628": "|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Xiu Li Team|[2512.06628](http://arxiv.org/abs/2512.06628)|null|\n", "2512.15739": "|**2025-12-06**|**Bayesian Modeling for Uncertainty Management in Financial Risk Forecasting and Compliance**|Lisan Al Amin Team|[2512.15739](http://arxiv.org/abs/2512.15739)|null|\n", "2512.06563": "|**2025-12-06**|**Deep Manifold Part 2: Neural Network Mathematics**|Gen-Hua Shi Team|[2512.06563](http://arxiv.org/abs/2512.06563)|null|\n", "2512.06521": "|**2025-12-06**|**ShadowWolf -- Automatic Labelling, Evaluation and Model Training Optimised for Camera Trap Wildlife Images**|Anna F\u00f6rster Team|[2512.06521](http://arxiv.org/abs/2512.06521)|null|\n", "2512.06511": "|**2025-12-06**|**Diagnosis-based mortality prediction for intensive care unit patients via transfer learning**|Joel Dubin Team|[2512.06511](http://arxiv.org/abs/2512.06511)|null|\n", "2512.13710": "|**2025-12-06**|**Predictive Modeling of Flood-Prone Areas Using SAR and Environmental Variables**|Denis Machanda Team|[2512.13710](http://arxiv.org/abs/2512.13710)|null|\n", "2512.06357": "|**2025-12-10**|**Proportional integral derivative booster for neural networks-based time-series prediction: Case of water demand prediction**|Wei He Team|[2512.06357](http://arxiv.org/abs/2512.06357)|null|\n", "2512.06280": "|**2025-12-06**|**Assessing the Information Content of Individual Spikes in Population-Level Models of Neural Spiking Activity**|Uri T. Eden Team|[2512.06280](http://arxiv.org/abs/2512.06280)|null|\n", "2512.11870": "|**2025-12-16**|**Using Socio-economic Indicators, Smart Transit Systems, and Urban Simulator to Accelerate ZEV Adoption and Reduce VMT**|Driss Benhaddou Team|[2512.11870](http://arxiv.org/abs/2512.11870)|null|\n", "2512.06158": "|**2025-12-05**|**Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation**|Mei Chen Team|[2512.06158](http://arxiv.org/abs/2512.06158)|null|\n", "2512.13707": "|**2025-12-05**|**Modular connectivity in neural networks emerges from Poisson noise-motivated regularisation, and promotes robustness and compositional generalisation**|Ila Fiete Team|[2512.13707](http://arxiv.org/abs/2512.13707)|null|\n", "2512.05955": "|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Yilun Du Team|[2512.05955](http://arxiv.org/abs/2512.05955)|null|\n", "2512.05933": "|**2025-12-05**|**Speech World Model: Causal State-Action Planning with Explicit Reasoning for Speech**|Gopala Anumanchipalli Team|[2512.05933](http://arxiv.org/abs/2512.05933)|null|\n", "2512.05927": "|**2025-12-05**|**World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty**|Anirudha Majumdar Team|[2512.05927](http://arxiv.org/abs/2512.05927)|null|\n", "2512.05895": "|**2025-12-08**|**A Machine Learning Framework for Predicting Glass-Forming Ability in Ternary Alloy Systems**|Fatemeh Mahmoudi Team|[2512.05895](http://arxiv.org/abs/2512.05895)|null|\n", "2512.05845": "|**2025-12-05**|**A Hybrid Dynamic Model for Predicting Human Cognition and Reliance during Automated Driving**|Neera Jain Team|[2512.05845](http://arxiv.org/abs/2512.05845)|null|\n", "2512.05818": "|**2025-12-05**|**Machine-learning-enabled interpretation of tribological deformation patterns in large-scale MD data**|Stefan J. Eder Team|[2512.05818](http://arxiv.org/abs/2512.05818)|null|\n", "2512.05809": "|**2025-12-05**|**Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling**|Sarath Chandar Team|[2512.05809](http://arxiv.org/abs/2512.05809)|null|\n", "2512.05808": "|**2025-12-05**|**Real-time Remote Tracking and Autonomous Planning for Whale Rendezvous using Robots**|Stephanie Gil Team|[2512.05808](http://arxiv.org/abs/2512.05808)|null|\n", "2512.05725": "|**2025-12-05**|**Opinion dynamics modelling: distinct attraction and repulsion topologies highlight quantitative effects of trolling**|Mathew Zuparic Team|[2512.05725](http://arxiv.org/abs/2512.05725)|null|\n", "2512.05680": "|**2025-12-05**|**Meta-Learning Multi-armed Bandits for Beam Tracking in 5G and 6G Networks**|Christopher Mutschler Team|[2512.05680](http://arxiv.org/abs/2512.05680)|null|\n", "2512.05536": "|**2025-12-05**|**Eye of the Beholder: Towards Measuring Visualization Complexity**|Niklas Elmqvist Team|[2512.05536](http://arxiv.org/abs/2512.05536)|null|\n", "2512.05456": "|**2025-12-05**|**Do We Really Even Need Data? A Modern Look at Drawing Inference with Predicted Data**|Jeffrey T. Leek Team|[2512.05456](http://arxiv.org/abs/2512.05456)|null|\n", "2512.05367": "|**2025-12-05**|**Enhancing Dimensionality Prediction in Hybrid Metal Halides via Feature Engineering and Class-Imbalance Mitigation**|Hendrik Heinz Team|[2512.05367](http://arxiv.org/abs/2512.05367)|null|\n", "2512.05361": "|**2025-12-05**|**FieldSeer I: Physics-Guided World Models for Long-Horizon Electromagnetic Dynamics under Partial Observability**|Yang Bu Team|[2512.05361](http://arxiv.org/abs/2512.05361)|null|\n", "2512.05292": "|**2025-12-08**|**Disturbance Compensation for Safe Kinematic Control of Robotic Systems with Closed Architecture**|Qin Lin Team|[2512.05292](http://arxiv.org/abs/2512.05292)|null|\n", "2512.05265": "|**2025-12-04**|**Real-time optimal quantum control for atomic magnetometers with decoherence**|Julia Amoros-Binefa Team|[2512.05265](http://arxiv.org/abs/2512.05265)|null|\n", "2512.05213": "|**2025-12-04**|**GA-NIFS: A smouldering disk galaxy undergoing ordered rotation at z=4.26**|Sandra Zamora Team|[2512.05213](http://arxiv.org/abs/2512.05213)|null|\n"}, "Embodied-Navigation": {"2512.15047": "|**2025-12-17**|**HERO: Hierarchical Traversable 3D Scene Graphs for Embodied Navigation Among Movable Obstacles**|Renjing Xu Team|[2512.15047](http://arxiv.org/abs/2512.15047)|null|\n", "2512.14691": "|**2025-12-17**|**MMGR: Multi-Modal Generative Reasoning**|Junjie Hu Team|[2512.14691](http://arxiv.org/abs/2512.14691)|null|\n", "2512.14442": "|**2025-12-16**|**A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning**|Ying-Cong Chen Team|[2512.14442](http://arxiv.org/abs/2512.14442)|null|\n", "2512.14222": "|**2025-12-17**|**History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation**|Jie Qin Team|[2512.14222](http://arxiv.org/abs/2512.14222)|null|\n", "2512.14217": "|**2025-12-16**|**DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos**|Gitta Kutyniok Team|[2512.14217](http://arxiv.org/abs/2512.14217)|null|\n", "2512.14032": "|**2025-12-16**|**ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM**|Andrew J. Davison Team|[2512.14032](http://arxiv.org/abs/2512.14032)|**[link](https://github.com/ialzugaray/ace-slam)**|\n", "2512.13609": "|**2025-12-15**|**Do-Undo: Generating and Reversing Physical Actions in Vision-Language Models**|Fatih Porikli Team|[2512.13609](http://arxiv.org/abs/2512.13609)|null|\n", "2512.12622": "|**2025-12-14**|**D3D-VLP: Dynamic 3D Vision-Language-Planning Model for Embodied Grounding and Navigation**|Gim Hee Lee Team|[2512.12622](http://arxiv.org/abs/2512.12622)|null|\n", "2512.12046": "|**2025-12-12**|**Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning**|Ahmed H. Qureshi Team|[2512.12046](http://arxiv.org/abs/2512.12046)|null|\n", "2512.11612": "|**2025-12-12**|**Embodied Image Compression**|Guangtao Zhai Team|[2512.11612](http://arxiv.org/abs/2512.11612)|null|\n", "2512.11234": "|**2025-12-12**|**RoomPilot: Controllable Synthesis of Interactive Indoor Environments via Multimodal Semantic Parsing**|Ruihui Li Team|[2512.11234](http://arxiv.org/abs/2512.11234)|null|\n", "2512.10958": "|**2025-12-11**|**WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World**|Ziwei Liu Team|[2512.10958](http://arxiv.org/abs/2512.10958)|**[link](https://worldbench.github.io/worldlens)**|\n", "2512.10668": "|**2025-12-11**|**XDen-1K: A Density Field Dataset of Real-World Objects**|Jingyi Yu Team|[2512.10668](http://arxiv.org/abs/2512.10668)|null|\n", "2512.10394": "|**2025-12-11**|**RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI**|Jian Cheng Team|[2512.10394](http://arxiv.org/abs/2512.10394)|null|\n", "2512.10360": "|**2025-12-11**|**CLASH: Collaborative Large-Small Hierarchical Framework for Continuous Vision-and-Language Navigation**|Qijun Chen Team|[2512.10360](http://arxiv.org/abs/2512.10360)|null|\n", "2512.10322": "|**2025-12-11**|**User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation**|Xiaojun Chang Team|[2512.10322](http://arxiv.org/abs/2512.10322)|null|\n", "2512.10310": "|**2025-12-11**|**Efficient-VLN: A Training-Efficient Vision-Language Navigation Model**|Liwei Wang Team|[2512.10310](http://arxiv.org/abs/2512.10310)|null|\n", "2512.10071": "|**2025-12-12**|**Openpi Comet: Competition Solution For 2025 BEHAVIOR Challenge**|Xiaohui Zeng Team|[2512.10071](http://arxiv.org/abs/2512.10071)|null|\n", "2512.10046": "|**2025-12-10**|**SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration**|Tianmin Shu Team|[2512.10046](http://arxiv.org/abs/2512.10046)|null|\n", "2512.08639": "|**2025-12-09**|**Aerial Vision-Language Navigation with a Unified Framework for Spatial, Temporal and Embodied Reasoning**|Feng Xu Team|[2512.08639](http://arxiv.org/abs/2512.08639)|null|\n", "2512.08186": "|**2025-12-09**|**Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation**|Xihui Liu Team|[2512.08186](http://arxiv.org/abs/2512.08186)|null|\n", "2512.07976": "|**2025-12-08**|**VLD: Visual Language Goal Distance for Reinforcement Learning Navigation**|Jonas Frey Team|[2512.07976](http://arxiv.org/abs/2512.07976)|null|\n", "2512.07237": "|**2025-12-08**|**Unified Camera Positional Encoding for Controlled Video Generation**|Jianfei Cai Team|[2512.07237](http://arxiv.org/abs/2512.07237)|**[link](https://github.com/chengzhag/UCPE)**|\n", "2512.06387": "|**2025-12-06**|**Beyond Model Jailbreak: Systematic Dissection of the \"Ten DeadlySins\" in Embodied Intelligence**|Xiuzhen Cheng Team|[2512.06387](http://arxiv.org/abs/2512.06387)|null|\n", "2512.05060": "|**2025-12-04**|**4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer**|Xinggang Wang Team|[2512.05060](http://arxiv.org/abs/2512.05060)|**[link](https://github.com/hustvl/4DLangVGGT)**|\n", "2512.04686": "|**2025-12-07**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Xiaolong Zheng Team|[2512.04686](http://arxiv.org/abs/2512.04686)|null|\n", "2512.04537": "|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Mike Zheng Shou Team|[2512.04537](http://arxiv.org/abs/2512.04537)|null|\n", "2512.04515": "|**2025-12-04**|**EgoLCD: Egocentric Video Generation with Long Context Diffusion**|Hao Tang Team|[2512.04515](http://arxiv.org/abs/2512.04515)|null|\n", "2512.04308": "|**2025-12-03**|**ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models**|Jianwei Zhang Team|[2512.04308](http://arxiv.org/abs/2512.04308)|**[link](https://sites.google.com/view/responsible-robotbench)**|\n", "2512.03958": "|**2025-12-15**|**MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation**|Xiang Li Team|[2512.03958](http://arxiv.org/abs/2512.03958)|null|\n", "2512.03438": "|**2025-12-03**|**Multimodal Reinforcement Learning with Agentic Verifier for AI Agents**|Jianfeng Gao Team|[2512.03438](http://arxiv.org/abs/2512.03438)|null|\n", "2512.03418": "|**2025-12-03**|**YOLOA: Real-Time Affordance Detection via LLM Adapter**|Xinbo Gao Team|[2512.03418](http://arxiv.org/abs/2512.03418)|null|\n", "2512.02982": "|**2025-12-02**|**U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences**|Qingshan Liu Team|[2512.02982](http://arxiv.org/abs/2512.02982)|null|\n", "2512.02631": "|**2025-12-02**|**SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization**|Deheng Ye Team|[2512.02631](http://arxiv.org/abs/2512.02631)|null|\n", "2512.02458": "|**2025-12-02**|**Vision to Geometry: 3D Spatial Memory for Sequential Embodied MLLM Reasoning and Exploration**|Yu Kong Team|[2512.02458](http://arxiv.org/abs/2512.02458)|null|\n", "2512.02020": "|**2025-12-14**|**EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI**|Xiangyu Xu Team|[2512.02020](http://arxiv.org/abs/2512.02020)|**[link](https://efficientflow.github.io/)**|\n", "2512.01952": "|**2025-12-01**|**GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment**|Sebastian Scherer Team|[2512.01952](http://arxiv.org/abs/2512.01952)|null|\n", "2512.01889": "|**2025-12-01**|**KM-ViPE: Online Tightly Coupled Vision-Language-Geometry Fusion for Open-Vocabulary Semantic SLAM**|Sergey Kolyubin Team|[2512.01889](http://arxiv.org/abs/2512.01889)|null|\n", "2512.01629": "|**2025-12-02**|**SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge**|Chenfanfu Jiang Team|[2512.01629](http://arxiv.org/abs/2512.01629)|**[link](https://heyumeng.com/SPARK/index.html.)**|\n", "2512.01550": "|**2025-12-01**|**NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction**|Mu Xu Team|[2512.01550](http://arxiv.org/abs/2512.01550)|null|\n", "2512.01223": "|**2025-12-01**|**S$^2$-MLLM: Boosting Spatial Reasoning Capability of MLLMs for 3D Visual Grounding with Structural Guidance**|Hesheng Wang Team|[2512.01223](http://arxiv.org/abs/2512.01223)|null|\n", "2512.01204": "|**2025-12-05**|**TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image**|Hu Su Team|[2512.01204](http://arxiv.org/abs/2512.01204)|**[link](https://d-robotics-ai-lab.github.io/TabletopGen.project/)**|\n", "2512.00547": "|**2025-11-29**|**Asset-Driven Sematic Reconstruction of Dynamic Scene with Multi-Human-Object Interactions**|Hamid Rezatofighi Team|[2512.00547](http://arxiv.org/abs/2512.00547)|null|\n", "2512.00493": "|**2025-11-29**|**CC-FMO: Camera-Conditioned Zero-Shot Single Image to 3D Scene Generation with Foundation Model Orchestration**|Gao Huang Team|[2512.00493](http://arxiv.org/abs/2512.00493)|null|\n", "2512.00226": "|**2025-11-28**|**DenseScan: Advancing 3D Scene Understanding with 2D Dense Annotation**|Tao Zhang Team|[2512.00226](http://arxiv.org/abs/2512.00226)|null|\n", "2511.22098": "|**2025-11-27**|**WorldWander: Bridging Egocentric and Exocentric Worlds in Video Generation**|Mike Zheng Shou Team|[2511.22098](http://arxiv.org/abs/2511.22098)|null|\n", "2511.21945": "|**2025-11-26**|**AmodalGen3D: Generative Amodal 3D Object Reconstruction from Sparse Unposed Views**|Yu-Wing Tai Team|[2511.21945](http://arxiv.org/abs/2511.21945)|null|\n", "2511.21460": "|**2025-11-26**|**MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning**|Xi Sheryl Zhang Team|[2511.21460](http://arxiv.org/abs/2511.21460)|null|\n", "2511.21428": "|**2025-11-26**|**From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings**|Alexander Kleiner Team|[2511.21428](http://arxiv.org/abs/2511.21428)|null|\n", "2511.21784": "|**2025-11-26**|**Physics-Informed Spiking Neural Networks via Conservative Flux Quantization**|Lin Wang Team|[2511.21784](http://arxiv.org/abs/2511.21784)|null|\n", "2511.21161": "|**2025-11-26**|**MarketGen: A Scalable Simulation Platform with Auto-Generated Embodied Supermarket Environments**|Zhaoxiang Zhang Team|[2511.21161](http://arxiv.org/abs/2511.21161)|**[link](https://xuhu0529.github.io/MarketGen)**|\n", "2511.21135": "|**2025-11-26**|**SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation**|Yu Zhang Team|[2511.21135](http://arxiv.org/abs/2511.21135)|null|\n", "2511.21025": "|**2025-11-26**|**CaptionQA: Is Your Caption as Useful as the Image Itself?**|Chenfeng Xu Team|[2511.21025](http://arxiv.org/abs/2511.21025)|null|\n", "2511.20620": "|**2025-11-25**|**Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI**|Chen Feng Team|[2511.20620](http://arxiv.org/abs/2511.20620)|null|\n", "2511.19861": "|**2025-11-30**|**GigaWorld-0: World Models as Data Engine to Empower Embodied AI**|Zheng Zhu Team|[2511.19861](http://arxiv.org/abs/2511.19861)|**[link](https://giga-world-0.github.io/)**|\n", "2511.20714": "|**2025-11-25**|**Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation**|Bohan Zhuang Team|[2511.20714](http://arxiv.org/abs/2511.20714)|null|\n", "2511.19430": "|**2025-11-24**|**Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution**|Xiang Bai Team|[2511.19430](http://arxiv.org/abs/2511.19430)|**[link](https://github.com/H-EmbodVis/GRANT})**|\n", "2511.19119": "|**2025-11-24**|**MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images**|Shijie Li Team|[2511.19119](http://arxiv.org/abs/2511.19119)|null|\n", "2511.18960": "|**2025-12-02**|**AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention**|Xiaoyuan Yu Team|[2511.18960](http://arxiv.org/abs/2511.18960)|null|\n", "2511.18950": "|**2025-11-24**|**Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation**|Wenjing Qian Team|[2511.18950](http://arxiv.org/abs/2511.18950)|null|\n", "2511.18929": "|**2025-12-17**|**Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and Scalable Tree-Based Search**|Liang Lin Team|[2511.18929](http://arxiv.org/abs/2511.18929)|null|\n", "2511.18845": "|**2025-11-24**|**UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model**|Jianqiang Li Team|[2511.18845](http://arxiv.org/abs/2511.18845)|null|\n", "2511.18173": "|**2025-11-22**|**EgoControl: Controllable Egocentric Video Generation via 3D Full-Body Poses**|Juergen Gall Team|[2511.18173](http://arxiv.org/abs/2511.18173)|null|\n", "2511.17925": "|**2025-12-08**|**Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game**|Tianyu Li Team|[2511.17925](http://arxiv.org/abs/2511.17925)|null|\n", "2511.17869": "|**2025-11-22**|**The Horcrux: Mechanistically Interpretable Task Decomposition for Detecting and Mitigating Reward Hacking in Embodied AI Systems**|Jared Junkin Team|[2511.17869](http://arxiv.org/abs/2511.17869)|null|\n", "2511.17225": "|**2025-11-21**|**TP-MDDN: Task-Preferenced Multi-Demand-Driven Navigation with Autonomous Decision-Making**|Xiangyang Xue Team|[2511.17225](http://arxiv.org/abs/2511.17225)|null|\n", "2511.17097": "|**2025-11-21**|**Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation**|Zhaoxin Fan Team|[2511.17097](http://arxiv.org/abs/2511.17097)|null|\n", "2511.16651": "|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Jiangmiao Pang Team|[2511.16651](http://arxiv.org/abs/2511.16651)|null|\n", "2511.16567": "|**2025-11-21**|**POMA-3D: The Point Map Way to 3D Scene Understanding**|Krystian Mikolajczyk Team|[2511.16567](http://arxiv.org/abs/2511.16567)|null|\n", "2511.16518": "|**2025-11-20**|**MiMo-Embodied: X-Embodied Foundation Model Technical Report**|Long Chen Team|[2511.16518](http://arxiv.org/abs/2511.16518)|**[link](https://github.com/XiaomiMiMo/MiMo-Embodied)**|\n", "2511.16449": "|**2025-11-21**|**VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference**|Bo Zhao Team|[2511.16449](http://arxiv.org/abs/2511.16449)|null|\n", "2511.16347": "|**2025-11-20**|**The Shawshank Redemption of Embodied AI: Understanding and Benchmarking Indirect Environmental Jailbreaks**|Jianfeng Ma Team|[2511.16347](http://arxiv.org/abs/2511.16347)|null|\n", "2511.15379": "|**2025-11-19**|**Zero-Shot Open-Vocabulary Human Motion Grounding with Test-Time Training**|Jianfei Yang Team|[2511.15379](http://arxiv.org/abs/2511.15379)|null|\n", "2511.15279": "|**2025-11-19**|**Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception**|Wenzhao Lian Team|[2511.15279](http://arxiv.org/abs/2511.15279)|null|\n", "2511.14396": "|**2025-12-12**|**Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning**|Hongpeng Wang Team|[2511.14396](http://arxiv.org/abs/2511.14396)|**[link](https://qhemu.github.io/CCoL/)**|\n", "2511.14291": "|**2025-11-18**|**GEN3D: Generating Domain-Free 3D Scenes from a Single Image**|Houde Liu Team|[2511.14291](http://arxiv.org/abs/2511.14291)|null|\n", "2511.14161": "|**2025-11-19**|**RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action**|Jiayu Chen Team|[2511.14161](http://arxiv.org/abs/2511.14161)|null|\n", "2511.14131": "|**2025-11-18**|**Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation**|Yunji Chen Team|[2511.14131](http://arxiv.org/abs/2511.14131)|null|\n", "2511.13648": "|**2025-11-17**|**PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image**|Ziwei Liu Team|[2511.13648](http://arxiv.org/abs/2511.13648)|**[link](https://physx-anything.github.io/)**|\n", "2511.13524": "|**2025-11-17**|**FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI**|Jiangtao Gong Team|[2511.13524](http://arxiv.org/abs/2511.13524)|null|\n", "2511.13132": "|**2025-11-17**|**Shedding Light on VLN Robustness: A Black-box Framework for Indoor Lighting-based Adversarial Attack**|Yang Liu Team|[2511.13132](http://arxiv.org/abs/2511.13132)|null|\n", "2511.12368": "|**2025-11-15**|**Fast Reasoning Segmentation for Images and Videos**|Mathias Unberath Team|[2511.12368](http://arxiv.org/abs/2511.12368)|null|\n", "2511.12040": "|**2025-11-15**|**SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images**|Min Tan Team|[2511.12040](http://arxiv.org/abs/2511.12040)|**[link](https://xinyuanhu66.github.io/SRSplat/)**|\n", "2512.00041": "|**2025-11-14**|**VISTAv2: World Imagination for Indoor Vision-and-Language Navigation**|Zhengzhong Tu Team|[2512.00041](http://arxiv.org/abs/2512.00041)|null|\n", "2511.10376": "|**2025-11-14**|**MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation**|Chenglu Wen Team|[2511.10376](http://arxiv.org/abs/2511.10376)|null|\n", "2511.09964": "|**2025-11-13**|**EnvTrace: Simulation-Based Semantic Evaluation of LLM Code via Execution Trace Alignment -- Demonstrated at Synchrotron Beamlines**|Esther H. R. Tsai Team|[2511.09964](http://arxiv.org/abs/2511.09964)|null|\n", "2511.08935": "|**2025-11-12**|**Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation**|Hongbin Sun Team|[2511.08935](http://arxiv.org/abs/2511.08935)|null|\n", "2511.08007": "|**2025-11-12**|**EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision**|Xun Tu Team|[2511.08007](http://arxiv.org/abs/2511.08007)|null|\n", "2511.07710": "|**2025-11-29**|**Cross Modal Fine-Grained Alignment via Granularity-Aware and Region-Uncertain Modeling**|Yuncheng Jiang Team|[2511.07710](http://arxiv.org/abs/2511.07710)|null|\n", "2511.07412": "|**2025-11-10**|**TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for Embodied AI Research**|Mathias Unberath Team|[2511.07412](http://arxiv.org/abs/2511.07412)|null|\n", "2511.07403": "|**2025-11-10**|**SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards**|Ronald Clark Team|[2511.07403](http://arxiv.org/abs/2511.07403)|null|\n", "2511.06619": "|**2025-11-10**|**How Do VLAs Effectively Inherit from VLMs?**|Jiang Bian Team|[2511.06619](http://arxiv.org/abs/2511.06619)|null|\n", "2511.06182": "|**2025-11-21**|**OpenVLN: Open-world Aerial Vision-Language Navigation**|Yang Cong Team|[2511.06182](http://arxiv.org/abs/2511.06182)|null|\n", "2511.05936": "|**2025-11-08**|**10 Open Challenges Steering the Future of Vision-Language-Action Models**|David Hsu Team|[2511.05936](http://arxiv.org/abs/2511.05936)|null|\n", "2511.05304": "|**2025-11-07**|**psiUnity: A Platform for Multimodal Data-Driven XR**|Mohsen Moghaddam Team|[2511.05304](http://arxiv.org/abs/2511.05304)|null|\n", "2511.04976": "|**2025-11-07**|**iFlyBot-VLM Technical Report**|Jia Pan Team|[2511.04976](http://arxiv.org/abs/2511.04976)|null|\n", "2512.00027": "|**2025-11-06**|**A Survey on Improving Human Robot Collaboration through Vision-and-Language Navigation**|Virendra Singh Shekhawat Team|[2512.00027](http://arxiv.org/abs/2512.00027)|null|\n", "2511.03997": "|**2025-11-06**|**PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection**|Qi Li Team|[2511.03997](http://arxiv.org/abs/2511.03997)|null|\n", "2511.03992": "|**2025-11-06**|**CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation**|Yuan Xie Team|[2511.03992](http://arxiv.org/abs/2511.03992)|null|\n", "2511.03497": "|**2025-11-05**|**ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications**|Giovanni Toffetti Team|[2511.03497](http://arxiv.org/abs/2511.03497)|null|\n", "2511.03370": "|**2025-11-29**|**EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation**|Alexandra Brintrup Team|[2511.03370](http://arxiv.org/abs/2511.03370)|null|\n", "2511.02225": "|**2025-11-04**|**Learning Interactive World Model for Object-Centric Reinforcement Learning**|Sara Magliacane Team|[2511.02225](http://arxiv.org/abs/2511.02225)|null|\n", "2511.00940": "|**2025-11-02**|**URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model**|Shanghang Zhang Team|[2511.00940](http://arxiv.org/abs/2511.00940)|null|\n", "2511.00933": "|**2025-11-02**|**Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation**|Qi Wu Team|[2511.00933](http://arxiv.org/abs/2511.00933)|null|\n", "2510.27033": "|**2025-10-30**|**A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics**|Hamid Rezatofighi Team|[2510.27033](http://arxiv.org/abs/2510.27033)|null|\n", "2510.26909": "|**2025-11-04**|**NaviTrace: Evaluating Embodied Navigation of Vision-Language Models**|Jonas Frey Team|[2510.26909](http://arxiv.org/abs/2510.26909)|null|\n", "2510.25760": "|**2025-11-02**|**Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks**|Xuming Hu Team|[2510.25760](http://arxiv.org/abs/2510.25760)|null|\n", "2510.25268": "|**2025-10-29**|**SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation**|Dan Guo Team|[2510.25268](http://arxiv.org/abs/2510.25268)|null|\n", "2510.25191": "|**2025-10-29**|**SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning**|Wei Pan Team|[2510.25191](http://arxiv.org/abs/2510.25191)|null|\n", "2510.23190": "|**2025-10-27**|**Evaluation of Vision-LLMs in Surveillance Video**|Jelte P. Mense Team|[2510.23190](http://arxiv.org/abs/2510.23190)|null|\n", "2511.00033": "|**2025-10-27**|**STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization**|Dingwen Zhang Team|[2511.00033](http://arxiv.org/abs/2511.00033)|null|\n", "2510.22672": "|**2025-10-28**|**Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views**|Jonas Beskow Team|[2510.22672](http://arxiv.org/abs/2510.22672)|**[link](https://huggingface.co/datasets/annadeichler/KTH-ARIA-referential)**|\n", "2510.21991": "|**2025-10-24**|**Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising**|Yinchuan Li Team|[2510.21991](http://arxiv.org/abs/2510.21991)|null|\n", "2510.21307": "|**2025-12-15**|**Towards Physically Executable 3D Gaussian for Embodied Navigation**|Juncheng Li Team|[2510.21307](http://arxiv.org/abs/2510.21307)|**[link](https://sage-3d.github.io/)**|\n", "2510.20818": "|**2025-10-23**|**VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation**|Abhishek Gupta Team|[2510.20818](http://arxiv.org/abs/2510.20818)|null|\n", "2510.20578": "|**2025-10-23**|**EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence**|Yurui Zhu Team|[2510.20578](http://arxiv.org/abs/2510.20578)|null|\n", "2510.19944": "|**2025-10-22**|**Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets**|Xuanmeng Zhang Team|[2510.19944](http://arxiv.org/abs/2510.19944)|**[link](https://seed.bytedance.com/seed3d)**|\n", "2510.19655": "|**2025-10-22**|**LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments**|Yang Gao Team|[2510.19655](http://arxiv.org/abs/2510.19655)|null|\n", "2510.19400": "|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Baining Guo Team|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|\n", "2510.21809": "|**2025-10-21**|**Embodied Navigation with Auxiliary Task of Action Description Prediction**|Asako Kanezaki Team|[2510.21809](http://arxiv.org/abs/2510.21809)|null|\n", "2510.17369": "|**2025-10-20**|**Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots**|Josie Hughes Team|[2510.17369](http://arxiv.org/abs/2510.17369)|null|\n", "2510.16732": "|**2025-11-29**|**A Comprehensive Survey on World Models for Embodied AI**|Yun Liu Team|[2510.16732](http://arxiv.org/abs/2510.16732)|**[link](https://github.com/Li-Zn-H/AwesomeWorldModels)**|\n", "2510.16457": "|**2025-10-18**|**NavQ: Learning a Q-Model for Foresighted Vision-and-Language Navigation**|Yadong MU Team|[2510.16457](http://arxiv.org/abs/2510.16457)|null|\n", "2510.15018": "|**2025-10-16**|**UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos**|Bolei Zhou Team|[2510.15018](http://arxiv.org/abs/2510.15018)|**[link](https://urbanverseproject.github.io/)**|\n", "2510.14357": "|**2025-10-16**|**SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation**|Xiang Li Team|[2510.14357](http://arxiv.org/abs/2510.14357)|null|\n", "2510.20835": "|**2025-10-15**|**Rethinking the Simulation vs. Rendering Dichotomy: No Free Lunch in Spatial World Modelling**|Hokin Deng Team|[2510.20835](http://arxiv.org/abs/2510.20835)|null|\n", "2510.12749": "|**2025-10-14**|**SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding**|Zhu Yang Team|[2510.12749](http://arxiv.org/abs/2510.12749)|null|\n", "2510.12693": "|**2025-10-14**|**ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning**|Tong Zhang Team|[2510.12693](http://arxiv.org/abs/2510.12693)|null|\n", "2510.11687": "|**2025-10-13**|**Beyond 'Templates': Category-Agnostic Object Pose, Size, and Shape Estimation from a Single View**|Yanwei Fu Team|[2510.11687](http://arxiv.org/abs/2510.11687)|null|\n", "2510.11307": "|**2025-10-13**|**FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks**|Alessandro Suglia Team|[2510.11307](http://arxiv.org/abs/2510.11307)|null|\n", "2510.11760": "|**2025-10-13**|**Audio-Guided Visual Perception for Audio-Visual Navigation**|Wendong Zheng Team|[2510.11760](http://arxiv.org/abs/2510.11760)|null|\n", "2510.10932": "|**2025-10-13**|**TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models**|Yu-Gang Jiang Team|[2510.10932](http://arxiv.org/abs/2510.10932)|null|\n", "2510.10823": "|**2025-10-12**|**The Irrational Machine: Neurosis and the Limits of Algorithmic Safety**|Daniel Howard Team|[2510.10823](http://arxiv.org/abs/2510.10823)|null|\n", "2510.09561": "|**2025-12-15**|**TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control**|Ethem Can Team|[2510.09561](http://arxiv.org/abs/2510.09561)|**[link](https://minkyoungcho.github.io/tc-lora/)**|\n", "2510.09507": "|**2025-10-10**|**PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs**|Ying-Cong Chen Team|[2510.09507](http://arxiv.org/abs/2510.09507)|null|\n", "2510.09483": "|**2025-10-10**|**FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents**|Kai Furmans Team|[2510.09483](http://arxiv.org/abs/2510.09483)|null|\n", "2510.09269": "|**2025-10-10**|**Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects**|Jingfeng Zhang Team|[2510.09269](http://arxiv.org/abs/2510.09269)|null|\n", "2510.08713": "|**2025-10-09**|**Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation**|Alexander G Hauptmann Team|[2510.08713](http://arxiv.org/abs/2510.08713)|**[link](https://github.com/F1y1113/UniWM)**|\n", "2510.08553": "|**2025-10-09**|**Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation**|Zhe Liu Team|[2510.08553](http://arxiv.org/abs/2510.08553)|null|\n", "2510.08316": "|**2025-10-09**|**Unlocking 3D Affordance Segmentation with 2D Semantic Knowledge**|Wei Shen Team|[2510.08316](http://arxiv.org/abs/2510.08316)|null|\n", "2510.08227": "|**2025-10-09**|**Practicing a Second Language Without Fear: Mixed Reality Agents for Interactive Group Conversation**|Diego Gomez-Zara Team|[2510.08227](http://arxiv.org/abs/2510.08227)|null|\n", "2510.08173": "|**2025-10-09**|**NavSpace: How Navigation Agents Follow Spatial Intelligence Instructions**|Hao Dong Team|[2510.08173](http://arxiv.org/abs/2510.08173)|null|\n", "2510.07975": "|**2025-10-09**|**Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation**|Jianhua Sun Team|[2510.07975](http://arxiv.org/abs/2510.07975)|null|\n", "2510.07791": "|**2025-10-10**|**GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models**|Long Zeng Team|[2510.07791](http://arxiv.org/abs/2510.07791)|null|\n", "2510.07067": "|**2025-10-08**|**Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models**|Elena Tutubalina Team|[2510.07067](http://arxiv.org/abs/2510.07067)|null|\n", "2510.05865": "|**2025-10-07**|**The Safety Challenge of World Models for Embodied AI Agents: A Review**|Lorenzo Baraldi Team|[2510.05865](http://arxiv.org/abs/2510.05865)|null|\n", "2510.05684": "|**2025-12-17**|**D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI**|Yunsung Lee Team|[2510.05684](http://arxiv.org/abs/2510.05684)|null|\n", "2510.04401": "|**2025-10-06**|**Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting**|Jiahao Zhang Team|[2510.04401](http://arxiv.org/abs/2510.04401)|null|\n", "2510.04041": "|**2025-10-05**|**SITCOM: Scaling Inference-Time COMpute for VLAs**|Esha Pahwa Team|[2510.04041](http://arxiv.org/abs/2510.04041)|null|\n", "2510.03909": "|**2025-10-04**|**Generating Human Motion Videos using a Cascaded Text-to-Video Framework**|Hyungjin Chung Team|[2510.03909](http://arxiv.org/abs/2510.03909)|**[link](https://hyelinnam.github.io/Cameo/)**|\n", "2510.03153": "|**2025-10-03**|**Improving Cooperation in Collaborative Embodied AI**|Oliver Lemon Team|[2510.03153](http://arxiv.org/abs/2510.03153)|null|\n", "2510.02851": "|**2025-11-06**|**Action Deviation-Aware Inference for Low-Latency Wireless Robots**|Seong-Lyun Kim Team|[2510.02851](http://arxiv.org/abs/2510.02851)|null|\n", "2510.01623": "|**2025-10-02**|**VLA-R1: Enhancing Reasoning in Vision-Language-Action Models**|Zheng Zhu Team|[2510.01623](http://arxiv.org/abs/2510.01623)|null|\n", "2510.01438": "|**2025-11-26**|**Differentiable Skill Optimisation for Powder Manipulation in Laboratory Automation**|Ze Ji Team|[2510.01438](http://arxiv.org/abs/2510.01438)|null|\n", "2510.01388": "|**2025-10-01**|**VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation**|Amirreza Shaban Team|[2510.01388](http://arxiv.org/abs/2510.01388)|null|\n", "2510.00604": "|**2025-10-01**|**Disentangling Foreground and Background for vision-Language Navigation via Online Augmentation**|Richang Hong Team|[2510.00604](http://arxiv.org/abs/2510.00604)|null|\n", "2510.00441": "|**2025-10-21**|**Seeing through Uncertainty: Robust Task-Oriented Optimization in Visual Navigation**|Hesheng Wang Team|[2510.00441](http://arxiv.org/abs/2510.00441)|null|\n", "2510.00181": "|**2025-09-30**|**CHAI: Command Hijacking against embodied AI**|Alvaro A Cardenas Team|[2510.00181](http://arxiv.org/abs/2510.00181)|null|\n", "2510.00167": "|**2025-09-30**|**Drones that Think on their Feet: Sudden Landing Decisions with Embodied AI**|Alvaro A. Cardenas Team|[2510.00167](http://arxiv.org/abs/2510.00167)|null|\n", "2509.26536": "|**2025-11-25**|**OceanGym: A Benchmark Environment for Underwater Embodied Agents**|Huajun Chen Team|[2509.26536](http://arxiv.org/abs/2509.26536)|null|\n", "2509.25970": "|**2025-09-30**|**PinPoint3D: Fine-Grained 3D Part Segmentation from a Few Clicks**|Feng Zheng Team|[2509.25970](http://arxiv.org/abs/2509.25970)|null|\n", "2509.25852": "|**2025-09-30**|**Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation**|Hao Chen Team|[2509.25852](http://arxiv.org/abs/2509.25852)|null|\n", "2509.25687": "|**2025-10-09**|**OmniNav: A Unified Framework for Prospective Exploration and Visual-Language Navigation**|Zedong Chu Team|[2509.25687](http://arxiv.org/abs/2509.25687)|null|\n", "2509.25655": "|**2025-09-30**|**Landmark-Guided Knowledge for Vision-and-Language Navigation**|Yinfeng Yu Team|[2509.25655](http://arxiv.org/abs/2509.25655)|null|\n", "2509.25528": "|**2025-10-21**|**LLM-RG: Referential Grounding in Outdoor Scenarios using Large Language Models**|Wenshan Wang Team|[2509.25528](http://arxiv.org/abs/2509.25528)|null|\n", "2509.25139": "|**2025-09-29**|**Vision-and-Language Navigation with Analogical Textual Descriptions in LLMs**|Parisa Kordjamshidi Team|[2509.25139](http://arxiv.org/abs/2509.25139)|null|\n", "2509.24591": "|**2025-10-30**|**PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control**|Wei Pan Team|[2509.24591](http://arxiv.org/abs/2509.24591)|null|\n", "2509.24528": "|**2025-12-07**|**CORE-3D: Context-aware Open-vocabulary Retrieval by Embeddings in 3D**|Babak Khalaj Team|[2509.24528](http://arxiv.org/abs/2509.24528)|null|\n", "2509.24387": "|**2025-09-29**|**AdaNav: Adaptive Reasoning with Uncertainty for Vision-Language Navigation**|Ting Cao Team|[2509.24387](http://arxiv.org/abs/2509.24387)|null|\n", "2509.24321": "|**2025-09-29**|**SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm**|Jiankun Wang Team|[2509.24321](http://arxiv.org/abs/2509.24321)|null|\n", "2509.22653": "|**2025-09-26**|**See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation**|Yu-Lun Liu Team|[2509.22653](http://arxiv.org/abs/2509.22653)|**[link](https://spf-web.pages.dev)**|\n", "2509.22548": "|**2025-09-26**|**JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation**|Xing Wei Team|[2509.22548](http://arxiv.org/abs/2509.22548)|**[link](https://miv-xjtu.github.io/JanusVLN.github.io/)**|\n", "2509.22353": "|**2025-09-26**|**Context and Diversity Matter: The Emergence of In-Context Learning in World Models**|Yu Kang Team|[2509.22353](http://arxiv.org/abs/2509.22353)|null|\n", "2509.21930": "|**2025-09-26**|**DynaNav: Dynamic Feature and Layer Selection for Efficient Visual Navigation**|Changhao Chen Team|[2509.21930](http://arxiv.org/abs/2509.21930)|null|\n", "2509.21651": "|**2025-11-21**|**Can AI Perceive Physical Danger and Intervene?**|Vikas Sindhwani Team|[2509.21651](http://arxiv.org/abs/2509.21651)|null|\n", "2509.22720": "|**2025-09-24**|**LayoutAgent: A Vision-Language Agent Guided Compositional Diffusion for Spatial Layout Planning**|Kannan Achan Team|[2509.22720](http://arxiv.org/abs/2509.22720)|null|\n", "2509.20499": "|**2025-09-24**|**Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting**|Henry X. Liu Team|[2509.20499](http://arxiv.org/abs/2509.20499)|null|\n", "2509.20021": "|**2025-09-24**|**Embodied AI: From LLMs to World Models**|Wenwu Zhu Team|[2509.20021](http://arxiv.org/abs/2509.20021)|null|\n", "2509.20414": "|**2025-10-26**|**SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent**|Siyuan Huang Team|[2509.20414](http://arxiv.org/abs/2509.20414)|null|\n", "2509.19843": "|**2025-09-24**|**PersONAL: Towards a Comprehensive Benchmark for Personalized Embodied Agents**|Tommaso Campari Team|[2509.19843](http://arxiv.org/abs/2509.19843)|null|\n", "2509.19002": "|**2025-11-15**|**VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction**|Daisuke Kawahara Team|[2509.19002](http://arxiv.org/abs/2509.19002)|null|\n", "2509.21377": "|**2025-09-23**|**Dynamic Multi-Target Fusion for Efficient Audio-Visual Navigation**|Meiling Zhu Team|[2509.21377](http://arxiv.org/abs/2509.21377)|null|\n", "2509.18610": "|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Mac Schwager Team|[2509.18610](http://arxiv.org/abs/2509.18610)|null|\n", "2509.18592": "|**2025-09-23**|**VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation**|Ufuk Topcu Team|[2509.18592](http://arxiv.org/abs/2509.18592)|**[link](https://vln-zero.github.io/)**|\n", "2509.17430": "|**2025-09-23**|**EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats from a Mobile Device**|Zsolt Kira Team|[2509.17430](http://arxiv.org/abs/2509.17430)|null|\n", "2509.18200": "|**2025-09-20**|**Conversational Orientation Reasoning: Egocentric-to-Allocentric Navigation with Multimodal Chain-of-Thought**|Yu Ti Huang Team|[2509.18200](http://arxiv.org/abs/2509.18200)|null|\n", "2509.16176": "|**2025-09-19**|**Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories**|Hugh H. -T. Liu Team|[2509.16176](http://arxiv.org/abs/2509.16176)|null|\n", "2509.15333": "|**2025-09-18**|**Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception**|Gao Huang Team|[2509.15333](http://arxiv.org/abs/2509.15333)|null|\n", "2509.15273": "|**2025-09-23**|**Embodied Arena: A Comprehensive, Unified, and Evolving Evaluation Platform for Embodied AI**|Jianye Hao Team|[2509.15273](http://arxiv.org/abs/2509.15273)|null|\n", "2509.14687": "|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Tao Shen Team|[2509.14687](http://arxiv.org/abs/2509.14687)|null|\n", "2509.15250": "|**2025-09-22**|**Walk and Read Less: Improving the Efficiency of Vision-and-Language Navigation via Tuning-Free Multimodal Token Pruning**|Margrit Betke Team|[2509.15250](http://arxiv.org/abs/2509.15250)|**[link](https://github.com/wdqin/VLN-NAP)**|\n", "2509.13733": "|**2025-11-25**|**FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph**|Zhizhong Su Team|[2509.13733](http://arxiv.org/abs/2509.13733)|**[link](https://horizonrobotics.github.io/robot_lab/fsr-vln/)**|\n", "2509.12989": "|**2025-09-16**|**PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era**|Xuming Hu Team|[2509.12989](http://arxiv.org/abs/2509.12989)|null|\n", "2509.12618": "|**2025-09-16**|**ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation**|Feng Zheng Team|[2509.12618](http://arxiv.org/abs/2509.12618)|null|\n", "2509.12129": "|**2025-09-16**|**Embodied Navigation Foundation Model**|He Wang Team|[2509.12129](http://arxiv.org/abs/2509.12129)|**[link](https://pku-epic.github.io/NavFoM-Web/)**|\n", "2509.11895": "|**2025-09-15**|**Integrating Prior Observations for Incremental 3D Scene Graph Prediction**|Martin Atzmueller Team|[2509.11895](http://arxiv.org/abs/2509.11895)|null|\n", "2509.11197": "|**2025-09-14**|**DreamNav: A Trajectory-Based Imaginative Framework for Zero-Shot Vision-and-Language Navigation**|Renjing Xu Team|[2509.11197](http://arxiv.org/abs/2509.11197)|null|\n", "2509.10884": "|**2025-09-13**|**Nav-R1: Reasoning and Navigation in Embodied Scenes**|Hao Tang Team|[2509.10884](http://arxiv.org/abs/2509.10884)|null|\n", "2509.10813": "|**2025-10-14**|**InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts**|Jiangmiao Pang Team|[2509.10813](http://arxiv.org/abs/2509.10813)|null|\n", "2509.10454": "|**2025-09-12**|**GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation**|Jiwen Lu Team|[2509.10454](http://arxiv.org/abs/2509.10454)|**[link](https://bagh2178.github.io/GC-VLN/))**|\n"}, "Autonomous-Driving-Temporal": {"2512.16919": "|**2025-12-18**|**DVGT: Driving Visual Geometry Transformer**|Jiwen Lu Team|[2512.16919](http://arxiv.org/abs/2512.16919)|**[link](https://github.com/wzzheng/DVGT)**|\n", "2512.16907": "|**2025-12-18**|**Flowing from Reasoning to Motion: Learning 3D Hand Trajectory Prediction from Egocentric Human Interaction Videos**|Yue Liu Team|[2512.16907](http://arxiv.org/abs/2512.16907)|**[link](https://egoman-project.github.io)**|\n", "2512.16818": "|**2025-12-18**|**DenseBEV: Transforming BEV Grid Cells into 3D Objects**|J. Marius Z\u00f6llner Team|[2512.16818](http://arxiv.org/abs/2512.16818)|null|\n", "2512.16784": "|**2025-12-18**|**R3ST: A Synthetic 3D Dataset With Realistic Trajectories**|Irene Amerini Team|[2512.16784](http://arxiv.org/abs/2512.16784)|null|\n", "2512.16760": "|**2025-12-18**|**Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future**|Junwei Liang Team|[2512.16760](http://arxiv.org/abs/2512.16760)|**[link](https://github.com/worldbench/awesome-vla-for-ad)**|\n", "2512.16605": "|**2025-12-18**|**The Bi-objective Electric Autonomous Dial-a-Ride Problem**|Jakob Puchinger Team|[2512.16605](http://arxiv.org/abs/2512.16605)|null|\n", "2512.16123": "|**2025-12-18**|**Autoencoder-based Denoising Defense against Adversarial Attacks on Object Detection**|Huy Kang Kim Team|[2512.16123](http://arxiv.org/abs/2512.16123)|null|\n", "2512.16055": "|**2025-12-18**|**Driving in Corner Case: A Real-World Adversarial Closed-Loop Evaluation Platform for End-to-End Autonomous Driving**|Yanjun Huang Team|[2512.16055](http://arxiv.org/abs/2512.16055)|null|\n", "2512.15971": "|**2025-12-17**|**From Words to Wavelengths: VLMs for Few-Shot Multispectral Object Detection**|S\u00e9bastien Lef\u00e8vre Team|[2512.15971](http://arxiv.org/abs/2512.15971)|null|\n", "2512.15621": "|**2025-12-17**|**OccSTeP: Benchmarking 4D Occupancy Spatio-Temporal Persistence**|Jiaming Zhang Team|[2512.15621](http://arxiv.org/abs/2512.15621)|null|\n", "2512.15829": "|**2025-12-17**|**Human-like Working Memory from Artificial Intrinsic Plasticity Neurons**|Kezhou Yang Team|[2512.15829](http://arxiv.org/abs/2512.15829)|null|\n", "2512.15381": "|**2025-12-17**|**Gaussian Process Dual MPC using Active Inference: An Autonomous Vehicle Usecase**|Tom Lefebvre Team|[2512.15381](http://arxiv.org/abs/2512.15381)|null|\n", "2512.15311": "|**2025-12-17**|**KD360-VoxelBEV: LiDAR and 360-degree Camera Cross Modality Knowledge Distillation for Bird's-Eye-View Segmentation**|Toby P. Breckon Team|[2512.15311](http://arxiv.org/abs/2512.15311)|null|\n", "2512.15195": "|**2025-12-17**|**EPSM: A Novel Metric to Evaluate the Safety of Environmental Perception in Autonomous Driving**|Oliver Bringmann Team|[2512.15195](http://arxiv.org/abs/2512.15195)|null|\n", "2512.15111": "|**2025-12-17**|**BEV-Patch-PF: Particle Filtering with BEV-Aerial Feature Matching for Off-Road Geo-Localization**|Joydeep Biswas Team|[2512.15111](http://arxiv.org/abs/2512.15111)|null|\n", "2512.15109": "|**2025-12-17**|**Large Model Enabled Embodied Intelligence for 6G Integrated Perception, Communication, and Computation Network**|Yongming Huang Team|[2512.15109](http://arxiv.org/abs/2512.15109)|null|\n", "2512.15038": "|**2025-12-18**|**LADY: Linear Attention for Autonomous Driving Efficiency without Transformers**|Tengju Ye Team|[2512.15038](http://arxiv.org/abs/2512.15038)|null|\n", "2512.14998": "|**2025-12-17**|**Beyond Proximity: A Keypoint-Trajectory Framework for Classifying Affiliative and Agonistic Social Networks in Dairy Cattle**|Suresh Neethirajan Team|[2512.14998](http://arxiv.org/abs/2512.14998)|null|\n", "2512.14595": "|**2025-12-16**|**TUMTraf EMOT: Event-Based Multi-Object Tracking Dataset and Baseline for Traffic Scenarios**|Hu Cao Team|[2512.14595](http://arxiv.org/abs/2512.14595)|null|\n", "2512.14266": "|**2025-12-16**|**DriverGaze360: OmniDirectional Driver Attention with Object-Level Guidance**|Jason Rambach Team|[2512.14266](http://arxiv.org/abs/2512.14266)|null|\n", "2512.14225": "|**2025-12-16**|**OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving**|Xiaodan Liang Team|[2512.14225](http://arxiv.org/abs/2512.14225)|null|\n", "2512.14158": "|**2025-12-16**|**CIS-BA: Continuous Interaction Space Based Backdoor Attack for Object Detection in the Real-World**|Yilang Zhang Team|[2512.14158](http://arxiv.org/abs/2512.14158)|null|\n", "2512.14044": "|**2025-12-16**|**OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving**|Wuxiong Huang Team|[2512.14044](http://arxiv.org/abs/2512.14044)|null|\n", "2512.13982": "|**2025-12-16**|**FocalComm: Hard Instance-Aware Multi-Agent Perception**|Vijayakumar Bhagavatula Team|[2512.13982](http://arxiv.org/abs/2512.13982)|null|\n", "2512.13836": "|**2025-12-15**|**A Convex Obstacle Avoidance Formulation**|Iman Soltani Team|[2512.13836](http://arxiv.org/abs/2512.13836)|null|\n", "2512.13636": "|**2025-12-16**|**MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning**|Xiang Bai Team|[2512.13636](http://arxiv.org/abs/2512.13636)|**[link](https://xiaomi-mlab.github.io/MindDrive/)**|\n", "2512.13262": "|**2025-12-15**|**Post-Training and Test-Time Scaling of Generative Agent Behavior Models for Interactive Autonomous Driving**|Monu Surana Team|[2512.13262](http://arxiv.org/abs/2512.13262)|null|\n", "2512.13177": "|**2025-12-16**|**MMDrive: Interactive Scene Understanding Beyond Vision with Multi-representational Fusion**|Weiping Ding Team|[2512.13177](http://arxiv.org/abs/2512.13177)|null|\n", "2512.13130": "|**2025-12-15**|**LeafTrackNet: A Deep Learning Framework for Robust Leaf Tracking in Top-Down Plant Phenotyping**|Marina M. -C. H\u00f6hne Team|[2512.13130](http://arxiv.org/abs/2512.13130)|null|\n", "2512.13107": "|**2025-12-18**|**Diffusion-Based Restoration for Multi-Modal 3D Object Detection in Adverse Weather**|Xiaoyu Tang Team|[2512.13107](http://arxiv.org/abs/2512.13107)|null|\n", "2512.13094": "|**2025-12-15**|**Sequence of Expert: Boosting Imitation Planners for Autonomous Driving through Temporal Alternation**|Zhong Cao Team|[2512.13094](http://arxiv.org/abs/2512.13094)|null|\n", "2512.12907": "|**2025-12-15**|**Machine Learning Architectures for the Estimation of Predicted Occupancy Grids in Road Traffic**|Sebastian Sardina Team|[2512.12907](http://arxiv.org/abs/2512.12907)|null|\n", "2512.12827": "|**2025-12-14**|**GradID: Adversarial Detection via Intrinsic Dimensionality of Gradients**|Saeed Bagheri Shouraki Team|[2512.12827](http://arxiv.org/abs/2512.12827)|null|\n", "2512.12799": "|**2025-12-14**|**DrivePI: Spatial-aware 4D MLLM for Unified Autonomous Driving Understanding, Perception, Prediction and Planning**|Hengshuang Zhao Team|[2512.12799](http://arxiv.org/abs/2512.12799)|null|\n", "2512.12776": "|**2025-12-14**|**High Order Control Lyapunov Function - Control Barrier Function - Quadratic Programming Based Autonomous Driving Controller for Bicyclist Safety**|Bilin Aksun-Guvenc Team|[2512.12776](http://arxiv.org/abs/2512.12776)|null|\n", "2512.12751": "|**2025-12-14**|**GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation**|Hengshuang Zhao Team|[2512.12751](http://arxiv.org/abs/2512.12751)|**[link](https://huster-yzy.github.io/geniedrive_project_page/)**|\n", "2512.12724": "|**2025-12-14**|**A Coulomb-included model for high-order harmonic generation from atoms**|Yanjun Chen Team|[2512.12724](http://arxiv.org/abs/2512.12724)|null|\n", "2512.12377": "|**2025-12-13**|**INDOOR-LiDAR: Bridging Simulation and Reality for Robot-Centric 360 degree Indoor LiDAR Perception -- A Robot-Centric Hybrid Dataset**|Tomi Westerlund Team|[2512.12377](http://arxiv.org/abs/2512.12377)|null|\n", "2512.12302": "|**2025-12-13**|**From Human Intention to Action Prediction: A Comprehensive Benchmark for Intention-driven End-to-End Autonomous Driving**|Jianbing Shen Team|[2512.12302](http://arxiv.org/abs/2512.12302)|null|\n", "2512.12211": "|**2025-12-13**|**Measuring What Matters: Scenario-Driven Evaluation for Trajectory Predictors in Autonomous Driving**|Manish Saroya Team|[2512.12211](http://arxiv.org/abs/2512.12211)|null|\n", "2512.11750": "|**2025-12-12**|**LUCID: Learning-Enabled Uncertainty-Aware Certification of Stochastic Dynamical Systems**|Sadegh Soudjani Team|[2512.11750](http://arxiv.org/abs/2512.11750)|null|\n", "2512.11574": "|**2025-12-12**|**Evaluating Foundation Models' 3D Understanding Through Multi-View Correspondence Analysis**|Mohammadreza Salehi Team|[2512.11574](http://arxiv.org/abs/2512.11574)|null|\n", "2512.11944": "|**2025-12-12**|**A Review of Learning-Based Motion Planning: Toward a Data-Driven Optimal Control Approach**|Haoran Wang Team|[2512.11944](http://arxiv.org/abs/2512.11944)|null|\n", "2512.11551": "|**2025-12-12**|**CarlaNCAP: A Framework for Quantifying the Safety of Vulnerable Road Users in Infrastructure-Assisted Collective Perception Using EuroNCAP Scenarios**|Oliver Bringmann Team|[2512.11551](http://arxiv.org/abs/2512.11551)|null|\n", "2512.11319": "|**2025-12-12**|**SATMapTR: Satellite Image Enhanced Online HD Map Construction**|Jianping Wang Team|[2512.11319](http://arxiv.org/abs/2512.11319)|null|\n", "2512.11249": "|**2025-12-12**|**Elevation Aware 2D/3D Co-simulation Framework for Large-scale Traffic Flow and High-fidelity Vehicle Dynamics**|Weizi Li Team|[2512.11249](http://arxiv.org/abs/2512.11249)|null|\n", "2512.11226": "|**2025-12-12**|**FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model**|Zhen Li Team|[2512.11226](http://arxiv.org/abs/2512.11226)|null|\n", "2512.11926": "|**2025-12-12**|**TransBridge: Boost 3D Object Detection by Scene-Level Completion with Transformer Decoder**|Jianbing Shen Team|[2512.11926](http://arxiv.org/abs/2512.11926)|null|\n", "2512.10947": "|**2025-12-12**|**Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving**|Yue Wang Team|[2512.10947](http://arxiv.org/abs/2512.10947)|**[link](https://jiawei-yang.github.io/Flex/)**|\n", "2512.10945": "|**2025-12-11**|**MeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation**|Yu-Gang Jiang Team|[2512.10945](http://arxiv.org/abs/2512.10945)|**[link](https://henghuiding.com/MeViS/)**|\n", "2512.10935": "|**2025-12-11**|**Any4D: Unified Feed-Forward Metric 4D Reconstruction**|Deva Ramanan Team|[2512.10935](http://arxiv.org/abs/2512.10935)|**[link](https://any-4d.github.io/)**|\n", "2512.10719": "|**2025-12-11**|**SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving**|Andreas Zell Team|[2512.10719](http://arxiv.org/abs/2512.10719)|null|\n", "2512.10660": "|**2025-12-11**|**NaviHydra: Controllable Navigation-guided End-to-end Autonomous Driving with Hydra-distillation**|Christoph Stiller Team|[2512.10660](http://arxiv.org/abs/2512.10660)|null|\n", "2512.10492": "|**2025-12-11**|**UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning**|Xueqian Wang Team|[2512.10492](http://arxiv.org/abs/2512.10492)|null|\n", "2512.10461": "|**2025-12-11**|**T-SKM-Net: Trainable Neural Network Framework for Linear Constraint Satisfaction via Sampling Kaczmarz-Motzkin Method**|Qingchun Hou Team|[2512.10461](http://arxiv.org/abs/2512.10461)|null|\n", "2512.10419": "|**2025-12-11**|**TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning**|Aniket Bera Team|[2512.10419](http://arxiv.org/abs/2512.10419)|null|\n", "2512.10386": "|**2025-12-11**|**Adaptive Dual-Weighted Gravitational Point Cloud Denoising Method**|Bin Liu Team|[2512.10386](http://arxiv.org/abs/2512.10386)|null|\n", "2512.10376": "|**2025-12-11**|**RaLiFlow: Scene Flow Estimation with 4D Radar and LiDAR Point Clouds**|Na Zhao Team|[2512.10376](http://arxiv.org/abs/2512.10376)|null|\n", "2512.10305": "|**2025-12-11**|**InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck**|Xiao Wu Team|[2512.10305](http://arxiv.org/abs/2512.10305)|null|\n", "2512.10256": "|**2025-12-11**|**Error Analysis of Generalized Langevin Equations with Approximated Memory Kernels**|Jianfeng Lu Team|[2512.10256](http://arxiv.org/abs/2512.10256)|null|\n", "2512.10226": "|**2025-12-11**|**Latent Chain-of-Thought World Modeling for End-to-End Driving**|Boris Ivanovic Team|[2512.10226](http://arxiv.org/abs/2512.10226)|null|\n", "2512.09864": "|**2025-12-10**|**UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving**|Ying-Cong Chen Team|[2512.09864](http://arxiv.org/abs/2512.09864)|**[link](https://seed-uniugp.github.io/)**|\n", "2512.09670": "|**2025-12-10**|**An Automated Tip-and-Cue Framework for Optimized Satellite Tasking and Visual Intelligence**|Israel Cohen Team|[2512.09670](http://arxiv.org/abs/2512.09670)|null|\n", "2512.09349": "|**2025-12-10**|**COVLM-RL: Critical Object-Oriented Reasoning for Autonomous Driving Using VLM-Guided Reinforcement Learning**|Chen Lv Team|[2512.09349](http://arxiv.org/abs/2512.09349)|null|\n", "2512.09296": "|**2025-12-10**|**Traffic Scene Small Target Detection Method Based on YOLOv8n-SPTS Model for Autonomous Driving**|Songhan Wu Team|[2512.09296](http://arxiv.org/abs/2512.09296)|**[link](https://github.com/SonghanWu/yolov8n-SPTS)**|\n", "2512.09260": "|**2025-12-10**|**From Forecast to Action: Uncertainty-Aware UAV Deployment for Ocean Drifter Recovery**|Yourim Yoon Team|[2512.09260](http://arxiv.org/abs/2512.09260)|null|\n", "2512.09190": "|**2025-12-09**|**Understanding Mental States in Active and Autonomous Driving with EEG**|Ali Etemad Team|[2512.09190](http://arxiv.org/abs/2512.09190)|null|\n", "2512.08931": "|**2025-12-15**|**Astra: General Interactive World Model with Autoregressive Denoising**|Jiwen Lu Team|[2512.08931](http://arxiv.org/abs/2512.08931)|**[link](https://github.com/EternalEvan/Astra)**|\n", "2512.08580": "|**2025-12-10**|**Mind to Hand: Purposeful Robotic Control via Embodied Reasoning**|Jianan Wang Team|[2512.08580](http://arxiv.org/abs/2512.08580)|null|\n", "2512.08506": "|**2025-12-09**|**OCCDiff: Occupancy Diffusion Model for High-Fidelity 3D Building Reconstruction from Noisy Point Clouds**|Hongsheng Zhang Team|[2512.08506](http://arxiv.org/abs/2512.08506)|null|\n", "2512.08476": "|**2025-12-09**|**A Multi-Agent LLM Framework for Design Space Exploration in Autonomous Driving Systems**|Chih-Han Chang Team|[2512.08476](http://arxiv.org/abs/2512.08476)|null|\n", "2512.11887": "|**2025-12-09**|**Advancing Autonomous Driving System Testing: Demands, Challenges, and Future Directions**|Yurou Dai Team|[2512.11887](http://arxiv.org/abs/2512.11887)|null|\n", "2512.08247": "|**2025-12-09**|**Distilling Future Temporal Knowledge with Masked Feature Reconstruction for 3D Object Detection**|Yanyan Liang Team|[2512.08247](http://arxiv.org/abs/2512.08247)|null|\n", "2512.08237": "|**2025-12-09**|**FastBEV++: Fast by Algorithm, Deployable by Design**|TianKun Zhao Team|[2512.08237](http://arxiv.org/abs/2512.08237)|null|\n", "2512.08163": "|**2025-12-09**|**Accuracy Does Not Guarantee Human-Likeness in Monocular Depth Estimators**|Taiki Fukiage Team|[2512.08163](http://arxiv.org/abs/2512.08163)|null|\n", "2512.07776": "|**2025-12-08**|**GorillaWatch: An Automated System for In-the-Wild Gorilla Re-Identification and Population Monitoring**|Gerard de Melo Team|[2512.07776](http://arxiv.org/abs/2512.07776)|null|\n", "2512.07745": "|**2025-12-08**|**DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving**|Xinggang Wang Team|[2512.07745](http://arxiv.org/abs/2512.07745)|null|\n", "2512.07507": "|**2025-12-08**|**VP-AutoTest: A Virtual-Physical Fusion Autonomous Driving Testing Platform**|Jian Sun Team|[2512.07507](http://arxiv.org/abs/2512.07507)|null|\n", "2512.07390": "|**2025-12-08**|**Towards Reliable Test-Time Adaptation: Style Invariance as a Correctness Likelihood**|Eunho Yang Team|[2512.07390](http://arxiv.org/abs/2512.07390)|null|\n", "2512.07237": "|**2025-12-08**|**Unified Camera Positional Encoding for Controlled Video Generation**|Jianfei Cai Team|[2512.07237](http://arxiv.org/abs/2512.07237)|**[link](https://github.com/chengzhag/UCPE)**|\n", "2512.07910": "|**2025-12-08**|**The interstellar signature: A computational framework for open source interstellar tracking**|Pancha Narayan Sahu Team|[2512.07910](http://arxiv.org/abs/2512.07910)|**[link](https://panchacodes.xyz/)**|\n", "2512.07135": "|**2025-12-09**|**TrajMoE: Scene-Adaptive Trajectory Planning with Mixture of Experts and Reinforcement Learning**|Dongbin Zhao Team|[2512.07135](http://arxiv.org/abs/2512.07135)|null|\n", "2512.07130": "|**2025-12-08**|**Mimir: Hierarchical Goal-Driven Diffusion with Uncertainty Propagation for End-to-End Autonomous Driving**|Dongbin Zhao Team|[2512.07130](http://arxiv.org/abs/2512.07130)|null|\n", "2512.06865": "|**2025-12-07**|**Spatial Retrieval Augmented Autonomous Driving**|Yu-Gang Jiang Team|[2512.06865](http://arxiv.org/abs/2512.06865)|**[link](https://spatialretrievalad.github.io/)**|\n", "2512.06838": "|**2025-12-07**|**SparseCoop: Cooperative Perception with Kinematic-Grounded Queries**|Jianqiang Wang Team|[2512.06838](http://arxiv.org/abs/2512.06838)|null|\n", "2512.06676": "|**2025-12-07**|**FedDSR: Federated Deep Supervision and Regularization Towards Autonomous Driving**|Jianping Wang Team|[2512.06676](http://arxiv.org/abs/2512.06676)|null|\n", "2512.06664": "|**2025-12-07**|**Statistic-Augmented, Decoupled MoE Routing and Aggregating in Autonomous Driving**|Jianping Wang Team|[2512.06664](http://arxiv.org/abs/2512.06664)|null|\n", "2512.06406": "|**2025-12-06**|**UncertaintyZoo: A Unified Toolkit for Quantifying Predictive Uncertainty in Deep Learning Systems**|Qiang Hu Team|[2512.06406](http://arxiv.org/abs/2512.06406)|null|\n", "2512.11872": "|**2025-12-06**|**WAM-Diff: A Masked Diffusion VLA Framework with MoE and Online Reinforcement Learning for Autonomous Driving**|Siyu Zhu Team|[2512.11872](http://arxiv.org/abs/2512.11872)|null|\n", "2512.06376": "|**2025-12-06**|**Are AI-Generated Driving Videos Ready for Autonomous Driving? A Diagnostic Evaluation Framework**|Jiawei Zhang Team|[2512.06376](http://arxiv.org/abs/2512.06376)|null|\n", "2512.06251": "|**2025-12-06**|**NexusFlow: Unifying Disparate Tasks under Partial Supervision via Invertible Flow Networks**|Ziming Zhang Team|[2512.06251](http://arxiv.org/abs/2512.06251)|null|\n", "2512.06190": "|**2025-12-05**|**Multi-Modal Zero-Shot Prediction of Color Trajectories in Food Drying**|Chenhui Shao Team|[2512.06190](http://arxiv.org/abs/2512.06190)|null|\n", "2512.06182": "|**2025-12-05**|**Situation-Aware Interactive MPC Switching for Autonomous Driving**|Sofie Haesaert Team|[2512.06182](http://arxiv.org/abs/2512.06182)|null|\n", "2512.11869": "|**2025-12-05**|**Temporal-Anchor3DLane: Enhanced 3D Lane Detection with Multi-Task Losses and LSTM Fusion**|K. Muni Team|[2512.11869](http://arxiv.org/abs/2512.11869)|null|\n", "2512.06112": "|**2025-12-11**|**WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving**|Siyu Zhu Team|[2512.06112](http://arxiv.org/abs/2512.06112)|**[link](https://github.com/fudan-generative-vision/WAM-Flow)**|\n", "2512.06096": "|**2025-12-05**|**BeLLA: End-to-End Birds Eye View Large Language Assistant for Autonomous Driving**|Amit Arvind Kale Team|[2512.06096](http://arxiv.org/abs/2512.06096)|null|\n", "2512.06058": "|**2025-12-05**|**Representation Learning for Point Cloud Understanding**|Siming Yan Team|[2512.06058](http://arxiv.org/abs/2512.06058)|null|\n", "2512.05698": "|**2025-12-05**|**OWL: Unsupervised 3D Object Detection by Occupancy Guided Warm-up and Large Model Priors Reasoning**|Chenglu Wen Team|[2512.05698](http://arxiv.org/abs/2512.05698)|null|\n", "2512.05682": "|**2025-12-05**|**Scenario-aware Uncertainty Quantification for Trajectory Prediction with Statistical Guarantees**|Chen Sun Team|[2512.05682](http://arxiv.org/abs/2512.05682)|null|\n", "2512.05482": "|**2025-12-05**|**Concept-based Explainable Data Mining with VLM for 3D Detection**|Mai Tsujimoto Team|[2512.05482](http://arxiv.org/abs/2512.05482)|**[link](https://github.com/mm1129/concept_based_rare_detector_2025)**|\n", "2512.05335": "|**2025-12-05**|**State-Conditional Adversarial Learning: An Off-Policy Visual Domain Transfer Method for End-to-End Imitation Learning**|Shengfan Cao Team|[2512.05335](http://arxiv.org/abs/2512.05335)|null|\n", "2512.05277": "|**2025-12-16**|**From Segments to Scenes: Temporal Understanding in Autonomous Driving via Vision-Language Model**|Mohammad Akbari Team|[2512.05277](http://arxiv.org/abs/2512.05277)|null|\n", "2512.05270": "|**2025-12-04**|**XR-DT: Extended Reality-Enhanced Digital Twin for Agentic Mobile Robots**|Christian Claudel Team|[2512.05270](http://arxiv.org/abs/2512.05270)|null|\n", "2512.11852": "|**2025-12-04**|**Explainable AI for Smart Greenhouse Control: Interpretability of Temporal Fusion Transformer in the Internet of Robotic Things**|Eoghan Furey Team|[2512.11852](http://arxiv.org/abs/2512.11852)|null|\n", "2512.04830": "|**2025-12-04**|**FreeGen: Feed-Forward Reconstruction-Generation Co-Training for Free-Viewpoint Driving Scene Synthesis**|Peixi Peng Team|[2512.04830](http://arxiv.org/abs/2512.04830)|null|\n", "2512.04734": "|**2025-12-09**|**MT-Depth: Multi-task Instance feature analysis for the Depth Completion**|Xinhai Sun Team|[2512.04734](http://arxiv.org/abs/2512.04734)|null|\n", "2512.04733": "|**2025-12-04**|**E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving**|Chengzhong Xu Team|[2512.04733](http://arxiv.org/abs/2512.04733)|null|\n", "2512.04459": "|**2025-12-04**|**dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning**|Chaowei Xiao Team|[2512.04459](http://arxiv.org/abs/2512.04459)|null|\n", "2512.04441": "|**2025-12-08**|**MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving**|Ziying Song Team|[2512.04441](http://arxiv.org/abs/2512.04441)|null|\n", "2512.04358": "|**2025-12-04**|**MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching**|Fangyuan Chen Team|[2512.04358](http://arxiv.org/abs/2512.04358)|null|\n", "2512.04279": "|**2025-12-03**|**Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies**|Jaerock Kwon Team|[2512.04279](http://arxiv.org/abs/2512.04279)|null|\n", "2512.04039": "|**2025-12-03**|**Fast & Efficient Normalizing Flows and Applications of Image Generative Models**|Sandeep Nagar Team|[2512.04039](http://arxiv.org/abs/2512.04039)|null|\n", "2512.03992": "|**2025-12-03**|**DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation**|Xiaoqiang Team|[2512.03992](http://arxiv.org/abs/2512.03992)|null|\n", "2512.03936": "|**2025-12-03**|**Driving is a Game: Combining Planning and Prediction with Bayesian Iterative Best Response**|Johannes Betz Team|[2512.03936](http://arxiv.org/abs/2512.03936)|null|\n", "2512.03886": "|**2025-12-03**|**A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments**|Javier Perez-Robles Team|[2512.03886](http://arxiv.org/abs/2512.03886)|null|\n", "2512.03795": "|**2025-12-03**|**MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving**|Haoran Wang Team|[2512.03795](http://arxiv.org/abs/2512.03795)|null|\n", "2512.03774": "|**2025-12-03**|**Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving**|Christoph Stiller Team|[2512.03774](http://arxiv.org/abs/2512.03774)|null|\n", "2512.03639": "|**2025-12-03**|**Context-Triggered Contingency Games for Strategic Multi-Agent Interaction**|Anne-Kathrin Schmuck Team|[2512.03639](http://arxiv.org/abs/2512.03639)|null|\n", "2512.03510": "|**2025-12-03**|**CSMapping: Scalable Crowdsourced Semantic Mapping and Topology Inference for Autonomous Driving**|Shaojie Shen Team|[2512.03510](http://arxiv.org/abs/2512.03510)|null|\n", "2512.03454": "|**2025-12-11**|**Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles**|Zhenning Li Team|[2512.03454](http://arxiv.org/abs/2512.03454)|null|\n", "2512.03427": "|**2025-12-03**|**Generalization Evaluation of Deep Stereo Matching Methods for UAV-Based Forestry Applications**|Richard Green Team|[2512.03427](http://arxiv.org/abs/2512.03427)|null|\n", "2512.03370": "|**2025-12-03**|**ShelfGaussian: Shelf-Supervised Open-Vocabulary Gaussian-based 3D Scene Understanding**|Lu Gan Team|[2512.03370](http://arxiv.org/abs/2512.03370)|null|\n", "2512.03317": "|**2025-12-03**|**NavMapFusion: Diffusion-based Fusion of Navigation Maps for Online Vectorized HD Map Construction**|Sihao Ding Team|[2512.03317](http://arxiv.org/abs/2512.03317)|null|\n", "2512.03004": "|**2025-12-02**|**DGGT: Feedforward 4D Reconstruction of Dynamic Driving Scenes using Unposed Images**|Hao Zhao Team|[2512.03004](http://arxiv.org/abs/2512.03004)|null|\n", "2512.02982": "|**2025-12-02**|**U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences**|Qingshan Liu Team|[2512.02982](http://arxiv.org/abs/2512.02982)|null|\n", "2512.02972": "|**2025-12-02**|**BEVDilation: LiDAR-Centric Multi-Modal Fusion for 3D Object Detection**|Lei Zhang Team|[2512.02972](http://arxiv.org/abs/2512.02972)|null|\n", "2512.02966": "|**2025-12-02**|**Lumos: Let there be Language Model System Certification**|Gagandeep Singh Team|[2512.02966](http://arxiv.org/abs/2512.02966)|null|\n", "2512.02932": "|**2025-12-02**|**EGGS: Exchangeable 2D/3D Gaussian Splatting for Geometry-Appearance Balanced Novel View Synthesis**|Chen Chen Team|[2512.02932](http://arxiv.org/abs/2512.02932)|null|\n", "2512.02844": "|**2025-12-02**|**VLM as Strategist: Adaptive Generation of Safety-critical Testing Scenarios via Guided Diffusion**|Yong Shen Team|[2512.02844](http://arxiv.org/abs/2512.02844)|null|\n", "2512.02777": "|**2025-12-02**|**CogDrive: Cognition-Driven Multimodal Prediction-Planning Fusion for Safe Autonomy**|Jianqiang Wang Team|[2512.02777](http://arxiv.org/abs/2512.02777)|null|\n", "2512.02686": "|**2025-12-02**|**ClimaOoD: Improving Anomaly Segmentation via Physically Realistic Synthetic Data**|Yong Liu Team|[2512.02686](http://arxiv.org/abs/2512.02686)|null|\n", "2512.02448": "|**2025-12-02**|**nuScenes Revisited: Progress and Challenges in Autonomous Driving**|Holger Caesar Team|[2512.02448](http://arxiv.org/abs/2512.02448)|null|\n", "2512.02417": "|**2025-12-02**|**Vehicle Dynamics Embedded World Models for Autonomous Driving**|Zhihua Zhong Team|[2512.02417](http://arxiv.org/abs/2512.02417)|null|\n", "2512.02392": "|**2025-12-02**|**From Detection to Association: Learning Discriminative Object Embeddings for Multi-Object Tracking**|Xiao Sun Team|[2512.02392](http://arxiv.org/abs/2512.02392)|null|\n", "2512.02389": "|**2025-12-02**|**Synthetic Error Injection Fails to Elicit Self-Correction In Language Models**|Stuart Russell Team|[2512.02389](http://arxiv.org/abs/2512.02389)|null|\n", "2512.02368": "|**2025-12-02**|**Multi-Domain Enhanced Map-Free Trajectory Prediction with Selective Attention**|Jian Chen Team|[2512.02368](http://arxiv.org/abs/2512.02368)|null|\n", "2512.02346": "|**2025-12-02**|**Near-Memory Architecture for Threshold-Ordinal Surface-Based Corner Detection of Event Cameras**|Arindam Basu Team|[2512.02346](http://arxiv.org/abs/2512.02346)|null|\n", "2512.01993": "|**2025-12-01**|**RoaD: Rollouts as Demonstrations for Closed-Loop Supervised Fine-Tuning of Autonomous Driving Policies**|Marco Pavone Team|[2512.01993](http://arxiv.org/abs/2512.01993)|null|\n", "2512.01934": "|**2025-12-01**|**Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory**|Jonathan Petit Team|[2512.01934](http://arxiv.org/abs/2512.01934)|null|\n", "2512.01885": "|**2025-12-16**|**TransientTrack: Advanced Multi-Object Tracking and Classification of Cancer Cells with Transient Fluorescent Signals**|Katarzyna Bozek Team|[2512.01885](http://arxiv.org/abs/2512.01885)|null|\n", "2512.01830": "|**2025-12-02**|**OpenREAD: Reinforced Open-Ended Reasoning for End-to-End Autonomous Driving with LLM-as-Critic**|Chen Lv Team|[2512.01830](http://arxiv.org/abs/2512.01830)|null|\n", "2512.01478": "|**2025-12-09**|**CourtMotion: Learning Event-Driven Motion Representations from Skeletal Data for Basketball**|Lior Wolf Team|[2512.01478](http://arxiv.org/abs/2512.01478)|null|\n", "2512.01427": "|**2025-12-01**|**Language-Guided Open-World Anomaly Segmentation**|Federico Tombari Team|[2512.01427](http://arxiv.org/abs/2512.01427)|null|\n", "2512.01383": "|**2025-12-01**|**PointNet4D: A Lightweight 4D Point Cloud Video Backbone for Online and Offline Perception in Robotic Applications**|Jiayang Ao Team|[2512.01383](http://arxiv.org/abs/2512.01383)|null|\n", "2512.01363": "|**2025-12-01**|**SocialDriveGen: Generating Diverse Traffic Scenarios with Controllable Social Interactions**|Weinan Zhang Team|[2512.01363](http://arxiv.org/abs/2512.01363)|null|\n", "2512.01352": "|**2025-12-01**|**OpenBox: Annotate Any Bounding Boxes in 3D**|Jaesik Park Team|[2512.01352](http://arxiv.org/abs/2512.01352)|null|\n", "2512.01300": "|**2025-12-01**|**RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving**|Huadong Ma Team|[2512.01300](http://arxiv.org/abs/2512.01300)|null|\n", "2512.01102": "|**2025-11-30**|**Semantic Communications for Vehicle-Based Mission-Critical Services: Challenges and Solutions**|Celimuge Wu Team|[2512.01102](http://arxiv.org/abs/2512.01102)|null|\n", "2512.00856": "|**2025-11-30**|**Robust Probabilistic Load Forecasting for a Single Household: A Comparative Study from SARIMA to Transformers on the REFIT Dataset**|Midhun Manoj Team|[2512.00856](http://arxiv.org/abs/2512.00856)|**[link](https://github.com/middhun-31/Robust-Probabilistic-Load-Forecasting-for-a-Single-Household])**|\n", "2512.00834": "|**2025-11-30**|**SemAgent: Semantic-Driven Agentic AI Empowered Trajectory Prediction in Vehicular Networks**|Kun Yang Team|[2512.00834](http://arxiv.org/abs/2512.00834)|null|\n", "2512.00723": "|**2025-11-30**|**TrajDiff: End-to-end Autonomous Driving without Perception Annotation**|Jianbing Shen Team|[2512.00723](http://arxiv.org/abs/2512.00723)|null|\n", "2512.00677": "|**2025-11-30**|**Dynamic-eDiTor: Training-Free Text-Driven 4D Scene Editing with Multimodal Diffusion Transformer**|Karthik Ramani Team|[2512.00677](http://arxiv.org/abs/2512.00677)|null|\n", "2512.00574": "|**2025-11-29**|**GCMCG: A Clustering-Aware Graph Attention and Expert Fusion Network for Multi-Paradigm, Multi-task, and Cross-Subject EEG Decoding**|Zhenghui Feng Team|[2512.00574](http://arxiv.org/abs/2512.00574)|null|\n", "2512.00470": "|**2025-12-02**|**LAP: Fast LAtent Diffusion Planner with Fine-Grained Feature Distillation for Autonomous Driving**|Jie Mei Team|[2512.00470](http://arxiv.org/abs/2512.00470)|null|\n", "2512.00385": "|**2025-11-29**|**EZ-SP: Fast and Lightweight Superpoint-Based 3D Segmentation**|Damien Robert Team|[2512.00385](http://arxiv.org/abs/2512.00385)|null|\n", "2512.00370": "|**2025-11-29**|**Multi-Task Temporal Fusion Transformer for Joint Sales and Inventory Forecasting in Amazon E-Commerce Supply Chain**|Hanwu Li Team|[2512.00370](http://arxiv.org/abs/2512.00370)|null|\n", "2512.00303": "|**2025-11-29**|**Gradient Inversion in Federated Reinforcement Learning**|Shenghong He Team|[2512.00303](http://arxiv.org/abs/2512.00303)|null|\n", "2512.00300": "|**2025-11-29**|**TGSFormer: Scalable Temporal Gaussian Splatting for Embodied Semantic Scene Completion**|Lihua Xie Team|[2512.00300](http://arxiv.org/abs/2512.00300)|null|\n", "2511.23440": "|**2025-11-28**|**Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation**|Holger Fr\u00f6ning Team|[2511.23440](http://arxiv.org/abs/2511.23440)|null|\n", "2511.23369": "|**2025-11-28**|**SimScale: Learning to Drive via Real-World Simulation at Scale**|Hongyang Li Team|[2511.23369](http://arxiv.org/abs/2511.23369)|**[link](https://opendrivelab.com/SimScale)**|\n", "2511.23311": "|**2025-11-28**|**Toward Automatic Safe Driving Instruction: A Large-Scale Vision Language Model Approach**|Taro Watanabe Team|[2511.23311](http://arxiv.org/abs/2511.23311)|null|\n", "2511.22928": "|**2025-11-28**|**Seeing before Observable: Potential Risk Reasoning in Autonomous Driving via Vision Language Models**|Jun Li Team|[2511.22928](http://arxiv.org/abs/2511.22928)|null|\n", "2511.22896": "|**2025-11-28**|**DM$^3$T: Harmonizing Modalities via Diffusion for Multi-Object Tracking**|Zhenbo Li Team|[2511.22896](http://arxiv.org/abs/2511.22896)|null|\n", "2511.22865": "|**2025-11-28**|**SUPER-AD: Semantic Uncertainty-aware Planning for End-to-End Robust Autonomous Driving**|Hyunjung Shim Team|[2511.22865](http://arxiv.org/abs/2511.22865)|null|\n", "2511.22532": "|**2025-11-27**|**CoT4AD: A Vision-Language-Action Model with Explicit Chain-of-Thought Reasoning for Autonomous Driving**|Hao Tang Team|[2511.22532](http://arxiv.org/abs/2511.22532)|null|\n", "2511.22466": "|**2025-11-27**|**RoadSceneBench: A Lightweight Benchmark for Mid-Level Road Scene Understanding**|Zhen Lu Team|[2511.22466](http://arxiv.org/abs/2511.22466)|null|\n", "2511.22404": "|**2025-11-27**|**UAV-MM3D: A Large-Scale Synthetic Benchmark for 3D Perception of Unmanned Aerial Vehicles with Multi-Modal Data**|Yaowei Wang Team|[2511.22404](http://arxiv.org/abs/2511.22404)|null|\n", "2511.22264": "|**2025-11-27**|**DriveVGGT: Visual Geometry Transformer for Autonomous Driving**|Junchi Yan Team|[2511.22264](http://arxiv.org/abs/2511.22264)|null|\n", "2511.22187": "|**2025-12-03**|**HybridWorldSim: A Scalable and Controllable High-fidelity Simulator for Autonomous Driving**|Ligang Liu Team|[2511.22187](http://arxiv.org/abs/2511.22187)|**[link](https://hybridworldsim.github.io/)**|\n", "2511.22181": "|**2025-11-27**|**MTR-VP: Towards End-to-End Trajectory Planning through Context-Driven Image Encoding and Multiple Trajectory Prediction**|Ross Greer Team|[2511.22181](http://arxiv.org/abs/2511.22181)|null|\n", "2511.22142": "|**2025-11-27**|**SemOD: Semantic Enabled Object Detection Network under Various Weather Conditions**|Zhaoliang Zheng Team|[2511.22142](http://arxiv.org/abs/2511.22142)|null|\n", "2511.22061": "|**2025-11-27**|**Aligning with Human Values to Enhance Interaction: An eHMI-Mediated Lane-Changing Negotiation Strategy Using Bayesian Inference**|Linkun Liu Team|[2511.22061](http://arxiv.org/abs/2511.22061)|null|\n", "2511.22039": "|**2025-12-17**|**SparseWorld-TC: Trajectory-Conditioned Sparse Occupancy World Model**|Qijun Chen Team|[2511.22039](http://arxiv.org/abs/2511.22039)|null|\n", "2511.21925": "|**2025-11-26**|**OpenTwinMap: An Open-Source Digital Twin Generator for Urban Autonomous Driving**|Jonathan Sprinkle Team|[2511.21925](http://arxiv.org/abs/2511.21925)|null|\n", "2511.21584": "|**2025-11-26**|**Model-Based Policy Adaptation for Closed-Loop End-to-End Autonomous Driving**|Ding Zhao Team|[2511.21584](http://arxiv.org/abs/2511.21584)|**[link](https://openreview.net/forum?id=4OLbpaTKJe)**|\n", "2511.21256": "|**2025-11-26**|**LaGen: Towards Autoregressive LiDAR Scene Generation**|Junchi Yan Team|[2511.21256](http://arxiv.org/abs/2511.21256)|null|\n", "2511.21053": "|**2025-12-01**|**AerialMind: Towards Referring Multi-Object Tracking in UAV Scenarios**|Qing-Long Han Team|[2511.21053](http://arxiv.org/abs/2511.21053)|null|\n", "2511.20834": "|**2025-11-25**|**Accelerating Sparse Convolutions in Voxel-Based Point Cloud Networks**|Christina Giannoula Team|[2511.20834](http://arxiv.org/abs/2511.20834)|null|\n", "2511.20511": "|**2025-11-26**|**Efficient Parallel Implementation of the Pilot Assignment Problem in Massive MIMO Systems**|Ashfaq Khokhar Team|[2511.20511](http://arxiv.org/abs/2511.20511)|null|\n", "2511.20418": "|**2025-11-25**|**StableTrack: Stabilizing Multi-Object Tracking on Low-Frequency Detections**|Karina Kvanchiani Team|[2511.20418](http://arxiv.org/abs/2511.20418)|null|\n", "2511.20325": "|**2025-11-25**|**AD-R1: Closed-Loop Reinforcement Learning for End-to-End Autonomous Driving with Impartial World Models**|Jianbing Shen Team|[2511.20325](http://arxiv.org/abs/2511.20325)|null|\n", "2511.20239": "|**2025-11-25**|**Occlusion-Aware Multi-Object Tracking via Expected Probability of Detection**|Ond\u0159ej Straka Team|[2511.20239](http://arxiv.org/abs/2511.20239)|null|\n", "2511.20156": "|**2025-11-25**|**Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving**|Zhenning Li Team|[2511.20156](http://arxiv.org/abs/2511.20156)|null|\n", "2511.20154": "|**2025-11-25**|**Alzheimers Disease Progression Prediction Based on Manifold Mapping of Irregularly Sampled Longitudinal Data**|Yen-Wei Chen Team|[2511.20154](http://arxiv.org/abs/2511.20154)|null|\n", "2511.20726": "|**2025-11-25**|**Learning from Risk: LLM-Guided Generation of Safety-Critical Scenarios with Prior Knowledge**|Jinhua Zhao Team|[2511.20726](http://arxiv.org/abs/2511.20726)|null|\n", "2511.20058": "|**2025-11-25**|**DeLightMono: Enhancing Self-Supervised Monocular Depth Estimation in Endoscopy by Decoupling Uneven Illumination**|Jiang Liu Team|[2511.20058](http://arxiv.org/abs/2511.20058)|null|\n", "2511.20022": "|**2025-11-25**|**WaymoQA: A Multi-View Visual Question Answering Dataset for Safety-Critical Reasoning in Autonomous Driving**|Hyunjung Shim Team|[2511.20022](http://arxiv.org/abs/2511.20022)|null|\n", "2511.20000": "|**2025-11-25**|**Cross-Modal Semantic Communication for Heterogeneous Collaborative Perception**|Shi Jin Team|[2511.20000](http://arxiv.org/abs/2511.20000)|null|\n", "2511.20720": "|**2025-11-25**|**DeeAD: Dynamic Early Exit of Vision-Language Action for Efficient Autonomous Driving**|Chun Jason Xue Team|[2511.20720](http://arxiv.org/abs/2511.20720)|null|\n", "2511.19986": "|**2025-11-25**|**On-Demand Multi-Task Sparsity for Efficient Large-Model Deployment on Edge Devices**|Chun Jason Xue Team|[2511.19986](http://arxiv.org/abs/2511.19986)|null|\n", "2511.19952": "|**2025-11-25**|**Hierarchical Spatio-Temporal Attention Network with Adaptive Risk-Aware Decision for Forward Collision Warning in Complex Scenarios**|Changhao Piao Team|[2511.19952](http://arxiv.org/abs/2511.19952)|null|\n", "2511.19914": "|**2025-11-25**|**CoC-VLA: Delving into Adversarial Domain Transfer for Explainable Autonomous Driving via Chain-of-Causality Visual-Language-Action Model**|Qingguo Zhou Team|[2511.19914](http://arxiv.org/abs/2511.19914)|null|\n", "2511.19912": "|**2025-11-25**|**Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model for Autonomous Driving**|Tat-Seng Chua Team|[2511.19912](http://arxiv.org/abs/2511.19912)|null|\n", "2511.19836": "|**2025-11-25**|**4DWorldBench: A Comprehensive Evaluation Framework for 3D/4D World Generation Models**|Zhibo Chen Team|[2511.19836](http://arxiv.org/abs/2511.19836)|null|\n", "2511.19334": "|**2025-11-24**|**Normative active inference: A numerical proof of principle for a computational and economic legal analytic approach to AI governance**|Karl J. Friston Team|[2511.19334](http://arxiv.org/abs/2511.19334)|null|\n", "2511.19235": "|**2025-11-24**|**IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes**|Lennart Svensson Team|[2511.19235](http://arxiv.org/abs/2511.19235)|null|\n", "2511.19221": "|**2025-11-24**|**Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving**|Hang Xu Team|[2511.19221](http://arxiv.org/abs/2511.19221)|null|\n", "2511.19146": "|**2025-11-25**|**VIL2C: Value-of-Information Aware Low-Latency Communication for Multi-Agent Reinforcement Learning**|Jun Zhang Team|[2511.19146](http://arxiv.org/abs/2511.19146)|null|\n", "2511.19119": "|**2025-11-24**|**MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images**|Shijie Li Team|[2511.19119](http://arxiv.org/abs/2511.19119)|null|\n", "2511.19109": "|**2025-11-24**|**HABIT: Human Action Benchmark for Interactive Traffic in CARLA**|Fabian B. Flohr Team|[2511.19109](http://arxiv.org/abs/2511.19109)|null|\n"}}